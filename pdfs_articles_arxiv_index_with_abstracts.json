[
  {
    "article_id": "2002.09565v4_Adversarial_Attacks_on_Machine_Learning_Systems_for_High-Frequency_Trading",
    "title": "2002.09565v4 Adversarial Attacks on Machine Learning Systems for High-Frequency Trading",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2002.09565v4_Adversarial_Attacks_on_Machine_Learning_Systems_for_High-Frequency_Trading.pdf",
    "url": "http://arxiv.org/abs/2002.09565v4_Adversarial_Attacks_on_Machine_Learning_Systems_for_High-Frequency_Trading",
    "pdf_url": "https://arxiv.org/pdf/2002.09565v4_Adversarial_Attacks_on_Machine_Learning_Systems_for_High-Frequency_Trading",
    "file_size_mb": 0.75,
    "abstract": "Algorithmic trading systems are often completely automated, and deep learning is increasingly receiving attention in this domain. Nonetheless, little is known about the robustness properties of these models. We study valuation models for algorithmic trading from the perspective of adversarial machine learning. We introduce new attacks specific to this domain with size constraints that minimize attack costs. We further discuss how these attacks can be used as an analysis tool to study and evaluate the robustness properties of financial models. Finally, we investigate the feasibility of realistic adversarial attacks in which an adversarial trader fools automated trading systems into making inaccurate predictions. CCS CONCEPTS • Computing methodologies →Machine learning algorithms.",
    "keywords": [
      "Machine learning",
      "adversarial attack",
      "finance",
      "trading",
      "HFT"
    ]
  },
  {
    "article_id": "2006.05574v2_Multi-Agent_Reinforcement_Learning_in_a_Realistic_Limit_Order_Book_Market_Simulation",
    "title": "2006.05574v2 Multi-Agent Reinforcement Learning in a Realistic Limit Order Book Market Simulation",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2006.05574v2_Multi-Agent_Reinforcement_Learning_in_a_Realistic_Limit_Order_Book_Market_Simulation.pdf",
    "url": "http://arxiv.org/abs/2006.05574v2_Multi-Agent_Reinforcement_Learning_in_a_Realistic_Limit_Order_Book_Market_Simulation",
    "pdf_url": "https://arxiv.org/pdf/2006.05574v2_Multi-Agent_Reinforcement_Learning_in_a_Realistic_Limit_Order_Book_Market_Simulation",
    "file_size_mb": 0.96,
    "abstract": "Optimal order execution is widely studied by industry practitioners and academic researchers because it determines the profitability of investment decisions and high-level trading strategies, particu- larly those involving large volumes of orders. However, complex and unknown market dynamics pose significant challenges for the development and validation of optimal execution strategies. In this paper, we propose a model-free approach by training Reinforcement Learning (RL) agents in a realistic market simulation environment with multiple agents. First, we configure a multi-agent historical order book simulation environment for execution tasks built on an Agent-Based Interactive Discrete Event Simulation (ABIDES) [6]. Second, we formulate the problem of optimal execution in an RL setting where an intelligent agent can make order execution and placement decisions based on market microstructure trading signals in High Frequency Trading (HFT). Third, we develop and train an RL execution agent using the Double Deep Q-Learning (DDQL) algorithm in the ABIDES environment. In some scenarios, our RL agent converges towards a Time-Weighted Average Price (TWAP) strategy. Finally, we evaluate the simulation with our RL agent by comparing it with a market replay simulation using real market Limit Order Book (LOB) data.",
    "keywords": [
      "high-frequency trading",
      "limit order book",
      "market simulation",
      "multi-"
    ]
  },
  {
    "article_id": "2106.12950v2_Learning_Multiple_Stock_Trading_Patterns_with_Temporal_Routing_Adaptor_and_Optimal_Transport",
    "title": "2106.12950v2 Learning Multiple Stock Trading Patterns with Temporal Routing Adaptor and Optimal Transport",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2106.12950v2_Learning_Multiple_Stock_Trading_Patterns_with_Temporal_Routing_Adaptor_and_Optimal_Transport.pdf",
    "url": "http://arxiv.org/abs/2106.12950v2_Learning_Multiple_Stock_Trading_Patterns_with_Temporal_Routing_Adaptor_and_Optimal_Transport",
    "pdf_url": "https://arxiv.org/pdf/2106.12950v2_Learning_Multiple_Stock_Trading_Patterns_with_Temporal_Routing_Adaptor_and_Optimal_Transport",
    "file_size_mb": 3.18,
    "abstract": "Successful quantitative investment usually relies on precise pre- dictions of the future movement of the stock price. Recently, ma- chine learning based solutions have shown their capacity to give more accurate stock prediction and become indispensable compo- nents in modern quantitative investment systems. However, the i.i.d. assumption behind existing methods is inconsistent with the existence of diverse trading patterns1 in the stock market, which inevitably limits their ability to achieve better stock prediction performance. In this paper, we propose a novel architecture, Tem- poral Routing Adaptor (TRA), to empower existing stock prediction models with the ability to model multiple stock trading patterns. Essentially, TRA is a lightweight module that consists of a set of independent predictors for learning multiple patterns as well as a router to dispatch samples to different predictors. Nevertheless, the lack of explicit pattern identifiers makes it quite challenging to train an effective TRA-based model. To tackle this challenge, we further design a learning algorithm based on Optimal Transport (OT) to obtain the optimal sample to predictor assignment and effectively optimize the router with such assignment through an auxiliary loss term. Experiments on the real-world stock ranking task show that compared to the state-of-the-art baselines, e.g., Attention LSTM and Transformer, the proposed method can improve information coefficient (IC) from 0.053 to 0.059 and 0.051 to 0.056 respectively. Our dataset and code used in this work are publicly available2. ∗The first two authors have equal contribution. †This work was done when the first author was an intern at Microsoft Research Asia. 1In this paper, a trading pattern means the causal relation between the available information at the current time (i.e., feature) and the stock price movement in the future (i.e., label). 2https://github.com/microsoft/qlib/tree/main/examples/benchmarks/TRA Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. KDD ’21, August 14–18, 2021, Virtual Event, Singapore. © 2021 Association for Computing Machinery. ACM ISBN 978-1-4503-8332-5/21/08...$15.00 https://doi.org/10.1145/3447548.3467358 CCS CONCEPTS • Computing methodologies →Machine learning; • Applied computing →Forecasting.",
    "keywords": [
      "computational finance",
      "stock prediction",
      "gated network",
      "conditional"
    ]
  },
  {
    "article_id": "2107.00261v1_Price_change_prediction_of_ultra_high_frequency_financial_data_based_on_temporal_convolutional_netwo",
    "title": "2107.00261v1 Price change prediction of ultra high frequency financial data based on temporal convolutional netwo",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2107.00261v1_Price_change_prediction_of_ultra_high_frequency_financial_data_based_on_temporal_convolutional_netwo.pdf",
    "url": "http://arxiv.org/abs/2107.00261v1_Price_change_prediction_of_ultra_high_frequency_financial_data_based_on_temporal_convolutional_netwo",
    "pdf_url": "https://arxiv.org/pdf/2107.00261v1_Price_change_prediction_of_ultra_high_frequency_financial_data_based_on_temporal_convolutional_netwo",
    "file_size_mb": 0.29,
    "abstract": "Through in-depth analysis of ultra high frequency (UHF) stock price change data, more reasonable discrete dynamic distribution models are constructed in this paper. Firstly, we classify the price changes into several categories. Then, temporal convolutional network (TCN) is utilized to predict the conditional probability for each category. Furthermore, attention mechanism is added into the TCN architecture to model the time-varying distribution for stock price change data. Empirical research on constituent stocks of Chinese Shenzhen Stock Exchange 100 Index (SZSE 100) found that the TCN framework model and the TCN (attention) framework have a better overall performance than GARCH family models and the long short- term memory (LSTM) framework model for the description of the dynamic process of the UHF stock price change sequence. In addition, the scale of the dataset reached nearly 10 million, to the best of our knowledge, there has been no previous attempt to apply TCN to such a large-scale UHF transaction price dataset in Chinese stock market. © 2021 The Authors. Published by Elsevier B.V. Selection and/or peer-review under responsibility of the organizers of ITQM 2020&2021",
    "keywords": [
      "Temporal convolutional network",
      "Ultra high frequency",
      "Financial prediction"
    ]
  },
  {
    "article_id": "2107.09055v1_Stock_price_prediction_using_BERT_and_GAN",
    "title": "2107.09055v1 Stock price prediction using BERT and GAN",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2107.09055v1_Stock_price_prediction_using_BERT_and_GAN.pdf",
    "url": "http://arxiv.org/abs/2107.09055v1_Stock_price_prediction_using_BERT_and_GAN",
    "pdf_url": "https://arxiv.org/pdf/2107.09055v1_Stock_price_prediction_using_BERT_and_GAN",
    "file_size_mb": 1.53,
    "abstract": "The stock market has been a popular topic of interest in the recent past. The growth in the inflation rate has compelled people to in- vest in the stock and commodity markets and other areas rather than saving. Further, the ability of Deep Learning models to make predictions on the time series data has been proven time and again. Technical analysis on the stock market with the help of technical indicators has been the most common practice among traders and investors. One more aspect is the sentiment analysis - the emotion of the investors that shows the willingness to invest. A variety of techniques have been used by people around the globe involving basic Machine Learning and Neural Networks. Ranging from the basic linear regression to the advanced neural networks people have experimented with all possible techniques to predict the stock market. It’s evident from recent events how news and headlines affect the stock markets and cryptocurrencies. This paper proposes an ensemble of state-of-the-art methods for predicting stock prices. Firstly sentiment analysis of the news and the headlines for the company Apple Inc, listed on the NASDAQ is performed using a ver- sion of BERT, which is a pre-trained transformer model by Google for Natural Language Processing (NLP). Afterward, a Generative Adversarial Network (GAN) predicts the stock price for Apple Inc using the technical indicators, stock indexes of various countries, some commodities, and historical prices along with the sentiment scores. Comparison is done with baseline models like - Long Short Term Memory (LSTM), Gated Recurrent Units (GRU), vanilla GAN, and Auto-Regressive Integrated Moving Average (ARIMA) model.",
    "keywords": [
      "Stock-market",
      "Deep-Learning",
      "Artificial-Intelligence",
      "Sentiment-"
    ]
  },
  {
    "article_id": "2108.10065v1_Previsão_dos_preços_de_abertura_mínima_e_máxima_de_índices_de_mercados_financeiros_usando_a_associaç",
    "title": "2108.10065v1 Previsão dos preços de abertura mínima e máxima de índices de mercados financeiros usando a associaç",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2108.10065v1_Previsão_dos_preços_de_abertura_mínima_e_máxima_de_índices_de_mercados_financeiros_usando_a_associaç.pdf",
    "url": "http://arxiv.org/abs/2108.10065v1_Previsão_dos_preços_de_abertura_mínima_e_máxima_de_índices_de_mercados_financeiros_usando_a_associaç",
    "pdf_url": "https://arxiv.org/pdf/2108.10065v1_Previsão_dos_preços_de_abertura_mínima_e_máxima_de_índices_de_mercados_financeiros_usando_a_associaç",
    "file_size_mb": 0.57,
    "abstract": null,
    "keywords": []
  },
  {
    "article_id": "2109.15059v1_Stock_Price_Prediction_Under_Anomalous_Circumstances",
    "title": "2109.15059v1 Stock Price Prediction Under Anomalous Circumstances",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2109.15059v1_Stock_Price_Prediction_Under_Anomalous_Circumstances.pdf",
    "url": "http://arxiv.org/abs/2109.15059v1_Stock_Price_Prediction_Under_Anomalous_Circumstances",
    "pdf_url": "https://arxiv.org/pdf/2109.15059v1_Stock_Price_Prediction_Under_Anomalous_Circumstances",
    "file_size_mb": 0.65,
    "abstract": "—The stock market is volatile and complicated, especially in 2020. Because of a series of global and regional “black swans”, such as the COVID-19 pandemic, the U.S. stock market triggered the circuit breaker three times within one week of March 9 to 16, which is unprecedented throughout the history. Affected by the whole circumstance, the stock prices of individual corporations also plummeted by rates that were never predicted by any pre-developed forecasting models. It reveals that there was a lack of satisfactory models that could predict the changes of stocks prices when catastrophic, highly unlikely events occur. To fill the void of such models and to help prevent investors from heavy losses during uncertain times, this paper aims to capture the movement pattern of stock prices under anomalous circumstances. First, we detect outliers in sequential stock prices by fitting a standard ARIMA model and identifying the points where predictions deviate significantly from actual values. With the selected data points, we train ARIMA and LSTM models at the single-stock level, industry level, and the general market level, respectively. Since the public moods affect the stock market tremendously, a sentiment analysis is also incorporated into the models in the form of sentiment scores, which are converted from comments about specific stocks on Reddit. Based on 100 companies’ stock prices in the period of 2016 to 2020, the models achieve an average prediction accuracy of 98% which can be used to optimize existing prediction methodologies.",
    "keywords": [
      "Stock Price Prediction",
      "Outlier Detection"
    ]
  },
  {
    "article_id": "2111.04709v1_Stock_Portfolio_Optimization_Using_a_Deep_Learning_LSTM_Model",
    "title": "2111.04709v1 Stock Portfolio Optimization Using a Deep Learning LSTM Model",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2111.04709v1_Stock_Portfolio_Optimization_Using_a_Deep_Learning_LSTM_Model.pdf",
    "url": "http://arxiv.org/abs/2111.04709v1_Stock_Portfolio_Optimization_Using_a_Deep_Learning_LSTM_Model",
    "pdf_url": "https://arxiv.org/pdf/2111.04709v1_Stock_Portfolio_Optimization_Using_a_Deep_Learning_LSTM_Model",
    "file_size_mb": 0.93,
    "abstract": "—Predicting future stock prices and their movement patterns is a complex problem. Hence, building a portfolio of capital assets using the predicted prices to achieve the optimization between its return and risk is an even more difficult task. This work has carried out an analysis of the time series of the historical prices of the top five stocks from the nine different sectors of the Indian stock market from January 1, 2016, to December 31, 2020. Optimum portfolios are built for each of these sectors. For predicting future stock prices, a long-and-short-term memory (LSTM) model is also designed and fine-tuned. After five months of the portfolio construction, the actual and the predicted returns and risks of each portfolio are computed. The predicted and the actual returns of each portfolio are found to be high, indicating the high precision of the LSTM model.",
    "keywords": [
      "Portfolio"
    ]
  },
  {
    "article_id": "2111.04976v1_Analysis_of_Sectoral_Profitability_of_the_Indian_Stock_Market_Using_an_LSTM_Regression_Model",
    "title": "2111.04976v1 Analysis of Sectoral Profitability of the Indian Stock Market Using an LSTM Regression Model",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2111.04976v1_Analysis_of_Sectoral_Profitability_of_the_Indian_Stock_Market_Using_an_LSTM_Regression_Model.pdf",
    "url": "http://arxiv.org/abs/2111.04976v1_Analysis_of_Sectoral_Profitability_of_the_Indian_Stock_Market_Using_an_LSTM_Regression_Model",
    "pdf_url": "https://arxiv.org/pdf/2111.04976v1_Analysis_of_Sectoral_Profitability_of_the_Indian_Stock_Market_Using_an_LSTM_Regression_Model",
    "file_size_mb": 0.98,
    "abstract": "— Predictive model design for accurately predicting future stock prices has always been considered an interesting and challenging research problem. The task becomes complex due to the volatile and stochastic nature of the stock prices in the real world which is affected by numerous controllable and uncontrollable variables. This paper presents an optimized predictive model built on long- and-short-term memory (LSTM) architecture for automatically extracting past stock prices from the web over a specified time interval and predicting their future prices for a specified forecast horizon, and forecasts the future stock prices. The model is deployed for making buy and sell transactions based on its predicted results for 70 important stocks from seven different sectors listed in the National Stock Exchange (NSE) of India. The profitability of each sector is derived based on the total profit yielded by the stocks in that sector over a period from Jan 1, 2010 to Aug 26, 2021. The sectors are compared based on their profitability values. The prediction accuracy of the model is also evaluated for each sector. The results indicate that the model is highly accurate in predicting future stock prices.",
    "keywords": [
      "Stock Price Prediction",
      "Long and Short-Term"
    ]
  },
  {
    "article_id": "2111.15354v1_An_Improved_Reinforcement_Learning_Model_Based_on_Sentiment_Analysis",
    "title": "2111.15354v1 An Improved Reinforcement Learning Model Based on Sentiment Analysis",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2111.15354v1_An_Improved_Reinforcement_Learning_Model_Based_on_Sentiment_Analysis.pdf",
    "url": "http://arxiv.org/abs/2111.15354v1_An_Improved_Reinforcement_Learning_Model_Based_on_Sentiment_Analysis",
    "pdf_url": "https://arxiv.org/pdf/2111.15354v1_An_Improved_Reinforcement_Learning_Model_Based_on_Sentiment_Analysis",
    "file_size_mb": 0.85,
    "abstract": "With the development of artificial intelligence technology, quantitative trading systems represented by reinforcement learning have emerged in the stock trading market. The authors combined the deep Q network in reinforcement learning with the sentiment quantitative indicator ARBR to build a high-frequency stock trading model for the share market. To improve the performance of the model, the PCA algorithm is used to reduce the dimensionality feature vector while incorporating the influence of market sentiment on the long-short power into the spatial state of the trading model and uses the LSTM layer to replace the fully connected layer to solve the traditional DQN model due to limited empirical data storage. Through the use of cumulative income, Sharpe ratio to evaluate the performance of the model and the use of double moving averages and other strategies for comparison. The results show that the improved model proposed by authors is far superior to the comparison model in terms of income, achieving a maximum annualized rate of return of 54.5%, which is proven to be able to increase reinforcement learning performance significantly in stock trading.",
    "keywords": [
      "Reinforcement learning",
      "Deep recurrent network"
    ]
  },
  {
    "article_id": "2111.15356v1_Improved_Method_of_Stock_Trading_under_Reinforcement_Learning_Based_on_DRQN_and_Sentiment_Indicators",
    "title": "2111.15356v1 Improved Method of Stock Trading under Reinforcement Learning Based on DRQN and Sentiment Indicators",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2111.15356v1_Improved_Method_of_Stock_Trading_under_Reinforcement_Learning_Based_on_DRQN_and_Sentiment_Indicators.pdf",
    "url": "http://arxiv.org/abs/2111.15356v1_Improved_Method_of_Stock_Trading_under_Reinforcement_Learning_Based_on_DRQN_and_Sentiment_Indicators",
    "pdf_url": "https://arxiv.org/pdf/2111.15356v1_Improved_Method_of_Stock_Trading_under_Reinforcement_Learning_Based_on_DRQN_and_Sentiment_Indicators",
    "file_size_mb": 0.43,
    "abstract": "—With the application of artificial intelligence in the financial field, quantitative trading is considered to be profitable. Based on this, this paper proposes an improved deep recurrent DRQN-ARBR model because the existing quantitative trading model ignores the impact of irrational investor behavior on the market, making the application effect poor in an environment where the stock market in China is non-efficiency. By changing the fully connected layer in the original model to the LSTM layer and using the emotion indicator ARBR to construct a trading strategy, this model solves the problems of the traditional DQN model with limited memory for empirical data storage and the impact of observable Markov properties on performance. At the same time, this paper also improved the shortcomings of the original model with fewer stock states and chose more technical indicators as the input values of the model. The experimental results show that the DRQN-ARBR algorithm proposed in this paper can significantly improve the performance of reinforcement learning in stock trading.",
    "keywords": [
      "reinforcement learning",
      "deep recurrent network",
      "Q learning",
      "deep recurrent Q"
    ]
  },
  {
    "article_id": "2112.03946v1_Generative_Adversarial_Network_GAN_and_Enhanced_Root_Mean_Square_Error_ERMSE_Deep_Learning_for_Stock",
    "title": "2112.03946v1 Generative Adversarial Network GAN and Enhanced Root Mean Square Error ERMSE Deep Learning for Stock",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2112.03946v1_Generative_Adversarial_Network_GAN_and_Enhanced_Root_Mean_Square_Error_ERMSE_Deep_Learning_for_Stock.pdf",
    "url": "http://arxiv.org/abs/2112.03946v1_Generative_Adversarial_Network_GAN_and_Enhanced_Root_Mean_Square_Error_ERMSE_Deep_Learning_for_Stock",
    "pdf_url": "https://arxiv.org/pdf/2112.03946v1_Generative_Adversarial_Network_GAN_and_Enhanced_Root_Mean_Square_Error_ERMSE_Deep_Learning_for_Stock",
    "file_size_mb": 0.64,
    "abstract": "The prediction of stock price movement direction is significant in financial circles and academic. Stock price contains complex, incomplete, and fuzzy information which makes it an extremely difficult task to predict its development trend. Predicting and analysing financial data is a nonlinear, time-dependent problem. With rapid development in machine learning and deep learning, this task can be performed more effectively by a purposely designed network. This paper aims to improve prediction accuracy and minimizing forecasting error loss through deep learning architecture by using Generative Adversarial Networks. It was proposed a generic model consisting of Phase-space Reconstruction (PSR) method for reconstructing price series and Generative Adversarial Network (GAN) which is a combination of two neural networks which are Long Short-Term Memory (LSTM) as Generative model and Convolutional Neural Network (CNN) as Discriminative model for adversarial training to forecast the stock market. LSTM will generate new instances based on historical basic indicators information and then CNN will estimate whether the data is predicted by LSTM or is real. It was found that the Generative Adversarial Network (GAN) has performed well on the enhanced root mean square error to LSTM, as it was 4.35% more accurate in predicting the direction and reduced processing time and RMSE by 78 secs and 0.029, respectively. This study provides a better result in the accuracy of the stock index. It seems that the proposed system concentrates on minimizing the root mean square error and processing time and improving the direction prediction accuracy, and provides a better result in the accuracy of the stock index.",
    "keywords": [
      "Stock market prediction",
      "Phase-space reconstruction",
      "Generative adversarial networks",
      "Deep learning"
    ]
  },
  {
    "article_id": "2201.00350v5_The_Interpretability_of_LSTM_Models_for_Predicting_Oil_Company_Stocks_Impact_of_Correlated_Features",
    "title": "2201.00350v5 The Interpretability of LSTM Models for Predicting Oil Company Stocks Impact of Correlated Features",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2201.00350v5_The_Interpretability_of_LSTM_Models_for_Predicting_Oil_Company_Stocks_Impact_of_Correlated_Features.pdf",
    "url": "http://arxiv.org/abs/2201.00350v5_The_Interpretability_of_LSTM_Models_for_Predicting_Oil_Company_Stocks_Impact_of_Correlated_Features",
    "pdf_url": "https://arxiv.org/pdf/2201.00350v5_The_Interpretability_of_LSTM_Models_for_Predicting_Oil_Company_Stocks_Impact_of_Correlated_Features",
    "file_size_mb": 1.84,
    "abstract": null,
    "keywords": []
  },
  {
    "article_id": "2201.08218v1_Long_Short-Term_Memory_Neural_Network_for_Financial_Time_Series",
    "title": "2201.08218v1 Long Short-Term Memory Neural Network for Financial Time Series",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2201.08218v1_Long_Short-Term_Memory_Neural_Network_for_Financial_Time_Series.pdf",
    "url": "http://arxiv.org/abs/2201.08218v1_Long_Short-Term_Memory_Neural_Network_for_Financial_Time_Series",
    "pdf_url": "https://arxiv.org/pdf/2201.08218v1_Long_Short-Term_Memory_Neural_Network_for_Financial_Time_Series",
    "file_size_mb": 0.92,
    "abstract": "Performance forecasting is an age-old problem in economics and ﬁnance. Recently, devel- opments in machine learning and neural networks have given rise to non-linear time series models that provide modern and promising alternatives to traditional methods of analysis. In this paper, we present an ensemble of independent and parallel long short-term memory (LSTM) neural networks for the prediction of stock price movement. LSTMs have been shown to be especially suited for time series data due to their ability to incorporate past information, while neural network ensembles have been found to reduce variability in results and improve generalization. A binary classiﬁcation problem based on the median of returns is used, and the ensemble’s forecast depends on a threshold value, which is the minimum number of LSTMs required to agree upon the result. The model is applied to the constituents of the smaller, less eﬃcient Stockholm OMX30 instead of other major market indices such as the DJIA and S&P500 commonly found in literature. With a straightforward trading strategy, comparisons with a randomly chosen portfolio and a portfolio containing all the stocks in the index show that the portfolio resulting from the LSTM ensemble provides better average daily returns and higher cumulative returns over time. Moreover, the LSTM portfolio also exhibits less volatility, leading to higher risk-return ratios.",
    "keywords": []
  },
  {
    "article_id": "2203.08143v1_HiSA-SMFM_Historical_and_Sentiment_Analysis_based_Stock_Market_Forecasting_Model",
    "title": "2203.08143v1 HiSA-SMFM Historical and Sentiment Analysis based Stock Market Forecasting Model",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2203.08143v1_HiSA-SMFM_Historical_and_Sentiment_Analysis_based_Stock_Market_Forecasting_Model.pdf",
    "url": "http://arxiv.org/abs/2203.08143v1_HiSA-SMFM_Historical_and_Sentiment_Analysis_based_Stock_Market_Forecasting_Model",
    "pdf_url": "https://arxiv.org/pdf/2203.08143v1_HiSA-SMFM_Historical_and_Sentiment_Analysis_based_Stock_Market_Forecasting_Model",
    "file_size_mb": 0.55,
    "abstract": "One of the pillars to build a country’s economy is the stock market. Over the years, people are investing in stock markets to earn as much proﬁt as possible from the amount of money that they possess. Hence, it is vital to have a prediction model which can accurately predict future stock prices. With the help of machine learning, it is not an impossible task as the various machine learning techniques if modeled properly may be able to provide the best prediction values. This would enable the investors to decide whether to buy, sell or hold the share. The aim of this paper is to predict the future of the ﬁnancial stocks of a company with improved accuracy. In this paper, we have proposed the use of historical as well as sentiment data to efﬁciently predict stock prices by applying LSTM. It has been found by analyzing the existing research in the area of sentiment analysis that there is a strong correlation between the movement of stock prices and the publication of news articles. Therefore, in this paper, we have integrated these factors to predict the stock prices more accurately.",
    "keywords": [
      "Stock market prediction",
      "Machine learning",
      "Long Short Term Memory(LSTM)",
      "Sentiment analysis"
    ]
  },
  {
    "article_id": "2204.02623v2_Attention-based_CNN-LSTM_and_XGBoost_hybrid_model_for_stock_prediction",
    "title": "2204.02623v2 Attention-based CNN-LSTM and XGBoost hybrid model for stock prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2204.02623v2_Attention-based_CNN-LSTM_and_XGBoost_hybrid_model_for_stock_prediction.pdf",
    "url": "http://arxiv.org/abs/2204.02623v2_Attention-based_CNN-LSTM_and_XGBoost_hybrid_model_for_stock_prediction",
    "pdf_url": "https://arxiv.org/pdf/2204.02623v2_Attention-based_CNN-LSTM_and_XGBoost_hybrid_model_for_stock_prediction",
    "file_size_mb": 0.59,
    "abstract": "—Stock market plays an important role in the eco- nomic development. Due to the complex volatility of the stock market, the research and prediction on the change of the stock price, can avoid the risk for the investors. The traditional time series model ARIMA can not describe the nonlinearity, and can not achieve satisfactory results in the stock prediction. As neural networks are with strong nonlinear generalization ability, this paper proposes an attention-based CNN-LSTM and XGBoost hybrid model to predict the stock price. The model constructed in this paper integrates the time series model, the Convolutional Neural Networks with Attention mechanism, the Long Short-Term Memory network, and XGBoost regressor in a non-linear relationship, and improves the prediction accuracy. The model can fully mine the historical information of the stock market in multiple periods. The stock data is ﬁrst pre- processed through ARIMA. Then, the deep learning architecture formed in pretraining-ﬁnetuning framework is adopted. The pre-training model is the Attention-based CNN-LSTM model based on sequence-to-sequence framework. The model ﬁrst uses convolution to extract the deep features of the original stock data, and then uses the Long Short-Term Memory networks to mine the long-term time series features. Finally, the XGBoost model is adopted for ﬁne-tuning. The results show that the hybrid model is more effective and the prediction accuracy is relatively high, which can help investors or institutions to make decisions and achieve the purpose of expanding return and avoiding risk. Source code is available at https://github.com/ zshicode/Attention-CLX-stock-prediction.",
    "keywords": [
      "Attention mechanism",
      "Convolutional Neural"
    ]
  },
  {
    "article_id": "2204.05783v1_Stock_Price_Prediction_using_Sentiment_Analysis_and_Deep_Learning_for_Indian_Markets",
    "title": "2204.05783v1 Stock Price Prediction using Sentiment Analysis and Deep Learning for Indian Markets",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2204.05783v1_Stock_Price_Prediction_using_Sentiment_Analysis_and_Deep_Learning_for_Indian_Markets.pdf",
    "url": "http://arxiv.org/abs/2204.05783v1_Stock_Price_Prediction_using_Sentiment_Analysis_and_Deep_Learning_for_Indian_Markets",
    "pdf_url": "https://arxiv.org/pdf/2204.05783v1_Stock_Price_Prediction_using_Sentiment_Analysis_and_Deep_Learning_for_Indian_Markets",
    "file_size_mb": 0.7,
    "abstract": ". Stock market prediction has been an active area of research for a con- siderable period. Arrival of computing, followed by Machine Learning has up- graded the speed of research as well as opened new avenues. As part of this re- search study, we aimed to predict the future stock movement of shares using the historical prices aided with availability of sentiment data. Two models were used as part of the exercise, LSTM was the first model with historical prices as the independent variable. Sentiment Analysis captured using Intensity Analyzer was used as the major parameter for Random Forest Model used for the second part, some macro parameters like Gold, Oil prices, USD exchange rate and Indian Govt. Securities yields were also added to the model for improved accuracy of the model. As the end product, prices of 4 stocks viz. Reliance, HDFC Bank, TCS and SBI were predicted using the aforementioned two models. The results were evaluated using RMSE metric.",
    "keywords": [
      "Sentiment analysis",
      "Stock Prediction",
      "LSTM",
      "Random Forest"
    ]
  },
  {
    "article_id": "2205.04678v1_Real-time_Forecasting_of_Time_Series_in_Financial_Markets_Using_Sequentially_Trained_Many-to-one_LST",
    "title": "2205.04678v1 Real-time Forecasting of Time Series in Financial Markets Using Sequentially Trained Many-to-one LST",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2205.04678v1_Real-time_Forecasting_of_Time_Series_in_Financial_Markets_Using_Sequentially_Trained_Many-to-one_LST.pdf",
    "url": "http://arxiv.org/abs/2205.04678v1_Real-time_Forecasting_of_Time_Series_in_Financial_Markets_Using_Sequentially_Trained_Many-to-one_LST",
    "pdf_url": "https://arxiv.org/pdf/2205.04678v1_Real-time_Forecasting_of_Time_Series_in_Financial_Markets_Using_Sequentially_Trained_Many-to-one_LST",
    "file_size_mb": 0.86,
    "abstract": "Financial markets are highly complex and volatile; thus, learning about such markets for the sake of making predictions is vital to make early alerts about crashes and subsequent recoveries. People have been using learning tools from diverse ﬁelds such as ﬁnancial mathematics and machine learning in the attempt of making trustworthy predictions on such markets. However, the accuracy of such techniques had not been adequate until artiﬁcial neural network (ANN) frameworks were developed. Moreover, making accurate real- time predictions of ﬁnancial time series is highly subjective to the ANN architecture in use and the procedure of training it. Long short-term memory (LSTM) is a member of the recurrent neural network family which has been widely utilized for time series predictions. Especially, we train two LSTMs with a known length, say T time steps, of previous data and predict only one time step ahead. At each iteration, while one LSTM is employed to ﬁnd the best number of epochs, the second LSTM is trained only for the best number of epochs to make predictions. We treat the current prediction as in the training set for the next prediction and train the same LSTM. While classic ways of training result in more error when the predictions are made further away in the test period, our approach is capable of maintaining a superior accuracy as training increases when it proceeds through the testing period. The forecasting accuracy of our approach is validated using three time series from each of the three diverse ﬁnancial markets: stock, cryptocurrency, and commodity. The results are compared with those of an extended Kalman ﬁlter, an autoregressive model, and an autoregressive integrated moving average model.",
    "keywords": [
      "Many-to-one LSTM",
      "sequential training",
      "real-time forecasting",
      "time series",
      "ﬁnancial markets"
    ]
  },
  {
    "article_id": "2205.06673v1_Univariate_and_Multivariate_LSTM_Model_for_Short-Term_Stock_Market_Prediction",
    "title": "2205.06673v1 Univariate and Multivariate LSTM Model for Short-Term Stock Market Prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2205.06673v1_Univariate_and_Multivariate_LSTM_Model_for_Short-Term_Stock_Market_Prediction.pdf",
    "url": "http://arxiv.org/abs/2205.06673v1_Univariate_and_Multivariate_LSTM_Model_for_Short-Term_Stock_Market_Prediction",
    "pdf_url": "https://arxiv.org/pdf/2205.06673v1_Univariate_and_Multivariate_LSTM_Model_for_Short-Term_Stock_Market_Prediction",
    "file_size_mb": 0.83,
    "abstract": "- Designing robust and accurate prediction models has been a viable research area since a long time. While proponents of a well-functioning market predictors believe that it is difficult to accurately predict market prices but many scholars disagree. Robust and accurate prediction systems will not only be helpful to the businesses but also to the individuals in making their financial investments. This paper presents an LSTM model with two different input approaches for predicting the short-term stock prices of two Indian companies, Reliance Industries and Infosys Ltd. Ten years of historic data (2012-2021) is taken from the yahoo finance website to carry out analysis of proposed approaches. In the first approach, closing prices of two selected companies are directly applied on univariate LSTM model. For the approach second, technical indicators values are calculated from the closing prices and then collectively applied on Multivariate LSTM model. Short term market behaviour for upcoming days is evaluated. Experimental outcomes revel that approach one is useful to determine the future trend but multivariate LSTM model with technical indicators found to be useful in accurately predicting the future price behaviours.",
    "keywords": [
      "Short Term Stock Prediction",
      "Deep learning",
      "stacked LSTM",
      "Time frame",
      "Technical indicators"
    ]
  },
  {
    "article_id": "2206.14114v1_On_the_universality_of_the_volatility_formation_process_when_machine_learning_and_rough_volatility_a",
    "title": "2206.14114v1 On the universality of the volatility formation process when machine learning and rough volatility a",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2206.14114v1_On_the_universality_of_the_volatility_formation_process_when_machine_learning_and_rough_volatility_a.pdf",
    "url": "http://arxiv.org/abs/2206.14114v1_On_the_universality_of_the_volatility_formation_process_when_machine_learning_and_rough_volatility_a",
    "pdf_url": "https://arxiv.org/pdf/2206.14114v1_On_the_universality_of_the_volatility_formation_process_when_machine_learning_and_rough_volatility_a",
    "file_size_mb": 0.75,
    "abstract": "We train an LSTM network based on a pooled dataset made of hundreds of liquid stocks aiming to forecast the next daily realized volatility for all stocks. Showing the consistent outper- formance of this universal LSTM relative to other asset-speciﬁc parametric models, we uncover nonparametric evidences of a universal volatility formation mechanism across assets relating past market realizations, including daily returns and volatilities, to current volatilities. A parsi- monious parametric forecasting device combining the rough fractional stochastic volatility and quadratic rough Heston models with ﬁxed parameters results in the same level of performance as the universal LSTM, which conﬁrms the universality of the volatility formation process from a parametric perspective.",
    "keywords": [
      "Volatility formation",
      "universality",
      "forecast",
      "LSTM",
      "HAR",
      "rough volatility",
      "quadratic rough"
    ]
  },
  {
    "article_id": "2207.06605v2_StockBot_Using_LSTMs_to_Predict_Stock_Prices",
    "title": "2207.06605v2 StockBot Using LSTMs to Predict Stock Prices",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2207.06605v2_StockBot_Using_LSTMs_to_Predict_Stock_Prices.pdf",
    "url": "http://arxiv.org/abs/2207.06605v2_StockBot_Using_LSTMs_to_Predict_Stock_Prices",
    "pdf_url": "https://arxiv.org/pdf/2207.06605v2_StockBot_Using_LSTMs_to_Predict_Stock_Prices",
    "file_size_mb": 4.85,
    "abstract": "The evaluation of the ﬁnancial markets to predict their behaviour have been attempted using a number of approaches, to make smart and proﬁtable investment decisions. Owing to the highly non-linear trends and inter-dependencies, it is often diﬃcult to develop a statistical approach that elucidates the market behaviour entirely. To this end, we present a long-short term memory (LSTM) based model that leverages the sequential structure of the time-series data to provide an accurate market forecast. We then develop a decision making StockBot that buys/sells stocks at the end of the day with the goal of maximizing proﬁts. We successfully demonstrate an accurate prediction model, as a result of which our StockBot can outpace the market and can strategize for gains that are 15 times higher than the most aggressive ETFs in the market.",
    "keywords": [
      "Stock Prediction",
      "StockBot",
      "Long-Short Term Memory",
      "Stock"
    ]
  },
  {
    "article_id": "2210.02126v1_Stock_Volatility_Prediction_using_Time_Series_and_Deep_Learning_Approach",
    "title": "2210.02126v1 Stock Volatility Prediction using Time Series and Deep Learning Approach",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2210.02126v1_Stock_Volatility_Prediction_using_Time_Series_and_Deep_Learning_Approach.pdf",
    "url": "http://arxiv.org/abs/2210.02126v1_Stock_Volatility_Prediction_using_Time_Series_and_Deep_Learning_Approach",
    "pdf_url": "https://arxiv.org/pdf/2210.02126v1_Stock_Volatility_Prediction_using_Time_Series_and_Deep_Learning_Approach",
    "file_size_mb": 0.55,
    "abstract": "—Volatility clustering is a crucial property that has a substantial impact on stock market patterns. Nonetheless, developing robust models for accurately predicting future stock price volatility is a difficult research topic. For predicting the volatility of three equities listed on India's national stock market (NSE), we propose multiple volatility models depending on the generalized autoregressive conditional heteroscedasticity (GARCH), Glosten-Jagannathan-GARCH (GJR-GARCH), Exponential general autoregressive conditional heteroskedastic (EGARCH), and LSTM framework. Sector-wise stocks have been chosen in our study. The sectors which have been considered are banking, information technology (IT), and pharma. yahoo finance has been used to obtain stock price data from Jan 2017 to Dec 2021. Among the pulled-out records, the data from Jan 2017 to Dec 2020 have been taken for training, and data from 2021 have been chosen for testing our models. The performance of predicting the volatility of stocks of three sectors has been evaluated by implementing three different types of GARCH models as well as by the LSTM model are compared. It has been observed the LSTM performed better in predicting volatility in pharma over banking and IT sectors. In tandem, it was also observed that E-GARCH performed better in the case of the banking sector and for IT and pharma, GJR- GARCH performed better.",
    "keywords": [
      "Time Series",
      "GARCH",
      "GJR-GARCH",
      "EGARCH"
    ]
  },
  {
    "article_id": "2211.07392v1_FinBERT-LSTM_Deep_Learning_based_stock_price_prediction_using_News_Sentiment_Analysis",
    "title": "2211.07392v1 FinBERT-LSTM Deep Learning based stock price prediction using News Sentiment Analysis",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2211.07392v1_FinBERT-LSTM_Deep_Learning_based_stock_price_prediction_using_News_Sentiment_Analysis.pdf",
    "url": "http://arxiv.org/abs/2211.07392v1_FinBERT-LSTM_Deep_Learning_based_stock_price_prediction_using_News_Sentiment_Analysis",
    "pdf_url": "https://arxiv.org/pdf/2211.07392v1_FinBERT-LSTM_Deep_Learning_based_stock_price_prediction_using_News_Sentiment_Analysis",
    "file_size_mb": 0.53,
    "abstract": "—Economy is severely dependent on the stock market. An uptrend usually corresponds to prosperity while a downtrend correlates to recession. Predicting the stock market has thus been a centre of research and experiment for a long time. Being able to predict short term movements in the market enables investors to reap greater returns on their investments. Stock prices are extremely volatile and sensitive to ﬁnancial market. In this paper we use Deep Learning networks to predict stock prices, assimilating ﬁnancial, business and technology news articles which present information about the market. First, we create a simple Multilayer Perceptron (MLP) network and then expand into more complex Recurrent Neural Network (RNN) like Long Short Term Memory (LSTM), and ﬁnally propose FinBERT- LSTM model, which integrates news article sentiments to predict stock price with greater accuracy by analysing short-term market information. We then train the model on NASDAQ-100 index stock data and New York Times news articles to evaluate the performance of MLP, LSTM, FinBERT-LSTM models using mean absolute error (MAE), mean absolute percentage error (MAPE) and accuracy metrics.",
    "keywords": [
      "Stock price prediction",
      "RNN",
      "LSTM",
      "BERT"
    ]
  },
  {
    "article_id": "2211.07400v2_Efficient_Integration_of_Multi-Order_Dynamics_and_Internal_Dynamics_in_Stock_Movement_Prediction",
    "title": "2211.07400v2 Efficient Integration of Multi-Order Dynamics and Internal Dynamics in Stock Movement Prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2211.07400v2_Efficient_Integration_of_Multi-Order_Dynamics_and_Internal_Dynamics_in_Stock_Movement_Prediction.pdf",
    "url": "http://arxiv.org/abs/2211.07400v2_Efficient_Integration_of_Multi-Order_Dynamics_and_Internal_Dynamics_in_Stock_Movement_Prediction",
    "pdf_url": "https://arxiv.org/pdf/2211.07400v2_Efficient_Integration_of_Multi-Order_Dynamics_and_Internal_Dynamics_in_Stock_Movement_Prediction",
    "file_size_mb": 3.36,
    "abstract": "Advances in deep neural network (DNN) architectures have en- abled new prediction techniques for stock market data. Unlike other multivariate time-series data, stock markets show two unique characteristics: (i) multi-order dynamics, as stock prices are affected by strong non-pairwise correlations (e.g., within the same industry); and (ii) internal dynamics, as each individual stock shows some par- ticular behaviour. Recent DNN-based methods capture multi-order dynamics using hypergraphs, but rely on the Fourier basis in the convolution, which is both inefficient and ineffective. In addition, they largely ignore internal dynamics by adopting the same model for each stock, which implies a severe information loss. In this paper, we propose a framework for stock movement pre- diction to overcome the above issues. Specifically, the framework includes temporal generative filters that implement a memory- based mechanism onto an LSTM network in an attempt to learn individual patterns per stock. Moreover, we employ hypergraph attentions to capture the non-pairwise correlations. Here, using the wavelet basis instead of the Fourier basis, enables us to sim- plify the message passing and focus on the localized convolu- tion. Experiments with US market data over six years show that our framework outperforms state-of-the-art methods in terms of profit and stability. Our source code and data are available at https://github.com/thanhtrunghuynh93/estimate. CCS CONCEPTS • Computing methodologies →Neural networks;",
    "keywords": [
      "hypergraph embedding",
      "stock market",
      "temporal generative filters"
    ]
  },
  {
    "article_id": "2212.02721v2_A_Novel_Deep_Reinforcement_Learning_Based_Automated_Stock_Trading_System_Using_Cascaded_LSTM_Network",
    "title": "2212.02721v2 A Novel Deep Reinforcement Learning Based Automated Stock Trading System Using Cascaded LSTM Network",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2212.02721v2_A_Novel_Deep_Reinforcement_Learning_Based_Automated_Stock_Trading_System_Using_Cascaded_LSTM_Network.pdf",
    "url": "http://arxiv.org/abs/2212.02721v2_A_Novel_Deep_Reinforcement_Learning_Based_Automated_Stock_Trading_System_Using_Cascaded_LSTM_Network",
    "pdf_url": "https://arxiv.org/pdf/2212.02721v2_A_Novel_Deep_Reinforcement_Learning_Based_Automated_Stock_Trading_System_Using_Cascaded_LSTM_Network",
    "file_size_mb": 1.48,
    "abstract": "More and more stock trading strategies are constructed using deep reinforcement learning (DRL) algorithms, but DRL methods originally widely used in the gaming community are not directly adaptable to financial data with low signal-to-noise ratios and unevenness, and thus suffer from performance shortcomings. In this paper, to capture the hidden information, we propose a DRL based stock trading system using cascaded LSTM (CLSTM-PPO Model), which first uses LSTM to extract the time-series features from daily stock data, and then the features extracted are fed to the agent for training, while the strategy functions in reinforcement learning also use another LSTM for training. Experiments in 30 stocks from the Dow Jones Industrial index (DJI) in the US, 30 stocks from SSE50 on the Shanghai Stock Exchange in China, 30 stocks from SENSEX on the Bombay Stock Exchange in India and 30 stocks from FTSE 100 on London Stock Exchange in the UK show that our model outperforms previous baseline models in terms of cumulative returns by 5% to 52%, maximum earning rate by 8% to 52%, average profitability per trade by 6% to 14% and these advantages are more significant in the Chinese stock market, an emerging market, where cumulative returns have improved by 84.4% and the Sharpe ratio by 37.4% than ensemble strategy. It indicates that our proposed method is a promising way to build a automated stock trading system.",
    "keywords": [
      "Deep Reinforcement Learning",
      "Long Short-Term Memory",
      "Automated stock trading",
      "Proximal policy"
    ]
  },
  {
    "article_id": "2212.05369v1_Time_Series_Analysis_in_American_Stock_Market_Recovering_in_Post_COVID-19_Pandemic_Period",
    "title": "2212.05369v1 Time Series Analysis in American Stock Market Recovering in Post COVID-19 Pandemic Period",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2212.05369v1_Time_Series_Analysis_in_American_Stock_Market_Recovering_in_Post_COVID-19_Pandemic_Period.pdf",
    "url": "http://arxiv.org/abs/2212.05369v1_Time_Series_Analysis_in_American_Stock_Market_Recovering_in_Post_COVID-19_Pandemic_Period",
    "pdf_url": "https://arxiv.org/pdf/2212.05369v1_Time_Series_Analysis_in_American_Stock_Market_Recovering_in_Post_COVID-19_Pandemic_Period",
    "file_size_mb": 0.62,
    "abstract": "Every financial crisis has caused a dual shock to the global economy. The shortage of market liquidity, such as default in debt and bonds, has led to the spread of bankruptcies, such as Lehman Brothers in 2008. Using the data for the ETFs of the S&P 500, Nasdaq 100, and Dow Jones Industrial Average collected from Yahoo Finance, this study implemented Deep Learning, Neuro Network, and Time-series to analyze the trend of the American Stock Market in the post-COVID- 19 period. LSTM model in Neuro Network to predict the future trend, which suggests the US stock market keeps falling for the post-COVID-19 period. This study reveals a reasonable allocation method of Long Short-Term Memory for which there is strong evidence.",
    "keywords": [
      "The U.S. Stock Market",
      "Time Series Analysis",
      "Deep Learning",
      "Neuro Network",
      "Bayesian Inference",
      "Financial"
    ]
  },
  {
    "article_id": "2301.05693v1_Stock_market_forecasting_using_DRAGAN_and_feature_matching",
    "title": "2301.05693v1 Stock market forecasting using DRAGAN and feature matching",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2301.05693v1_Stock_market_forecasting_using_DRAGAN_and_feature_matching.pdf",
    "url": "http://arxiv.org/abs/2301.05693v1_Stock_market_forecasting_using_DRAGAN_and_feature_matching",
    "pdf_url": "https://arxiv.org/pdf/2301.05693v1_Stock_market_forecasting_using_DRAGAN_and_feature_matching",
    "file_size_mb": 0.66,
    "abstract": "Applying machine learning methods to forecast stock prices has been one of the research topics of interest in recent years. Almost few studies have been reported based on generative adversarial networks (GANs) in this area, but their results are promising. GANs are powerful generative models successfully applied in different areas but suffer from inherent challenges such as training instability and mode collapse. Also, a primary concern is capturing correlations in stock prices. Therefore, our challenges fall into two main categories: capturing correlations and inherent problems of GANs. In this paper, we have introduced a novel framework based on DRAGAN1 and feature matching for stock price forecasting, which improves training stability and alleviates mode collapse. We have employed windowing to acquire temporal correlations by the generator. Also, we have exploited conditioning on discriminator inputs to capture temporal correlations and correlations between prices and features. Experimental results on data from several stocks indicate that our proposed method outperformed long short-term memory (LSTM) as a baseline method, also basic GANs and WGAN-GP2 as two different variants of GANs.",
    "keywords": [
      "stock price prediction",
      "time series forecasting",
      "Generative Adversarial Networks"
    ]
  },
  {
    "article_id": "2301.09279v2_StockEmotions_Discover_Investor_Emotions_for_Financial_Sentiment_Analysis_and_Multivariate_Time_Seri",
    "title": "2301.09279v2 StockEmotions Discover Investor Emotions for Financial Sentiment Analysis and Multivariate Time Seri",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2301.09279v2_StockEmotions_Discover_Investor_Emotions_for_Financial_Sentiment_Analysis_and_Multivariate_Time_Seri.pdf",
    "url": "http://arxiv.org/abs/2301.09279v2_StockEmotions_Discover_Investor_Emotions_for_Financial_Sentiment_Analysis_and_Multivariate_Time_Seri",
    "pdf_url": "https://arxiv.org/pdf/2301.09279v2_StockEmotions_Discover_Investor_Emotions_for_Financial_Sentiment_Analysis_and_Multivariate_Time_Seri",
    "file_size_mb": 2.22,
    "abstract": "There has been growing interest in applying NLP techniques in the ﬁnancial domain, however, resources are extremely limited. This paper introduces StockEmotions, a new dataset for detecting emotions in the stock market that consists of 10k English comments collected from StockTwits, a ﬁnan- cial social media platform. Inspired by behavioral ﬁnance, it proposes 12 ﬁne-grained emotion classes that span the roller coaster of investor emotion. Unlike existing ﬁnancial senti- ment datasets, StockEmotions presents granular features such as investor sentiment classes, ﬁne-grained emotions, emo- jis, and time series data. To demonstrate the usability of the dataset, we perform a dataset analysis and conduct exper- imental downstream tasks. For ﬁnancial sentiment/emotion classiﬁcation tasks, DistilBERT outperforms other baselines, and for multivariate time series forecasting, a Temporal At- tention LSTM model combining price index, text, and emo- tion features achieves the best performance than using a sin- gle feature.",
    "keywords": []
  },
  {
    "article_id": "2303.02223v3_Feature_Selection_with_Annealing_for_Forecasting_Financial_Time_Series",
    "title": "2303.02223v3 Feature Selection with Annealing for Forecasting Financial Time Series",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2303.02223v3_Feature_Selection_with_Annealing_for_Forecasting_Financial_Time_Series.pdf",
    "url": "http://arxiv.org/abs/2303.02223v3_Feature_Selection_with_Annealing_for_Forecasting_Financial_Time_Series",
    "pdf_url": "https://arxiv.org/pdf/2303.02223v3_Feature_Selection_with_Annealing_for_Forecasting_Financial_Time_Series",
    "file_size_mb": 0.54,
    "abstract": "Stock market and cryptocurrency forecasting is very important to investors as they aspire to achieve even the slightest improvement to their buy-or-hold strategies so that they may increase profitability. However, obtaining accurate and reliable predictions is challenging, noting that accuracy does not equate to reliability, especially when financial time-series forecasting is applied owing to its complex and chaotic tendencies. To mitigate this complexity, this study provides a comprehensive method for forecasting financial time series based on tactical input–output feature mapping techniques using machine learning (ML) models. During the prediction process, selecting the relevant indicators is vital to obtaining the desired results. In the financial field, limited attention has been paid to this problem with ML solutions. We investigate the use of feature selection with annealing (FSA) for the first time in this field, and we apply the least absolute shrinkage and selection operator (Lasso) method to select the features from more than 1,000 candidates obtained from 26 technical classifiers with different periods and lags. Boruta (BOR) feature selection, a wrapper method, is used as a baseline for comparison. Logistic regression (LR), extreme gradient boosting (XGBoost), and long short-term memory (LSTM) are then applied to the selected features for forecasting purposes using 10 different financial datasets containing cryptocurrencies and stocks. The dependent variables consisted of daily logarithmic returns and trends. The mean-squared error for regression, area under the receiver operating characteristic curve, and classification accuracy were used to evaluate model performance, and the statistical significance of the forecasting results was tested using paired t-tests. Experiments indicate that the FSA algorithm increased the performance of ML models, regardless of problem type. The FSA hybrid models showed better performance and outperformed the other BOR models on seven of the 10 datasets for regression and classification. FSA-based models also outperformed Lasso-based models on six of the 10 datasets for regression and four of the 10 datasets for classification. None of the hybrid BOR models outperformed the hybrid FSA models. Lasso-based models, excluding the LR type, were comparable to the best models for six of the 10 datasets for classification. Detailed experimental analysis indicates that the proposed methodology can forecast returns and their movements efficiently and accurately, providing the field with a useful tool for investors.",
    "keywords": [
      "Financial time-series forecasting",
      "feature selection",
      "machine learning",
      "cryptocurrency"
    ]
  },
  {
    "article_id": "2303.09406v2_Exploiting_Supply_Chain_Interdependencies_for_Stock_Return_Prediction_A_Full-State_Graph_Convolution",
    "title": "2303.09406v2 Exploiting Supply Chain Interdependencies for Stock Return Prediction A Full-State Graph Convolution",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2303.09406v2_Exploiting_Supply_Chain_Interdependencies_for_Stock_Return_Prediction_A_Full-State_Graph_Convolution.pdf",
    "url": "http://arxiv.org/abs/2303.09406v2_Exploiting_Supply_Chain_Interdependencies_for_Stock_Return_Prediction_A_Full-State_Graph_Convolution",
    "pdf_url": "https://arxiv.org/pdf/2303.09406v2_Exploiting_Supply_Chain_Interdependencies_for_Stock_Return_Prediction_A_Full-State_Graph_Convolution",
    "file_size_mb": 12.84,
    "abstract": "Stock return prediction is fundamental to financial decision-making, yet traditional time series models fail to capture the complex interdependencies between companies in modern markets. We propose the Full-State Graph Convolutional LSTM (FS- GCLSTM), a novel temporal graph neural network that incorporates value-chain relationships to enhance stock return forecasting. Our approach features two key innovations: First, we represent inter-firm dependencies through value-chain networks, where nodes correspond to companies and edges capture supplier–customer relationships, enabling the model to leverage information beyond historical price data. Second, FS-GCLSTM applies graph convolutions to all LSTM components—current input features, previous hidden states, and cell states—ensuring that spatial information from the value-chain network influences every aspect of the temporal update mechanism. We evaluate FS-GCLSTM on Eurostoxx 600 and S&P 500 datasets using LSEG value- chain data. While not achieving the lowest traditional prediction errors, FS-GCLSTM consistently delivers superior portfolio performance, attaining the highest annualized returns, Sharpe ratios, and Sortino ratios across both markets. Performance gains are more pronounced in the denser Eurostoxx 600 network, and robustness tests confirm stability across different input sequence lengths, demonstrating the practical value of integrating value-chain data with temporal graph neural networks.",
    "keywords": []
  },
  {
    "article_id": "2304.14544v1_Assessing_Text_Mining_and_Technical_Analyses_on_Forecasting_Financial_Time_Series",
    "title": "2304.14544v1 Assessing Text Mining and Technical Analyses on Forecasting Financial Time Series",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2304.14544v1_Assessing_Text_Mining_and_Technical_Analyses_on_Forecasting_Financial_Time_Series.pdf",
    "url": "http://arxiv.org/abs/2304.14544v1_Assessing_Text_Mining_and_Technical_Analyses_on_Forecasting_Financial_Time_Series",
    "pdf_url": "https://arxiv.org/pdf/2304.14544v1_Assessing_Text_Mining_and_Technical_Analyses_on_Forecasting_Financial_Time_Series",
    "file_size_mb": 0.41,
    "abstract": "Forecasting financial time series (FTS) is an essential field in finance and economics that anticipates market movements in financial markets. This paper investigates the accuracy of text mining and technical analyses in forecasting financial time series. It focuses on the S&P500 stock market index during the pandemic, which tracks the performance of the largest publicly traded companies in the US. The study compares two methods of forecasting the future price of the S&P500: text mining, which uses NLP techniques to extract meaningful insights from financial news, and technical analysis, which uses historical price and volume data to make predictions. The study examines the advantages and limitations of both methods and analyze their performance in predicting the S&P500. The FinBERT model outperforms other models in terms of S&P500 price pre- diction, as evidenced by its lower RMSE value, and has the potential to revolutionize financial analysis and prediction using financial news data.",
    "keywords": [
      "ARIMA",
      "BERT",
      "FinBERT",
      "Forecasting Financial Time Series",
      "GARCH",
      "LSTM"
    ]
  },
  {
    "article_id": "2305.03835v1_Spatiotemporal_Transformer_for_Stock_Movement_Prediction",
    "title": "2305.03835v1 Spatiotemporal Transformer for Stock Movement Prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2305.03835v1_Spatiotemporal_Transformer_for_Stock_Movement_Prediction.pdf",
    "url": "http://arxiv.org/abs/2305.03835v1_Spatiotemporal_Transformer_for_Stock_Movement_Prediction",
    "pdf_url": "https://arxiv.org/pdf/2305.03835v1_Spatiotemporal_Transformer_for_Stock_Movement_Prediction",
    "file_size_mb": 0.65,
    "abstract": "Financial markets are an intriguing place that offer investors the potential to gain large proﬁts if timed correctly. Unfor- tunately, the dynamic, non-linear nature of ﬁnancial markets makes it extremely hard to predict future price movements. Within the US stock exchange, there are a countless num- ber of factors that play a role in the price of a company’s stock, including but not limited to ﬁnancial statements, so- cial and news sentiment, overall market sentiment, political happenings and trading psychology. Correlating these factors is virtually impossible for a human. Therefore, we propose STST, a novel approach using a Spatiotemporal Transformer- LSTM model for stock movement prediction. Our model ob- tains accuracies of 63.707 and 56.879 percent against the ACL18 and KDD17 datasets, respectively. In addition, our model was used in simulation to determine its real-life appli- cability. It obtained a minimum of 10.41% higher proﬁt than the S&P500 stock index, with a minimum annualized return of 31.24%.",
    "keywords": []
  },
  {
    "article_id": "2305.14378v1_Predicting_Stock_Market_Time-Series_Data_using_CNN-LSTM_Neural_Network_Model",
    "title": "2305.14378v1 Predicting Stock Market Time-Series Data using CNN-LSTM Neural Network Model",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2305.14378v1_Predicting_Stock_Market_Time-Series_Data_using_CNN-LSTM_Neural_Network_Model.pdf",
    "url": "http://arxiv.org/abs/2305.14378v1_Predicting_Stock_Market_Time-Series_Data_using_CNN-LSTM_Neural_Network_Model",
    "pdf_url": "https://arxiv.org/pdf/2305.14378v1_Predicting_Stock_Market_Time-Series_Data_using_CNN-LSTM_Neural_Network_Model",
    "file_size_mb": 0.55,
    "abstract": "—Stock market is often important as it represents the ownership claims on businesses. Without sufﬁcient stocks, a company cannot perform well in ﬁnance. Predicting a stock market performance of a company is nearly hard because every time the prices of a company’s stock keeps changing and not constant. So, it’s complex to determine the stock data. But if the previous performance of a company in stock market is known, then we can track the data and provide predictions to stockholders in order to wisely take decisions on handling the stocks to a company. To handle this, many machine learning models have been invented but they didn’t succeed due to many reasons like absence of advanced libraries, inaccuracy of model when made to train with real time data and much more. So, to track the patterns and the features of data, a CNN-LSTM Neural Network can be made. Recently, CNN is now used in Natural Language Processing (NLP) based applications, so by identifying the features from stock data and converting them into tensors, we can obtain the features and then send it to LSTM neural network to ﬁnd the patterns and thereby predicting the stock market for given period of time. The accuracy of the CNN- LSTM NN model is found to be high even when allowed to train on real-time stock market data. This paper describes about the features of the custom CNN-LSTM model, experiments we made with the model (like training with stock market datasets, performance comparison with other models) and the end product we obtained at ﬁnal stage.",
    "keywords": [
      "CNN-LSTM",
      "Deep Learning",
      "Time-Series Pre-"
    ]
  },
  {
    "article_id": "2305.14382v1_Stock_and_market_index_prediction_using_Informer_network",
    "title": "2305.14382v1 Stock and market index prediction using Informer network",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2305.14382v1_Stock_and_market_index_prediction_using_Informer_network.pdf",
    "url": "http://arxiv.org/abs/2305.14382v1_Stock_and_market_index_prediction_using_Informer_network",
    "pdf_url": "https://arxiv.org/pdf/2305.14382v1_Stock_and_market_index_prediction_using_Informer_network",
    "file_size_mb": 3.16,
    "abstract": "Applications of deep learning in ﬁnancial market prediction has attracted huge attention from investors and researchers. In particular, intra-day prediction at the minute scale, the dramatically ﬂuctuating volume and stock prices within short time periods have posed a great challenge for the convergence of networks result. Informer is a more novel network, improved on Transformer with smaller computational complexity, longer prediction length and global time stamp features. We have designed three experiments to compare Informer with the commonly used networks LSTM, Transformer and BERT on 1-minute and 5-minute frequencies for four diﬀerent stocks/ market indices. The prediction results are mea- sured by three evaluation criteria: MAE, RMSE and MAPE. Informer has obtained best performance among all the networks on every dataset. Net- work without the global time stamp mechanism has signiﬁcantly lower prediction eﬀect compared to the complete Informer; it is evident that this mechanism grants the time series to the characteristics and substan- tially improves the prediction accuracy of the networks. Finally, transfer learning capability experiment is conducted, Informer also achieves a good performance. Informer has good robustness and improved perfor- mance in market prediction, which can be exactly adapted to real trading.",
    "keywords": [
      "Deep learning",
      "Informer",
      "Stock Price Prediction",
      "Predictive"
    ]
  },
  {
    "article_id": "2306.02136v3_Financial_sentiment_analysis_using_FinBERT_with_application_in_predicting_stock_movement",
    "title": "2306.02136v3 Financial sentiment analysis using FinBERT with application in predicting stock movement",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2306.02136v3_Financial_sentiment_analysis_using_FinBERT_with_application_in_predicting_stock_movement.pdf",
    "url": "http://arxiv.org/abs/2306.02136v3_Financial_sentiment_analysis_using_FinBERT_with_application_in_predicting_stock_movement",
    "pdf_url": "https://arxiv.org/pdf/2306.02136v3_Financial_sentiment_analysis_using_FinBERT_with_application_in_predicting_stock_movement",
    "file_size_mb": 0.55,
    "abstract": "In this study, we integrate sentiment analysis within a financial framework by leveraging Fin- BERT, a fine-tuned BERT model specialized for financial text, to construct an advanced deep learn- ing model based on Long Short-Term Memory (LSTM) networks. Our objective is to forecast financial market trends with greater accuracy. To evaluate our model’s predictive capabilities, we apply it to a comprehensive dataset of stock mar- ket news and perform a comparative analysis against standard BERT, standalone LSTM, and the traditional ARIMA models. Our findings indi- cate that incorporating sentiment analysis signifi- cantly enhances the model’s ability to anticipate market fluctuations. Furthermore, we propose a suite of optimization techniques aimed at refin- ing the model’s performance, paving the way for more robust and reliable market prediction tools in the field of AI-driven finance.",
    "keywords": []
  },
  {
    "article_id": "2306.03620v1_Forecasting_the_Performance_of_US_Stock_Market_Indices_During_COVID-19_RF_vs_LSTM",
    "title": "2306.03620v1 Forecasting the Performance of US Stock Market Indices During COVID-19 RF vs LSTM",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2306.03620v1_Forecasting_the_Performance_of_US_Stock_Market_Indices_During_COVID-19_RF_vs_LSTM.pdf",
    "url": "http://arxiv.org/abs/2306.03620v1_Forecasting_the_Performance_of_US_Stock_Market_Indices_During_COVID-19_RF_vs_LSTM",
    "pdf_url": "https://arxiv.org/pdf/2306.03620v1_Forecasting_the_Performance_of_US_Stock_Market_Indices_During_COVID-19_RF_vs_LSTM",
    "file_size_mb": 0.48,
    "abstract": "The US stock market experienced instability following the recession (2007-2009). COVID-19 poses a significant challenge to US stock traders and investors. Traders and investors should keep up with the stock market. This is to mitigate risks and improve profits by using forecasting models that account for the effects of the pandemic. With consideration of the COVID-19 pandemic after the recession, two machine learning models, including Random Forest and LSTM are used to forecast two major US stock market indices. Data on historical prices after the big recession is used for developing machine learning models and forecasting index returns. To evaluate the model performance during training, cross- validation is used. Additionally, hyperparameter optimizing, regularization, such as dropouts and weight decays, and preprocessing improve the performances of Machine Learning techniques. Using high-accuracy machine learning techniques, traders and investors can forecast stock market behavior, stay ahead of their competition, and improve profitability.",
    "keywords": [
      "COVID-19",
      "LSTM",
      "S&P500",
      "Random Forest",
      "Russell 2000",
      "Forecasting"
    ]
  },
  {
    "article_id": "2307.10649v1_An_Adaptive_Dual-level_Reinforcement_Learning_Approach_for_Optimal_Trade_Execution",
    "title": "2307.10649v1 An Adaptive Dual-level Reinforcement Learning Approach for Optimal Trade Execution",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2307.10649v1_An_Adaptive_Dual-level_Reinforcement_Learning_Approach_for_Optimal_Trade_Execution.pdf",
    "url": "http://arxiv.org/abs/2307.10649v1_An_Adaptive_Dual-level_Reinforcement_Learning_Approach_for_Optimal_Trade_Execution",
    "pdf_url": "https://arxiv.org/pdf/2307.10649v1_An_Adaptive_Dual-level_Reinforcement_Learning_Approach_for_Optimal_Trade_Execution",
    "file_size_mb": 1.26,
    "abstract": "The purpose of this research is to devise a tactic that can closely track the daily cumulative volume-weighted average price (VWAP) using reinforcement learning. Previous studies often choose a relatively short trading horizon to imple- ment their models, making it difficult to accurately track the daily cumulative VWAP since the variations of financial data are often insignificant within the short trading horizon. In this paper, we aim to develop a strategy that can accurately track the daily cumulative VWAP while minimizing the deviation from the VWAP. We propose a method that leverages the U-shaped pattern of intraday stock trade volumes and use Proximal Policy Optimization (PPO) as the learning algorithm. Our method follows a dual-level approach: a Transformer model that captures the over- all(global) distribution of daily volumes in a U-shape, and a LSTM model that handles the distribution of orders within smaller(local) time intervals. The results from our experiments suggest that this dual-level architecture improves the accuracy of approximating the cumulative VWAP, when compared to previous reinforcement learning-based models.",
    "keywords": [
      "Volume-Weighted Average Price",
      "Reinforcement Learning",
      "Optimal Trading Execution",
      "Proximal Policy"
    ]
  },
  {
    "article_id": "2308.04419v1_Stock_Market_Price_Prediction_A_Hybrid_LSTM_and_Sequential_Self-Attention_based_Approach",
    "title": "2308.04419v1 Stock Market Price Prediction A Hybrid LSTM and Sequential Self-Attention based Approach",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2308.04419v1_Stock_Market_Price_Prediction_A_Hybrid_LSTM_and_Sequential_Self-Attention_based_Approach.pdf",
    "url": "http://arxiv.org/abs/2308.04419v1_Stock_Market_Price_Prediction_A_Hybrid_LSTM_and_Sequential_Self-Attention_based_Approach",
    "pdf_url": "https://arxiv.org/pdf/2308.04419v1_Stock_Market_Price_Prediction_A_Hybrid_LSTM_and_Sequential_Self-Attention_based_Approach",
    "file_size_mb": 0.65,
    "abstract": "— One of the most enticing research areas is the stock market, and projecting stock prices may help investors profit by making the best decisions at the correct time. Deep learning strategies have emerged as a critical technique in the field of the financial market. The stock market is impacted due to two aspects, one is the geo-political, social and global events on the bases of which the price trends could be affected. Meanwhile, the second aspect purely focuses on historical price trends and seasonality, allowing us to forecast stock prices. In this paper, our aim is to focus on the second aspect and build a model that predicts future prices with minimal errors. In order to provide better prediction results of stock price, we propose a new model named Long Short-Term Memory (LSTM) with Sequential Self-Attention Mechanism (LSTM-SSAM). Finally, we conduct extensive experiments on the three stock datasets: SBIN, HDFCBANK, and BANKBARODA. The experimental results prove the effectiveness and feasibility of the proposed model compared to existing models. The experimental findings demonstrate that the root-mean-squared error (RMSE), and R-square (R2) evaluation indicators are giving the best results.",
    "keywords": [
      "Stock prediction",
      "LSTM",
      "Self-Attention"
    ]
  },
  {
    "article_id": "2308.16538v1_The_AI_Revolution_Opportunities_and_Challenges_for_the_Finance_Sector",
    "title": "2308.16538v1 The AI Revolution Opportunities and Challenges for the Finance Sector",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2308.16538v1_The_AI_Revolution_Opportunities_and_Challenges_for_the_Finance_Sector.pdf",
    "url": "http://arxiv.org/abs/2308.16538v1_The_AI_Revolution_Opportunities_and_Challenges_for_the_Finance_Sector",
    "pdf_url": "https://arxiv.org/pdf/2308.16538v1_The_AI_Revolution_Opportunities_and_Challenges_for_the_Finance_Sector",
    "file_size_mb": 0.52,
    "abstract": null,
    "keywords": []
  },
  {
    "article_id": "2309.00136v1_Predicting_Financial_Market_Trends_using_Time_Series_Analysis_and_Natural_Language_Processing",
    "title": "2309.00136v1 Predicting Financial Market Trends using Time Series Analysis and Natural Language Processing",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2309.00136v1_Predicting_Financial_Market_Trends_using_Time_Series_Analysis_and_Natural_Language_Processing.pdf",
    "url": "http://arxiv.org/abs/2309.00136v1_Predicting_Financial_Market_Trends_using_Time_Series_Analysis_and_Natural_Language_Processing",
    "pdf_url": "https://arxiv.org/pdf/2309.00136v1_Predicting_Financial_Market_Trends_using_Time_Series_Analysis_and_Natural_Language_Processing",
    "file_size_mb": 0.55,
    "abstract": "— Forecasting financial market trends through time series analysis and natural language processing poses a complex and demanding undertaking, owing to the numerous variables that can influence stock prices. These variables encompass a spectrum of economic and political occurrences, as well as prevailing public attitudes. Recent research has indicated that the expression of public sentiments on social media platforms such as Twitter may have a noteworthy impact on the determination of stock prices. The objective of this study was to assess the viability of Twitter sentiments as a tool for predicting stock prices of major corporations such as Tesla, Apple. Our study has revealed a robust association between the emotions conveyed in tweets and fluctuations in stock prices. Our findings indicate that positivity, negativity, and subjectivity are the primary determinants of fluctuations in stock prices. The data was analyzed utilizing the Long-Short Term Memory neural network (LSTM) model, which is currently recognized as the leading methodology for predicting stock prices by incorporating Twitter sentiments and historical stock prices data. Our analysis yielded findings indicating that Twitter sentiments possess significant potential as an informative resource for forecasting stock prices. The models utilized in our study demonstrated a high degree of reliability and yielded precise outcomes for the designated corporations. In summary, this research emphasizes the significance of incorporating public opinions into the prediction of stock prices. The application of Time Series Analysis and Natural Language Processing methodologies can yield significant scientific findings regarding financial market patterns, thereby facilitating informed decision-making among investors. The results of our study indicate that the utilization of Twitter sentiments can serve as a potent instrument for forecasting stock prices, and ought to be factored in when formulating investment strategies.",
    "keywords": [
      "stock price prediction",
      "time series analysis"
    ]
  },
  {
    "article_id": "2309.00638v1_Generative_AI_for_End-to-End_Limit_Order_Book_Modelling_A_Token-Level_Autoregressive_Generative_Mode",
    "title": "2309.00638v1 Generative AI for End-to-End Limit Order Book Modelling A Token-Level Autoregressive Generative Mode",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2309.00638v1_Generative_AI_for_End-to-End_Limit_Order_Book_Modelling_A_Token-Level_Autoregressive_Generative_Mode.pdf",
    "url": "http://arxiv.org/abs/2309.00638v1_Generative_AI_for_End-to-End_Limit_Order_Book_Modelling_A_Token-Level_Autoregressive_Generative_Mode",
    "pdf_url": "https://arxiv.org/pdf/2309.00638v1_Generative_AI_for_End-to-End_Limit_Order_Book_Modelling_A_Token-Level_Autoregressive_Generative_Mode",
    "file_size_mb": 2.11,
    "abstract": "Developing a generative model of realistic order flow in financial markets is a challenging open problem, with numerous applications for market participants. Addressing this, we propose the first end- to-end autoregressive generative model that generates tokenized limit order book (LOB) messages. These messages are interpreted by a Jax-LOB simulator, which updates the LOB state. To handle long sequences efficiently, the model employs simplified structured state-space layers to process sequences of order book states and tokenized messages. Using LOBSTER data of NASDAQ equity LOBs, we develop a custom tokenizer for message data, converting groups of successive digits to tokens, similar to tokenization in large lan- guage models. Out-of-sample results show promising performance in approximating the data distribution, as evidenced by low model perplexity. Furthermore, the mid-price returns calculated from the generated order flow exhibit a significant correlation with the data, indicating impressive conditional forecast performance. Due to the granularity of generated data, and the accuracy of the model, it offers new application areas for future work beyond forecasting, e.g. acting as a world model in high-frequency financial reinforcement learning applications. Overall, our results invite the use and exten- sion of the model in the direction of autoregressive large financial models for the generation of high-frequency financial data and we commit to open-sourcing our code to facilitate future research. CCS CONCEPTS • Computing methodologies →Machine learning; Supervised learning.",
    "keywords": [
      "generative AI",
      "structured state space models",
      "limit order books"
    ]
  },
  {
    "article_id": "2309.02072v6_Global_Neural_Networks_and_The_Data_Scaling_Effect_in_Financial_Time_Series_Forecasting",
    "title": "2309.02072v6 Global Neural Networks and The Data Scaling Effect in Financial Time Series Forecasting",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2309.02072v6_Global_Neural_Networks_and_The_Data_Scaling_Effect_in_Financial_Time_Series_Forecasting.pdf",
    "url": "http://arxiv.org/abs/2309.02072v6_Global_Neural_Networks_and_The_Data_Scaling_Effect_in_Financial_Time_Series_Forecasting",
    "pdf_url": "https://arxiv.org/pdf/2309.02072v6_Global_Neural_Networks_and_The_Data_Scaling_Effect_in_Financial_Time_Series_Forecasting",
    "file_size_mb": 6.1,
    "abstract": "Neural networks have revolutionized many empirical fields, yet their application to financial time series forecasting remains controversial. In this study, we demonstrate that the conventional practice of estimating models locally in data-scarce environments may underlie the mixed empirical performance observed in prior work. By focusing on volatility forecasting, we employ a dataset comprising over 10,000 global stocks and implement a global estimation strategy that pools information across cross-sections. Our econometric analysis reveals that forecasting accuracy improves markedly as the training dataset becomes larger and more heterogeneous. Notably, even with as little as 12 months of data, globally trained networks deliver robust predictions for individ- ual stocks and portfolios that are even not in the training dataset. Furthermore, our interpretation of the model dynamics shows that these networks not only capture key stylized facts of volatility but also exhibit resilience to outliers and rapid adaptation to market regime changes. These findings underscore the importance of leveraging extensive and diverse datasets in financial forecasting and advocate for a shift from traditional local training approaches to integrated global estimation methods.",
    "keywords": [
      "volatility modeling",
      "deep learning",
      "global training"
    ]
  },
  {
    "article_id": "2309.05560v1_New_News_is_Bad_News",
    "title": "2309.05560v1 New News is Bad News",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2309.05560v1_New_News_is_Bad_News.pdf",
    "url": "http://arxiv.org/abs/2309.05560v1_New_News_is_Bad_News",
    "pdf_url": "https://arxiv.org/pdf/2309.05560v1_New_News_is_Bad_News",
    "file_size_mb": 1.97,
    "abstract": "An increase in the novelty of news predicts negative stock market returns and negative macroeconomic outcomes over the next year. We quantify news novelty – changes in the distribution of news text – through an entropy measure, calculated using a recurrent neural network applied to a large news corpus. Entropy is a better out-of-sample predictor of market returns than a collection of standard measures. Cross-sectional entropy exposure carries a negative risk premium, suggesting that assets that positively covary with entropy hedge the aggregate risk associated with shifting news language. Entropy risk cannot be explained by existing long-short factors.",
    "keywords": [
      "entropy",
      "natural language processing",
      "news articles",
      "empirical asset pricing"
    ]
  },
  {
    "article_id": "2309.06538v1_Desenvolvimento_de_modelo_para_predição_de_cotações_de_ação_baseada_em_análise_de_sentimentos_de_twe",
    "title": "2309.06538v1 Desenvolvimento de modelo para predição de cotações de ação baseada em análise de sentimentos de twe",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2309.06538v1_Desenvolvimento_de_modelo_para_predição_de_cotações_de_ação_baseada_em_análise_de_sentimentos_de_twe.pdf",
    "url": "http://arxiv.org/abs/2309.06538v1_Desenvolvimento_de_modelo_para_predição_de_cotações_de_ação_baseada_em_análise_de_sentimentos_de_twe",
    "pdf_url": "https://arxiv.org/pdf/2309.06538v1_Desenvolvimento_de_modelo_para_predição_de_cotações_de_ação_baseada_em_análise_de_sentimentos_de_twe",
    "file_size_mb": 2.22,
    "abstract": "—O treinamento de modelos de aprendizado de máquina para predição de cotações de ações tem sido um assunto cada vez mais abordado à medida que o avanço tecnológico possibilitou o envio automatizado e instantâneo de ordens de compra e venda desses ativos. Enquanto a grande maioria das abordagens nesta disciplina consiste em treinar modelos de Redes Neurais com base somente na cotação histórica dos ativos, neste trabalho utilizamos a plataforma iFeel 2.0 para extrair 19 indicadores de sentimentos de postagens da plataforma de microblogs Tweeter relacionadas à empresa Petrobras e treinamos modelos XGBoost para prever a cotação das ações desta empresa. Posteriormente, simulamos o desempenho deste modelo e comparamos à média de outros 100 aleatórios para determinar que houve ganho médio de R$88,82 (brutos) no período ao utilizar o modelo treinado, quando comparado ao rendimento médio dos outros cem modelos aleatórios.",
    "keywords": [
      "análise de sentimentos",
      "tweets",
      "cotações",
      "ações"
    ]
  },
  {
    "article_id": "2309.06559v1_Media_Moments_and_Corporate_Connections_A_Deep_Learning_Approach_to_Stock_Movement_Classification",
    "title": "2309.06559v1 Media Moments and Corporate Connections A Deep Learning Approach to Stock Movement Classification",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2309.06559v1_Media_Moments_and_Corporate_Connections_A_Deep_Learning_Approach_to_Stock_Movement_Classification.pdf",
    "url": "http://arxiv.org/abs/2309.06559v1_Media_Moments_and_Corporate_Connections_A_Deep_Learning_Approach_to_Stock_Movement_Classification",
    "pdf_url": "https://arxiv.org/pdf/2309.06559v1_Media_Moments_and_Corporate_Connections_A_Deep_Learning_Approach_to_Stock_Movement_Classification",
    "file_size_mb": 0.49,
    "abstract": "The financial industry poses great challenges with risk modeling and profit generation. These entities are intricately tied to the sophisticated prediction of stock movements. A stock forecaster must untangle the randomness and ever-changing behaviors of the stock market. Stock movements are influenced by a myriad of factors, including company history, performance, and economic-industry connections. However, there are other factors that aren't traditionally included, such as social media and correlations between stocks. Social platforms such as Reddit, Facebook, and X (Twitter) create opportunities for niche communities to share their sentiment on financial assets. By aggregating these opinions from social media in various mediums such as posts, interviews, and news updates, we propose a more holistic approach to include these “media moments” within stock market movement prediction. We introduce a method that combines financial data, social media, and correlated stock relationships via a graph neural network in a hierarchical temporal fashion. Through numerous trials on current S&P 500 index data, with results showing an improvement in cumulative returns by 28%, we provide empirical evidence of our tool's applicability for use in investment decisions.",
    "keywords": []
  },
  {
    "article_id": "2309.09094v2_Sizing_Strategies_for_Algorithmic_Trading_in_Volatile_Markets_A_Study_of_Backtesting_and_Risk_Mitiga",
    "title": "2309.09094v2 Sizing Strategies for Algorithmic Trading in Volatile Markets A Study of Backtesting and Risk Mitiga",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2309.09094v2_Sizing_Strategies_for_Algorithmic_Trading_in_Volatile_Markets_A_Study_of_Backtesting_and_Risk_Mitiga.pdf",
    "url": "http://arxiv.org/abs/2309.09094v2_Sizing_Strategies_for_Algorithmic_Trading_in_Volatile_Markets_A_Study_of_Backtesting_and_Risk_Mitiga",
    "pdf_url": "https://arxiv.org/pdf/2309.09094v2_Sizing_Strategies_for_Algorithmic_Trading_in_Volatile_Markets_A_Study_of_Backtesting_and_Risk_Mitiga",
    "file_size_mb": 5.4,
    "abstract": "Backtest is a way of financial risk evaluation which helps to analyze how our trading algorithm would work in markets with past time frame. The high volatility situation has always been a critical situation which creates challenges for algorithmic traders. The paper investigates different models of sizing in financial trading and backtest to high volatility situations to understand how sizing models can lower the models of VaR during crisis events. Hence it tries to show that how crisis events with high volatility can be controlled using short and long positional size. The paper also investigates stocks with AR, ARIMA, LSTM, GARCH with ETF data.",
    "keywords": [
      "Quantative Finance",
      "Algorithmic Trading",
      "Positional Size",
      "Value-at-"
    ]
  },
  {
    "article_id": "2310.00747v2_NoxTrader_LSTM-Based_Stock_Return_Momentum_Prediction_for_Quantitative_Trading",
    "title": "2310.00747v2 NoxTrader LSTM-Based Stock Return Momentum Prediction for Quantitative Trading",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2310.00747v2_NoxTrader_LSTM-Based_Stock_Return_Momentum_Prediction_for_Quantitative_Trading.pdf",
    "url": "http://arxiv.org/abs/2310.00747v2_NoxTrader_LSTM-Based_Stock_Return_Momentum_Prediction_for_Quantitative_Trading",
    "pdf_url": "https://arxiv.org/pdf/2310.00747v2_NoxTrader_LSTM-Based_Stock_Return_Momentum_Prediction_for_Quantitative_Trading",
    "file_size_mb": 0.53,
    "abstract": "— We introduce NoxTrader, a sophisticated system designed for portfolio construction and trading execution with the primary objective of achieving profitable outcomes in the stock market, specifically aiming to generate moderate to long- term profits. The underlying learning process of NoxTrader is rooted in the assimilation of valuable insights derived from historical trading data, particularly focusing on time-series analysis due to the nature of the dataset employed. In our approach, we utilize price and volume data of US stock market for feature engineering to generate effective features, including Return Momentum, Week Price Momentum, and Month Price Momentum. We choose the Long Short-Term Memory (LSTM) model to capture continuous price trends and implement dynamic model updates during the trading execution process, enabling the model to continuously adapt to the current market trends. Notably, we have developed a comprehensive trading backtesting system — NoxTrader, which allows us to manage portfolios based on predictive scores and utilize custom evaluation metrics to conduct a thorough assessment of our trading performance. Our rigorous feature engineering and careful selection of prediction targets enable us to generate prediction data with an impressive correlation range between 0.65 and 0.75. Finally, we monitor the dispersion of our prediction data and perform a comparative analysis against actual market data. Through the use of filtering techniques, we improved the initial -60% investment return to 325%.",
    "keywords": []
  },
  {
    "article_id": "2310.02090v2_1D-CapsNet-LSTM_A_Deep_Learning-Based_Model_for_Multi-Step_Stock_Index_Forecasting",
    "title": "2310.02090v2 1D-CapsNet-LSTM A Deep Learning-Based Model for Multi-Step Stock Index Forecasting",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2310.02090v2_1D-CapsNet-LSTM_A_Deep_Learning-Based_Model_for_Multi-Step_Stock_Index_Forecasting.pdf",
    "url": "http://arxiv.org/abs/2310.02090v2_1D-CapsNet-LSTM_A_Deep_Learning-Based_Model_for_Multi-Step_Stock_Index_Forecasting",
    "pdf_url": "https://arxiv.org/pdf/2310.02090v2_1D-CapsNet-LSTM_A_Deep_Learning-Based_Model_for_Multi-Step_Stock_Index_Forecasting",
    "file_size_mb": 2.01,
    "abstract": "Multi-step stock index forecasting is vital in finance for informed decision-making. Current forecasting methods on this task frequently produce unsatisfactory results due to the inherent data randomness and instability, thereby underscoring the demand for advanced forecasting models. Given the superiority of capsule network (CapsNet) over CNN in various forecasting and classification tasks, this study investigates the potential of integrating a 1D CapsNet with an LSTM network for multi-step stock index forecasting. To this end, a hybrid 1D-CapsNet-LSTM model is introduced, which utilizes a 1D CapsNet to generate high-level capsules from sequential data and a LSTM network to capture temporal dependencies. To maintain stochastic dependencies over different forecasting horizons, a multi-input multi-output (MIMO) strategy is employed. The model's performance is evaluated on real-world stock market indices, including S&P 500, DJIA, IXIC, and NYSE, and compared to baseline models, including LSTM, RNN, and CNN- LSTM, using metrics such as RMSE, MAE, MAPE, and TIC. The proposed 1D-CapsNet-LSTM model consistently outperforms baseline models in two key aspects. It exhibits significant reductions in forecasting errors compared to baseline models. Furthermore, it displays a slower rate of error increase with lengthening forecast horizons, indicating increased robustness for multi-step forecasting tasks.",
    "keywords": [
      "1D-CapsNet-LSTM",
      "deep learning",
      "time series",
      "stock index",
      "multi-step forecasting"
    ]
  },
  {
    "article_id": "2310.05892v1_A_Generalization_Bound_of_Deep_Neural_Networks_for_Dependent_Data",
    "title": "2310.05892v1 A Generalization Bound of Deep Neural Networks for Dependent Data",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2310.05892v1_A_Generalization_Bound_of_Deep_Neural_Networks_for_Dependent_Data.pdf",
    "url": "http://arxiv.org/abs/2310.05892v1_A_Generalization_Bound_of_Deep_Neural_Networks_for_Dependent_Data",
    "pdf_url": "https://arxiv.org/pdf/2310.05892v1_A_Generalization_Bound_of_Deep_Neural_Networks_for_Dependent_Data",
    "file_size_mb": 0.16,
    "abstract": "Existing generalization bounds for deep neural networks require data to be independent and identically distributed (iid). This assumption may not hold in real-life applications such as evolutionary biology, infectious disease epidemiology, and stock price prediction. This work establishes a generalization bound of feed- forward neural networks for non-stationary ϕ-mixing data.",
    "keywords": [
      "neural networks",
      "generalization bound",
      "non-stationary process"
    ]
  },
  {
    "article_id": "2310.07427v3_Quantum-Enhanced_Forecasting_Leveraging_Quantum_Gramian_Angular_Field_and_CNNs_for_Stock_Return_Pred",
    "title": "2310.07427v3 Quantum-Enhanced Forecasting Leveraging Quantum Gramian Angular Field and CNNs for Stock Return Pred",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2310.07427v3_Quantum-Enhanced_Forecasting_Leveraging_Quantum_Gramian_Angular_Field_and_CNNs_for_Stock_Return_Pred.pdf",
    "url": "http://arxiv.org/abs/2310.07427v3_Quantum-Enhanced_Forecasting_Leveraging_Quantum_Gramian_Angular_Field_and_CNNs_for_Stock_Return_Pred",
    "pdf_url": "https://arxiv.org/pdf/2310.07427v3_Quantum-Enhanced_Forecasting_Leveraging_Quantum_Gramian_Angular_Field_and_CNNs_for_Stock_Return_Pred",
    "file_size_mb": 3.22,
    "abstract": "We propose a time series forecasting method named Quantum Gramian Angular Field (QGAF). This approach merges the advantages of quantum computing technology with deep learning, aiming to enhance the precision of time series classification and forecasting. We successfully transformed stock return time series data into two-dimensional images suitable for Convolutional Neural Network (CNN) training by designing specific quantum circuits. Distinct from the classical Gramian Angular Field (GAF) approach, QGAF’s uniqueness lies in eliminating the need for data normalization and inverse cosine calculations, simplifying the transformation process from time series data to two-dimensional images. To validate the effectiveness of this method, we conducted experiments on datasets from three major stock markets: the China A-share market, the Hong Kong stock market, and the US stock market. Experimental results revealed that compared to the classical GAF method, the QGAF approach significantly improved time series prediction accuracy, reducing prediction errors by an average of 25% for Mean Absolute Error (MAE) and 48% for Mean Squared Error (MSE). This research confirms the potential and promising prospects of integrating quantum computing with deep learning techniques in financial time series forecasting.",
    "keywords": [
      "Time series forecasting",
      "Quantum Gramian angular field",
      "Convolutional neural network",
      "Stock return"
    ]
  },
  {
    "article_id": "2310.09622v1_Neural_Network_for_valuing_Bitcoin_options_under_jump-diffusion_and_market_sentiment_model",
    "title": "2310.09622v1 Neural Network for valuing Bitcoin options under jump-diffusion and market sentiment model",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2310.09622v1_Neural_Network_for_valuing_Bitcoin_options_under_jump-diffusion_and_market_sentiment_model.pdf",
    "url": "http://arxiv.org/abs/2310.09622v1_Neural_Network_for_valuing_Bitcoin_options_under_jump-diffusion_and_market_sentiment_model",
    "pdf_url": "https://arxiv.org/pdf/2310.09622v1_Neural_Network_for_valuing_Bitcoin_options_under_jump-diffusion_and_market_sentiment_model",
    "file_size_mb": 0.8,
    "abstract": "Cryptocurrencies and Bitcoin, in particular, are prone to wild swings resulting in frequent jumps in prices, making them historically popular for traders to speculate. A better understanding of these fluctuations can greatly benefit crypto investors by allowing them to make informed decisions. It is claimed in recent literature that Bitcoin price is influenced by sentiment about the Bitcoin system. Transaction, as well as the popularity, have shown positive evidence as potential drivers of Bitcoin price. This study considers a bivariate jump-diffusion model to describe Bitcoin price dynamics and the number of Google searches affecting the price, representing a sentiment indicator. We obtain a closed formula for the Bitcoin price and derive the Black-Scholes equation for Bitcoin options. We first solve the corresponding Bitcoin option partial differential equation for the pricing process by introducing artificial neural networks and incorporating multi-layer perceptron techniques. The prediction performance and the model validation using various high-volatile stocks were assessed.",
    "keywords": [
      "Jump-diffusion model",
      "Cryptocurrencies",
      "PDE",
      "Bitcoin",
      "Black-Scholes equation"
    ]
  },
  {
    "article_id": "2310.14536v1_Co-Training_Realized_Volatility_Prediction_Model_with_Neural_Distributional_Transformation",
    "title": "2310.14536v1 Co-Training Realized Volatility Prediction Model with Neural Distributional Transformation",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2310.14536v1_Co-Training_Realized_Volatility_Prediction_Model_with_Neural_Distributional_Transformation.pdf",
    "url": "http://arxiv.org/abs/2310.14536v1_Co-Training_Realized_Volatility_Prediction_Model_with_Neural_Distributional_Transformation",
    "pdf_url": "https://arxiv.org/pdf/2310.14536v1_Co-Training_Realized_Volatility_Prediction_Model_with_Neural_Distributional_Transformation",
    "file_size_mb": 2.3,
    "abstract": null,
    "keywords": [
      "and Phrases: realized volatility",
      "neural networks",
      "time-series prediction",
      "normalizing flow"
    ]
  },
  {
    "article_id": "2310.16855v1_Stock_Market_Directional_Bias_Prediction_Using_ML_Algorithms",
    "title": "2310.16855v1 Stock Market Directional Bias Prediction Using ML Algorithms",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2310.16855v1_Stock_Market_Directional_Bias_Prediction_Using_ML_Algorithms.pdf",
    "url": "http://arxiv.org/abs/2310.16855v1_Stock_Market_Directional_Bias_Prediction_Using_ML_Algorithms",
    "pdf_url": "https://arxiv.org/pdf/2310.16855v1_Stock_Market_Directional_Bias_Prediction_Using_ML_Algorithms",
    "file_size_mb": 0.45,
    "abstract": "—The stock market has been established since the 13th century, but in the current epoch of time, it is substantially more practicable to anticipate the stock market than it was at any other point in time due to the tools and data that are available for both traditional and algorithmic trading. There are many different machine learning models that can do time-series forecasting in the context of machine learning. These models can be used to anticipate the future prices of assets and/or the directional bias of assets. In this study, we examine and contrast the effectiveness of three different machine learning algorithms—namely, logistic regression, decision tree, and random forest—to forecast the movement of the assets traded on the Japanese stock market. In addition, the models are compared to a feed forward deep neural network, and it is found that all of the models consistently reach above 50% in directional bias forecasting for the stock market. The results of our study contribute to a better understanding of the complexity involved in stock market forecasting and give insight on the possible role that machine learning could play in this context.",
    "keywords": [
      "Machine Learning",
      "Stock Market",
      "Prediction"
    ]
  },
  {
    "article_id": "2311.10719v1_Analysis_of_frequent_trading_effects_of_various_machine_learning_models",
    "title": "2311.10719v1 Analysis of frequent trading effects of various machine learning models",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2311.10719v1_Analysis_of_frequent_trading_effects_of_various_machine_learning_models.pdf",
    "url": "http://arxiv.org/abs/2311.10719v1_Analysis_of_frequent_trading_effects_of_various_machine_learning_models",
    "pdf_url": "https://arxiv.org/pdf/2311.10719v1_Analysis_of_frequent_trading_effects_of_various_machine_learning_models",
    "file_size_mb": 3.32,
    "abstract": "In recent years, high-frequency trading has emerged as a crucial strategy in stock trading. This study aims to develop an advanced high-frequency trading algorithm and compare the performance of three different mathematical models: the combination of the cross-entropy loss function and the quasi-Newton algorithm, the FCNN model, and the vector machine. The proposed algorithm employs neural network predictions to generate trading signals and execute buy and sell operations based on specific conditions. By harnessing the power of neural networks, the algorithm enhances the accuracy and reliability of the trading strategy. To assess the effectiveness of the algorithm, the study evaluates the performance of the three mathematical models. The combination of the cross-entropy loss function and the quasi-Newton algorithm is a widely utilized logistic regression approach. The FCNN model, on the other hand, is a deep learning algorithm that can extract and classify features from stock data. Meanwhile, the vector machine is a supervised learning algorithm recognized for achieving improved classification results by mapping data into high- dimensional spaces. By comparing the performance of these three models, the study aims to determine the most effective approach for high-frequency trading. This research makes a valuable contribution by introducing a novel methodology for high-frequency trading, thereby providing investors with a more accurate and reliable stock trading strategy.",
    "keywords": [
      "high-frequency trading",
      "mathematical model",
      "logic regression algorithm",
      "FCNN model",
      "support vector machine",
      "stock"
    ]
  },
  {
    "article_id": "2312.01020v2_ResNLS_An_Improved_Model_for_Stock_Price_Forecasting",
    "title": "2312.01020v2 ResNLS An Improved Model for Stock Price Forecasting",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2312.01020v2_ResNLS_An_Improved_Model_for_Stock_Price_Forecasting.pdf",
    "url": "http://arxiv.org/abs/2312.01020v2_ResNLS_An_Improved_Model_for_Stock_Price_Forecasting",
    "pdf_url": "https://arxiv.org/pdf/2312.01020v2_ResNLS_An_Improved_Model_for_Stock_Price_Forecasting",
    "file_size_mb": 1.39,
    "abstract": "Stock prices forecasting has always been a challenging task. Although many research projects try to address the problem, few of them pay attention to the varying degrees of dependencies between stock prices. In this paper, we introduce a hybrid model that improves the predic- tion of stock prices by emphasizing the dependencies between adjacent stock prices. The proposed model, ResNLS, is mainly composed of two neural architectures, ResNet and LSTM. ResNet serves as a feature extractor to identify dependencies between stock prices, while LSTM analyzes the initial time series data with the combination of depen- dencies, which are considered as residuals. Our experiment reveals that when the closing price data for the previous 5 consecutive trading days is used as input, the performance of the model (ResNLS-5) is optimal compared to those with other inputs. Furthermore, ResNLS-5 demonstrates at least a 20% improvement over current state-of-the-art baselines. To verify whether ResNLS-5 can help clients effectively avoid risks and earn profits in the stock market, we construct a quantitative trading framework for back testing. The result shows that the trad- ing strategy based on ResNLS-5 predictions can successfully mitigate losses during declining stock prices and generate profits in periods of rising stock prices. The relevant code is publicly available on GitHub∗.",
    "keywords": [
      "Stock Price Forecasting",
      "ResNLS"
    ]
  },
  {
    "article_id": "2312.05756v3_A_quantitative_fusion_strategy_of_stock_picking_and_timing_based_on_Particle_Swarm_Optimized-Back_Pr",
    "title": "2312.05756v3 A quantitative fusion strategy of stock picking and timing based on Particle Swarm Optimized-Back Pr",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2312.05756v3_A_quantitative_fusion_strategy_of_stock_picking_and_timing_based_on_Particle_Swarm_Optimized-Back_Pr.pdf",
    "url": "http://arxiv.org/abs/2312.05756v3_A_quantitative_fusion_strategy_of_stock_picking_and_timing_based_on_Particle_Swarm_Optimized-Back_Pr",
    "pdf_url": "https://arxiv.org/pdf/2312.05756v3_A_quantitative_fusion_strategy_of_stock_picking_and_timing_based_on_Particle_Swarm_Optimized-Back_Pr",
    "file_size_mb": 1.6,
    "abstract": null,
    "keywords": [
      "and Phrases: Quantitative Stock",
      "Timing and Picking",
      "Multivariate Gaussian",
      "Hidden Markov"
    ]
  },
  {
    "article_id": "2312.15730v1_Deep_Reinforcement_Learning_for_Quantitative_Trading",
    "title": "2312.15730v1 Deep Reinforcement Learning for Quantitative Trading",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2312.15730v1_Deep_Reinforcement_Learning_for_Quantitative_Trading.pdf",
    "url": "http://arxiv.org/abs/2312.15730v1_Deep_Reinforcement_Learning_for_Quantitative_Trading",
    "pdf_url": "https://arxiv.org/pdf/2312.15730v1_Deep_Reinforcement_Learning_for_Quantitative_Trading",
    "file_size_mb": 0.43,
    "abstract": "—Artificial Intelligence (AI) and Machine Learning (ML) are transforming the domain of Quantitative Trading (QT) through the deployment of advanced algorithms capable of sifting through extensive financial datasets to pinpoint lucrative investment openings. AI-driven models, particularly those em- ploying ML techniques such as deep learning and reinforcement learning, have shown great prowess in predicting market trends and executing trades at a speed and accuracy that far surpass human capabilities. Its capacity to automate critical tasks, such as discerning market conditions and executing trading strategies, has been pivotal. However, persistent challenges exist in current QT methods, especially in effectively handling noisy and high- frequency financial data. Striking a balance between exploration and exploitation poses another challenge for AI-driven trading agents. To surmount these hurdles, our proposed solution, QT- Net, introduces an adaptive trading model that autonomously formulates QT strategies through an intelligent trading agent. Incorporating deep reinforcement learning (DRL) with imitative learning methodologies, we bolster the proficiency of our model. To tackle the challenges posed by volatile financial datasets, we conceptualize the QT mechanism within the framework of a Par- tially Observable Markov Decision Process (POMDP). Moreover, by embedding imitative learning, the model can capitalize on traditional trading tactics, nurturing a balanced synergy between discovery and utilization. For a more realistic simulation, our trading agent undergoes training using minute-frequency data sourced from the live financial market. Experimental findings underscore the model’s proficiency in extracting robust market features and its adaptability to diverse market conditions.",
    "keywords": [
      "Quantitative Trading",
      "Reinforcement Learning"
    ]
  },
  {
    "article_id": "2401.01846v1_DGDNN_Decoupled_Graph_Diffusion_Neural_Network_for_Stock_Movement_Prediction",
    "title": "2401.01846v1 DGDNN Decoupled Graph Diffusion Neural Network for Stock Movement Prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2401.01846v1_DGDNN_Decoupled_Graph_Diffusion_Neural_Network_for_Stock_Movement_Prediction.pdf",
    "url": "http://arxiv.org/abs/2401.01846v1_DGDNN_Decoupled_Graph_Diffusion_Neural_Network_for_Stock_Movement_Prediction",
    "pdf_url": "https://arxiv.org/pdf/2401.01846v1_DGDNN_Decoupled_Graph_Diffusion_Neural_Network_for_Stock_Movement_Prediction",
    "file_size_mb": 1.02,
    "abstract": "Forecasting future stock trends remains challenging for academia and industry due to stochastic inter-stock dy- namics and hierarchical intra-stock dynamics influencing stock prices. In recent years, graph neural networks have achieved remarkable performance in this problem by formulating multiple stocks as graph-structured data. However, most of these approaches rely on artificially defined factors to construct static stock graphs, which fail to capture the intrinsic interdependencies between stocks that rapidly evolve. In addition, these methods often ignore the hierarchical features of the stocks and lose distinctive information within. In this work, we propose a novel graph learning approach implemented without expert knowledge to address these issues. First, our approach automatically constructs dynamic stock graphs by entropy-driven edge generation from a signal processing perspective. Then, we further learn task-optimal dependencies between stocks via a generalized graph diffusion process on constructed stock graphs. Last, a decoupled representation learning scheme is adopted to capture distinctive hierarchical intra-stock features. Experimental results demonstrate substantial improvements over state-of-the-art baselines on real-world datasets. Moreover, the ablation study and sensitivity study further illustrate the effectiveness of the proposed method in modeling the time-evolving inter-stock and intra-stock dynamics.",
    "keywords": [
      "Stock prediction",
      "Graph neural network",
      "Graph structure learning",
      "Information propagation"
    ]
  },
  {
    "article_id": "2401.04632v2_Hypercomplex_neural_network_in_time_series_forecasting_of_stock_data",
    "title": "2401.04632v2 Hypercomplex neural network in time series forecasting of stock data",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2401.04632v2_Hypercomplex_neural_network_in_time_series_forecasting_of_stock_data.pdf",
    "url": "http://arxiv.org/abs/2401.04632v2_Hypercomplex_neural_network_in_time_series_forecasting_of_stock_data",
    "pdf_url": "https://arxiv.org/pdf/2401.04632v2_Hypercomplex_neural_network_in_time_series_forecasting_of_stock_data",
    "file_size_mb": 0.56,
    "abstract": "The goal of this paper is to test three classes of neural network (NN) architectures based on four-dimensional (4D) hypercomplex algebras for time series prediction. We evaluate different architectures, varying the input layers to include convolutional, Long Short-Term Memory (LSTM), or dense hypercomplex layers for 4D algebras. Four related Stock Market time series are used as input data, with the prediction focused on one of them. Hyperparameter optimization for each ar- chitecture class was conducted to compare the best-performing neural networks within each class. The results indicate that, in most cases, architectures with hypercomplex dense layers achieve similar Mean Absolute Error (MAE) accuracy compared to other architectures, but with significantly fewer trainable parameters. Consequently, hyper- complex neural networks demonstrate the ability to learn and process time series data faster than the other tested architectures. Addition- ally, it was found that the ordering of the input time series have a notable impact on effectiveness.",
    "keywords": [
      "times series prediction",
      "4D hypercomplex algebras",
      "hypercom-"
    ]
  },
  {
    "article_id": "2401.05426v2_CoSS_Co-optimizing_Sensor_and_Sampling_Rate_for_Data-Efficient_AI_in_Human_Activity_Recognition",
    "title": "2401.05426v2 CoSS Co-optimizing Sensor and Sampling Rate for Data-Efficient AI in Human Activity Recognition",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2401.05426v2_CoSS_Co-optimizing_Sensor_and_Sampling_Rate_for_Data-Efficient_AI_in_Human_Activity_Recognition.pdf",
    "url": "http://arxiv.org/abs/2401.05426v2_CoSS_Co-optimizing_Sensor_and_Sampling_Rate_for_Data-Efficient_AI_in_Human_Activity_Recognition",
    "pdf_url": "https://arxiv.org/pdf/2401.05426v2_CoSS_Co-optimizing_Sensor_and_Sampling_Rate_for_Data-Efficient_AI_in_Human_Activity_Recognition",
    "file_size_mb": 0.62,
    "abstract": "Recent advancements in Artificial Neural Networks have sig- nificantly improved human activity recognition using multi- ple time-series sensors. While employing numerous sensors with high-frequency sampling rates usually improves the re- sults, it often leads to data inefficiency and unnecessary ex- pansion of the ANN, posing a challenge for their practical de- ployment on edge devices. Addressing these issues, our work introduces a pragmatic framework for data-efficient utiliza- tion in HAR tasks, considering the optimization of both sen- sor modalities and sampling rate simultaneously. Central to our approach are the designed trainable parameters, termed ’Weight Scores,’ which assess the significance of each sensor modality and sampling rate during the training phase. These scores guide the sensor modalities and sampling rate selec- tion. The pruning method allows users to make a trade-off between computational budgets and performance by select- ing the sensor modalities and sampling rates according to the weight score ranking. We tested our framework’s effective- ness in optimizing sensor modality and sampling rate selec- tion using three public HAR benchmark datasets. The results show that the sensor and sampling rate combination selected via CoSS achieves similar classification performance to con- figurations using the highest sampling rate with all sensors, but at a reduced hardware cost.",
    "keywords": []
  },
  {
    "article_id": "2401.05430v1_Multi-relational_Graph_Diffusion_Neural_Network_with_Parallel_Retention_for_Stock_Trends_Classificat",
    "title": "2401.05430v1 Multi-relational Graph Diffusion Neural Network with Parallel Retention for Stock Trends Classificat",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2401.05430v1_Multi-relational_Graph_Diffusion_Neural_Network_with_Parallel_Retention_for_Stock_Trends_Classificat.pdf",
    "url": "http://arxiv.org/abs/2401.05430v1_Multi-relational_Graph_Diffusion_Neural_Network_with_Parallel_Retention_for_Stock_Trends_Classificat",
    "pdf_url": "https://arxiv.org/pdf/2401.05430v1_Multi-relational_Graph_Diffusion_Neural_Network_with_Parallel_Retention_for_Stock_Trends_Classificat",
    "file_size_mb": 0.31,
    "abstract": "Stock trend classification remains a fundamental yet challenging task, owing to the intricate time-evolving dynamics between and within stocks. To tackle these two challenges, we propose a graph- based representation learning approach aimed at predicting the fu- ture movements of multiple stocks. Initially, we model the complex time-varying relationships between stocks by generating dynamic multi-relational stock graphs. This is achieved through a novel edge generation algorithm that leverages information entropy and signal energy to quantify the intensity and directionality of inter-stock relations on each trading day. Then, we further refine these initial graphs through a stochastic multi-relational diffusion process, adap- tively learning task-optimal edges. Subsequently, we implement a decoupled representation learning scheme with parallel retention to obtain the final graph representation. This strategy better captures the unique temporal features within individual stocks while also capturing the overall structure of the stock graph. Comprehensive experiments conducted on real-world datasets from two US mar- kets (NASDAQ and NYSE) and one Chinese market (Shanghai Stock Exchange: SSE) validate the effectiveness of our method. Our approach consistently outperforms state-of-the-art baselines in forecasting next trading day stock trends across three test periods spanning seven years. Datasets and code have been released.1",
    "keywords": [
      "stock market prediction",
      "graph neural network"
    ]
  },
  {
    "article_id": "2402.06633v1_MDGNN_Multi-Relational_Dynamic_Graph_Neural_Network_for_Comprehensive_and_Dynamic_Stock_Investment_P",
    "title": "2402.06633v1 MDGNN Multi-Relational Dynamic Graph Neural Network for Comprehensive and Dynamic Stock Investment P",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2402.06633v1_MDGNN_Multi-Relational_Dynamic_Graph_Neural_Network_for_Comprehensive_and_Dynamic_Stock_Investment_P.pdf",
    "url": "http://arxiv.org/abs/2402.06633v1_MDGNN_Multi-Relational_Dynamic_Graph_Neural_Network_for_Comprehensive_and_Dynamic_Stock_Investment_P",
    "pdf_url": "https://arxiv.org/pdf/2402.06633v1_MDGNN_Multi-Relational_Dynamic_Graph_Neural_Network_for_Comprehensive_and_Dynamic_Stock_Investment_P",
    "file_size_mb": 1.04,
    "abstract": "The stock market is a crucial component of the financial sys- tem, but predicting the movement of stock prices is challeng- ing due to the dynamic and intricate relations arising from various aspects such as economic indicators, financial reports, global news, and investor sentiment. Traditional sequential methods and graph-based models have been applied in stock movement prediction, but they have limitations in capturing the multifaceted and temporal influences in stock price move- ments. To address these challenges, the Multi-relational Dy- namic Graph Neural Network (MDGNN) framework is pro- posed, which utilizes a discrete dynamic graph to comprehen- sively capture multifaceted relations among stocks and their evolution over time. The representation generated from the graph offers a complete perspective on the interrelationships among stocks and associated entities. Additionally, the power of the Transformer structure is leveraged to encode the tem- poral evolution of multiplex relations, providing a dynamic and effective approach to predicting stock investment. Fur- ther, our proposed MDGNN framework achieves the best per- formance in public datasets compared with state-of-the-art (SOTA) stock investment methods.",
    "keywords": []
  },
  {
    "article_id": "2402.06689v1_A_Study_on_Stock_Forecasting_Using_Deep_Learning_and_Statistical_Models",
    "title": "2402.06689v1 A Study on Stock Forecasting Using Deep Learning and Statistical Models",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2402.06689v1_A_Study_on_Stock_Forecasting_Using_Deep_Learning_and_Statistical_Models.pdf",
    "url": "http://arxiv.org/abs/2402.06689v1_A_Study_on_Stock_Forecasting_Using_Deep_Learning_and_Statistical_Models",
    "pdf_url": "https://arxiv.org/pdf/2402.06689v1_A_Study_on_Stock_Forecasting_Using_Deep_Learning_and_Statistical_Models",
    "file_size_mb": 1.29,
    "abstract": "—Predicting a fast and accurate model for stock price forecasting is been a challenging task and this is an active area of research where it is yet to be found which is the best way to forecast the stock price. Machine learning, deep learning and statistical analysis techniques are used here to get the accurate result so the investors can see the future trend and maximize the return of investment in stock trading. This paper will review many deep learning algorithms for stock price forecasting. We use a record of s&p 500 index data for training and testing. The survey motive is to check various deep learning and statistical model techniques for stock price forecasting that are Moving Averages, ARIMA which are statistical techniques and LSTM, RNN, CNN, and FULL CNN which are deep learning models. It will discuss various models, including the Auto regression integration moving average model, the Recurrent neural network model, the long short-term model which is the type of RNN used for long dependency for data, the convolutional neural network model, and the full convolutional neural network model, in terms of error calculation or percentage of accuracy that how much it is accurate which measures by the function like Root mean square error, mean absolute error, mean squared error. The model can be used to predict the stock price by checking the low MAE value as lower the MAE value the difference between the predicting and the actual value will be less and this model will predict the price more accurately than other models.",
    "keywords": [
      "component",
      "formatting",
      "style",
      "styling",
      "insert"
    ]
  },
  {
    "article_id": "2402.18485v3_A_Multimodal_Foundation_Agent_for_Financial_Trading_Tool-Augmented_Diversified_and_Generalist",
    "title": "2402.18485v3 A Multimodal Foundation Agent for Financial Trading Tool-Augmented Diversified and Generalist",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2402.18485v3_A_Multimodal_Foundation_Agent_for_Financial_Trading_Tool-Augmented_Diversified_and_Generalist.pdf",
    "url": "http://arxiv.org/abs/2402.18485v3_A_Multimodal_Foundation_Agent_for_Financial_Trading_Tool-Augmented_Diversified_and_Generalist",
    "pdf_url": "https://arxiv.org/pdf/2402.18485v3_A_Multimodal_Foundation_Agent_for_Financial_Trading_Tool-Augmented_Diversified_and_Generalist",
    "file_size_mb": 14.65,
    "abstract": "Financial trading is a crucial component of the markets, informed by a multimodal information landscape encompassing news, prices, and Kline charts, and encompasses diverse tasks such as quantita- tive trading and high-frequency trading with various assets. While advanced AI techniques like deep learning and reinforcement learn- ing are extensively utilized in finance, their application in financial trading tasks often faces challenges due to inadequate handling of multimodal data and limited generalizability across various tasks. To address these challenges, we present FinAgent, a multimodal foundational agent with tool augmentation for financial trading. FinAgent’s market intelligence module processes a diverse range of data—numerical, textual, and visual—to accurately analyze the financial market. Its unique dual-level reflection module not only enables rapid adaptation to market dynamics but also incorpo- rates a diversified memory retrieval system, enhancing the agent’s ability to learn from historical data and improve decision-making processes. The agent’s emphasis on reasoning for actions fosters trust in its financial decisions. Moreover, FinAgent integrates es- tablished trading strategies and expert insights, ensuring that its ∗Lingxuan Zhao and Haochong Xia contributed equally to this research. †Corresponding Authors. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. KDD ’24, August 25–29, 2024, Barcelona, Spain © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 979-8-4007-0490-1/24/08 https://doi.org/10.1145/3637528.3671801 trading approaches are both data-driven and rooted in sound fi- nancial principles. With comprehensive experiments on 6 financial datasets, including stocks and Crypto, FinAgent significantly out- performs 12 state-of-the-art baselines in terms of 6 financial metrics with over 36% average improvement on profit. Specifically, a 92.27% return (a 84.39% relative improvement) is achieved on one dataset. Notably, FinAgent is the first advanced multimodal foundation agent designed for financial trading tasks. CCS CONCEPTS • Information systems →Data mining; • Computing method- ologies →Machine learning; • Applied computing →Elec- tronic commerce.",
    "keywords": [
      "Large Language Models",
      "Quantitative Trading",
      "Financial AI Agents"
    ]
  },
  {
    "article_id": "2402.18959v1_MambaStock_Selective_state_space_model_for_stock_prediction",
    "title": "2402.18959v1 MambaStock Selective state space model for stock prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2402.18959v1_MambaStock_Selective_state_space_model_for_stock_prediction.pdf",
    "url": "http://arxiv.org/abs/2402.18959v1_MambaStock_Selective_state_space_model_for_stock_prediction",
    "pdf_url": "https://arxiv.org/pdf/2402.18959v1_MambaStock_Selective_state_space_model_for_stock_prediction",
    "file_size_mb": 0.28,
    "abstract": "—The stock market plays a pivotal role in economic development, yet its intricate volatility poses challenges for in- vestors. Consequently, research and accurate predictions of stock price movements are crucial for mitigating risks. Traditional time series models fall short in capturing nonlinearity, leading to unsatisfactory stock predictions. This limitation has spurred the widespread adoption of neural networks for stock predic- tion, owing to their robust nonlinear generalization capabilities. Recently, Mamba, a structured state space sequence model with a selection mechanism and scan module (S6), has emerged as a powerful tool in sequence modeling tasks. Leveraging this framework, this paper proposes a novel Mamba-based model for stock price prediction, named MambaStock. The proposed MambaStock model effectively mines historical stock market data to predict future stock prices without handcrafted features or extensive preprocessing procedures. Empirical studies on several stocks indicate that the MambaStock model outperforms previous methods, delivering highly accurate predictions. This enhanced accuracy can assist investors and institutions in making informed decisions, aiming to maximize returns while minimizing risks. This work underscores the value of Mamba in time- series forecasting. Source code is available at https://github.com/ zshicode/MambaStock.",
    "keywords": [
      "Mamba",
      "structured state space model",
      "selective"
    ]
  },
  {
    "article_id": "2403.00772v1_Do_Weibo_platform_experts_perform_better_at_predicting_stock_market",
    "title": "2403.00772v1 Do Weibo platform experts perform better at predicting stock market",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2403.00772v1_Do_Weibo_platform_experts_perform_better_at_predicting_stock_market.pdf",
    "url": "http://arxiv.org/abs/2403.00772v1_Do_Weibo_platform_experts_perform_better_at_predicting_stock_market",
    "pdf_url": "https://arxiv.org/pdf/2403.00772v1_Do_Weibo_platform_experts_perform_better_at_predicting_stock_market",
    "file_size_mb": 0.76,
    "abstract": ". Sentiment analysis can be used for stock market prediction. However, existing research has not studied the impact of a user’s finan- cial background on sentiment-based forecasting of the stock market using artificial neural networks. In this work, a novel combination of neural net- works is used for the assessment of sentiment-based stock market predic- tion, based on the financial background of the population that generated the sentiment. The state-of-the-art language processing model Bidirec- tional Encoder Representations from Transformers (BERT) is used to classify the sentiment and a Long-Short Term Memory (LSTM) model is used for time-series based stock market prediction. For evaluation, the Weibo social networking platform is used as a sentiment data collection source. Weibo users (and their comments respectively) are divided into Authorized Financial Advisor (AFA) and Unauthorized Financial Advi- sor (UFA) groups according to their background information, as collected by Weibo. The Hong Kong Hang Seng index is used to extract historical stock market change data. The results indicate that stock market pre- diction learned from the AFA group users is 39.67% more precise than that learned from the UFA group users and shows the highest accuracy (87%) when compared to existing approaches.",
    "keywords": [
      "Sentiment analysis",
      "Artificial neural networks",
      "Stock pre-"
    ]
  },
  {
    "article_id": "2403.06779v1_From_Factor_Models_to_Deep_Learning_Machine_Learning_in_Reshaping_Empirical_Asset_Pricing",
    "title": "2403.06779v1 From Factor Models to Deep Learning Machine Learning in Reshaping Empirical Asset Pricing",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2403.06779v1_From_Factor_Models_to_Deep_Learning_Machine_Learning_in_Reshaping_Empirical_Asset_Pricing.pdf",
    "url": "http://arxiv.org/abs/2403.06779v1_From_Factor_Models_to_Deep_Learning_Machine_Learning_in_Reshaping_Empirical_Asset_Pricing",
    "pdf_url": "https://arxiv.org/pdf/2403.06779v1_From_Factor_Models_to_Deep_Learning_Machine_Learning_in_Reshaping_Empirical_Asset_Pricing",
    "file_size_mb": 0.85,
    "abstract": "This paper comprehensively reviews the applica- tion of machine learning (ML) and AI in finance, specifically in the context of asset pricing. It starts by summarizing the traditional asset pricing mod- els and examining their limitations in capturing the complexities of financial markets. It explores how 1) ML models, including supervised, unsuper- vised, semi-supervised, and reinforcement learn- ing, provide versatile frameworks to address these complexities, and 2) the incorporation of advanced ML algorithms into traditional financial models en- hances return prediction and portfolio optimization. These methods can adapt to changing market dy- namics by modeling structural changes and incor- porating heterogeneous data sources, such as text and images. In addition, this paper explores chal- lenges in applying ML in asset pricing, addressing the growing demand for explainability in decision- making and mitigating overfitting in complex mod- els. This paper aims to provide insights into novel methodologies showcasing the potential of ML to reshape the future of quantitative finance.",
    "keywords": []
  },
  {
    "article_id": "2403.07916v1_Advancing_Investment_Frontiers_Industry-grade_Deep_Reinforcement_Learning_for_Portfolio_Optimization",
    "title": "2403.07916v1 Advancing Investment Frontiers Industry-grade Deep Reinforcement Learning for Portfolio Optimization",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2403.07916v1_Advancing_Investment_Frontiers_Industry-grade_Deep_Reinforcement_Learning_for_Portfolio_Optimization.pdf",
    "url": "http://arxiv.org/abs/2403.07916v1_Advancing_Investment_Frontiers_Industry-grade_Deep_Reinforcement_Learning_for_Portfolio_Optimization",
    "pdf_url": "https://arxiv.org/pdf/2403.07916v1_Advancing_Investment_Frontiers_Industry-grade_Deep_Reinforcement_Learning_for_Portfolio_Optimization",
    "file_size_mb": 3.2,
    "abstract": "This research paper delves into the application of Deep Reinforcement Learning (DRL) in asset-class agnostic portfolio optimization, integrating industry-grade methodologies with quantitative finance. At the heart of this integration is our robust framework that not only merges advanced DRL algorithms with modern computational techniques but also emphasizes stringent statistical analysis, software engineering and regulatory compliance. To the best of our knowledge, this is the first study integrating financial Reinforcement Learning with sim-to-real methodologies from robotics and mathematical physics, thus enriching our frameworks and arguments with this unique perspective. Our research culminates with the introduction of AlphaOptimizerNet, a proprietary Reinforcement Learning agent (and corresponding library). Developed from a synthesis of state-of-the-art (SOTA) literature and our unique interdisciplinary methodology, AlphaOptimizerNet demonstrates encouraging risk- return optimization across various asset classes with realistic constraints. These preliminary results underscore the practical efficacy of our frameworks. As the finance sector increasingly gravitates towards advanced algorithmic solutions, our study bridges theoretical advancements with real-world applicability, offering a template for ensuring safety and robust standards in this technologically driven future.",
    "keywords": [
      "Portfolio Optimization",
      "Artificial Intelligence",
      "Mathematical Finance",
      "Deep Reinforcement Learning"
    ]
  },
  {
    "article_id": "2403.10916v2_FishNet_Deep_Neural_Networks_for_Low-Cost_Fish_Stock_Estimation",
    "title": "2403.10916v2 FishNet Deep Neural Networks for Low-Cost Fish Stock Estimation",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2403.10916v2_FishNet_Deep_Neural_Networks_for_Low-Cost_Fish_Stock_Estimation.pdf",
    "url": "http://arxiv.org/abs/2403.10916v2_FishNet_Deep_Neural_Networks_for_Low-Cost_Fish_Stock_Estimation",
    "pdf_url": "https://arxiv.org/pdf/2403.10916v2_FishNet_Deep_Neural_Networks_for_Low-Cost_Fish_Stock_Estimation",
    "file_size_mb": 4.6,
    "abstract": "—Fish stock assessment often involves manual fish counting by taxonomy specialists, which is both time-consuming and costly. We propose FishNet, an automated computer vision system for both taxonomic classification and fish size estimation from images captured with a low-cost digital camera. The system first performs object detection and segmentation using a Mask R-CNN to identify individual fish from images containing multiple fish, possibly consisting of different species. Then each fish species is classified and the length is predicted using separate machine learning models. To develop the model, we use a dataset of 300,000 hand-labeled images containing 1.2M fish of 163 different species and ranging in length from 10 cm to 250 cm, with additional annotations and quality control methods used to curate high- quality training data. On held-out test data sets, our system achieves a 92% intersection over union on the fish segmentation task, a 89% top-1 classification accuracy on single fish species classification, and a 2.3 cm mean absolute error on the fish length estimation task.",
    "keywords": [
      "Computer Vision",
      "Fish Stock Estimation",
      "Image"
    ]
  },
  {
    "article_id": "2403.16667v1_Deep_Reinforcement_Learning_and_Mean-Variance_Strategies_for_Responsible_Portfolio_Optimization",
    "title": "2403.16667v1 Deep Reinforcement Learning and Mean-Variance Strategies for Responsible Portfolio Optimization",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2403.16667v1_Deep_Reinforcement_Learning_and_Mean-Variance_Strategies_for_Responsible_Portfolio_Optimization.pdf",
    "url": "http://arxiv.org/abs/2403.16667v1_Deep_Reinforcement_Learning_and_Mean-Variance_Strategies_for_Responsible_Portfolio_Optimization",
    "pdf_url": "https://arxiv.org/pdf/2403.16667v1_Deep_Reinforcement_Learning_and_Mean-Variance_Strategies_for_Responsible_Portfolio_Optimization",
    "file_size_mb": 0.59,
    "abstract": "Portfolio optimization involves determining the optimal allo- cation of portfolio assets in order to maximize a given invest- ment objective. Traditionally, some form of mean-variance optimization is used with the aim of maximizing returns while minimizing risk, however, more recently, deep reinforcement learning formulations have been explored. Increasingly, in- vestors have demonstrated an interest in incorporating ESG objectives when making investment decisions, and modifica- tions to the classical mean-variance optimization framework have been developed. In this work, we study the use of deep reinforcement learning for responsible portfolio optimization, by incorporating ESG states and objectives, and provide com- parisons against modified mean-variance approaches. Our results show that deep reinforcement learning policies can provide competitive performance against mean-variance ap- proaches for responsible portfolio allocation across additive and multiplicative utility functions of financial and ESG re- sponsibility objectives.",
    "keywords": []
  },
  {
    "article_id": "2403.18822v1_Enhancing_Financial_Data_Visualization_for_Investment_Decision-Making",
    "title": "2403.18822v1 Enhancing Financial Data Visualization for Investment Decision-Making",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2403.18822v1_Enhancing_Financial_Data_Visualization_for_Investment_Decision-Making.pdf",
    "url": "http://arxiv.org/abs/2403.18822v1_Enhancing_Financial_Data_Visualization_for_Investment_Decision-Making",
    "pdf_url": "https://arxiv.org/pdf/2403.18822v1_Enhancing_Financial_Data_Visualization_for_Investment_Decision-Making",
    "file_size_mb": 0.41,
    "abstract": "— Navigating the intricate landscape of financial markets requires adept forecasting of stock price movements. This paper delves into the potential of Long Short-Term Memory (LSTM) networks for predicting stock dynamics, with a focus on discerning nuanced rise and fall patterns. Leveraging a dataset from the New York Stock Exchange (NYSE), the study incorporates multiple features to enhance LSTM's capacity in capturing complex patterns. Visualization of key attributes, such as opening, closing, low, and high prices, aids in unraveling subtle distinctions crucial for comprehensive market understanding. The meticulously crafted LSTM input structure, inspired by established guidelines, incorporates both price and volume attributes over a 25-day time step, enabling the model to capture temporal intricacies. A comprehensive methodology, including hyperparameter tuning with Grid Search, Early Stopping, and Callback mechanisms, leads to a remarkable 53% improvement in predictive accuracy. The study concludes with insights into model robustness, contributions to financial forecasting literature, and a roadmap for real-time stock market prediction. The amalgamation of LSTM networks, strategic hyperparameter tuning, and informed feature selection presents a potent framework for advancing the accuracy of stock price predictions, contributing substantively to financial time series forecasting discourse.",
    "keywords": [
      "Stock Price Prediction",
      "Long Short-Term"
    ]
  },
  {
    "article_id": "2403.18823v1_Artificial_Intelligence-based_Analysis_of_Change_in_Public_Finance_between_US_and_International_Mark",
    "title": "2403.18823v1 Artificial Intelligence-based Analysis of Change in Public Finance between US and International Mark",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2403.18823v1_Artificial_Intelligence-based_Analysis_of_Change_in_Public_Finance_between_US_and_International_Mark.pdf",
    "url": "http://arxiv.org/abs/2403.18823v1_Artificial_Intelligence-based_Analysis_of_Change_in_Public_Finance_between_US_and_International_Mark",
    "pdf_url": "https://arxiv.org/pdf/2403.18823v1_Artificial_Intelligence-based_Analysis_of_Change_in_Public_Finance_between_US_and_International_Mark",
    "file_size_mb": 0.19,
    "abstract": "—Public finances are one of the fundamental mech- anisms of economic governance that refer to the financial activities and decisions made by government entities to fund public services, projects, and operations through assets. In today’s globalized landscape, even subtle shifts in one nation’s public debt landscape can have significant impacts on that of international finances, necessitating a nuanced understanding of the correlations between international and national markets to help investors make informed investment decisions. Therefore, by leveraging the capabilities of artificial intelligence, this study utilizes neural networks to depict the correlations between US and International Public Finances and predict the changes in international public finances based on the changes in US public finances. With the neural network model achieving a commendable Mean Squared Error (MSE) value of 2.79, it is able to affirm a discernible correlation and also plot the effect of US market volatility on international markets. To further test the accuracy and significance of the model, an economic analysis was conducted that aimed to correlate the changes seen by the results of the model with historical stock market changes. This model demonstrates significant potential for investors to predict changes in international public finances based on signals from US markets, marking a significant stride in comprehending the intricacies of global public finances and the role of artificial intelligence in decoding its multifaceted patterns for practical forecasting.",
    "keywords": [
      "computational finance",
      "artificial intelligence"
    ]
  },
  {
    "article_id": "2404.00424v3_Quantformer_from_attention_to_profit_with_a_quantitative_transformer_trading_strategy",
    "title": "2404.00424v3 Quantformer from attention to profit with a quantitative transformer trading strategy",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2404.00424v3_Quantformer_from_attention_to_profit_with_a_quantitative_transformer_trading_strategy.pdf",
    "url": "http://arxiv.org/abs/2404.00424v3_Quantformer_from_attention_to_profit_with_a_quantitative_transformer_trading_strategy",
    "pdf_url": "https://arxiv.org/pdf/2404.00424v3_Quantformer_from_attention_to_profit_with_a_quantitative_transformer_trading_strategy",
    "file_size_mb": 1.02,
    "abstract": "In traditional quantitative trading practice, navigating the complicated and dynamic financial market presents a persistent challenge. Fully capturing various market variables, including long-term information, as well as essential signals that may lead to profit remains a difficult task for learning algorithms. In order to tackle this challenge, this paper introduces quantformer, an en- hanced neural network architecture based on transformer, to build investment factors. By transfer learning from sentiment analysis, quantformer not only exploits its original inherent advantages in capturing long-range dependencies and modeling complex data relationships, but is also able to solve tasks with numerical inputs and accurately forecast future returns over a given period. This work collects more than 5,000,000 rolling data of 4,601 stocks in the Chinese capital market from 2010 to 2023. The results of this study demon- strate the model’s superior performance in predicting stock trends compared ∗Co-first authors: zhangzf@umich.edu, chenbanghao@u.nus.edu ∗∗Co-corresponding authors: nicolaslangrene@uic.edu.cn, shengxin.zhu@bnu.edu.cn Preprint submitted to arXiv August 19, 2025 arXiv:2404.00424v3 [q-fin.MF] 18 Aug 2025 with other 100-factor-based quantitative strategies. Notably, the model’s in- novative use of transformer-like model to establish factors, in conjunction with market sentiment information, has been shown to enhance the accu- racy of trading signals significantly, thereby offering promising implications for the future of quantitative trading strategies. The implementation details and code is available on Github.",
    "keywords": [
      "quantformer",
      "transformer",
      "neural networks",
      "quantitative"
    ]
  },
  {
    "article_id": "2404.01624v1_Intelligent_Optimization_of_Mine_Environmental_Damage_Assessment_and_Repair_Strategies_Based_on_Deep",
    "title": "2404.01624v1 Intelligent Optimization of Mine Environmental Damage Assessment and Repair Strategies Based on Deep",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2404.01624v1_Intelligent_Optimization_of_Mine_Environmental_Damage_Assessment_and_Repair_Strategies_Based_on_Deep.pdf",
    "url": "http://arxiv.org/abs/2404.01624v1_Intelligent_Optimization_of_Mine_Environmental_Damage_Assessment_and_Repair_Strategies_Based_on_Deep",
    "pdf_url": "https://arxiv.org/pdf/2404.01624v1_Intelligent_Optimization_of_Mine_Environmental_Damage_Assessment_and_Repair_Strategies_Based_on_Deep",
    "file_size_mb": 1.25,
    "abstract": "—In recent decades, financial quantification has emerged and matured rapidly. For financial institutions such as funds, investment institutions are increasingly dissatisfied with the situation of passively constructing investment portfolios with average market returns, and are paying more and more attention to active quantitative strategy investment portfolios. This requires the introduction of active stock investment fund management models. Currently, in my country's stock fund investment market, there are many active quantitative investment strategies, and the algorithms used vary widely, such as SVM, random forest, RNN recurrent memory network, etc. This article focuses on this trend, using the emerging LSTM-GRU gate-controlled long short-term memory network model in the field of financial stock investment as a basis to build a set of active investment stock strategies, and combining it with SVM, which has been widely used in the field of quantitative stock investment. Comparing models such as RNN, theoretically speaking, compared to SVM that simply relies on kernel functions for high-order mapping and classification of data, neural network algorithms such as RNN and LSTM-GRU have better principles and are more suitable for processing financial stock data. Then, through multiple By comparison, it was finally found that the LSTM- GRU gate-controlled long short-term memory network has a better accuracy. By selecting the LSTM-GRU algorithm to construct a trading strategy based on the Shanghai and Shenzhen 300 Index constituent stocks, the parameters were adjusted and the neural layer connection was adjusted. Finally, It has significantly outperformed the benchmark index CSI 300 over the long term. The conclusion of this article is that the research results can provide certain quantitative strategy references for financial institutions to construct active stock investment portfolios.",
    "keywords": [
      "Quantitative investment",
      "LSTM-GRU network"
    ]
  },
  {
    "article_id": "2404.08935v1_Developing_An_Attention-Based_Ensemble_Learning_Framework_for_Financial_Portfolio_Optimisation",
    "title": "2404.08935v1 Developing An Attention-Based Ensemble Learning Framework for Financial Portfolio Optimisation",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2404.08935v1_Developing_An_Attention-Based_Ensemble_Learning_Framework_for_Financial_Portfolio_Optimisation.pdf",
    "url": "http://arxiv.org/abs/2404.08935v1_Developing_An_Attention-Based_Ensemble_Learning_Framework_for_Financial_Portfolio_Optimisation",
    "pdf_url": "https://arxiv.org/pdf/2404.08935v1_Developing_An_Attention-Based_Ensemble_Learning_Framework_for_Financial_Portfolio_Optimisation",
    "file_size_mb": 0.72,
    "abstract": "—In recent years, deep or reinforcement learning approaches have been applied to optimise investment portfolios through learning the spatial and temporal information under the dynamic financial market. Yet in most cases, the existing approaches may produce biased trading signals based on the con- ventional price data due to a lot of market noises, which possibly fails to balance the investment returns and risks. Accordingly, a multi-agent and self-adaptive portfolio optimisation framework integrated with attention mechanisms and time series, namely the MASAAT, is proposed in this work in which multiple trading agents are created to observe and analyse the price series and directional change data that recognises the significant changes of asset prices at different levels of granularity for enhancing the signal-to-noise ratio of price series. Afterwards, by reconstructing the tokens of financial data in a sequence, the attention-based cross-sectional analysis module and temporal analysis module of each agent can effectively capture the correlations between assets and the dependencies between time points. Besides, a portfolio generator is integrated into the proposed framework to fuse the spatial-temporal information and then summarise the portfolios suggested by all trading agents to produce a newly ensemble portfolio for reducing biased trading actions and balancing the overall returns and risks. The experimental results clearly demonstrate that the MASAAT framework achieves impressive enhancement when compared with many well-known portfolio optimsation approaches on three challenging data sets of DJIA, S&P 500 and CSI 300. More importantly, our proposal has potential strengths in many possible applications for future study.",
    "keywords": [
      "attention mechanism",
      "directional change",
      "multi-"
    ]
  },
  {
    "article_id": "2404.10683v1_Simplex_Decomposition_for_Portfolio_Allocation_Constraints_in_Reinforcement_Learning",
    "title": "2404.10683v1 Simplex Decomposition for Portfolio Allocation Constraints in Reinforcement Learning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2404.10683v1_Simplex_Decomposition_for_Portfolio_Allocation_Constraints_in_Reinforcement_Learning.pdf",
    "url": "http://arxiv.org/abs/2404.10683v1_Simplex_Decomposition_for_Portfolio_Allocation_Constraints_in_Reinforcement_Learning",
    "pdf_url": "https://arxiv.org/pdf/2404.10683v1_Simplex_Decomposition_for_Portfolio_Allocation_Constraints_in_Reinforcement_Learning",
    "file_size_mb": 0.37,
    "abstract": ". Portfolio optimization tasks describe sequential decision problems in which the investor’s wealth is distributed across a set of assets. Allocation constraints are used to enforce minimal or maxi- mal investments into particular subsets of assets to control for objec- tives such as limiting the portfolio’s exposure to a certain sector due to environmental concerns. Although methods for constrained Rein- forcement Learning (CRL) can optimize policies while considering allocation constraints, it can be observed that these general methods yield suboptimal results. In this paper, we propose a novel approach to handle allocation constraints based on a decomposition of the con- straint action space into a set of unconstrained allocation problems. In particular, we examine this approach for the case of two con- straints. For example, an investor may wish to invest at least a certain percentage of the portfolio into green technologies while limiting the investment in the fossil energy sector. We show that the action space of the task is equivalent to the decomposed action space, and intro- duce a new reinforcement learning (RL) approach CAOSD, which is built on top of the decomposition. The experimental evaluation on real-world Nasdaq-100 data demonstrates that our approach con- sistently outperforms state-of-the-art CRL benchmarks for portfolio optimization.",
    "keywords": []
  },
  {
    "article_id": "2404.12598v1_Continuous-time_Risk-sensitive_Reinforcement_Learning_via_Quadratic_Variation_Penalty",
    "title": "2404.12598v1 Continuous-time Risk-sensitive Reinforcement Learning via Quadratic Variation Penalty",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2404.12598v1_Continuous-time_Risk-sensitive_Reinforcement_Learning_via_Quadratic_Variation_Penalty.pdf",
    "url": "http://arxiv.org/abs/2404.12598v1_Continuous-time_Risk-sensitive_Reinforcement_Learning_via_Quadratic_Variation_Penalty",
    "pdf_url": "https://arxiv.org/pdf/2404.12598v1_Continuous-time_Risk-sensitive_Reinforcement_Learning_via_Quadratic_Variation_Penalty",
    "file_size_mb": 0.71,
    "abstract": "This paper studies continuous-time risk-sensitive reinforcement learning (RL) under the entropy-regularized, exploratory diﬀusion process formulation with the exponential-form ob- jective. The risk-sensitive objective arises either as the agent’s risk attitude or as a distribu- tionally robust approach against the model uncertainty. Owing to the martingale perspective in Jia and Zhou (2023), the risk-sensitive RL problem is shown to be equivalent to ensuring the martingale property of a process involving both the value function and the q-function, augmented by an additional penalty term: the quadratic variation of the value process, captur- ing the variability of the value-to-go along the trajectory. This characterization allows for the straightforward adaptation of existing RL algorithms developed for non-risk-sensitive scenarios to incorporate risk sensitivity by adding the realized variance of the value process. Additionally, I highlight that the conventional policy gradient representation is inadequate for risk-sensitive problems due to the nonlinear nature of quadratic variation; however, q-learning oﬀers a solution and extends to inﬁnite horizon settings. Finally, I prove the convergence of the proposed algo- rithm for Merton’s investment problem and quantify the impact of temperature parameter on the behavior of the learning procedure. I also conduct simulation experiments to demonstrate how risk-sensitive RL improves the ﬁnite-sample performance in the linear-quadratic control problem.",
    "keywords": [
      "risk-sensitive control",
      "continuous-time reinforcement learning",
      "exponential martingale",
      "quadratic"
    ]
  },
  {
    "article_id": "2405.01604v1_Portfolio_Management_using_Deep_Reinforcement_Learning",
    "title": "2405.01604v1 Portfolio Management using Deep Reinforcement Learning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2405.01604v1_Portfolio_Management_using_Deep_Reinforcement_Learning.pdf",
    "url": "http://arxiv.org/abs/2405.01604v1_Portfolio_Management_using_Deep_Reinforcement_Learning",
    "pdf_url": "https://arxiv.org/pdf/2405.01604v1_Portfolio_Management_using_Deep_Reinforcement_Learning",
    "file_size_mb": 1.04,
    "abstract": null,
    "keywords": [
      "Portfolio Management",
      "Deep Learning",
      "Deep Reinforcement Learning"
    ]
  },
  {
    "article_id": "2405.03151v1_Time_Series_Stock_Price_Forecasting_Based_on_Genetic_Algorithm_GA-Long_Short-Term_Memory_Network_LST",
    "title": "2405.03151v1 Time Series Stock Price Forecasting Based on Genetic Algorithm GA-Long Short-Term Memory Network LST",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2405.03151v1_Time_Series_Stock_Price_Forecasting_Based_on_Genetic_Algorithm_GA-Long_Short-Term_Memory_Network_LST.pdf",
    "url": "http://arxiv.org/abs/2405.03151v1_Time_Series_Stock_Price_Forecasting_Based_on_Genetic_Algorithm_GA-Long_Short-Term_Memory_Network_LST",
    "pdf_url": "https://arxiv.org/pdf/2405.03151v1_Time_Series_Stock_Price_Forecasting_Based_on_Genetic_Algorithm_GA-Long_Short-Term_Memory_Network_LST",
    "file_size_mb": 0.48,
    "abstract": ". In this paper, a time series algorithm based on Genetic Algorithm (GA) and Long Short-Term Memory Network (LSTM) optimization is used to forecast stock prices effectively, taking into account the trend of the big data era. The data are first analyzed by descriptive statistics, and then the model is built and trained and tested on the dataset. After optimization and adjustment, the mean absolute error (MAE) of the model gradually decreases from 0.11 to 0.01 and tends to be stable, indicating that the model prediction effect is gradually close to the real value. The results on the test set show that the time series algorithm optimized based on Genetic Algorithm (GA)-Long Short-Term Memory Network (LSTM) is able to accurately predict the stock prices, and is highly consistent with the actual price trends and values, with strong generalization ability. The MAE on the test set is 2.41, the MSE is 9.84, the RMSE is 3.13, and the R2 is 0.87. This research result not only provides a novel stock price prediction method, but also provides a useful reference for financial market analysis using computer technology and big data.",
    "keywords": [
      "Time Series Stock",
      "LSTM",
      "Genetic Algorithm"
    ]
  },
  {
    "article_id": "2405.05449v1_Markowitz_Meets_Bellman_Knowledge-distilled_Reinforcement_Learning_for_Portfolio_Management",
    "title": "2405.05449v1 Markowitz Meets Bellman Knowledge-distilled Reinforcement Learning for Portfolio Management",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2405.05449v1_Markowitz_Meets_Bellman_Knowledge-distilled_Reinforcement_Learning_for_Portfolio_Management.pdf",
    "url": "http://arxiv.org/abs/2405.05449v1_Markowitz_Meets_Bellman_Knowledge-distilled_Reinforcement_Learning_for_Portfolio_Management",
    "pdf_url": "https://arxiv.org/pdf/2405.05449v1_Markowitz_Meets_Bellman_Knowledge-distilled_Reinforcement_Learning_for_Portfolio_Management",
    "file_size_mb": 0.66,
    "abstract": null,
    "keywords": []
  },
  {
    "article_id": "2405.08089v1_Comparative_Study_of_Bitcoin_Price_Prediction",
    "title": "2405.08089v1 Comparative Study of Bitcoin Price Prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2405.08089v1_Comparative_Study_of_Bitcoin_Price_Prediction.pdf",
    "url": "http://arxiv.org/abs/2405.08089v1_Comparative_Study_of_Bitcoin_Price_Prediction",
    "pdf_url": "https://arxiv.org/pdf/2405.08089v1_Comparative_Study_of_Bitcoin_Price_Prediction",
    "file_size_mb": 0.85,
    "abstract": "—Prediction of stock prices has been a crucial and challenging task, especially in the case of highly volatile digital currencies such as Bitcoin. This research examineS the potential of using neural network models, namely LSTMs and GRUs, to forecast Bitcoin’s price movements. We employ five-fold cross- validation to enhance generalization and utilize L2 regularization to reduce overfitting and noise. Our study demonstrates that the GRUs models offer better accuracy than LSTMs model for predicting Bitcoin’s price. Specifically, the GRU model has an MSE of 4.67, while the LSTM model has an MSE of 6.25 when compared to the actual prices in the test set data. This finding indicates that GRU models are better equipped to process sequen- tial data with long-term dependencies, a characteristic of financial time series data such as Bitcoin prices. In summary, our results provide valuable insights into the potential of neural network models for accurate Bitcoin price prediction and emphasize the importance of employing appropriate regularization techniques to enhance model performance.",
    "keywords": [
      "Bitcoin",
      "price prediction",
      "LSTMs",
      "GRUs",
      "neural"
    ]
  },
  {
    "article_id": "2405.08284v1_Predicting_NVIDIAs_Next-Day_Stock_Price_A_Comparative_Analysis_of_LSTM_MLP_ARIMA_and_ARIMA-GARCH_Mod",
    "title": "2405.08284v1 Predicting NVIDIAs Next-Day Stock Price A Comparative Analysis of LSTM MLP ARIMA and ARIMA-GARCH Mod",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2405.08284v1_Predicting_NVIDIAs_Next-Day_Stock_Price_A_Comparative_Analysis_of_LSTM_MLP_ARIMA_and_ARIMA-GARCH_Mod.pdf",
    "url": "http://arxiv.org/abs/2405.08284v1_Predicting_NVIDIAs_Next-Day_Stock_Price_A_Comparative_Analysis_of_LSTM_MLP_ARIMA_and_ARIMA-GARCH_Mod",
    "pdf_url": "https://arxiv.org/pdf/2405.08284v1_Predicting_NVIDIAs_Next-Day_Stock_Price_A_Comparative_Analysis_of_LSTM_MLP_ARIMA_and_ARIMA-GARCH_Mod",
    "file_size_mb": 0.87,
    "abstract": "Forecasting stock prices remains a considerable challenge in financial markets, bearing significant implications for investors, traders, and financial institutions. Amid the ongoing AI revolution, NVIDIA has emerged as a key player driving innovation across various sectors. Given its prominence, we chose NVIDIA as the subject of our study. We evaluate the effectiveness of four different forecasting models on NVIDIA's next day stock prices: Autoregressive Integrated Moving Average (ARIMA), Multilayer Perceptron Network (MLP), Long Short-Term Memory (LSTM) networks, and ARIMA integrated with the Generalized Autoregressive Conditional Heteroskedasticity (GARCH) model. Utilizing data sourced from Yahoo Finance's API over a five-year period, from April 12, 2019, to April 11, 2024, we perform detailed analyses and assessments of NVIDIA’s stock performance. Our findings indicate that the innovative ARIMA-GARCH model outperforms the others in terms of Root Mean Square Error (RMSE) for predicting NVIDIA's next day stock prices. This result underscores the effectiveness of combining volatility modeling with other time series forecasting techniques to enhance prediction accuracy in volatile financial markets.",
    "keywords": [
      "Stock prediction",
      "NVDIA",
      "ARIMA",
      "MLP",
      "LSTM"
    ]
  },
  {
    "article_id": "2405.08602v1_Optimizing_Deep_Reinforcement_Learning_for_American_Put_Option_Hedging",
    "title": "2405.08602v1 Optimizing Deep Reinforcement Learning for American Put Option Hedging",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2405.08602v1_Optimizing_Deep_Reinforcement_Learning_for_American_Put_Option_Hedging.pdf",
    "url": "http://arxiv.org/abs/2405.08602v1_Optimizing_Deep_Reinforcement_Learning_for_American_Put_Option_Hedging",
    "pdf_url": "https://arxiv.org/pdf/2405.08602v1_Optimizing_Deep_Reinforcement_Learning_for_American_Put_Option_Hedging",
    "file_size_mb": 0.48,
    "abstract": "This paper contributes to the existing literature on hedging American options with Deep Reinforcement Learning (DRL). The study first investigates hyperparameter impact on hedging performance, considering learning rates, training episodes, neural network architectures, training steps, and transaction cost penalty functions. Results highlight the importance of avoiding certain combinations, such as high learning rates with a high number of training episodes or low learning rates with few training episodes and emphasize the significance of utilizing moderate values for optimal outcomes. Additionally, the paper warns against excessive training steps to prevent instability and demonstrates the superiority of a quadratic transaction cost penalty function over a linear version. This study then expands upon the work of Pickard et al. (2024), who utilize a Chebyshev interpolation option pricing method to train DRL agents with market calibrated stochastic volatility models. While the results of Pickard et al. (2024) showed that these DRL agents achieve satisfactory performance on empirical asset paths, this study introduces a novel approach where new agents at weekly intervals to newly calibrated stochastic volatility models. Results show DRL agents re-trained using weekly market data surpass the performance of those trained solely on the sale date. Furthermore, the paper demonstrates that both single-train and weekly-train DRL agents outperform the Black-Scholes Delta method at transaction costs of 1% and 3%. This practical relevance suggests that practitioners can leverage readily available market data to train DRL agents for effective hedging of options in their portfolios.",
    "keywords": [
      "reinforcement learning",
      "neural networks",
      "dynamic stock option"
    ]
  },
  {
    "article_id": "2405.11431v2_Review_of_deep_learning_models_for_crypto_price_prediction_implementation_and_evaluation",
    "title": "2405.11431v2 Review of deep learning models for crypto price prediction implementation and evaluation",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2405.11431v2_Review_of_deep_learning_models_for_crypto_price_prediction_implementation_and_evaluation.pdf",
    "url": "http://arxiv.org/abs/2405.11431v2_Review_of_deep_learning_models_for_crypto_price_prediction_implementation_and_evaluation",
    "pdf_url": "https://arxiv.org/pdf/2405.11431v2_Review_of_deep_learning_models_for_crypto_price_prediction_implementation_and_evaluation",
    "file_size_mb": 10.02,
    "abstract": "There has been much interest in accurate cryptocurrency price forecast models by investors and researchers. Deep Learning models are prominent machine learning techniques that have transformed various fields and have shown potential for finance and economics. Although various deep learning models have been explored for cryptocurrency price forecasting, it is not clear which models are suitable due to high market volatility. In this study, we review the literature about deep learning for cryptocurrency price forecasting and evaluate novel deep learning models for cryptocurrency stock price prediction. Our deep learning models include variants of long short-term memory (LSTM) recurrent neural networks, variants of convolutional neural networks (CNNs), and the Transformer model. We evaluate univariate and multivariate approaches for multi-step ahead predicting of cryptocurrencies close-price. We also carry out volatility analysis on the four cryptocurrencies which reveals significant fluctuations in their prices throughout the COVID-19 pandemic. Additionally, we investigate the prediction accuracy of two scenarios identified by different training sets for the models. First, we use the pre-COVID-19 datasets to model cryptocurrency close-price forecasting during the early period of COVID-19. Secondly, we utilise data from the COVID-19 period to predict prices for 2023 to 2024. Our results show that the convolutional LSTM with a multivariate approach provides the best prediction accuracy in two major experimental settings. Our results also indicate that the multivariate deep learning models exhibit better performance in forecasting four different cryptocurrencies when compared to the univariate models.",
    "keywords": [
      "cryptocurrency",
      "deep learning",
      "time series prediciton"
    ]
  },
  {
    "article_id": "2405.11686v1_Exploiting_Distributional_Value_Functions_for_Financial_Market_Valuation_Enhanced_Feature_Creation_a",
    "title": "2405.11686v1 Exploiting Distributional Value Functions for Financial Market Valuation Enhanced Feature Creation a",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2405.11686v1_Exploiting_Distributional_Value_Functions_for_Financial_Market_Valuation_Enhanced_Feature_Creation_a.pdf",
    "url": "http://arxiv.org/abs/2405.11686v1_Exploiting_Distributional_Value_Functions_for_Financial_Market_Valuation_Enhanced_Feature_Creation_a",
    "pdf_url": "https://arxiv.org/pdf/2405.11686v1_Exploiting_Distributional_Value_Functions_for_Financial_Market_Valuation_Enhanced_Feature_Creation_a",
    "file_size_mb": 1.19,
    "abstract": "Many research studies of reinforcement learning applied to financial markets have been published in recent years. While they predominantly concentrate on finding optimal behaviours or trading rules, it is worth to take a step back and realize that the reinforcement learning returns Gt and state value functions themselves are of interest and play a pivotal role when it comes to the evaluation of assets. Thus, in this paper instead of focussing on the more complex task of finding optimal decision rules, the power of distributional state value functions is for the first time studied and applied in the context of financial market valuation and machine learning based trading algorithms. Although the values of Gt, representing a time weighted average of future market changes, cannot be known explicitly ahead of time, accurate and trustworthy estimates of their distributions and expected values provide a competitive edge leading to better informed decisions and more optimal behaviour. Herein, ideas from predictive knowledge and deep reinforcement learning are combined to introduce a novel family of models called CDG-Model, resulting in a highly flexible framework in the context of financial markets and intuitive approach with minimal assumptions regarding underlying distributions. The models allow seamless integration of typical financial modelling pitfalls like transaction costs, slippage and other possible costs or benefits into the model calculation. They can be applied to any kind of trading strategy or asset class. The frameworks introduced provide concrete business value through their potential in market valuation of single assets and portfolios, in the comparison of strategies as well as in the improvement of market timing. In addition, they can positively impact the performance and enhance the learning process of existing or new trading algorithms. They are of interest from a scientific point-of- view and open up multiple areas of future research. Initial implementations and tests were performed on real market data. While the results are promising, applying a robust statistical framework to evaluate the models in general remains a challenge and further investigations are needed.",
    "keywords": [
      "Quantitative Finance",
      "Machine Learning in Finance",
      "Deep Reinforcement Learning",
      "Predictive Knowl-"
    ]
  },
  {
    "article_id": "2405.11730v1_Degree_of_Irrationality_Sentiment_and_Implied_Volatility_Surface",
    "title": "2405.11730v1 Degree of Irrationality Sentiment and Implied Volatility Surface",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2405.11730v1_Degree_of_Irrationality_Sentiment_and_Implied_Volatility_Surface.pdf",
    "url": "http://arxiv.org/abs/2405.11730v1_Degree_of_Irrationality_Sentiment_and_Implied_Volatility_Surface",
    "pdf_url": "https://arxiv.org/pdf/2405.11730v1_Degree_of_Irrationality_Sentiment_and_Implied_Volatility_Surface",
    "file_size_mb": 1.26,
    "abstract": "In this study, we constructed daily high-frequency sentiment data and used the VAR method to attempt to predict the next day’s implied volatility surface. We utilized 630,000 text data entries from East Money Stock Forum from 2014 to 2023, and employed deep learning methods such as BERT and LSTM to build daily market sentiment indicators. By applying FFT and EMD methods for sentiment decomposition, we found that high-frequency senti- ment had a stronger correlation with at-the-money (ATM) options’ implied volatility, while low-frequency sentiment was more strongly correlated with deep out-of-the-money (DOTM) options’ implied volatility. Further analysis revealed that the shape of the implied volatility surface contains richer market sentiment information beyond just market panic. We demon- strated that incorporating this sentiment information can improve the accuracy of implied volatility surface predictions.",
    "keywords": [
      "implied volatility surface",
      "market sentiment",
      "deep learning"
    ]
  },
  {
    "article_id": "2405.13609v3_Tackling_Decision_Processes_with_Non-Cumulative_Objectives_using_Reinforcement_Learning",
    "title": "2405.13609v3 Tackling Decision Processes with Non-Cumulative Objectives using Reinforcement Learning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2405.13609v3_Tackling_Decision_Processes_with_Non-Cumulative_Objectives_using_Reinforcement_Learning.pdf",
    "url": "http://arxiv.org/abs/2405.13609v3_Tackling_Decision_Processes_with_Non-Cumulative_Objectives_using_Reinforcement_Learning",
    "pdf_url": "https://arxiv.org/pdf/2405.13609v3_Tackling_Decision_Processes_with_Non-Cumulative_Objectives_using_Reinforcement_Learning",
    "file_size_mb": 3.45,
    "abstract": "Markov decision processes (MDPs) are used to model a wide variety of applications ranging from game playing over robotics to finance. Their optimal policy typically maximizes the expected sum of rewards given at each step of the decision process. However, many real- world problems do not fit straightforwardly into this framework: Non-cumulative Markov decision processes (NCMDPs), where instead of the expected sum of rewards, the expected value of an arbitrary function of the rewards is maximized. Example functions include the maximum of the rewards or their mean divided by their standard deviation. In this work, we introduce a general mapping of NCMDPs to standard MDPs. This allows all techniques developed to find optimal policies for MDPs, such as reinforcement learning or dynamic programming, to be directly applied to the larger class of NCMDPs. We demonstrate the effectiveness of our approach in diverse reinforcement learning tasks, including classical control, financial portfolio optimization, and discrete optimization. Our approach improves both final performance and training efficiency compared to relying on standard MDPs.",
    "keywords": [
      "Markov Decision Processes",
      "Reinforcement Learning",
      "Deep Learning",
      "Discrete"
    ]
  },
  {
    "article_id": "2405.15833v1_DSPO_An_End-to-End_Framework_for_Direct_Sorted_Portfolio_Construction",
    "title": "2405.15833v1 DSPO An End-to-End Framework for Direct Sorted Portfolio Construction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2405.15833v1_DSPO_An_End-to-End_Framework_for_Direct_Sorted_Portfolio_Construction.pdf",
    "url": "http://arxiv.org/abs/2405.15833v1_DSPO_An_End-to-End_Framework_for_Direct_Sorted_Portfolio_Construction",
    "pdf_url": "https://arxiv.org/pdf/2405.15833v1_DSPO_An_End-to-End_Framework_for_Direct_Sorted_Portfolio_Construction",
    "file_size_mb": 0.7,
    "abstract": "In quantitative investment, constructing characteristic-sorted portfolios is a cru- cial strategy for asset allocation. Traditional methods transform raw stock data of varying frequencies into predictive characteristic factors for asset sorting, of- ten requiring extensive manual design and misalignment between prediction and optimization goals. To address these challenges, we introduce Direct Sorted Port- folio Optimization (DSPO), an innovative end-to-end framework that efficiently processes raw stock data to construct sorted portfolios directly. DSPO’s neural network architecture seamlessly transitions stock data from input to output while effectively modeling the intra-dependency of time-steps and inter-dependency among all tradable stocks. Additionally, we incorporate a novel Monotonical Lo- gistic Regression loss, which directly maximizes the likelihood of constructing optimal sorted portfolios. To the best of our knowledge, DSPO is the first method capable of handling market cross-sections with thousands of tradable stocks fully end-to-end from raw multi-frequency data. Empirical results demonstrate DSPO’s effectiveness, yielding a RankIC4 of 10.12% and an accumulated return of 121.94% on the New York Stock Exchange in 2023-2024, and a RankIC of 9.11% with a return of 108.74% in other markets during 2021-2022. 2021-01-23 2021-03-14 2021-05-03 2021-06-22 2021-08-11 2021-09-30 2021-11-19 57.2±1.4% 16.4±7.4% 31.2±14.8% DSPO (Ours) CNN DIN Figure 1: Comparison of the mean accumulative return (colored lines) and its variance across eight trials (color spread around the lines) during the 2021-2022 backtesting period in A-Share market. Our Direct Sorted Portfolio Optimization (DSPO) framework DOUBLES the accumulative return with 1/10 the variance across different trials over other approaches. ∗These authors contributed equally to this work. †Work during an internship at IDEA Research. ‡Corresponding author 4RankIC, a non-parametric rank-based measure of prediction accuracy, measures the Spearman correlation between predicted and actual asset returns Preprint. Under review. arXiv:2405.15833v1 [q-fin.PM] 24 May 2024",
    "keywords": []
  },
  {
    "article_id": "2405.16449v5_Reinforcement_Learning_for_Jump-Diffusions_with_Financial_Applications",
    "title": "2405.16449v5 Reinforcement Learning for Jump-Diffusions with Financial Applications",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2405.16449v5_Reinforcement_Learning_for_Jump-Diffusions_with_Financial_Applications.pdf",
    "url": "http://arxiv.org/abs/2405.16449v5_Reinforcement_Learning_for_Jump-Diffusions_with_Financial_Applications",
    "pdf_url": "https://arxiv.org/pdf/2405.16449v5_Reinforcement_Learning_for_Jump-Diffusions_with_Financial_Applications",
    "file_size_mb": 1.06,
    "abstract": "We study continuous-time reinforcement learning (RL) for stochastic control in which sys- tem dynamics are governed by jump-diffusion processes. We formulate an entropy-regularized exploratory control problem with stochastic policies to capture the exploration–exploitation balance essential for RL. Unlike the pure diffusion case initially studied by Wang et al. (2020), the derivation of the exploratory dynamics under jump-diffusions calls for a careful formulation of the jump part. Through a theoretical analysis, we find that one can simply use the same policy evaluation and q-learning algorithms in Jia and Zhou (2022a, 2023), originally developed for controlled diffusions, without needing to check a priori whether the underlying data come from a pure diffusion or a jump-diffusion. However, we show that the presence of jumps ought to affect parameterizations of actors and critics in general. We investigate as an application the mean–variance portfolio selection problem with stock price modelled as a jump-diffusion, and show that both RL algorithms and parameterizations are invariant with respect to jumps. Finally, we present a detailed study on applying the general theory to option hedging.",
    "keywords": [
      "Reinforcement learning",
      "continuous time",
      "jump-diffusions",
      "exploratory formulation"
    ]
  },
  {
    "article_id": "2406.02604v1_Gated_recurrent_neural_network_with_TPE_Bayesian_optimization_for_enhancing_stock_index_prediction_a",
    "title": "2406.02604v1 Gated recurrent neural network with TPE Bayesian optimization for enhancing stock index prediction a",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2406.02604v1_Gated_recurrent_neural_network_with_TPE_Bayesian_optimization_for_enhancing_stock_index_prediction_a.pdf",
    "url": "http://arxiv.org/abs/2406.02604v1_Gated_recurrent_neural_network_with_TPE_Bayesian_optimization_for_enhancing_stock_index_prediction_a",
    "pdf_url": "https://arxiv.org/pdf/2406.02604v1_Gated_recurrent_neural_network_with_TPE_Bayesian_optimization_for_enhancing_stock_index_prediction_a",
    "file_size_mb": 1.52,
    "abstract": "The recent advancement of deep learning architectures, neural networks, and the combination of abundant financial data and powerful computers are transforming finance, leading us to develop an advanced method for predicting future stock prices. However, the accessibility of investment and trading at everyone's fingertips made the stock markets increasingly intricate and prone to volatility. The increased complexity and volatility of the stock market have driven demand for more models, which would effectively capture high volatility and non-linear behavior of the different stock prices. This study explored gated recurrent neural network (GRNN) algorithms such as LSTM (long short- term memory), GRU (gated recurrent unit), and hybrid models like GRU-LSTM, LSTM-GRU, with Tree- structured Parzen Estimator (TPE) Bayesian optimization for hyperparameter optimization (TPE- GRNN). The aim is to improve the prediction accuracy of the next day's closing price of the NIFTY 50 index, a prominent Indian stock market index, using TPE-GRNN. A combination of eight influential factors is carefully chosen from fundamental stock data, technical indicators, crude oil price, and macroeconomic data to train the models for capturing the changes in the price of the index with the factors of the broader economy. Single-layer and multi-layer TPE-GRNN models have been developed. The models’ performance is evaluated using standard matrices like R2, MAPE, and RMSE. The analysis of models’ performance reveals the impact of feature selection and hyperparameter optimization (HPO) in enhancing stock index price prediction accuracy. The results show that the MAPE of our proposed TPE-LSTM method is the lowest (best) with respect to all the previous models for stock index price prediction.",
    "keywords": [
      "LSTM",
      "GRU",
      "GRU-LSTM",
      "LSTM-GRU",
      "NIFTY 50",
      "TPE Bayesian optimization"
    ]
  },
  {
    "article_id": "2406.07888v2_Classification_Modeling_with_RNN-Based_Random_Forest_and_XGBoost_for_Imbalanced_Data_A_Case_of_Early",
    "title": "2406.07888v2 Classification Modeling with RNN-Based Random Forest and XGBoost for Imbalanced Data A Case of Early",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2406.07888v2_Classification_Modeling_with_RNN-Based_Random_Forest_and_XGBoost_for_Imbalanced_Data_A_Case_of_Early.pdf",
    "url": "http://arxiv.org/abs/2406.07888v2_Classification_Modeling_with_RNN-Based_Random_Forest_and_XGBoost_for_Imbalanced_Data_A_Case_of_Early",
    "pdf_url": "https://arxiv.org/pdf/2406.07888v2_Classification_Modeling_with_RNN-Based_Random_Forest_and_XGBoost_for_Imbalanced_Data_A_Case_of_Early",
    "file_size_mb": 0.52,
    "abstract": ". Purpose: This research aims to evaluate the performance of several Recurrent Neural Network (RNN) architectures, including Simple RNN, Gated Recurrent Units (GRU), and Long Short-Term Memory (LSTM), compared to classic algorithms such as Random Forest and XGBoost, in building classification models for early crash detection in the ASEAN-5 stock markets. Methods: The study examines imbalanced data, which is expected due to the rarity of market crashes. It analyzes daily data from 2010 to 2023 across the major stock markets of the ASEAN-5 countries: Indonesia, Malaysia, Singapore, Thailand, and the Philippines. A market crash is the target variable when the primary stock price indices fall below the Value at Risk (VaR) thresholds of 5%, 2.5%, and 1%. Predictors include technical indicators from major local and global markets and commodity markets. The study incorporates 213 predictors with their respective lags (5, 10, 15, 22, 50, 200) and uses a time step of 7, expanding the total number of predictors to 1,491. The challenge of data imbalance is addressed with SMOTE-ENN. Model performance is evaluated using the false alarm rate, hit rate, balanced accuracy, and the precision-recall curve (PRC) score. Result: The results indicate that all RNN-based architectures outperform Random Forest and XGBoost. Among the various RNN architectures, Simple RNN is the most superior, primarily due to its simple data characteristics and focus on short-term information. Novelty: This study enhances and extends the range of phenomena observed in previous studies by incorporating variables such as different geographical zones and periods and methodological adjustments.",
    "keywords": [
      "Early crash detection",
      "GRU",
      "LSTM",
      "RNN",
      "Random forest",
      "XGBoost"
    ]
  },
  {
    "article_id": "2406.18394v5_AlphaForge_A_Framework_to_Mine_and_Dynamically_Combine_Formulaic_Alpha_Factors",
    "title": "2406.18394v5 AlphaForge A Framework to Mine and Dynamically Combine Formulaic Alpha Factors",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2406.18394v5_AlphaForge_A_Framework_to_Mine_and_Dynamically_Combine_Formulaic_Alpha_Factors.pdf",
    "url": "http://arxiv.org/abs/2406.18394v5_AlphaForge_A_Framework_to_Mine_and_Dynamically_Combine_Formulaic_Alpha_Factors",
    "pdf_url": "https://arxiv.org/pdf/2406.18394v5_AlphaForge_A_Framework_to_Mine_and_Dynamically_Combine_Formulaic_Alpha_Factors",
    "file_size_mb": 2.92,
    "abstract": "The complexity of financial data, characterized by its vari- ability and low signal-to-noise ratio, necessitates advanced methods in quantitative investment that prioritize both per- formance and interpretability.Transitioning from early man- ual extraction to genetic programming, the most advanced approach in the alpha factor mining domain currently em- ploys reinforcement learning to mine a set of combination factors with fixed weights. However, the performance of re- sultant alpha factors exhibits inconsistency, and the inflexi- bility of fixed factor weights proves insufficient in adapting to the dynamic nature of financial markets. To address this issue, this paper proposes a two-stage formulaic alpha gen- erating framework AlphaForge, for alpha factor mining and factor combination. This framework employs a generative- predictive neural network to generate factors, leveraging the robust spatial exploration capabilities inherent in deep learn- ing while concurrently preserving diversity. The combination model within the framework incorporates the temporal per- formance of factors for selection and dynamically adjusts the weights assigned to each component alpha factor. Ex- periments conducted on real-world datasets demonstrate that our proposed model outperforms contemporary benchmarks in formulaic alpha factor mining. Furthermore, our model ex- hibits a notable enhancement in portfolio returns within the realm of quantitative investment and real money investment.",
    "keywords": []
  },
  {
    "article_id": "2407.01572v1_Exploring_Sectoral_Profitability_in_the_Indian_Stock_Market_Using_Deep_Learning",
    "title": "2407.01572v1 Exploring Sectoral Profitability in the Indian Stock Market Using Deep Learning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2407.01572v1_Exploring_Sectoral_Profitability_in_the_Indian_Stock_Market_Using_Deep_Learning.pdf",
    "url": "http://arxiv.org/abs/2407.01572v1_Exploring_Sectoral_Profitability_in_the_Indian_Stock_Market_Using_Deep_Learning",
    "pdf_url": "https://arxiv.org/pdf/2407.01572v1_Exploring_Sectoral_Profitability_in_the_Indian_Stock_Market_Using_Deep_Learning",
    "file_size_mb": 1.66,
    "abstract": "This paper explores using a deep learning Long Short-Term Memory (LSTM) model for accurate stock price prediction and its implications for portfolio design. Despite the efficient market hypothesis suggesting that predicting stock prices is impossible, recent research has shown the potential of advanced algorithms and predictive models. The study builds upon existing literature on stock price prediction methods, emphasizing the shift toward machine learning and deep learning approaches. Using historical stock prices of 180 stocks across 18 sectors listed on the NSE, India, the LSTM model predicts future prices. These predictions guide buy/sell decisions for each stock and analyze sector profitability. The study's main contributions are threefold: introducing an optimized LSTM model for robust portfolio design, utilizing LSTM predictions for buy/sell transactions, and insights into sector profitability and volatility. Results demonstrate the efficacy of the LSTM model in accurately predicting stock prices and informing investment decisions. By comparing sector profitability and prediction accuracy, the work provides valuable insights into the dynamics of the current financial markets in India.",
    "keywords": [
      "Deep Learning",
      "Long-and-Short-Term Memory (LSTM) Network",
      "Return",
      "Sectoral Portfolio",
      "Return"
    ]
  },
  {
    "article_id": "2407.02236v1_Indian_Stock_Market_Prediction_using_Augmented_Financial_Intelligence_ML",
    "title": "2407.02236v1 Indian Stock Market Prediction using Augmented Financial Intelligence ML",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2407.02236v1_Indian_Stock_Market_Prediction_using_Augmented_Financial_Intelligence_ML.pdf",
    "url": "http://arxiv.org/abs/2407.02236v1_Indian_Stock_Market_Prediction_using_Augmented_Financial_Intelligence_ML",
    "pdf_url": "https://arxiv.org/pdf/2407.02236v1_Indian_Stock_Market_Prediction_using_Augmented_Financial_Intelligence_ML",
    "file_size_mb": 0.5,
    "abstract": "This paper presents price prediction models using Machine Learning algorithms augmented with Superforecasters’ predictions, aimed at enhancing investment decisions. Five Machine Learning models are built, including Bidirectional LSTM, ARIMA, a combination of CNN and LSTM, GRU, and a model built using LSTM and GRU algorithms. The models are evaluated using the Mean Absolute Error (MAE) to determine their predictive accuracy. Additionally, the paper suggests incorporating human intelligence by identifying \"Superforecasters\" and tracking their predictions to anticipate unpredictable shifts or changes in stock prices (Mihov et al, 2022). To collect user predictions and identify Superforecasters, a user-friendly website has been developed. The predictions made by these users can further enhance the accuracy of stock price predictions when combined with Machine Learning and Natural Language Processing (NLP) techniques. Predicting the price of any commodity can be a significant task but predicting the price of a stock in the stock market deals with much more uncertainty. This is mainly due to the market's volatile and disruptive nature. Prices can touch their 52-week high on one day and the other, we might witness a huge fall in price. Market dynamics plays a major role in deciding the price of stocks but there can be an enormous number of reasons behind the price play for this market. Recognising the limited knowledge and exposure to stocks among certain investors, this paper proposes price prediction models using Machine Learning algorithms. These models assist investors who have been hesitant to engage in stock market investments due to the lack of knowledge and experience. In this work, five Machine learning models are built using Bidirectional LSTM, ARIMA, a combination of CNN and LSTM, GRU and the last one is built using LSTM and GRU algorithms. Later these models are assessed using MAE scores to find which model is predicting with the highest accuracy. In addition to this, this paper also suggests the use of human intelligence to closely predict the shift in price patterns in the stock market The main goal is to identify ‘Superforecasters’ and track their predictions to anticipate unpredictable shifts or changes in stock prices. To collect this data from people and to identify super forecasters, we have built a user-friendly website using which people can submit their predictions about a certain stock. By leveraging the combined power of Machine Learning and the Human Intelligence, predictive accuracy can be significantly increased. Abbreviations: ML: Machine Learning AI: Artificial Intelligence LSTM: Long Short-Term Memory ARIMA: Autoregressive Integrated Moving Average CNN: Convolutional Neural Network GRU: Gated Recurrent Unit NLP: Natural Language Processing ANN: Artificial Neural Networks SVM: Support Vector Machine BSE: Bombay Stock Exchange 1 Electronic copy available at: https://ssrn.com/abstract=4697853 NIFTY: National Stock Exchange FIF",
    "keywords": []
  },
  {
    "article_id": "2407.03760v2_GraphCNNpred_A_stock_market_indices_prediction_using_a_Graph_based_deep_learning_system",
    "title": "2407.03760v2 GraphCNNpred A stock market indices prediction using a Graph based deep learning system",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2407.03760v2_GraphCNNpred_A_stock_market_indices_prediction_using_a_Graph_based_deep_learning_system.pdf",
    "url": "http://arxiv.org/abs/2407.03760v2_GraphCNNpred_A_stock_market_indices_prediction_using_a_Graph_based_deep_learning_system",
    "pdf_url": "https://arxiv.org/pdf/2407.03760v2_GraphCNNpred_A_stock_market_indices_prediction_using_a_Graph_based_deep_learning_system",
    "file_size_mb": 0.56,
    "abstract": "The application of deep learning techniques for predicting stock market prices is a prominent and widely researched topic in the field of data science. To effectively predict market trends, it is essential to utilize a diversified dataset. In this paper, we give a graph neural network based convolutional neural network (CNN) model, that can be applied on diverse source of data, in the attempt to extract features to predict the trends of indices of S&P 500, NASDAQ, DJI, NYSE, and RUSSEL. The experiments show that the associated models improve the performance of prediction in all indices over the baseline algorithms by about 4% to 15%, in terms of F-measure. A trading simulation is generated from predictions and gained a Sharpe ratio of over 3.",
    "keywords": [
      "Stock Markets Prediction",
      "CNN",
      "CNNpred",
      "Graph Neural Network"
    ]
  },
  {
    "article_id": "2407.13427v3_DeepClair_Utilizing_Market_Forecasts_for_Effective_Portfolio_Selection",
    "title": "2407.13427v3 DeepClair Utilizing Market Forecasts for Effective Portfolio Selection",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2407.13427v3_DeepClair_Utilizing_Market_Forecasts_for_Effective_Portfolio_Selection.pdf",
    "url": "http://arxiv.org/abs/2407.13427v3_DeepClair_Utilizing_Market_Forecasts_for_Effective_Portfolio_Selection",
    "pdf_url": "https://arxiv.org/pdf/2407.13427v3_DeepClair_Utilizing_Market_Forecasts_for_Effective_Portfolio_Selection",
    "file_size_mb": 1.49,
    "abstract": "Utilizing market forecasts is pivotal in optimizing portfolio selec- tion strategies. We introduce DeepClair, a novel framework for portfolio selection. DeepClair leverages a transformer-based time- series forecasting model to predict market trends, facilitating more informed and adaptable portfolio decisions. To integrate the fore- casting model into a deep reinforcement learning-driven portfo- lio selection framework, we introduced a two-step strategy: first, pre-training the time-series model on market data, followed by fine-tuning the portfolio selection architecture using this model. Additionally, we investigated the optimization technique, Low-Rank Adaptation (LoRA), to enhance the pre-trained forecasting model for fine-tuning in investment scenarios. This work bridges market forecasting and portfolio selection, facilitating the advancement of investment strategies. CCS Concepts • Computing methodologies →Artificial intelligence; • Ap- plied computing →Economics.",
    "keywords": [
      "Portfolio Selection",
      "Time Series Forecasting",
      "Artificial Intelligence"
    ]
  },
  {
    "article_id": "2407.14486v1_Explainable_Post_hoc_Portfolio_Management_Financial_Policy_of_a_Deep_Reinforcement_Learning_agent",
    "title": "2407.14486v1 Explainable Post hoc Portfolio Management Financial Policy of a Deep Reinforcement Learning agent",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2407.14486v1_Explainable_Post_hoc_Portfolio_Management_Financial_Policy_of_a_Deep_Reinforcement_Learning_agent.pdf",
    "url": "http://arxiv.org/abs/2407.14486v1_Explainable_Post_hoc_Portfolio_Management_Financial_Policy_of_a_Deep_Reinforcement_Learning_agent",
    "pdf_url": "https://arxiv.org/pdf/2407.14486v1_Explainable_Post_hoc_Portfolio_Management_Financial_Policy_of_a_Deep_Reinforcement_Learning_agent",
    "file_size_mb": 0.84,
    "abstract": ". Financial portfolio management investment policies computed quantitatively by modern portfolio theory techniques like the Markowitz model rely on a set on assumptions that are not supported by data in high volatility markets such as the technological sector or cryptocurren- cies. Hence, quantitative researchers are looking for alternative models to tackle this problem. Concretely, portfolio management is a problem that has been successfully addressed recently by Deep Reinforcement Learn- ing (DRL) approaches. In particular, DRL algorithms train an agent by estimating the distribution of the expected reward of every action performed by an agent given any financial state in a simulator, also called gymnasium. However, these methods rely on Deep Neural Net- works model to represent such a distribution, that although they are universal approximator models, capable of representing the previous dis- tribution over time, they cannot explain its behaviour, given by a set of parameters that are not interpretable. Critically, financial investors poli- cies require predictions to be interpretable, to assess whether they follow a reasonable behaviour, so DRL agents are not suited to follow a particu- lar policy or explain their actions. In this work, driven by the motivation of making DRL explainable, we developed a novel Explainable Deep Re- inforcement Learning (XDRL) approach for portfolio management, in- tegrating the Proximal Policy Optimization (PPO) deep reinforcement learning algorithm with the model agnostic explainable machine learn- ing techniques of feature importance, SHAP and LIME techniques to enhance transparency in prediction time. By executing our methodol- ogy, we can interpret in prediction time the actions of the agent to assess whether they follow the requisites of an investment policy or to assess the risk of following the agent suggestions. To the best of our knowl- edge, our proposed approach is the first explainable post hoc portfolio management financial policy of a DRL agent. We empirically illustrate our methodology by successfully identifying key features influencing in- vestment decisions, which demonstrate the ability to explain the agent actions in prediction time.",
    "keywords": [
      "Deep Reinforcement Learning",
      "Portfolio Management",
      "Explainable"
    ]
  },
  {
    "article_id": "2407.16150v1_Predicting_Stock_Prices_with_FinBERT-LSTM_Integrating_News_Sentiment_Analysis",
    "title": "2407.16150v1 Predicting Stock Prices with FinBERT-LSTM Integrating News Sentiment Analysis",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2407.16150v1_Predicting_Stock_Prices_with_FinBERT-LSTM_Integrating_News_Sentiment_Analysis.pdf",
    "url": "http://arxiv.org/abs/2407.16150v1_Predicting_Stock_Prices_with_FinBERT-LSTM_Integrating_News_Sentiment_Analysis",
    "pdf_url": "https://arxiv.org/pdf/2407.16150v1_Predicting_Stock_Prices_with_FinBERT-LSTM_Integrating_News_Sentiment_Analysis",
    "file_size_mb": 0.47,
    "abstract": null,
    "keywords": [
      "and Phrases: stock price",
      "FinBERT-LSTM",
      "news sentiment"
    ]
  },
  {
    "article_id": "2407.18324v1_AMA-LSTM_Pioneering_Robust_and_Fair_Financial_Audio_Analysis_for_Stock_Volatility_Prediction",
    "title": "2407.18324v1 AMA-LSTM Pioneering Robust and Fair Financial Audio Analysis for Stock Volatility Prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2407.18324v1_AMA-LSTM_Pioneering_Robust_and_Fair_Financial_Audio_Analysis_for_Stock_Volatility_Prediction.pdf",
    "url": "http://arxiv.org/abs/2407.18324v1_AMA-LSTM_Pioneering_Robust_and_Fair_Financial_Audio_Analysis_for_Stock_Volatility_Prediction",
    "pdf_url": "https://arxiv.org/pdf/2407.18324v1_AMA-LSTM_Pioneering_Robust_and_Fair_Financial_Audio_Analysis_for_Stock_Volatility_Prediction",
    "file_size_mb": 0.7,
    "abstract": "Stock volatility prediction is an important task in the financial industry. Recent advancements in multimodal methodologies, which integrate both textual and auditory data, have demon- strated significant improvements in this domain, such as earnings calls1. However, these mul- timodal methods have faced two drawbacks. First, they often fail to yield reliable models and overfit the data due to their absorption of stochastic information from the stock market. Moreover, using multimodal models to predict stock volatility suffers from gender bias and lacks an efficient way to eliminate such bias. To address these aforementioned problems, we use adversarial training to generate perturba- tions that simulate the inherent stochasticity and bias, by creating areas resistant to random information around the input space to improve model robustness and fairness. Our comprehen- sive experiments on two real-world financial audio datasets reveal that this method exceeds the performance of current state-of-the-art so- lution. This confirms the value of adversarial training in reducing stochasticity and bias for stock volatility prediction tasks.",
    "keywords": []
  },
  {
    "article_id": "2407.18519v1_TCGPN_Temporal-Correlation_Graph_Pre-trained_Network_for_Stock_Forecasting",
    "title": "2407.18519v1 TCGPN Temporal-Correlation Graph Pre-trained Network for Stock Forecasting",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2407.18519v1_TCGPN_Temporal-Correlation_Graph_Pre-trained_Network_for_Stock_Forecasting.pdf",
    "url": "http://arxiv.org/abs/2407.18519v1_TCGPN_Temporal-Correlation_Graph_Pre-trained_Network_for_Stock_Forecasting",
    "pdf_url": "https://arxiv.org/pdf/2407.18519v1_TCGPN_Temporal-Correlation_Graph_Pre-trained_Network_for_Stock_Forecasting",
    "file_size_mb": 1.65,
    "abstract": ". Recently, the incorporation of both temporal features and the correlation across time series has become an effective approach in time series prediction. Spatio-Temporal Graph Neu- ral Networks (STGNNs) demonstrate good performance on many Temporal-correlation Forecasting Problem. However, when applied to tasks lacking periodicity, such as stock data prediction, the effec- tiveness and robustness of STGNNs are found to be unsatisfactory. And STGNNs are limited by memory savings so that cannot han- dle problems with a large number of nodes. In this paper, we pro- pose a novel approach called the Temporal-Correlation Graph Pre- trained Network (TCGPN) to address these limitations. TCGPN uti- lize Temporal-correlation fusion encoder to get a mixed representa- tion and pre-training method with carefully designed temporal and correlation pre-training tasks. Entire structure is independent of the number and order of nodes, so better results can be obtained through various data enhancements. And memory consumption during train- ing can be significantly reduced through multiple sampling. Exper- iments are conducted on real stock market data sets CSI300 and CSI500 that exhibit minimal periodicity. We fine-tune a simple MLP in downstream tasks and achieve state-of-the-art results, validating the capability to capture more robust temporal correlation patterns.",
    "keywords": []
  },
  {
    "article_id": "2407.19848v4_Generative_modelling_of_financial_time_series_with_structured_noise_and_MMD-based_signature_learning",
    "title": "2407.19848v4 Generative modelling of financial time series with structured noise and MMD-based signature learning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2407.19848v4_Generative_modelling_of_financial_time_series_with_structured_noise_and_MMD-based_signature_learning.pdf",
    "url": "http://arxiv.org/abs/2407.19848v4_Generative_modelling_of_financial_time_series_with_structured_noise_and_MMD-based_signature_learning",
    "pdf_url": "https://arxiv.org/pdf/2407.19848v4_Generative_modelling_of_financial_time_series_with_structured_noise_and_MMD-based_signature_learning",
    "file_size_mb": 1.85,
    "abstract": "Generating synthetic financial time series data that accurately reflects real-world market dynamics holds tremendous potential for various applications, including portfolio optimization, risk manage- ment, and large scale machine learning. We present an approach that uses structured noise for training generative models for financial time series. The expressive power of the signature transform has been shown to be able to capture the complex dependencies and temporal structures inherent in financial data when used to train generative models in the form of a signature kernel . We employ a moving average model to model the variance of the noise input, enhancing the model’s ability to reproduce stylized facts such as volatility clustering. Through empirical experiments on S&P 500 index data, we demonstrate that our model effectively captures key characteristics of financial time series and outperforms comparable approaches. In addition, we explore the application of the synthetic data generated to train a reinforcement learning agent for portfolio management, achieving promising results. Finally, we propose a method to add robustness to the generative model by tweaking the noise input so that the generated sequences can be adjusted to different market environments with minimal data.",
    "keywords": []
  },
  {
    "article_id": "2407.19858v7_AI-Powered_Energy_Algorithmic_Trading_Integrating_Hidden_Markov_Models_with_Neural_Networks",
    "title": "2407.19858v7 AI-Powered Energy Algorithmic Trading Integrating Hidden Markov Models with Neural Networks",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2407.19858v7_AI-Powered_Energy_Algorithmic_Trading_Integrating_Hidden_Markov_Models_with_Neural_Networks.pdf",
    "url": "http://arxiv.org/abs/2407.19858v7_AI-Powered_Energy_Algorithmic_Trading_Integrating_Hidden_Markov_Models_with_Neural_Networks",
    "pdf_url": "https://arxiv.org/pdf/2407.19858v7_AI-Powered_Energy_Algorithmic_Trading_Integrating_Hidden_Markov_Models_with_Neural_Networks",
    "file_size_mb": 0.89,
    "abstract": "In quantitative finance, machine-learning methods are key for alpha generation. This study introduces a refreshing approach that combines Hidden Markov Models (HMM) and neural networks integrated with Black-Litterman portfolio optimization. The approach was tested dur- ing the COVID period (2019–2022), where it achieved an 83% return with a Sharpe ratio of 0.77. Two risk models were incorporated to en- hance risk management, particularly during the volatile periods. The methodology was implemented on the QuantConnect platform, which was chosen for its robust framework and experimental reproducibility. The system is designed to predict future price movements and includes a three-year warm-up period to ensure the proper use of the algorithm. It focuses on highly liquid, large-cap energy stocks to ensure stable and reliable results, while also accounting for broker payments. The dual-model alpha system utilizes log returns to select the optimal state based on historical performance. It combines state predictions with neural network outputs derived from historical data to generate trading signals. This study presents an in-depth examination of the trading system’s architecture, data pre-processing, training, and performance. 1 arXiv:2407.19858v7 [q-fin.PM] 17 Nov 2025 The full code and backtesting data are available under QuantConnect’s terms.",
    "keywords": [
      "Hidden Markov Models",
      "Neural Networks",
      "Algorithmic"
    ]
  },
  {
    "article_id": "2408.00652v1_Enhancing_Multistep_Prediction_of_Multivariate_Market_Indices_Using_Weighted_Optical_Reservoir_Compu",
    "title": "2408.00652v1 Enhancing Multistep Prediction of Multivariate Market Indices Using Weighted Optical Reservoir Compu",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2408.00652v1_Enhancing_Multistep_Prediction_of_Multivariate_Market_Indices_Using_Weighted_Optical_Reservoir_Compu.pdf",
    "url": "http://arxiv.org/abs/2408.00652v1_Enhancing_Multistep_Prediction_of_Multivariate_Market_Indices_Using_Weighted_Optical_Reservoir_Compu",
    "pdf_url": "https://arxiv.org/pdf/2408.00652v1_Enhancing_Multistep_Prediction_of_Multivariate_Market_Indices_Using_Weighted_Optical_Reservoir_Compu",
    "file_size_mb": 2.13,
    "abstract": "We propose and experimentally demonstrate an innovative stock index prediction method using a weighted optical reservoir computing system. We construct fundamental market data combined with macroeconomic data and technical indicators to capture the broader behavior of the stock market. Our approach shows significant higher performance than state-of-the-art methods such as linear regression, decision trees, and neural network architectures in- cluding long short-term memory. It captures well the market’s high volatility and nonlinear behaviors despite limited data, demonstrating great potential for real-time, parallel, multi-dimensional data processing and predictions.",
    "keywords": [
      "Optical reservoir computing",
      "Parallel data processing",
      "Stock"
    ]
  },
  {
    "article_id": "2408.00713v2_Reinforcement_Learning_applied_to_Insurance_Portfolio_Pursuit",
    "title": "2408.00713v2 Reinforcement Learning applied to Insurance Portfolio Pursuit",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2408.00713v2_Reinforcement_Learning_applied_to_Insurance_Portfolio_Pursuit.pdf",
    "url": "http://arxiv.org/abs/2408.00713v2_Reinforcement_Learning_applied_to_Insurance_Portfolio_Pursuit",
    "pdf_url": "https://arxiv.org/pdf/2408.00713v2_Reinforcement_Learning_applied_to_Insurance_Portfolio_Pursuit",
    "file_size_mb": 0.59,
    "abstract": "When faced with a new customer, many factors contribute to an insurance firm’s decision of what offer to make to that customer. In addition to the expected cost of providing the insurance, the firm must consider the other offers likely to be made to the customer, and how sensitive the customer is to differences in price. Moreover, firms often target a specific portfolio of customers that could depend on, e.g., age, location, and occupation. Given such a target portfolio, firms may choose to modulate an individual customer’s offer based on whether the firm desires the customer within their portfolio. We term the problem of modulating offers to achieve a desired target portfolio the portfolio pursuit problem. Having formulated the portfolio pursuit problem as a sequential decision making problem, we devise a novel reinforcement learning algorithm for its solution. We test our method on a complex synthetic market environment, and demonstrate that it outperforms a baseline method which mimics current industry approaches to portfolio pursuit.",
    "keywords": []
  },
  {
    "article_id": "2408.01005v1_Enhancing_Financial_Market_Predictions_Causality-Driven_Feature_Selection",
    "title": "2408.01005v1 Enhancing Financial Market Predictions Causality-Driven Feature Selection",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2408.01005v1_Enhancing_Financial_Market_Predictions_Causality-Driven_Feature_Selection.pdf",
    "url": "http://arxiv.org/abs/2408.01005v1_Enhancing_Financial_Market_Predictions_Causality-Driven_Feature_Selection",
    "pdf_url": "https://arxiv.org/pdf/2408.01005v1_Enhancing_Financial_Market_Predictions_Causality-Driven_Feature_Selection",
    "file_size_mb": 2.18,
    "abstract": ". This paper introduces FinSen dataset that revolutionizes fi- nancial market analysis by integrating economic and financial news arti- cles from 197 countries with stock market data. The dataset’s extensive coverage spans 15 years from 2007 to 2023 with temporal information, offering a rich, global perspective 160,000 records on financial market news. Our study leverages causally validated sentiment scores and LSTM models to enhance market forecast accuracy and reliability. Utilizing the FinSen dataset, we introduce an innovative Focal Calibration Loss, re- ducing Expected Calibration Error (ECE) to 3.34% with the DAN 3 model. This is not only improves prediction accuracy but also aligns probabilistic forecasts closely with real outcomes, crucial for financial sector where predicted probability is paramount. Our approach demon- strates the effectiveness of combining sentiment analysis with precise cal- ibration techniques for trustworthy financial forecasting where the cost of misinterpretation can be high.",
    "keywords": [
      "Financial News Dataset",
      "Time-Series",
      "Calibration"
    ]
  },
  {
    "article_id": "2408.05382v1_Optimizing_Portfolio_with_Two-Sided_Transactions_and_Lending_A_Reinforcement_Learning_Framework",
    "title": "2408.05382v1 Optimizing Portfolio with Two-Sided Transactions and Lending A Reinforcement Learning Framework",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2408.05382v1_Optimizing_Portfolio_with_Two-Sided_Transactions_and_Lending_A_Reinforcement_Learning_Framework.pdf",
    "url": "http://arxiv.org/abs/2408.05382v1_Optimizing_Portfolio_with_Two-Sided_Transactions_and_Lending_A_Reinforcement_Learning_Framework",
    "pdf_url": "https://arxiv.org/pdf/2408.05382v1_Optimizing_Portfolio_with_Two-Sided_Transactions_and_Lending_A_Reinforcement_Learning_Framework",
    "file_size_mb": 1.31,
    "abstract": "This study presents a Reinforcement Learning (RL)-based portfolio management model tailored for high-risk environments, addressing the limitations of traditional RL models and exploiting market opportunities through two-sided transactions and lending. Our approach integrates a new environmental formulation with a Profit and Loss (PnL)-based reward function, enhancing the RL agent’s ability in down- side risk management and capital optimization. We implemented the model using the Soft Actor-Critic (SAC) agent with a Convolutional Neural Network with Multi- Head Attention (CNN-MHA). This setup effectively manages a diversified 12-crypto asset portfolio in the Binance perpetual futures market, leveraging USDT for both granting and receiving loans and rebalancing every 4 hours, utilizing market data from the preceding 48 hours. Tested over two 16-month periods of varying market volatility, the model significantly outperformed benchmarks, particularly in high- volatility scenarios, achieving higher return-to-risk ratios and demonstrating robust profitability. These results confirm the model’s effectiveness in leveraging market dynamics and managing risks in volatile environments like the cryptocurrency mar- ket.",
    "keywords": [
      "Portfolio Management",
      "Reinforcement Learning",
      "Deep Learning",
      "Context-"
    ]
  },
  {
    "article_id": "2408.09242v3_Learning_to_Optimally_Stop_Diffusion_Processes_with_Financial_Applications",
    "title": "2408.09242v3 Learning to Optimally Stop Diffusion Processes with Financial Applications",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2408.09242v3_Learning_to_Optimally_Stop_Diffusion_Processes_with_Financial_Applications.pdf",
    "url": "http://arxiv.org/abs/2408.09242v3_Learning_to_Optimally_Stop_Diffusion_Processes_with_Financial_Applications",
    "pdf_url": "https://arxiv.org/pdf/2408.09242v3_Learning_to_Optimally_Stop_Diffusion_Processes_with_Financial_Applications",
    "file_size_mb": 1.55,
    "abstract": "We study optimal stopping for diffusion processes with unknown model primi- tives within the continuous-time reinforcement learning (RL) framework developed by Wang et al. (2020), and present applications to option pricing and portfolio choice. By penalizing the corresponding variational inequality formulation, we transform the stopping problem into a stochastic optimal control problem with two actions. We then randomize controls into Bernoulli distributions and add an entropy regularizer to encourage exploration. We derive a semi-analytical optimal Bernoulli distribution, based on which we devise RL algorithms using the martin- gale approach established in Jia and Zhou (2022a). We establish a policy improve- ment theorem and prove the fast convergence of the resulting policy iterations. We demonstrate the effectiveness of the algorithms in pricing finite-horizon Amer- ican put options, solving Merton’s problem with transaction costs, and scaling to high-dimensional optimal stopping problems. In particular, we show that both the offline and online algorithms achieve high accuracy in learning the value functions and characterizing the associated free boundaries.",
    "keywords": [
      "Optimal stopping",
      "reinforcement learning",
      "policy improvement",
      "option"
    ]
  },
  {
    "article_id": "2408.11740v1_Less_is_more_AI_Decision-Making_using_Dynamic_Deep_Neural_Networks_for_Short-Term_Stock_Index_Predic",
    "title": "2408.11740v1 Less is more AI Decision-Making using Dynamic Deep Neural Networks for Short-Term Stock Index Predic",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2408.11740v1_Less_is_more_AI_Decision-Making_using_Dynamic_Deep_Neural_Networks_for_Short-Term_Stock_Index_Predic.pdf",
    "url": "http://arxiv.org/abs/2408.11740v1_Less_is_more_AI_Decision-Making_using_Dynamic_Deep_Neural_Networks_for_Short-Term_Stock_Index_Predic",
    "pdf_url": "https://arxiv.org/pdf/2408.11740v1_Less_is_more_AI_Decision-Making_using_Dynamic_Deep_Neural_Networks_for_Short-Term_Stock_Index_Predic",
    "file_size_mb": 0.65,
    "abstract": "In this paper we introduce a multi-agent deep-learning method which trades in the Futures markets based on the US S&P 500 index. The method (referred to as Model A) is an innovation founded on existing well-established machine-learning models which sample market prices and associated derivatives in order to decide whether the investment should be long/short or closed (zero exposure), on a day-to-day decision. We compare the predictions with some conventional machine-learning methods namely, Long Short-Term Memory, Random Forest and Gradient-Boosted-Trees. Results are benchmarked against a passive model in which the Futures contracts are held (long) continuously with the same exposure (level of investment). Historical tests are based on daily daytime trading carried out over a period of 6 calendar years (2018-23). We find that Model A outperforms the passive investment in key performance metrics, placing it within the top quartile performance of US Large Cap active fund managers. Model A also outperforms the three machine-learning classification comparators over this period. We observe that Model A is extremely efficient (doing less and getting more) with an exposure to the market of only 41.95% compared to the 100% market exposure of the passive investment, and thus provides increased profitability with reduced risk. Performance Metrics (Based on Monthly Returns Jan 2018 – Dec 2023). Passive Model A Annualized Return 3.09% 14.92% Annualized Volatility 13.10% 10.26% Alpha (Annualized) 0.00% 11.60% Beta (Monthly) 1.00 0.18 Sharpe Ratio 0.15 1.16 Sortino Ratio 0.22 2.97",
    "keywords": []
  },
  {
    "article_id": "2408.12408v1_An_Evaluation_of_Deep_Learning_Models_for_Stock_Market_Trend_Prediction",
    "title": "2408.12408v1 An Evaluation of Deep Learning Models for Stock Market Trend Prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2408.12408v1_An_Evaluation_of_Deep_Learning_Models_for_Stock_Market_Trend_Prediction.pdf",
    "url": "http://arxiv.org/abs/2408.12408v1_An_Evaluation_of_Deep_Learning_Models_for_Stock_Market_Trend_Prediction",
    "pdf_url": "https://arxiv.org/pdf/2408.12408v1_An_Evaluation_of_Deep_Learning_Models_for_Stock_Market_Trend_Prediction",
    "file_size_mb": 0.35,
    "abstract": "—The stock market is a fundamental component of financial systems, reflecting economic health, providing investment opportunities, and influencing global dynamics. Accurate stock market predictions can lead to significant gains and promote better investment decisions. However, predicting stock market trends is challenging due to their non-linear and stochastic nature. This study investigates the efficacy of advanced deep learning models for short-term trend forecasting using daily and hourly closing prices from the S&P 500 index and the Brazilian ETF EWZ. The models explored include Temporal Convolutional Networks (TCN), Neural Basis Expansion Analysis for Time Series Forecasting (N-BEATS), Temporal Fusion Transformers (TFT), Neural Hierarchical Interpolation for Time Series Forecasting (N-HiTS), and Time-series Dense Encoder (TiDE). Furthermore, we introduce the Extended Long Short-Term Memory for Time Series (xLSTM-TS) model, an xLSTM adaptation optimised for time series prediction. Wavelet denoising techniques were applied to smooth the signal and reduce minor fluctuations, providing cleaner data as input for all approaches. Denoising significantly improved performance in predicting stock price direction. Among the models tested, xLSTM-TS consistently outperformed others. For example, it achieved a test accuracy of 72.82% and an F1 score of 73.16% on the EWZ daily dataset. By leveraging advanced deep learning models and effective data preprocessing techniques, this research provides valuable insights into the application of machine learning for market movement forecasting, highlighting both the potential and the challenges involved. Index Terms—Time Series, Prediction, Stock Market, xLSTM-TS, Wavelet Denoising, TCN, N-BEATS, TFT, N-HiTS, TiDE, S&P 500, EWZ",
    "keywords": []
  },
  {
    "article_id": "2408.14864v1_Dynamic_operator_management_in_meta-heuristics_using_reinforcement_learning_an_application_to_permut",
    "title": "2408.14864v1 Dynamic operator management in meta-heuristics using reinforcement learning an application to permut",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2408.14864v1_Dynamic_operator_management_in_meta-heuristics_using_reinforcement_learning_an_application_to_permut.pdf",
    "url": "http://arxiv.org/abs/2408.14864v1_Dynamic_operator_management_in_meta-heuristics_using_reinforcement_learning_an_application_to_permut",
    "pdf_url": "https://arxiv.org/pdf/2408.14864v1_Dynamic_operator_management_in_meta-heuristics_using_reinforcement_learning_an_application_to_permut",
    "file_size_mb": 2.6,
    "abstract": "This study develops a framework based on reinforcement learning to dynamically manage a large portfolio of search operators within meta-heuristics. Using the idea of tabu search, the framework allows for continuous adaptation by temporarily excluding less efficient operators and updating the portfolio composition during the search. A Q-learning-based adaptive operator selection mechanism is used to select the most suitable operator from the dynamically updated portfolio at each stage. Unlike traditional approaches, the proposed framework requires no input from the experts regarding the search operators, allowing domain-specific non-experts to effectively use the framework. The performance of the proposed framework is analyzed through an application to the permutation flowshop scheduling problem. The results demonstrate the superior performance of the proposed framework against state-of-the-art algorithms in terms of optimality gap and convergence speed.",
    "keywords": [
      "Operator management",
      "Reinforcement learning",
      "Tabu search",
      "Iterated greedy meta-heuristic"
    ]
  },
  {
    "article_id": "2409.00107v2_Evaluating_the_Impact_of_Multiple_DER_Aggregators_on_Wholesale_Energy_Markets_A_Hybrid_Mean_Field_Ap",
    "title": "2409.00107v2 Evaluating the Impact of Multiple DER Aggregators on Wholesale Energy Markets A Hybrid Mean Field Ap",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2409.00107v2_Evaluating_the_Impact_of_Multiple_DER_Aggregators_on_Wholesale_Energy_Markets_A_Hybrid_Mean_Field_Ap.pdf",
    "url": "http://arxiv.org/abs/2409.00107v2_Evaluating_the_Impact_of_Multiple_DER_Aggregators_on_Wholesale_Energy_Markets_A_Hybrid_Mean_Field_Ap",
    "pdf_url": "https://arxiv.org/pdf/2409.00107v2_Evaluating_the_Impact_of_Multiple_DER_Aggregators_on_Wholesale_Energy_Markets_A_Hybrid_Mean_Field_Ap",
    "file_size_mb": 0.7,
    "abstract": null,
    "keywords": [
      "Mean-field equilibrium",
      "multi-agent reinforcement learning",
      "distributed energy resource"
    ]
  },
  {
    "article_id": "2409.05778v1_Advanced_LSTM_Neural_Networks_for_Predicting_Directional_Changes_in_Sector-Specific_ETFs_Using_Machi",
    "title": "2409.05778v1 Advanced LSTM Neural Networks for Predicting Directional Changes in Sector-Specific ETFs Using Machi",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2409.05778v1_Advanced_LSTM_Neural_Networks_for_Predicting_Directional_Changes_in_Sector-Specific_ETFs_Using_Machi.pdf",
    "url": "http://arxiv.org/abs/2409.05778v1_Advanced_LSTM_Neural_Networks_for_Predicting_Directional_Changes_in_Sector-Specific_ETFs_Using_Machi",
    "pdf_url": "https://arxiv.org/pdf/2409.05778v1_Advanced_LSTM_Neural_Networks_for_Predicting_Directional_Changes_in_Sector-Specific_ETFs_Using_Machi",
    "file_size_mb": 0.59,
    "abstract": "— Trading and investing in stocks for some is their full-time career, while for others, it’s simply just a supplementary income stream. Universal among all investors is the desire to turn a profit. The key to achieving this goal is diversification. Spreading your investments across sectors is the key to profitability and maximizing returns. This study aims to gauge the viability of machine learning methods to practice the principle of diversification to maximize your portfolio returns. To test this, this study tests the Long-Short Term Memory (LSTM) model across 9 different sectors and upwards of 2,200 stocks using Vanguard's sector-based ETFs. Across all sectors, the R-squared value showed very promising results, with an average of .8651 and a high of .942 with the VNQ ETF. These findings suggest that the LSTM model is a capable and viable model for accurately predicting directional changes among various industry sectors and can help investors diversify and grow their portfolios.",
    "keywords": [
      "component",
      "Long Short-Term Memory (LSTM)"
    ]
  },
  {
    "article_id": "2409.06728v1_Leveraging_RNNs_and_LSTMs_for_Synchronization_Analysis_in_the_Indian_Stock_Market_A_Threshold-Based_",
    "title": "2409.06728v1 Leveraging RNNs and LSTMs for Synchronization Analysis in the Indian Stock Market A Threshold-Based ",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2409.06728v1_Leveraging_RNNs_and_LSTMs_for_Synchronization_Analysis_in_the_Indian_Stock_Market_A_Threshold-Based_.pdf",
    "url": "http://arxiv.org/abs/2409.06728v1_Leveraging_RNNs_and_LSTMs_for_Synchronization_Analysis_in_the_Indian_Stock_Market_A_Threshold-Based_",
    "pdf_url": "https://arxiv.org/pdf/2409.06728v1_Leveraging_RNNs_and_LSTMs_for_Synchronization_Analysis_in_the_Indian_Stock_Market_A_Threshold-Based_",
    "file_size_mb": 0.84,
    "abstract": "Our research presents a new approach for forecasting the synchronization of stock prices using machine learning and non-linear time-series analysis. To capture the complex non- linear relationships between stock prices, we utilize recurrence plots (RP) and cross- recurrence quantification analysis (CRQA). By transforming Cross Recurrence Plot (CRP) data into a time-series format, we enable the use of Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM) networks for predicting stock price synchronization through both regression and classification. We apply this methodology to a dataset of 20 highly capitalized stocks from the Indian market over a 21-year period. The findings reveal that our approach can predict stock price synchronization, with an accuracy of 0.98 and F1 score of 0.83 offering valuable insights for developing effective trading strategies and risk management tools.",
    "keywords": []
  },
  {
    "article_id": "2409.08282v3_LSR-IGRU_Stock_Trend_Prediction_Based_on_Long_Short-Term_Relationships_and_Improved_GRU",
    "title": "2409.08282v3 LSR-IGRU Stock Trend Prediction Based on Long Short-Term Relationships and Improved GRU",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2409.08282v3_LSR-IGRU_Stock_Trend_Prediction_Based_on_Long_Short-Term_Relationships_and_Improved_GRU.pdf",
    "url": "http://arxiv.org/abs/2409.08282v3_LSR-IGRU_Stock_Trend_Prediction_Based_on_Long_Short-Term_Relationships_and_Improved_GRU",
    "pdf_url": "https://arxiv.org/pdf/2409.08282v3_LSR-IGRU_Stock_Trend_Prediction_Based_on_Long_Short-Term_Relationships_and_Improved_GRU",
    "file_size_mb": 1.28,
    "abstract": "Stock price prediction is a challenging problem in the field of fi- nance and receives widespread attention. In recent years, with the rapid development of technologies such as deep learning and graph neural networks, more research methods have begun to focus on exploring the interrelationships between stocks. However, existing methods mostly focus on the short-term dynamic relationships of stocks and directly integrating relationship information with temporal information. They often overlook the complex nonlin- ear dynamic characteristics and potential higher-order interaction relationships among stocks in the stock market. Therefore, we pro- pose a stock price trend prediction model named LSR-IGRU in this paper, which is based on long short-term stock relationships and an improved GRU input. Firstly, we construct a long short-term relationship matrix between stocks, where secondary industry in- formation is employed for the first time to capture long-term rela- tionships of stocks, and overnight price information is utilized to establish short-term relationships. Next, we improve the inputs of the GRU model at each step, enabling the model to more effectively integrate temporal information and long short-term relationship information, thereby significantly improving the accuracy of pre- dicting stock trend changes. Finally, through extensive experiments on multiple datasets from stock markets in China and the United ∗These authors contributed equally to this work. †Corresponding author. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CIKM ’24, October 21–25, 2024, Boise, ID, USA © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 979-8-4007-0436-9/24/10 https://doi.org/10.1145/3627673.3680012 States, we validate the superiority of the proposed LSR-IGRU model over the current state-of-the-art baseline models. We also apply the proposed model to the algorithmic trading system of a financial company, achieving significantly higher cumulative portfolio re- turns compared to other baseline methods. Our sources are released at https://github.com/ZP1481616577/Baselines_LSR-IGRU. CCS Concepts • Information systems →Data mining.",
    "keywords": [
      "Stock Price Prediction",
      "Graph Neural Networks",
      "Long Short-term"
    ]
  },
  {
    "article_id": "2409.08297v1_Comparative_Study_of_Long_Short-Term_Memory_LSTM_and_Quantum_Long_Short-Term_Memory_QLSTM_Prediction",
    "title": "2409.08297v1 Comparative Study of Long Short-Term Memory LSTM and Quantum Long Short-Term Memory QLSTM Prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2409.08297v1_Comparative_Study_of_Long_Short-Term_Memory_LSTM_and_Quantum_Long_Short-Term_Memory_QLSTM_Prediction.pdf",
    "url": "http://arxiv.org/abs/2409.08297v1_Comparative_Study_of_Long_Short-Term_Memory_LSTM_and_Quantum_Long_Short-Term_Memory_QLSTM_Prediction",
    "pdf_url": "https://arxiv.org/pdf/2409.08297v1_Comparative_Study_of_Long_Short-Term_Memory_LSTM_and_Quantum_Long_Short-Term_Memory_QLSTM_Prediction",
    "file_size_mb": 1.3,
    "abstract": "In recent years, financial analysts have been trying to develop models to predict the movement of a stock price index. The task becomes challenging in vague economic, social, and political situations like in Pakistan. In this study, we employed efficient models of machine learning such as long short-term memory (LSTM) and quantum long short-term memory (QLSTM) to predict the Karachi Stock Exchange (KSE) 100 index by taking monthly data of twenty-six economic, social, political, and administrative indicators from February 2004 to December 2020. The comparative results of LSTM and QLSTM predicted values of the KSE 100 index with the actual values suggested QLSTM a potential technique to predict stock market trends.",
    "keywords": [
      "Recurrent Neural Network (RNN)",
      "Long Short-Term Memory (LSTM)",
      "KSE 100 Index"
    ]
  },
  {
    "article_id": "2409.08426v1_A_Deep_Reinforcement_Learning_Framework_For_Financial_Portfolio_Management",
    "title": "2409.08426v1 A Deep Reinforcement Learning Framework For Financial Portfolio Management",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2409.08426v1_A_Deep_Reinforcement_Learning_Framework_For_Financial_Portfolio_Management.pdf",
    "url": "http://arxiv.org/abs/2409.08426v1_A_Deep_Reinforcement_Learning_Framework_For_Financial_Portfolio_Management",
    "pdf_url": "https://arxiv.org/pdf/2409.08426v1_A_Deep_Reinforcement_Learning_Framework_For_Financial_Portfolio_Management",
    "file_size_mb": 1.39,
    "abstract": null,
    "keywords": []
  },
  {
    "article_id": "2409.11820v1_Optimizing_Job_Shop_Scheduling_in_the_Furniture_Industry_A_Reinforcement_Learning_Approach_Consideri",
    "title": "2409.11820v1 Optimizing Job Shop Scheduling in the Furniture Industry A Reinforcement Learning Approach Consideri",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2409.11820v1_Optimizing_Job_Shop_Scheduling_in_the_Furniture_Industry_A_Reinforcement_Learning_Approach_Consideri.pdf",
    "url": "http://arxiv.org/abs/2409.11820v1_Optimizing_Job_Shop_Scheduling_in_the_Furniture_Industry_A_Reinforcement_Learning_Approach_Consideri",
    "pdf_url": "https://arxiv.org/pdf/2409.11820v1_Optimizing_Job_Shop_Scheduling_in_the_Furniture_Industry_A_Reinforcement_Learning_Approach_Consideri",
    "file_size_mb": 0.64,
    "abstract": "This paper explores the potential application of Deep Reinforcement Learning (DRL) in the furniture industry. In order to offer a broad product portfolio, most furniture manufacturers are organized as a job shop, which ultimately results in the Job Shop Scheduling Problem (JSSP). The JSSP is addressed with a focus on extending traditional models to better represent the complexities of real-world production environments. Existing approaches to JSSPs frequently fail to consider critical factors such as machine setup times, varying batch sizes, intralogistics, buffer capacities, or deadlines, which are essential in industrial settings. In order to overcome these limitations, a concept for a model is proposed that incorporates these elements, providing a higher level of information detail to enhance scheduling accuracy and efficiency. The concept introduces the integration of DRL for production planning, which is particularly suited to batch production industries such as the furniture industry. The model extends traditional approaches to JSSPs by including job volumes, buffer management, transportation times, and machine setup times. This enables more precise forecasting and analysis of production flows and processes, accommodating the variability and complexity inherent in real-world manufacturing processes. In a training environment the Reinforcement Learning (RL) agent learns to optimize scheduling decisions. The agent operates within a discrete action space, making decisions based on detailed observations of machine states, job volumes, and buffer statuses. A reward function, specifically tailored to the specific industrial applications, guides the agent’s decision-making process, thereby promoting efficient scheduling and meeting production deadlines. Two integration strategies for implementing the RL agent are discussed: episodic planning, which is suitable for low-automation environments, and continuous planning, which is ideal for highly automated plants. While episodic planning can be employed as a standalone solution, the continuous planning approach necessitates the integration of the agent with Enterprise Resource Planning (ERP) and Manufacturing Execution Systems (MES). This integration enables real-time adjustments to production schedules based on dynamic changes.",
    "keywords": [
      "Job Shop Scheduling",
      "Production Scheduling",
      "Reinforcement Learning",
      "Markov Decision Process"
    ]
  },
  {
    "article_id": "2409.13253v1_Inductive_Spatial_Temporal_Prediction_Under_Data_Drift_with_Informative_Graph_Neural_Network",
    "title": "2409.13253v1 Inductive Spatial Temporal Prediction Under Data Drift with Informative Graph Neural Network",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2409.13253v1_Inductive_Spatial_Temporal_Prediction_Under_Data_Drift_with_Informative_Graph_Neural_Network.pdf",
    "url": "http://arxiv.org/abs/2409.13253v1_Inductive_Spatial_Temporal_Prediction_Under_Data_Drift_with_Informative_Graph_Neural_Network",
    "pdf_url": "https://arxiv.org/pdf/2409.13253v1_Inductive_Spatial_Temporal_Prediction_Under_Data_Drift_with_Informative_Graph_Neural_Network",
    "file_size_mb": 2.2,
    "abstract": ". Inductive spatial temporal prediction can generalize histori- cal data to predict unseen data, crucial for highly dynamic scenarios (e.g., traffic systems, stock markets). However, external events (e.g., urban structural growth, market crash) and emerging new entities (e.g., loca- tions, stocks) can undermine prediction accuracy by inducing data drift over time. Most existing studies extract invariant patterns to counter data drift but ignore pattern diversity, exhibiting poor generalization to unseen entities. To address this issue, we design an Informative Graph Neural Network (INF-GNN) to distill diversified invariant patterns and improve prediction accuracy under data drift. Firstly, we build an in- formative subgraph with a uniquely designed metric, Relation Impor- tance (RI), that can effectively select stable entities and distinct spatial relationships. This subgraph further generalizes new entities’ data via neighbors merging. Secondly, we propose an informative temporal mem- ory buffer to help the model emphasize valuable timestamps extracted using influence functions within time intervals. This memory buffer al- lows INF-GNN to discern influential temporal patterns. Finally, RI loss optimization is designed for pattern consolidation. Extensive experiments on real-world dataset under substantial data drift demonstrate that INF- GNN significantly outperforms existing alternatives.",
    "keywords": [
      "Spatial Temporal prediction",
      "Inductive learning",
      "Data"
    ]
  },
  {
    "article_id": "2409.14557v3_Exploiting_Exogenous_Structure_for_Sample-Efficient_Reinforcement_Learning",
    "title": "2409.14557v3 Exploiting Exogenous Structure for Sample-Efficient Reinforcement Learning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2409.14557v3_Exploiting_Exogenous_Structure_for_Sample-Efficient_Reinforcement_Learning.pdf",
    "url": "http://arxiv.org/abs/2409.14557v3_Exploiting_Exogenous_Structure_for_Sample-Efficient_Reinforcement_Learning",
    "pdf_url": "https://arxiv.org/pdf/2409.14557v3_Exploiting_Exogenous_Structure_for_Sample-Efficient_Reinforcement_Learning",
    "file_size_mb": 0.83,
    "abstract": null,
    "keywords": [
      "Reinforcement learning",
      "Exogenous MDPs",
      "linear-mixture MDPs",
      "inventory control"
    ]
  },
  {
    "article_id": "2409.14747v5_Distribution-Level_Feature_Distancing_for_Machine_Unlearning_Towards_a_Better_Trade-off_Between_Mode",
    "title": "2409.14747v5 Distribution-Level Feature Distancing for Machine Unlearning Towards a Better Trade-off Between Mode",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2409.14747v5_Distribution-Level_Feature_Distancing_for_Machine_Unlearning_Towards_a_Better_Trade-off_Between_Mode.pdf",
    "url": "http://arxiv.org/abs/2409.14747v5_Distribution-Level_Feature_Distancing_for_Machine_Unlearning_Towards_a_Better_Trade-off_Between_Mode",
    "pdf_url": "https://arxiv.org/pdf/2409.14747v5_Distribution-Level_Feature_Distancing_for_Machine_Unlearning_Towards_a_Better_Trade-off_Between_Mode",
    "file_size_mb": 1.1,
    "abstract": "With the explosive growth of deep learning applications and increasing privacy concerns, the right to be forgotten has be- come a critical requirement in various AI industries. For exam- ple, given a facial recognition system, some individuals may wish to remove their personal data that might have been used in the training phase. Unfortunately, deep neural networks sometimes unexpectedly leak personal identities, making this removal challenging. While recent machine unlearning al- gorithms aim to enable models to forget specific data, we identify an unintended utility drop—correlation collapse—in which the essential correlations between image features and true labels weaken during the forgetting process. To address this challenge, we propose Distribution-Level Feature Dis- tancing (DLFD), a novel method that efficiently forgets in- stances while preserving task-relevant feature correlations. Our method synthesizes data samples by optimizing the fea- ture distribution to be distinctly different from that of forget samples, achieving effective results within a single training epoch. Through extensive experiments on facial recognition datasets, we demonstrate that our approach significantly out- performs state-of-the-art machine unlearning methods in both forgetting performance and model utility preservation.",
    "keywords": []
  },
  {
    "article_id": "2409.15662v1_Double-Path_Adaptive-correlation_Spatial-Temporal_Inverted_Transformer_for_Stock_Time_Series_Forecas",
    "title": "2409.15662v1 Double-Path Adaptive-correlation Spatial-Temporal Inverted Transformer for Stock Time Series Forecas",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2409.15662v1_Double-Path_Adaptive-correlation_Spatial-Temporal_Inverted_Transformer_for_Stock_Time_Series_Forecas.pdf",
    "url": "http://arxiv.org/abs/2409.15662v1_Double-Path_Adaptive-correlation_Spatial-Temporal_Inverted_Transformer_for_Stock_Time_Series_Forecas",
    "pdf_url": "https://arxiv.org/pdf/2409.15662v1_Double-Path_Adaptive-correlation_Spatial-Temporal_Inverted_Transformer_for_Stock_Time_Series_Forecas",
    "file_size_mb": 2.0,
    "abstract": "Spatial-temporal graph neural networks (STGNNs) have achieved significant success in various time series forecasting tasks. However, due to the lack of explicit and fixed spatial relationships in stock prediction tasks, many STGNNs fail to perform effectively in this domain. While some STGNNs learn spatial relationships from time series, they often lack comprehensiveness. Research indicates that modeling time series using feature changes as tokens reveals en- tirely different information compared to using time steps as tokens. To more comprehensively extract dynamic spatial information from stock data, we propose a Double-Path Adaptive-correlation Spatial- Temporal Inverted Transformer (DPA-STIFormer). DPA-STIFormer models each node via continuous changes in features as tokens and introduces a Double Direction Self-adaptation Fusion mecha- nism. This mechanism decomposes node encoding into temporal and feature representations, simultaneously extracting different spatial correlations from a double path approach, and proposes a Double-path gating mechanism to fuse these two types of corre- lation information. Experiments conducted on four stock market datasets demonstrate state-of-the-art results, validating the model’s superior capability in uncovering latent temporal-correlation pat- terns. CCS Concepts • Information systems →Spatial-temporal systems.",
    "keywords": [
      "Spatial-Temporal Graph Neural Network",
      "Pre-training Model",
      "Time"
    ]
  },
  {
    "article_id": "2409.17183v1_Transfer_learning_for_financial_data_predictions_a_systematic_review",
    "title": "2409.17183v1 Transfer learning for financial data predictions a systematic review",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2409.17183v1_Transfer_learning_for_financial_data_predictions_a_systematic_review.pdf",
    "url": "http://arxiv.org/abs/2409.17183v1_Transfer_learning_for_financial_data_predictions_a_systematic_review",
    "pdf_url": "https://arxiv.org/pdf/2409.17183v1_Transfer_learning_for_financial_data_predictions_a_systematic_review",
    "file_size_mb": 1.12,
    "abstract": "Literature highlighted that financial time series data pose significant challenges for accurate stock price prediction, because these data are characterized by noise and susceptibility to news; traditional statistical methodologies made assumptions, such as linearity and normality, which are not suitable for the non-linear nature of financial time series; on the other hand, machine learning methodologies are able to capture non linear relationship in the data. To date, neural network is considered the main machine learning tool for the financial prices prediction. Transfer Learning, as a method aimed at transferring knowledge from source tasks to target tasks, can represent a very useful methodological tool for getting better financial prediction capability. Current reviews on the above body of knowledge are mainly focused on neural network architectures, for financial prediction, with very little emphasis on the transfer learning methodology; thus, this paper is aimed at going deeper on this topic by developing a systematic review with respect to application of Transfer Learning for financial market predictions and to challenges/potential future directions of the transfer learning methodologies for stock market predictions. 2",
    "keywords": []
  },
  {
    "article_id": "2409.17201v2_Immersion_and_Invariance-based_Coding_for_Privacy-Preserving_Federated_Learning",
    "title": "2409.17201v2 Immersion and Invariance-based Coding for Privacy-Preserving Federated Learning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2409.17201v2_Immersion_and_Invariance-based_Coding_for_Privacy-Preserving_Federated_Learning.pdf",
    "url": "http://arxiv.org/abs/2409.17201v2_Immersion_and_Invariance-based_Coding_for_Privacy-Preserving_Federated_Learning",
    "pdf_url": "https://arxiv.org/pdf/2409.17201v2_Immersion_and_Invariance-based_Coding_for_Privacy-Preserving_Federated_Learning",
    "file_size_mb": 6.57,
    "abstract": "Federated learning (FL) has emerged to preserve privacy in collaborative distributed learning. In FL, clients conduct AI model training directly on their devices rather than sharing their data with a centralized server, which could potentially pose privacy risks. However, it has been shown that despite FL’s partial preservation of local data privacy, information about clients’ data can still be inferred from shared model updates during the training process. In recent years, several privacy-preserving approaches have been developed to mitigate this privacy leakage in FL. However, they often provide privacy at the cost of model performance or system efficiency. Balancing these trade-offs poses a significant challenge in implementing FL schemes. In this manuscript, we introduce a privacy-preserving FL framework built on the synergy of differential privacy and system immersion and invariance tools from control theory. The core idea is to treat optimization algorithms used in the standard FL schemes (gradient-based algorithms) as a dynamical system that we seek to immerse into a higher-dimensional system (referred here to as the target optimization algorithm). The dynamics of the target optimization algorithm is designed such that, firstly, the model parameters of the original algorithm are immersed/embedded in its parameters, secondly, it works on distorted parameters, and, thirdly, converges to an encoded version of the true model parameters of the original algorithm. The encoded model parameters can be decoded at the server to extract the original model parameters. We demonstrate that the proposed privacy-preserving scheme can be tailored to offer any desired level of differential privacy for local and global model parameters while maintaining the same accuracy and convergence rate as standard FL algorithms. Key words: Privacy-preservation, Federated Learning, Immersion and Invariance, Differential Privacy.",
    "keywords": [
      "Privacy-preservation",
      "Federated Learning",
      "Immersion and Invariance",
      "Differential Privacy"
    ]
  },
  {
    "article_id": "2409.18664v1_How_green_is_continual_learning_really_Analyzing_the_energy_consumption_in_continual_training_of_vis",
    "title": "2409.18664v1 How green is continual learning really Analyzing the energy consumption in continual training of vis",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2409.18664v1_How_green_is_continual_learning_really_Analyzing_the_energy_consumption_in_continual_training_of_vis.pdf",
    "url": "http://arxiv.org/abs/2409.18664v1_How_green_is_continual_learning_really_Analyzing_the_energy_consumption_in_continual_training_of_vis",
    "pdf_url": "https://arxiv.org/pdf/2409.18664v1_How_green_is_continual_learning_really_Analyzing_the_energy_consumption_in_continual_training_of_vis",
    "file_size_mb": 1.5,
    "abstract": ". With the ever-growing adoption of AI, its impact on the en- vironment is no longer negligible. Despite the potential that continual learning could have towards Green AI, its environmental sustainability remains relatively uncharted. In this work we aim to gain a systematic understanding of the energy efficiency of continual learning algorithms. To that end, we conducted an extensive set of empirical experiments com- paring the energy consumption of recent representation-, prompt-, and exemplar-based continual learning algorithms and two standard base- line (fine tuning and joint training) when used to continually adapt a pre-trained ViT-B/16 foundation model. We performed our experiments on three standard datasets: CIFAR-100, ImageNet-R, and DomainNet. Additionally, we propose a novel metric, the Energy NetScore, which we use measure the algorithm efficiency in terms of energy-accuracy trade- off. Through numerous evaluations varying the number and size of the incremental learning steps, our experiments demonstrate that different types of continual learning algorithms have very different impacts on energy consumption during both training and inference. Although often overlooked in the continual learning literature, we found that the en- ergy consumed during the inference phase is crucial for evaluating the environmental sustainability of continual learning models.",
    "keywords": [
      "Green AI",
      "Continual Learning",
      "Foundation Models"
    ]
  },
  {
    "article_id": "2409.18735v1_Autoregressive_Policy_Optimization_for_Constrained_Allocation_Tasks",
    "title": "2409.18735v1 Autoregressive Policy Optimization for Constrained Allocation Tasks",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2409.18735v1_Autoregressive_Policy_Optimization_for_Constrained_Allocation_Tasks.pdf",
    "url": "http://arxiv.org/abs/2409.18735v1_Autoregressive_Policy_Optimization_for_Constrained_Allocation_Tasks",
    "pdf_url": "https://arxiv.org/pdf/2409.18735v1_Autoregressive_Policy_Optimization_for_Constrained_Allocation_Tasks",
    "file_size_mb": 0.95,
    "abstract": "Allocation tasks represent a class of problems where a limited amount of resources must be allocated to a set of entities at each time step. Prominent examples of this task include portfolio optimization or distributing computational workloads across servers. Allocation tasks are typically bound by linear constraints describing practical requirements that have to be strictly fulfilled at all times. In portfolio optimization, for example, investors may be obligated to allocate less than 30% of the funds into a certain industrial sector in any investment period. Such constraints restrict the action space of allowed allocations in intricate ways, which makes learning a policy that avoids constraint violations difficult. In this paper, we propose a new method for constrained allocation tasks based on an autoregressive process to sequentially sample allocations for each entity. In addition, we introduce a novel de-biasing mechanism to counter the initial bias caused by sequential sampling. We demonstrate the superior performance of our approach compared to a variety of Constrained Reinforcement Learning (CRL) methods on three distinct constrained allocation tasks: portfolio optimization, computational workload distribution, and a synthetic allocation benchmark. Our code is available at: https://github.com/ niklasdbs/paspo.",
    "keywords": []
  },
  {
    "article_id": "2409.19706v1_American_Call_Options_Pricing_With_Modular_Neural_Networks",
    "title": "2409.19706v1 American Call Options Pricing With Modular Neural Networks",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2409.19706v1_American_Call_Options_Pricing_With_Modular_Neural_Networks.pdf",
    "url": "http://arxiv.org/abs/2409.19706v1_American_Call_Options_Pricing_With_Modular_Neural_Networks",
    "pdf_url": "https://arxiv.org/pdf/2409.19706v1_American_Call_Options_Pricing_With_Modular_Neural_Networks",
    "file_size_mb": 0.5,
    "abstract": "An accurate valuation of American call options is critical in most financial de- cision making environments. However, traditional models like the Barone-Adesi Whaley (B-AW) and Binomial Option Pricing (BOP) methods fall short in hand- ling the complexities of early exercise and market dynamics present in American options. This paper proposes a Modular Neural Network (MNN) model which aims to capture the key aspects of American options pricing. By dividing the predic- tion process into specialized modules, the MNN effectively models the non-linear interactions that drive American call options pricing. Experimental results indic- ate that the MNN model outperform both traditional models as well as a simpler Feed-forward Neural Network (FNN) across multiple stocks (AAPL, NVDA, QQQ), with significantly lower RMSE and nRMSE (by mean). These findings highlight the potential of MNNs as a powerful tool to improve the accuracy of predicting option prices.",
    "keywords": []
  },
  {
    "article_id": "2410.00288v1_GARCH-Informed_Neural_Networks_for_Volatility_Prediction_in_Financial_Markets",
    "title": "2410.00288v1 GARCH-Informed Neural Networks for Volatility Prediction in Financial Markets",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2410.00288v1_GARCH-Informed_Neural_Networks_for_Volatility_Prediction_in_Financial_Markets.pdf",
    "url": "http://arxiv.org/abs/2410.00288v1_GARCH-Informed_Neural_Networks_for_Volatility_Prediction_in_Financial_Markets",
    "pdf_url": "https://arxiv.org/pdf/2410.00288v1_GARCH-Informed_Neural_Networks_for_Volatility_Prediction_in_Financial_Markets",
    "file_size_mb": 1.24,
    "abstract": "—Volatility, which indicates the dispersion of returns, is a crucial measure of risk and is hence used extensively for pricing and discriminating between different financial in- vestments. As a result, accurate volatility prediction receives extensive attention. The Generalized Autoregressive Conditional Heteroscedasticity (GARCH) model and its succeeding variants are well established models for stock volatility forecasting. More recently, deep learning models have gained popularity in volatility prediction as they demonstrated promising accuracy in certain time series prediction tasks. Inspired by Physics-Informed Neural Networks (PINN), we constructed a new, hybrid Deep Learning model that combines the strengths of GARCH with the flexibility of a Long Short-Term Memory (LSTM) Deep Neural Network (DNN), thus capturing and forecasting market volatility more accurately than either class of models are capable of on their own. We refer to this novel model as a GARCH-Informed Neural Network (GINN). When compared to other time series models, GINN showed superior out-of-sample prediction performance in terms of the Coefficient of Determination (R2), Mean Squared Error (MSE), and Mean Absolute Error (MAE).",
    "keywords": [
      "neural networks",
      "hybrid model",
      "volatility pre-"
    ]
  },
  {
    "article_id": "2410.01843v1_Optimizing_Time_Series_Forecasting_A_Comparative_Study_of_Adam_and_Nesterov_Accelerated_Gradient_on_",
    "title": "2410.01843v1 Optimizing Time Series Forecasting A Comparative Study of Adam and Nesterov Accelerated Gradient on ",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2410.01843v1_Optimizing_Time_Series_Forecasting_A_Comparative_Study_of_Adam_and_Nesterov_Accelerated_Gradient_on_.pdf",
    "url": "http://arxiv.org/abs/2410.01843v1_Optimizing_Time_Series_Forecasting_A_Comparative_Study_of_Adam_and_Nesterov_Accelerated_Gradient_on_",
    "pdf_url": "https://arxiv.org/pdf/2410.01843v1_Optimizing_Time_Series_Forecasting_A_Comparative_Study_of_Adam_and_Nesterov_Accelerated_Gradient_on_",
    "file_size_mb": 0.65,
    "abstract": "Several studies have discussed the impact different optimization techniques in the context of time series forecasting across different architectures. This paper examines the effectiveness of Adam and Nesterov’s Accelerated Gradient (NAG) optimization techniques on LSTM and GRU neu- ral networks for time series prediction, specifically stock market time-series. Our study was done by training LSTM and GRU models with two different optimization techniques - Adam and Nesterov Accelerated Gradient (NAG), comparing and evaluating their performance on Ap- ple Inc’ closing price data over the last decade. The GRU model optimized with Adam pro- duced the lowest RMSE, outperforming the other model-optimizer combinations in both accuracy and convergence speed. The GRU models with both optimizers outperformed the LSTM mod- els, whilst the Adam optimizer outperformed the NAG optimizer for both model architectures. The results suggest that GRU models optimized with Adam are well-suited for practitioners in time-series prediction, more specifically stock price time series prediction producing accurate and computationally efficient models. The code for the experiments in this project can be found at https://github.com/AhmadMak/Time-Series-Optimization-Research",
    "keywords": [
      "Time-series Forecasting",
      "Neural Network",
      "LSTM",
      "GRU",
      "Adam Optimizer",
      "Nesterov Accelerated"
    ]
  },
  {
    "article_id": "2410.01864v1_Dynamic_Portfolio_Rebalancing_A_Hybrid_new_Model_Using_GNNs_and_Pathfinding_for_Cost_Efficiency",
    "title": "2410.01864v1 Dynamic Portfolio Rebalancing A Hybrid new Model Using GNNs and Pathfinding for Cost Efficiency",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2410.01864v1_Dynamic_Portfolio_Rebalancing_A_Hybrid_new_Model_Using_GNNs_and_Pathfinding_for_Cost_Efficiency.pdf",
    "url": "http://arxiv.org/abs/2410.01864v1_Dynamic_Portfolio_Rebalancing_A_Hybrid_new_Model_Using_GNNs_and_Pathfinding_for_Cost_Efficiency",
    "pdf_url": "https://arxiv.org/pdf/2410.01864v1_Dynamic_Portfolio_Rebalancing_A_Hybrid_new_Model_Using_GNNs_and_Pathfinding_for_Cost_Efficiency",
    "file_size_mb": 0.42,
    "abstract": "This paper introduces a novel approach to optimizing portfolio rebalancing by integrating Graph Neural Networks (GNNs) for predicting transaction costs and Dijkstra's algorithm for identifying cost-efficient rebalancing paths. Using historical stock data from prominent technology firms, the GNN is trained to forecast future transaction costs, which are then applied as edge weights in a financial asset graph. Dijkstra's algorithm is used to find the least costly path for reallocating capital between assets. Empirical results show that this hybrid approach significantly reduces transaction costs, offering a powerful tool for portfolio managers, especially in high-frequency trading environments. This methodology demonstrates the potential of combining advanced machine learning techniques with classical optimization algorithms to improve financial decision- making processes. Future research will explore expanding the asset universe and incorporating reinforcement learning for continuous portfolio optimization.",
    "keywords": [
      "Portfolio Optimization",
      "Transaction Costs",
      "Graph Neural Networks (GNN)"
    ]
  },
  {
    "article_id": "2410.02024v3_FLAG_Financial_Long_Document_Classification_via_AMR-based_GNN",
    "title": "2410.02024v3 FLAG Financial Long Document Classification via AMR-based GNN",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2410.02024v3_FLAG_Financial_Long_Document_Classification_via_AMR-based_GNN.pdf",
    "url": "http://arxiv.org/abs/2410.02024v3_FLAG_Financial_Long_Document_Classification_via_AMR-based_GNN",
    "pdf_url": "https://arxiv.org/pdf/2410.02024v3_FLAG_Financial_Long_Document_Classification_via_AMR-based_GNN",
    "file_size_mb": 0.44,
    "abstract": "—The advent of large language models (LLMs) has initiated much research into their various financial applications. However, in applying LLMs on long documents, semantic rela- tions are not explicitly incorporated, and a full or arbitrarily sparse attention operation is employed. In recent years, progress has been made in Abstract Meaning Representation (AMR), which is a graph-based representation of text to preserve its semantic relations. Since AMR can represent semantic relation- ships at a deeper level, it can be beneficially utilized by graph neural networks (GNNs) for constructing effective document-level graph representations built upon LLM embeddings to predict target metrics in the financial domain. We propose FLAG: Financial Long document classification via AMR-based GNN, an AMR graph based framework to generate document-level embeddings for long financial document classification. We con- struct document-level graphs from sentence-level AMR graphs, endow them with specialized LLM word embeddings in the financial domain, apply a deep learning mechanism that utilizes a GNN, and examine the efficacy of our AMR-based approach in predicting labeled target data from long financial documents. Extensive experiments are conducted on a dataset of quarterly earnings calls transcripts of companies in various sectors of the economy, as well as on a corpus of more recent earnings calls of companies in the S&P 1500 Composite Index. We find that our AMR-based approach outperforms fine-tuning LLMs directly on text in predicting stock price movement trends at different time horizons in both datasets. Our work also outperforms previous work utilizing document graphs and GNNs for text classification.",
    "keywords": []
  },
  {
    "article_id": "2410.03707v2_Mamba_Meets_Financial_Markets_A_Graph-Mamba_Approach_for_Stock_Price_Prediction",
    "title": "2410.03707v2 Mamba Meets Financial Markets A Graph-Mamba Approach for Stock Price Prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2410.03707v2_Mamba_Meets_Financial_Markets_A_Graph-Mamba_Approach_for_Stock_Price_Prediction.pdf",
    "url": "http://arxiv.org/abs/2410.03707v2_Mamba_Meets_Financial_Markets_A_Graph-Mamba_Approach_for_Stock_Price_Prediction",
    "pdf_url": "https://arxiv.org/pdf/2410.03707v2_Mamba_Meets_Financial_Markets_A_Graph-Mamba_Approach_for_Stock_Price_Prediction",
    "file_size_mb": 0.41,
    "abstract": "—Stock markets play an important role in the global economy, where accurate stock price predictions can lead to significant financial returns. While existing transformer-based models have outperformed long short-term memory (LSTM) networks and convolutional neural networks (CNNs) in financial time series prediction, their high computational complexity and memory requirements limit their practicality for real-time trading and long-sequence data processing. To address these challenges, in this paper, we propose SAMBA, an innovative framework for stock return prediction that builds on the Mamba architecture and integrates graph neural networks (GNNs). SAMBA achieves near-linear computational complexity by utilizing a bidirectional Mamba block to capture long- term dependencies in historical price data and employing adaptive graph convolution to model dependencies between daily stock features. Our experimental results demonstrate that SAMBA significantly outperforms state-of-the-art baseline models in prediction performance, maintaining low computational complexity. The code and datasets are available at github.com/Ali-Meh619/SAMBA.",
    "keywords": []
  },
  {
    "article_id": "2410.03913v1_Leveraging_Fundamental_Analysis_for_Stock_Trend_Prediction_for_Profit",
    "title": "2410.03913v1 Leveraging Fundamental Analysis for Stock Trend Prediction for Profit",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2410.03913v1_Leveraging_Fundamental_Analysis_for_Stock_Trend_Prediction_for_Profit.pdf",
    "url": "http://arxiv.org/abs/2410.03913v1_Leveraging_Fundamental_Analysis_for_Stock_Trend_Prediction_for_Profit",
    "pdf_url": "https://arxiv.org/pdf/2410.03913v1_Leveraging_Fundamental_Analysis_for_Stock_Trend_Prediction_for_Profit",
    "file_size_mb": 0.2,
    "abstract": "This paper investigates the application of machine learning models, Long Short-Term Memory (LSTM), one-dimensional Convolutional Neural Networks (1D CNN), and Logistic Regression (LR), for predicting stock trends based on fundamental analysis. Unlike most existing studies that predominantly utilize technical or sentiment analysis, we emphasize the use of a company's financial statements and intrinsic value for trend forecasting. Using a dataset of 269 data points from publicly traded companies across various sectors from 2019 to 2023, we employ key financial ratios and the Discounted Cash Flow (DCF) model to formulate two prediction tasks: Annual Stock Price Difference (ASPD) and Difference between Current Stock Price and Intrinsic Value (DCSPIV). These tasks assess the likelihood of annual profit and current profitability, respectively. Our results demonstrate that LR models outperform CNN and LSTM models, achieving an average test accuracy of 74.66% for ASPD and 72.85% for DCSPIV. This study contributes to the limited literature on integrating fundamental analysis into machine learning for stock prediction, offering valuable insights for both academic research and practical investment strategies. By leveraging fundamental data, our approach highlights the potential for long-term stock trend prediction, supporting portfolio managers in their decision-making processes.",
    "keywords": [
      "Stock Trend Prediction",
      "Fundamental Analysis",
      "Machine Learning",
      "CNN",
      "LSTM",
      "Logistic Regression"
    ]
  },
  {
    "article_id": "2410.04217v2_Improving_Portfolio_Optimization_Results_with_Bandit_Networks",
    "title": "2410.04217v2 Improving Portfolio Optimization Results with Bandit Networks",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2410.04217v2_Improving_Portfolio_Optimization_Results_with_Bandit_Networks.pdf",
    "url": "http://arxiv.org/abs/2410.04217v2_Improving_Portfolio_Optimization_Results_with_Bandit_Networks",
    "pdf_url": "https://arxiv.org/pdf/2410.04217v2_Improving_Portfolio_Optimization_Results_with_Bandit_Networks",
    "file_size_mb": 6.44,
    "abstract": "In Reinforcement Learning (RL), multi-armed Bandit (MAB) problems have found applications across diverse domains such as recommender systems, health- care, and finance. Traditional MAB algorithms typically assume stationary reward distributions, which limits their effectiveness in real-world scenarios char- acterized by non-stationary dynamics. This paper addresses this limitation by introducing and evaluating novel Bandit algorithms designed for non-stationary environments. First, we present the Adaptive Discounted Thompson Sampling (ADTS) algorithm, which enhances adaptability through relaxed discounting and sliding window mechanisms to better respond to changes in reward distributions. We then extend this approach to the Portfolio Optimization problem by intro- ducing the Combinatorial Adaptive Discounted Thompson Sampling (CADTS) algorithm, which addresses computational challenges within Combinatorial Ban- dits and improves dynamic asset allocation. Additionally, we propose a novel architecture called Bandit Networks, which integrates the outputs of ADTS and CADTS, thereby mitigating computational limitations in stock selection. Through extensive experiments using real financial market data, we demon- strate the potential of these algorithms and architectures in adapting to dynamic environments and optimizing decision-making processes. For instance, the pro- posed bandit network instances present superior performance when compared to classic portfolio optimization approaches, such as capital asset pricing model, equal weights, risk parity, and Markovitz, with the best network presenting an out-of-sample Sharpe Ratio 20% higher than the best performing classical model. 1 arXiv:2410.04217v2 [cs.AI] 8 Oct 2024",
    "keywords": [
      "multi-armed bandits",
      "portfolio optimization",
      "non-stationary bandits"
    ]
  },
  {
    "article_id": "2410.04772v1_From_Transparency_to_Accountability_and_Back_A_Discussion_of_Access_and_Evidence_in_AI_Auditing",
    "title": "2410.04772v1 From Transparency to Accountability and Back A Discussion of Access and Evidence in AI Auditing",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2410.04772v1_From_Transparency_to_Accountability_and_Back_A_Discussion_of_Access_and_Evidence_in_AI_Auditing.pdf",
    "url": "http://arxiv.org/abs/2410.04772v1_From_Transparency_to_Accountability_and_Back_A_Discussion_of_Access_and_Evidence_in_AI_Auditing",
    "pdf_url": "https://arxiv.org/pdf/2410.04772v1_From_Transparency_to_Accountability_and_Back_A_Discussion_of_Access_and_Evidence_in_AI_Auditing",
    "file_size_mb": 0.37,
    "abstract": null,
    "keywords": []
  },
  {
    "article_id": "2410.07143v1_SARF_Enhancing_Stock_Market_Prediction_with_Sentiment-Augmented_Random_Forest",
    "title": "2410.07143v1 SARF Enhancing Stock Market Prediction with Sentiment-Augmented Random Forest",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2410.07143v1_SARF_Enhancing_Stock_Market_Prediction_with_Sentiment-Augmented_Random_Forest.pdf",
    "url": "http://arxiv.org/abs/2410.07143v1_SARF_Enhancing_Stock_Market_Prediction_with_Sentiment-Augmented_Random_Forest",
    "pdf_url": "https://arxiv.org/pdf/2410.07143v1_SARF_Enhancing_Stock_Market_Prediction_with_Sentiment-Augmented_Random_Forest",
    "file_size_mb": 0.28,
    "abstract": "Stock trend forecasting, a challenging problem in the financial domain, involves ex- tensive data and related indicators. Relying solely on empirical analysis often yields unsustainable and ineffective results. Machine learning researchers have demonstrated that the application of random forest algorithm can enhance predictions in this context, playing a crucial auxiliary role in forecasting stock trends. This study introduces a new approach to stock market prediction by integrating sentiment analysis using FinGPT generative AI model with the traditional Random Forest model. The proposed technique aims to optimize the accuracy of stock price forecasts by leveraging the nuanced understanding of financial sentiments provided by FinGPT. We present a new methodology called \"Sentiment-Augmented Random Forest\" (SARF), which in- corporates sentiment features into the Random Forest framework. Our experiments demonstrate that SARF outperforms conventional Random Forest and LSTM models with an average accuracy improvement of 9.23% and lower prediction errors in pre- dicting stock market movements.",
    "keywords": [
      "Machine learning",
      "Sentiment Analysis",
      "Finance",
      "Natural Language"
    ]
  },
  {
    "article_id": "2410.07216v1_Evaluating_Financial_Relational_Graphs_Interpretation_Before_Prediction",
    "title": "2410.07216v1 Evaluating Financial Relational Graphs Interpretation Before Prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2410.07216v1_Evaluating_Financial_Relational_Graphs_Interpretation_Before_Prediction.pdf",
    "url": "http://arxiv.org/abs/2410.07216v1_Evaluating_Financial_Relational_Graphs_Interpretation_Before_Prediction",
    "pdf_url": "https://arxiv.org/pdf/2410.07216v1_Evaluating_Financial_Relational_Graphs_Interpretation_Before_Prediction",
    "file_size_mb": 1.12,
    "abstract": "Accurate and robust stock trend forecasting has been a crucial and challenging task, as stock price changes are influenced by multi- ple factors. Graph neural network-based methods have recently achieved remarkable success in this domain by constructing stock relationship graphs that reflect internal factors and relationships between stocks. However, most of these methods rely on predefined factors to construct static stock relationship graphs due to the lack of suitable datasets, failing to capture the dynamic changes in stock relationships. Moreover, the evaluation of relationship graphs in these methods is often tied to the performance of neural network models on downstream tasks, leading to confusion and imprecision. To address these issues, we introduce the SPNews dataset, collected based on S&P 500 Index stocks, to facilitate the construction of dynamic relationship graphs. Furthermore, we propose a novel set of financial relationship graph evaluation methods that are inde- pendent of downstream tasks. By using the relationship graph to explain historical financial phenomena, we assess its validity before constructing a graph neural network, ensuring the graph’s effec- tiveness in capturing relevant financial relationships. Experimental results demonstrate that our evaluation methods can effectively differentiate between various financial relationship graphs, yielding more interpretable results compared to traditional approaches. We make our source code publicly available on GitHub to promote reproducibility and further research in this area 1. CCS Concepts • Computing methodologies →Machine learning; Knowledge representation and reasoning.",
    "keywords": [
      "Representation Learning",
      "Financial Markets",
      "Graph Neural Net-"
    ]
  },
  {
    "article_id": "2410.07234v1_A_Dynamic_Approach_to_Stock_Price_Prediction_Comparing_RNN_and_Mixture_of_Experts_Models_Across_Diff",
    "title": "2410.07234v1 A Dynamic Approach to Stock Price Prediction Comparing RNN and Mixture of Experts Models Across Diff",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2410.07234v1_A_Dynamic_Approach_to_Stock_Price_Prediction_Comparing_RNN_and_Mixture_of_Experts_Models_Across_Diff.pdf",
    "url": "http://arxiv.org/abs/2410.07234v1_A_Dynamic_Approach_to_Stock_Price_Prediction_Comparing_RNN_and_Mixture_of_Experts_Models_Across_Diff",
    "pdf_url": "https://arxiv.org/pdf/2410.07234v1_A_Dynamic_Approach_to_Stock_Price_Prediction_Comparing_RNN_and_Mixture_of_Experts_Models_Across_Diff",
    "file_size_mb": 0.36,
    "abstract": "This study evaluates the effectiveness of a Mixture of Experts (MoE) model for stock price prediction by comparing it to a Recurrent Neural Network (RNN) and a linear regression model. The MoE framework combines an RNN for volatile stocks and a linear model for stable stocks, dynamically adjusting the weight of each model through a gating network. Results indicate that the MoE approach significantly improves predictive accuracy across different volatility profiles. The RNN effectively captures non-linear patterns for volatile companies but tends to overfit stable data, whereas the linear model performs well for predictable trends. The MoE model's adaptability allows it to outperform each individual model, reducing errors such as Mean Squared Error (MSE) and Mean Absolute Error (MAE). Future work should focus on enhancing the gating mechanism and validating the model with real-world datasets to optimize its practical applicability.",
    "keywords": [
      "Mixture of Experts",
      "Recurrent Neural Network",
      "Stock Price Prediction"
    ]
  },
  {
    "article_id": "2410.12807v1_A_Hierarchical_conv-LSTM_and_LLM_Integrated_Model_for_Holistic_Stock_Forecasting",
    "title": "2410.12807v1 A Hierarchical conv-LSTM and LLM Integrated Model for Holistic Stock Forecasting",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2410.12807v1_A_Hierarchical_conv-LSTM_and_LLM_Integrated_Model_for_Holistic_Stock_Forecasting.pdf",
    "url": "http://arxiv.org/abs/2410.12807v1_A_Hierarchical_conv-LSTM_and_LLM_Integrated_Model_for_Holistic_Stock_Forecasting",
    "pdf_url": "https://arxiv.org/pdf/2410.12807v1_A_Hierarchical_conv-LSTM_and_LLM_Integrated_Model_for_Holistic_Stock_Forecasting",
    "file_size_mb": 1.0,
    "abstract": "The financial domain presents a complex environment for stock market prediction, characterized by volatile patterns and the influence of multifaceted data sources. Traditional models have leveraged either Convolutional Neural Networks (CNN) for spatial feature extraction or Long Short-Term Memory (LSTM) networks for capturing temporal dependencies, with limited integration of external textual data. This paper proposes a novel Two-Level Conv-LSTM Neural Network integrated with a Large Language Model (LLM) for comprehensive stock advising. The model harnesses the strengths of Conv-LSTM for analyzing time-series data and LLM for processing and understanding textual information from financial news, social media, and reports. In the first level, convolutional layers are employed to identify local patterns in historical stock prices and technical indicators, followed by LSTM layers to capture the temporal dynamics. The second level integrates the output with an LLM that analyzes sentiment and contextual information from textual data, providing a holistic view of market conditions. The combined approach aims to improve prediction accuracy and provide contextually rich stock advising.",
    "keywords": [
      "stock market prediction",
      "Conv-LSTM",
      "neural network",
      "large language model",
      "financial forecasting",
      "sentiment"
    ]
  },
  {
    "article_id": "2410.14807v1_Aligning_AI_Agents_via_Information-Directed_Sampling",
    "title": "2410.14807v1 Aligning AI Agents via Information-Directed Sampling",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2410.14807v1_Aligning_AI_Agents_via_Information-Directed_Sampling.pdf",
    "url": "http://arxiv.org/abs/2410.14807v1_Aligning_AI_Agents_via_Information-Directed_Sampling",
    "pdf_url": "https://arxiv.org/pdf/2410.14807v1_Aligning_AI_Agents_via_Information-Directed_Sampling",
    "file_size_mb": 0.51,
    "abstract": "The staggering feats of AI systems have brought to attention the topic of AI Alignment: align- ing a “superintelligent” AI agent’s actions with humanity’s interests. Many existing frame- works/algorithms in alignment study the problem on a myopic horizon or study learning from human feedback in isolation, relying on the contrived assumption that the agent has already perfectly iden- tified the environment. As a starting point to address these limitations, we define a class of bandit alignment problems as an extension of classic multi-armed bandit problems. A bandit alignment problem involves an agent tasked with maximizing long-run expected reward by interacting with an environment and a human, both involving details/preferences initially unknown to the agent. The reward of actions in the environment depends on both observed outcomes and human prefer- ences. Furthermore, costs are associated with querying the human to learn preferences. Therefore, an effective agent ought to intelligently trade-off exploration (of the environment and human) and exploitation. We study these trade-offs theoretically and empirically in a toy bandit alignment prob- lem which resembles the beta-Bernoulli bandit. We demonstrate while naive exploration algorithms which reflect current practices and even touted algorithms such as Thompson sampling both fail to provide acceptable solutions to this problem, information-directed sampling achieves favorable regret.",
    "keywords": [
      "AI Alignment",
      "Bandit Learning"
    ]
  },
  {
    "article_id": "2410.14927v1_Hierarchical_Reinforced_Trader_HRT_A_Bi-Level_Approach_for_Optimizing_Stock_Selection_and_Execution",
    "title": "2410.14927v1 Hierarchical Reinforced Trader HRT A Bi-Level Approach for Optimizing Stock Selection and Execution",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2410.14927v1_Hierarchical_Reinforced_Trader_HRT_A_Bi-Level_Approach_for_Optimizing_Stock_Selection_and_Execution.pdf",
    "url": "http://arxiv.org/abs/2410.14927v1_Hierarchical_Reinforced_Trader_HRT_A_Bi-Level_Approach_for_Optimizing_Stock_Selection_and_Execution",
    "pdf_url": "https://arxiv.org/pdf/2410.14927v1_Hierarchical_Reinforced_Trader_HRT_A_Bi-Level_Approach_for_Optimizing_Stock_Selection_and_Execution",
    "file_size_mb": 3.22,
    "abstract": "Leveraging Deep Reinforcement Learning (DRL) in automated stock trading has shown promising results, yet its application faces sig- nificant challenges, including the curse of dimensionality, inertia in trading actions, and insufficient portfolio diversification. Address- ing these challenges, we introduce the Hierarchical Reinforced Trader (HRT), a novel trading strategy employing a bi-level Hier- archical Reinforcement Learning framework. The HRT integrates a Proximal Policy Optimization (PPO)-based High-Level Controller (HLC) for strategic stock selection with a Deep Deterministic Policy Gradient (DDPG)-based Low-Level Controller (LLC) tasked with optimizing trade executions to enhance portfolio value. In our em- pirical analysis, comparing the HRT agent with standalone DRL models and the S&P 500 benchmark during both bullish and bearish market conditions, we achieve a positive and higher Sharpe ratio. This advancement not only underscores the efficacy of incorporat- ing hierarchical structures into DRL strategies but also mitigates the aforementioned challenges, paving the way for designing more profitable and robust trading algorithms in complex markets. CCS CONCEPTS • Computing methodologies →Reinforcement learning.",
    "keywords": [
      "Deep Reinforcement Learning",
      "Markov Decision Process",
      "Auto-"
    ]
  },
  {
    "article_id": "2410.17212v1_Neuroevolution_Neural_Architecture_Search_for_Evolving_RNNs_in_Stock_Return_Prediction_and_Portfolio",
    "title": "2410.17212v1 Neuroevolution Neural Architecture Search for Evolving RNNs in Stock Return Prediction and Portfolio",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2410.17212v1_Neuroevolution_Neural_Architecture_Search_for_Evolving_RNNs_in_Stock_Return_Prediction_and_Portfolio.pdf",
    "url": "http://arxiv.org/abs/2410.17212v1_Neuroevolution_Neural_Architecture_Search_for_Evolving_RNNs_in_Stock_Return_Prediction_and_Portfolio",
    "pdf_url": "https://arxiv.org/pdf/2410.17212v1_Neuroevolution_Neural_Architecture_Search_for_Evolving_RNNs_in_Stock_Return_Prediction_and_Portfolio",
    "file_size_mb": 0.2,
    "abstract": "Stock return forecasting is a major component of numerous ﬁnance applications. Predicted stock returns can be incorporated into port- folio trading algorithms to make informed buy or sell decisions which can optimize returns. In such portfolio trading applications, the predictive performance of a time series forecasting model is crucial. In this work, we propose the use of the Evolutionary eXplo- ration of Augmenting Memory Models (EXAMM) algorithm to pro- gressively evolve recurrent neural networks (RNNs) for stock re- turn predictions. RNNs are evolved independently for each stocks and portfolio trading decisions are made based on the predicted stock returns. The portfolio used for testing consists of the 30 com- panies in the Dow-Jones Index (DJI) with each stock have the same weight. Results show that using these evolved RNNs and a simple daily long-short strategy can generate higher returns than both the DJI index and the S&P 500 Index for both 2022 (bear market) and 2023 (bull market). CCS Concepts • Applied computing →Forecasting; Multi-criterion optimiza- tion and decision-making; • Computing methodologies →Su- pervised learning by regression; Genetic algorithms.",
    "keywords": [
      "Time Series Forecasting",
      "Stock Return Prediction",
      "Neuroevolution"
    ]
  },
  {
    "article_id": "2410.19291v2_A_Stock_Price_Prediction_Approach_Based_on_Time_Series_Decomposition_and_Multi-Scale_CNN_using_OHLCT",
    "title": "2410.19291v2 A Stock Price Prediction Approach Based on Time Series Decomposition and Multi-Scale CNN using OHLCT",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2410.19291v2_A_Stock_Price_Prediction_Approach_Based_on_Time_Series_Decomposition_and_Multi-Scale_CNN_using_OHLCT.pdf",
    "url": "http://arxiv.org/abs/2410.19291v2_A_Stock_Price_Prediction_Approach_Based_on_Time_Series_Decomposition_and_Multi-Scale_CNN_using_OHLCT",
    "pdf_url": "https://arxiv.org/pdf/2410.19291v2_A_Stock_Price_Prediction_Approach_Based_on_Time_Series_Decomposition_and_Multi-Scale_CNN_using_OHLCT",
    "file_size_mb": 2.07,
    "abstract": "Recently, deep learning in stock prediction has become an important branch. Image-based methods show potential by capturing complex visual patterns and spatial correlations, offering advantages in interpretability over time series models. However, image-based approaches are more prone to overfitting, hindering robust predictive performance. To improve accuracy, this paper proposes a novel method, named Sequence-based Multi-scale Fu- sion Regression Convolutional Neural Network (SMSFR-CNN), for predict- ing stock price movements in the China A-share market. Firstly, the historical opening, highest, lowest, closing price, and turnover rate (OHLCT) of stocks are converted into images, separated by weekends, with time information to help the CNN learn the impact of different trading periods. To reduce overfitting, long sequences of stock features are decom- posed into multiple time periods, and OHLCT images at different time scales are utilized as inputs, significantly reducing overfitting. Thirdly, in order to overcome the problem that classification labels lose information about the magnitude of stock price changes, we introduce regression labels to help the ∗Corresponding author: xiliu@must.edu.mo (Xin Liu) Preprint submitted to Neurocomputing October 30, 2024 arXiv:2410.19291v2 [cs.LG] 29 Oct 2024 model capture more latent features of stock price fluctuations. By utilizing CNN to learn sequential features and combining them with image features, we improve the accuracy of stock trend prediction on the A- share market stock dataset. This approach reduces the search space for image features, stabilizes and accelerates the training process. Extensive compar- ative experiments on 4,454 A-share stocks show that the model achieves 61.15% positive predictive value and 63.37% negative predictive value for the next 5 days, resulting in a total profit of 165.09%.",
    "keywords": [
      "Multi-Scale Fusion",
      "Stock Price Prediction",
      "Regression CNN",
      "A-share Stock"
    ]
  },
  {
    "article_id": "2410.20229v1_Modelling_of_Economic_Implications_of_Bias_in_AI-Powered_Health_Emergency_Response_Systems",
    "title": "2410.20229v1 Modelling of Economic Implications of Bias in AI-Powered Health Emergency Response Systems",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2410.20229v1_Modelling_of_Economic_Implications_of_Bias_in_AI-Powered_Health_Emergency_Response_Systems.pdf",
    "url": "http://arxiv.org/abs/2410.20229v1_Modelling_of_Economic_Implications_of_Bias_in_AI-Powered_Health_Emergency_Response_Systems",
    "pdf_url": "https://arxiv.org/pdf/2410.20229v1_Modelling_of_Economic_Implications_of_Bias_in_AI-Powered_Health_Emergency_Response_Systems",
    "file_size_mb": 0.14,
    "abstract": "We present a theoretical framework assessing the economic implications of bias in AI-powered emergency response systems. Integrating health economics, welfare economics, and artiﬁcial intelligence, we analyze how algorithmic bias aﬀects resource al- location, health outcomes, and social welfare. By incorporating a bias function into health production and social welfare models, we quantify its impact on demographic groups, showing that bias leads to suboptimal resource distribution, increased costs, and welfare losses. The framework highlights eﬃciency-equity trade-oﬀs and provides economic interpretations. We propose mitiga- tion strategies, including fairness-constrained optimization, algorithmic adjustments, and policy interventions. Our ﬁndings oﬀer insights for policymakers, emergency service providers, and technology developers, emphasizing the need for AI systems that are eﬃcient and equitable. By addressing the economic consequences of biased AI, this study contributes to policies and technologies promoting fairness, eﬃciency, and social welfare in emergency response services.",
    "keywords": [
      "Artiﬁcial Intelligence",
      "Bias",
      "Emergency Medicine",
      "Health Economics"
    ]
  },
  {
    "article_id": "2410.20679v3_MCI-GRU_Stock_Prediction_Model_Based_on_Multi-Head_Cross-Attention_and_Improved_GRU",
    "title": "2410.20679v3 MCI-GRU Stock Prediction Model Based on Multi-Head Cross-Attention and Improved GRU",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2410.20679v3_MCI-GRU_Stock_Prediction_Model_Based_on_Multi-Head_Cross-Attention_and_Improved_GRU.pdf",
    "url": "http://arxiv.org/abs/2410.20679v3_MCI-GRU_Stock_Prediction_Model_Based_on_Multi-Head_Cross-Attention_and_Improved_GRU",
    "pdf_url": "https://arxiv.org/pdf/2410.20679v3_MCI-GRU_Stock_Prediction_Model_Based_on_Multi-Head_Cross-Attention_and_Improved_GRU",
    "file_size_mb": 1.11,
    "abstract": "As financial markets become increasingly complex and the era of big data unfolds, accurate stock prediction has become more critical. Although traditional time series models, such as GRU, have been widely applied to stock prediction, they still exhibit limitations in addressing the intricate nonlinear dynamics of markets, particularly in the flexible selection and effective utilization of key historical information. In recent years, emerging methods like Graph Neural Networks and Reinforcement Learning have shown significant potential in stock prediction. How- ever, these methods often demand high data quality and quantity, and they tend to exhibit instability when dealing with data sparsity and noise. Moreover, the training and inference processes for these models are typically complex and computationally expensive, limiting their broad deployment in practical applications. Existing approaches also generally struggle to capture unobservable latent market states effectively, such as market sentiment and expecta- tions, microstructural factors, and participant behavior patterns, leading to an inadequate understanding of market dynamics and subsequently impact prediction accuracy. To address these challenges, this paper proposes a stock prediction model, MCI-GRU, based on a multi-head cross-attention mechanism and an improved GRU. First, we enhance the GRU model by replacing the reset gate with an attention mechanism, thereby increasing the model’s flex- ibility in selecting and utilizing historical information. Second, we design a multi-head cross-attention mechanism for learning unobservable latent market state representations, which are further enriched through interactions with both temporal features and cross-sectional features. Finally, extensive experiments conducted on the CSI 300 and CSI 500 datasets from the Chinese stock market, as well as the NASDAQ 100 and S&P 500 datasets from the U.S. stock market, demonstrate that the proposed method outperforms the current state-of-the-art methods across multiple metrics. Furthermore, this approach has been successfully applied in the real-world operations of a fund manage- ment company, validating its effectiveness and practicality in actual financial environments. The code is available at https://github.com/WinstonLiyt/MCI-GRU.",
    "keywords": [
      "stock prediction",
      "multi-head cross-attention",
      "improved GRU",
      "temporal features",
      "cross-sectional features"
    ]
  },
  {
    "article_id": "2410.21291v3_Achilles_Neural_Network_to_Predict_the_Gold_Vs_US_Dollar_Integration_with_Trading_Bot_for_Automatic_",
    "title": "2410.21291v3 Achilles Neural Network to Predict the Gold Vs US Dollar Integration with Trading Bot for Automatic ",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2410.21291v3_Achilles_Neural_Network_to_Predict_the_Gold_Vs_US_Dollar_Integration_with_Trading_Bot_for_Automatic_.pdf",
    "url": "http://arxiv.org/abs/2410.21291v3_Achilles_Neural_Network_to_Predict_the_Gold_Vs_US_Dollar_Integration_with_Trading_Bot_for_Automatic_",
    "pdf_url": "https://arxiv.org/pdf/2410.21291v3_Achilles_Neural_Network_to_Predict_the_Gold_Vs_US_Dollar_Integration_with_Trading_Bot_for_Automatic_",
    "file_size_mb": 1.05,
    "abstract": "Machine Learning Neural Network Long Short Term Memory Commodity Gold vs US Dollar FinBERT Financial News Trading Bot Predicting the stock market is a big challenge for the machine learning world. It is known how difficult it is to have accurate and consistent predictions with ML models. Some architectures are able to capture the movement of stocks but almost never are able to be launched to the production world. We present Achilles, with a classical architecture of LSTM(Long Short Term Memory) neural network this model is able to predict the Gold vs USD commodity. With the predictions minute-per-minute of this model we implemented a trading bot to run during a month of testing excluding weekends. At the end of the testing period we generated $1623.52 in profit with the methodology used. The results of our method demonstrate Machine Learning can successfully be implemented to predict the Gold vs USD commodity.",
    "keywords": [
      "Abstract"
    ]
  },
  {
    "article_id": "2411.01121v1_Hedging_and_Pricing_Structured_Products_Featuring_Multiple_Underlying_Assets",
    "title": "2411.01121v1 Hedging and Pricing Structured Products Featuring Multiple Underlying Assets",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2411.01121v1_Hedging_and_Pricing_Structured_Products_Featuring_Multiple_Underlying_Assets.pdf",
    "url": "http://arxiv.org/abs/2411.01121v1_Hedging_and_Pricing_Structured_Products_Featuring_Multiple_Underlying_Assets",
    "pdf_url": "https://arxiv.org/pdf/2411.01121v1_Hedging_and_Pricing_Structured_Products_Featuring_Multiple_Underlying_Assets",
    "file_size_mb": 0.7,
    "abstract": "Hedging a portfolio containing autocallable notes presents unique challenges due to the complex risk profile of these financial instru- ments. In addition to hedging, pricing these notes, particularly when multiple underlying assets are involved, adds another layer of com- plexity. Pricing autocallable notes involves intricate considerations of various risk factors, including underlying assets, interest rates, and volatility. Traditional pricing methods, such as sample-based Monte Carlo simulations, are often time-consuming and impractical for long maturities, particularly when there are multiple underlying assets. In this paper, we explore autocallable structured notes with three underlying assets and proposes a machine learning-based pricing method that significantly improves efficiency, computing prices 250 times faster than traditional Monte Carlo simulation based method. Additionally, we introduce a Distributional Reinforcement Learn- ing (RL) algorithm to hedge a portfolio containing an autocallable structured note. Our distributional RL based hedging strategy pro- vides better 𝑃𝑛𝐿compared to traditional Delta-neutral and Delta- Gamma neutral hedging strategies. The 𝑉𝑎𝑅5% (𝑃𝑛𝐿value) of our RL agent based hedging is 33.95, significantly outperforming both the Delta neutral strategy, which has a 𝑉𝑎𝑅5% of −0.04, and the Delta-Gamma neutral strategy, which has a 𝑉𝑎𝑅5% of 13.05. It also provides the hedging action with better left tail 𝑃𝑛𝐿, such as 95% and 99% value-at-risk (𝑉𝑎𝑅) and conditional value-at-risk (𝐶𝑉𝑎𝑅), highlighting its potential for front-office hedging and risk manage- ment.",
    "keywords": [
      "Hedging",
      "Reinforcement Learning",
      "Option Pricing",
      "Delta Hedging"
    ]
  },
  {
    "article_id": "2411.05788v1_News-Driven_Stock_Price_Forecasting_in_Indian_Markets_A_Comparative_Study_of_Advanced_Deep_Learning_",
    "title": "2411.05788v1 News-Driven Stock Price Forecasting in Indian Markets A Comparative Study of Advanced Deep Learning ",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2411.05788v1_News-Driven_Stock_Price_Forecasting_in_Indian_Markets_A_Comparative_Study_of_Advanced_Deep_Learning_.pdf",
    "url": "http://arxiv.org/abs/2411.05788v1_News-Driven_Stock_Price_Forecasting_in_Indian_Markets_A_Comparative_Study_of_Advanced_Deep_Learning_",
    "pdf_url": "https://arxiv.org/pdf/2411.05788v1_News-Driven_Stock_Price_Forecasting_in_Indian_Markets_A_Comparative_Study_of_Advanced_Deep_Learning_",
    "file_size_mb": 0.46,
    "abstract": "—Forecasting stock market prices is a challenging task for traders, analysts, and engineers due to the myriad of variables influencing stock prices. However, the advent of artifi- cial intelligence (AI) and natural language processing (NLP) has significantly advanced stock market forecasting. AI’s ability to analyze complex data sets allows for more informed predictions. Despite these advancements, stock price forecasting remains an area where AI has not yet achieved optimal results. In this paper, we forecast stock prices using 30 years of historical data from various national banks in India sourced from the National Stock Exchange. We employ advanced deep learning models, including multivariate multi-step Long Short-Term Memory (LSTM), Facebook Prophet with LightGBM and Optuna, and Seasonal Auto-Regressive Integrated Moving Average (SARIMA). Additionally, we analyze news data from tweets and reliable sources like Business Standard and Reuters, recognizing their significant impact on stock price movements.",
    "keywords": [
      "Stock Market Forecasting",
      "Data preprocess-"
    ]
  },
  {
    "article_id": "2411.05790v1_Comparative_Analysis_of_LSTM_GRU_and_Transformer_Models_for_Stock_Price_Prediction",
    "title": "2411.05790v1 Comparative Analysis of LSTM GRU and Transformer Models for Stock Price Prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2411.05790v1_Comparative_Analysis_of_LSTM_GRU_and_Transformer_Models_for_Stock_Price_Prediction.pdf",
    "url": "http://arxiv.org/abs/2411.05790v1_Comparative_Analysis_of_LSTM_GRU_and_Transformer_Models_for_Stock_Price_Prediction",
    "pdf_url": "https://arxiv.org/pdf/2411.05790v1_Comparative_Analysis_of_LSTM_GRU_and_Transformer_Models_for_Stock_Price_Prediction",
    "file_size_mb": 0.85,
    "abstract": "—In recent fast-paced financial markets, investors constantly seek ways to gain an edge and make informed decisions. Although achieving perfect accuracy in stock price predictions remains elusive, artificial intelligence (AI) advancements have significantly enhanced our ability to analyze historical data and identify potential trends. This paper takes AI- driven stock price trend prediction as the core research, makes a model training data set of famous Tesla cars from 2015 to 2024, and compares LSTM, GRU, and Transformer Models. The analysis is more consistent with the model of stock trend prediction, and the experimental results show that the accuracy of the LSTM model is 94%. These methods ultimately allow investors to make more informed decisions and gain a clearer insight into market behaviours.",
    "keywords": [
      "Artificial intelligence",
      "stock forecasting",
      "LSTM",
      "GRU"
    ]
  },
  {
    "article_id": "2411.10496v1_Guided_Learning_Lubricating_End-to-End_Modeling_for_Multi-stage_Decision-making",
    "title": "2411.10496v1 Guided Learning Lubricating End-to-End Modeling for Multi-stage Decision-making",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2411.10496v1_Guided_Learning_Lubricating_End-to-End_Modeling_for_Multi-stage_Decision-making.pdf",
    "url": "http://arxiv.org/abs/2411.10496v1_Guided_Learning_Lubricating_End-to-End_Modeling_for_Multi-stage_Decision-making",
    "pdf_url": "https://arxiv.org/pdf/2411.10496v1_Guided_Learning_Lubricating_End-to-End_Modeling_for_Multi-stage_Decision-making",
    "file_size_mb": 0.87,
    "abstract": "Multi-stage decision-making is crucial in various real-world artificial intelligence applications, including recommendation systems, autonomous driving, and quantitative investment systems. In quantitative investment, for example, the pro- cess typically involves several sequential stages such as factor mining, alpha prediction, portfolio optimization, and some- times order execution. While state-of-the-art end-to-end mod- eling aims to unify these stages into a single global frame- work, it faces significant challenges: (1) training such a uni- fied neural network consisting of multiple stages between ini- tial inputs and final outputs often leads to suboptimal solu- tions, or even collapse, and (2) many decision-making scenar- ios are not easily reducible to standard prediction problems. To overcome these challenges, we propose Guided Learn- ing, a novel methodological framework designed to enhance end-to-end learning in multi-stage decision-making. We in- troduce the concept of a “guide”, a function that induces the training of intermediate neural network layers towards some phased goals, directing gradients away from subopti- mal collapse. For decision scenarios lacking explicit super- visory labels, we incorporate a utility function that quanti- fies the “reward” of the throughout decision. Additionally, we explore the connections between Guided Learning and clas- sic machine learning paradigms such as supervised, unsuper- vised, semi-supervised, multi-task, and reinforcement learn- ing. Experiments on quantitative investment strategy building demonstrate that guided learning significantly outperforms both traditional stage-wise approaches and existing end-to- end methods.",
    "keywords": []
  },
  {
    "article_id": "2411.11059v1_Financial_News-Driven_LLM_Reinforcement_Learning_for_Portfolio_Management",
    "title": "2411.11059v1 Financial News-Driven LLM Reinforcement Learning for Portfolio Management",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2411.11059v1_Financial_News-Driven_LLM_Reinforcement_Learning_for_Portfolio_Management.pdf",
    "url": "http://arxiv.org/abs/2411.11059v1_Financial_News-Driven_LLM_Reinforcement_Learning_for_Portfolio_Management",
    "pdf_url": "https://arxiv.org/pdf/2411.11059v1_Financial_News-Driven_LLM_Reinforcement_Learning_for_Portfolio_Management",
    "file_size_mb": 1.01,
    "abstract": "Reinforcement learning (RL) has emerged as a transformative approach for finan- cial trading, enabling dynamic strategy optimization in complex markets. This study explores the integration of sentiment analysis, derived from large language models (LLMs), into RL frameworks to enhance trading performance. Experiments were conducted on single-stock trading with Apple Inc. (AAPL) and portfolio trading with the ING Corporate Leaders Trust Series B (LEXCX). The sentiment-enhanced RL models demonstrated superior net worth and cumulative profit compared to RL models without sentiment and, in the portfolio experiment, outperformed the actual LEXCX portfolio’s buy-and-hold strategy. These results highlight the potential of incorporating qualitative market signals to improve decision-making, bridging the gap between quantitative and qualitative approaches in financial trading.",
    "keywords": []
  },
  {
    "article_id": "2411.12747v1_A_Survey_of_Financial_AI_Architectures_Advances_and_Open_Challenges",
    "title": "2411.12747v1 A Survey of Financial AI Architectures Advances and Open Challenges",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2411.12747v1_A_Survey_of_Financial_AI_Architectures_Advances_and_Open_Challenges.pdf",
    "url": "http://arxiv.org/abs/2411.12747v1_A_Survey_of_Financial_AI_Architectures_Advances_and_Open_Challenges",
    "pdf_url": "https://arxiv.org/pdf/2411.12747v1_A_Survey_of_Financial_AI_Architectures_Advances_and_Open_Challenges",
    "file_size_mb": 0.49,
    "abstract": "Financial AI empowers sophisticated approaches to financial market forecasting, portfolio optimiza- tion, and automated trading. This survey pro- vides a systematic analysis of these developments across three primary dimensions: predictive models that capture complex market dynamics, decision- making frameworks that optimize trading and in- vestment strategies, and knowledge augmentation systems that leverage unstructured financial infor- mation. We examine significant innovations in- cluding foundation models for financial time series, graph-based architectures for market relationship modeling, and hierarchical frameworks for portfo- lio optimization. Analysis reveals crucial trade-offs between model sophistication and practical con- straints, particularly in high-frequency trading ap- plications. We identify critical gaps and open chal- lenges between theoretical advances and industrial implementation, outlining open challenges and op- portunities for improving both model performance and practical applicability1.",
    "keywords": []
  },
  {
    "article_id": "2411.13555v3_Deep_Learning_in_Long-Short_Stock_Portfolio_Allocation_An_Empirical_Study",
    "title": "2411.13555v3 Deep Learning in Long-Short Stock Portfolio Allocation An Empirical Study",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2411.13555v3_Deep_Learning_in_Long-Short_Stock_Portfolio_Allocation_An_Empirical_Study.pdf",
    "url": "http://arxiv.org/abs/2411.13555v3_Deep_Learning_in_Long-Short_Stock_Portfolio_Allocation_An_Empirical_Study",
    "pdf_url": "https://arxiv.org/pdf/2411.13555v3_Deep_Learning_in_Long-Short_Stock_Portfolio_Allocation_An_Empirical_Study",
    "file_size_mb": 2.2,
    "abstract": "This paper provides an empirical study explores the application of deep learning algorithms—Multilayer Perceptron (MLP), Convolutional Neural Networks (CNN), Long Short-Term Memory (LSTM), and Transformer—in constructing long-short stock portfolios. Two datasets comprising randomly selected stocks from the S&P 500 and NASDAQ indices, each spanning a decade of daily data, are utilized. The models predict daily stock returns based on historical features such as past returns, Relative Strength Index (RSI), trading volume, and volatility. Portfolios are dynam- ically adjusted by longing stocks with positive predicted returns and shorting those with negative predictions, with equal asset weights. Performance is evaluated over a two-year testing period, focusing on return, Sharpe ratio, and maximum drawdown metrics. The results demonstrate the efficacy of deep learning models in enhancing long-short stock portfolio performance.",
    "keywords": []
  },
  {
    "article_id": "2411.17900v1_Pretrained_LLM_Adapted_with_LoRA_as_a_Decision_Transformer_for_Offline_RL_in_Quantitative_Trading",
    "title": "2411.17900v1 Pretrained LLM Adapted with LoRA as a Decision Transformer for Offline RL in Quantitative Trading",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2411.17900v1_Pretrained_LLM_Adapted_with_LoRA_as_a_Decision_Transformer_for_Offline_RL_in_Quantitative_Trading.pdf",
    "url": "http://arxiv.org/abs/2411.17900v1_Pretrained_LLM_Adapted_with_LoRA_as_a_Decision_Transformer_for_Offline_RL_in_Quantitative_Trading",
    "pdf_url": "https://arxiv.org/pdf/2411.17900v1_Pretrained_LLM_Adapted_with_LoRA_as_a_Decision_Transformer_for_Offline_RL_in_Quantitative_Trading",
    "file_size_mb": 8.76,
    "abstract": "Developing effective quantitative trading strategies using reinforce- ment learning (RL) is challenging due to the high risks associated with online interaction with live financial markets. Consequently, offline RL, which leverages historical market data without addi- tional exploration, becomes essential. However, existing offline RL methods often struggle to capture the complex temporal dependen- cies inherent in financial time series and may overfit to historical patterns. To address these challenges, we introduce a Decision Transformer (DT) initialized with pre-trained GPT-2 weights and fine-tuned using Low-Rank Adaptation (LoRA). This architecture leverages the generalization capabilities of pre-trained language models and the efficiency of LoRA to learn effective trading poli- cies from expert trajectories solely from historical data. Our model performs competitively with established offline RL algorithms, in- cluding Conservative Q-Learning (CQL), Implicit Q-Learning (IQL), and Behavior Cloning (BC), as well as a baseline Decision Trans- former with randomly initialized GPT-2 weights and LoRA. Empiri- cal results demonstrate that our approach effectively learns from expert trajectories and secures superior rewards in certain trading scenarios, highlighting the effectiveness of integrating pre-trained ICAIF ’24 Workshop LLM & GenAI for Finance, November 14, 2024, Brooklyn, NY, USA 2024. language models and parameter-efficient fine-tuning in offline RL for quantitative trading. Replication code for our experiments is publicly available at the project GitHub repository. CCS Concepts • Applied computing →Financial services; • Computing method- ologies →Reinforcement learning; Natural language processing; Transfer learning.",
    "keywords": [
      "Quantitative Trading",
      "Decision Transformer",
      "Parameter Efficient"
    ]
  },
  {
    "article_id": "2411.18997v1_GRU-PFG_Extract_Inter-Stock_Correlation_from_Stock_Factors_with_Graph_Neural_Network",
    "title": "2411.18997v1 GRU-PFG Extract Inter-Stock Correlation from Stock Factors with Graph Neural Network",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2411.18997v1_GRU-PFG_Extract_Inter-Stock_Correlation_from_Stock_Factors_with_Graph_Neural_Network.pdf",
    "url": "http://arxiv.org/abs/2411.18997v1_GRU-PFG_Extract_Inter-Stock_Correlation_from_Stock_Factors_with_Graph_Neural_Network",
    "pdf_url": "https://arxiv.org/pdf/2411.18997v1_GRU-PFG_Extract_Inter-Stock_Correlation_from_Stock_Factors_with_Graph_Neural_Network",
    "file_size_mb": 0.97,
    "abstract": "The complexity of stocks and industries presents challenges for stock predic- tion. Currently, stock prediction models can be divided into two categories. One category, represented by GRU and ALSTM, relies solely on stock factors for pre- diction, with limited effectiveness. The other category, represented by HIST and TRA, incorporates not only stock factors but also industry information, industry financial reports, public sentiment, and other inputs for prediction. The second category of models can capture correlations between stocks by introducing addi- tional information, but the extra data is difficult to standardize and generalize. Considering the current state and limitations of these two types of models, this paper proposes the GRU-PFG (Project Factors into Graph) model. This model only takes stock factors as input and extracts inter-stock correlations using graph neural networks. It achieves prediction results that not only outperform the oth- ers models relies solely on stock factors, but also achieve comparable performance to the second category models. The experimental results show that on the CSI300 dataset, the IC of GRU-PFG is 0.134, outperforming HIST’s 0.131 and signifi- cantly surpassing GRU and Transformer, achieving results better than the second category models. Moreover as a model that relies solely on stock factors, it has greater potential for generalization.",
    "keywords": [
      "Stock trend prediction",
      "Inter-stock correlation",
      "Alpha360 factors"
    ]
  },
  {
    "article_id": "2411.19766v1_Stock_Price_Prediction_using_Multi-Faceted_Information_based_on_Deep_Recurrent_Neural_Networks",
    "title": "2411.19766v1 Stock Price Prediction using Multi-Faceted Information based on Deep Recurrent Neural Networks",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2411.19766v1_Stock_Price_Prediction_using_Multi-Faceted_Information_based_on_Deep_Recurrent_Neural_Networks.pdf",
    "url": "http://arxiv.org/abs/2411.19766v1_Stock_Price_Prediction_using_Multi-Faceted_Information_based_on_Deep_Recurrent_Neural_Networks",
    "pdf_url": "https://arxiv.org/pdf/2411.19766v1_Stock_Price_Prediction_using_Multi-Faceted_Information_based_on_Deep_Recurrent_Neural_Networks",
    "file_size_mb": 0.47,
    "abstract": "— Accurate prediction of stock market trends is crucial for informed investment decisions and effective portfolio management, ultimately leading to enhanced wealth creation and risk mitigation. This study proposes a novel approach for predicting stock prices in the stock market by integrating Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) networks, using sentiment analysis of social network data and candlestick data (price). The proposed methodology consists of two primary components: sentiment analysis of social network and candlestick data. By amalgamating candlestick data with insights gleaned from Twitter, this approach facilitates a more detailed and accurate examination of market trends and patterns, ultimately leading to more effective stock price predictions. Additionally, a Random Forest algorithm is used to classify tweets as either positive or negative, allowing for a more subtle and informed assessment of market sentiment. This study uses CNN and LSTM networks to predict stock prices. The CNN extracts short-term features, while the LSTM models long- term dependencies. The integration of both networks enables a more comprehensive analysis of market trends and patterns, leading to more accurate stock price predictions.",
    "keywords": [
      "Stock Price Prediction",
      "Deep Learning",
      "Sentiment"
    ]
  },
  {
    "article_id": "2412.06862v1_Stock_Type_Prediction_Model_Based_on_Hierarchical_Graph_Neural_Network",
    "title": "2412.06862v1 Stock Type Prediction Model Based on Hierarchical Graph Neural Network",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2412.06862v1_Stock_Type_Prediction_Model_Based_on_Hierarchical_Graph_Neural_Network.pdf",
    "url": "http://arxiv.org/abs/2412.06862v1_Stock_Type_Prediction_Model_Based_on_Hierarchical_Graph_Neural_Network",
    "pdf_url": "https://arxiv.org/pdf/2412.06862v1_Stock_Type_Prediction_Model_Based_on_Hierarchical_Graph_Neural_Network",
    "file_size_mb": 0.7,
    "abstract": "—This paper introduces a novel approach to stock data analysis by employing a Hierarchical Graph Neural Network (HGNN) model that captures multi-level information and relational structures in the stock market. The HGNN model integrates stock relationship data and hierarchical attributes to predict stock types effectively. The paper discusses the construction of a stock industry relationship graph and the extraction of temporal information from historical price sequences. It also highlights the design of a graph convolution operation and a temporal attention aggregator to model the macro market state. The integration of these features results in a comprehensive stock prediction model that addresses the challenges of utilizing stock relationship data and modeling hierarchical attributes in the stock market.",
    "keywords": [
      "Stock Market Analysis",
      "Graph Convolution"
    ]
  },
  {
    "article_id": "2412.07223v7_A_Consolidated_Volatility_Prediction_with_Back_Propagation_Neural_Network_and_Genetic_Algorithm",
    "title": "2412.07223v7 A Consolidated Volatility Prediction with Back Propagation Neural Network and Genetic Algorithm",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2412.07223v7_A_Consolidated_Volatility_Prediction_with_Back_Propagation_Neural_Network_and_Genetic_Algorithm.pdf",
    "url": "http://arxiv.org/abs/2412.07223v7_A_Consolidated_Volatility_Prediction_with_Back_Propagation_Neural_Network_and_Genetic_Algorithm",
    "pdf_url": "https://arxiv.org/pdf/2412.07223v7_A_Consolidated_Volatility_Prediction_with_Back_Propagation_Neural_Network_and_Genetic_Algorithm",
    "file_size_mb": 1.32,
    "abstract": "—This paper provides a unique approach with AI algorithms to predict emerging stock markets volatility. Traditionally, stock volatility is derived from historical volatility, Monte Carlo simulation and implied volatility as well. In this paper, the writer designs a consolidated model with back -propagation neural network and genetic algorithm to predict future volatility of emerging stock markets and found that the results are quite accurate with low errors.",
    "keywords": [
      "deep learning",
      "back propagation neural network"
    ]
  },
  {
    "article_id": "2412.10199v1_Integrative_Analysis_of_Financial_Market_Sentiment_Using_CNN_and_GRU_for_Risk_Prediction_and_Alert_S",
    "title": "2412.10199v1 Integrative Analysis of Financial Market Sentiment Using CNN and GRU for Risk Prediction and Alert S",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2412.10199v1_Integrative_Analysis_of_Financial_Market_Sentiment_Using_CNN_and_GRU_for_Risk_Prediction_and_Alert_S.pdf",
    "url": "http://arxiv.org/abs/2412.10199v1_Integrative_Analysis_of_Financial_Market_Sentiment_Using_CNN_and_GRU_for_Risk_Prediction_and_Alert_S",
    "pdf_url": "https://arxiv.org/pdf/2412.10199v1_Integrative_Analysis_of_Financial_Market_Sentiment_Using_CNN_and_GRU_for_Risk_Prediction_and_Alert_S",
    "file_size_mb": 0.65,
    "abstract": "—This document presents an in-depth examination of stock market sentiment through the integration of Convolutional Neural Networks (CNN) and Gated Recurrent Units (GRU), enabling precise risk alerts. The robust feature extraction capability of CNN is utilized to preprocess and analyze extensive network text data, identifying local features and patterns. The extracted feature sequences are then input into the GRU model to understand the progression of emotional states over time and their potential impact on future market sentiment and risk. This approach addresses the order dependence and long-term dependencies inherent in time series data, resulting in a detailed analysis of stock market sentiment and effective early warnings of future risks.",
    "keywords": [
      "CNN",
      "GRU",
      "Emotion Analysis",
      "Risk Warning"
    ]
  },
  {
    "article_id": "2412.10692v1_Continuous-time_optimal_investment_with_portfolio_constraints_a_reinforcement_learning_approach",
    "title": "2412.10692v1 Continuous-time optimal investment with portfolio constraints a reinforcement learning approach",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2412.10692v1_Continuous-time_optimal_investment_with_portfolio_constraints_a_reinforcement_learning_approach.pdf",
    "url": "http://arxiv.org/abs/2412.10692v1_Continuous-time_optimal_investment_with_portfolio_constraints_a_reinforcement_learning_approach",
    "pdf_url": "https://arxiv.org/pdf/2412.10692v1_Continuous-time_optimal_investment_with_portfolio_constraints_a_reinforcement_learning_approach",
    "file_size_mb": 1.59,
    "abstract": ". In a reinforcement learning (RL) framework, we study the exploratory version of the continuous time expected utility (EU) maximization problem with a portfolio constraint that includes widely-used ﬁnancial regulations such as short-selling constraints and borrowing prohibition. The optimal feedback policy of the exploratory unconstrained classical EU problem is shown to be Gaussian. In the case where the portfolio weight is constrained to a given interval, the corresponding constrained optimal exploratory policy follows a truncated Gaussian distribution. We verify that the closed form optimal solution obtained for logarithmic utility and quadratic utility for both unconstrained and constrained situations converge to the non-exploratory expected utility counterpart when the exploration weight goes to zero. Finally, we establish a policy improvement theorem and devise an implementable reinforcement learning algorithm by casting the optimal problem in a martingale framework. Our numerical examples show that exploration leads to an optimal wealth process that is more dispersedly distributed with heavier tail compared to that of the case without exploration. This eﬀect becomes less signiﬁcant as the exploration parameter is smaller. Moreover, the numerical implementation also conﬁrms the intuitive understanding that a broader domain of investment opportunities necessitates a higher exploration cost. Notably, when subjected to both short-selling and money borrowing constraints, the exploration cost becomes negligible compared to the unconstrained case.",
    "keywords": [
      "and phrases. Optimal investment",
      "entropy regularized",
      "reinforcement learning",
      "exploration",
      "stochastic"
    ]
  },
  {
    "article_id": "2412.11462v1_SP_500_Trend_Prediction",
    "title": "2412.11462v1 SP 500 Trend Prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2412.11462v1_SP_500_Trend_Prediction.pdf",
    "url": "http://arxiv.org/abs/2412.11462v1_SP_500_Trend_Prediction",
    "pdf_url": "https://arxiv.org/pdf/2412.11462v1_SP_500_Trend_Prediction",
    "file_size_mb": 1.96,
    "abstract": "This project aims to predict short-term and long-term upward trends in the S&P 500 index using machine learning models and feature engineering based on the \"101 Formulaic Alphas\" methodology. The study employed multiple models, including Logistic Regression, Decision Trees, Random Forests, Neural Networks, K-Nearest Neighbors (KNN), and XGBoost, to identify market trends from historical stock data collected from Yahoo! Finance. Data preprocessing involved handling missing values, standardization, and iterative feature selection to ensure relevance and variability. For short-term predictions, KNN emerged as the most effective model, delivering robust performance with high recall for upward trends, while for long-term forecasts, XGBoost demonstrated the highest accuracy and AUC scores after hyperparameter tuning and class imbalance adjustments using SMOTE. Feature importance analysis highlighted the dominance of momentum-based and volume-related indicators in driving predictions. However, models exhibited limitations such as overfitting and low recall for positive market movements, particularly in imbalanced datasets. The study concludes that KNN is ideal for short-term alerts, whereas XGBoost is better suited for long-term trend forecasting. Future enhancements could include advanced architectures like Long Short-Term Memory (LSTM) networks and further feature refinement to improve precision and generalizability. These findings contribute to developing reliable machine learning tools for market trend prediction and investment decision-making.",
    "keywords": []
  },
  {
    "article_id": "2412.12516v1_Enhanced_Momentum_with_Momentum_Transformers",
    "title": "2412.12516v1 Enhanced Momentum with Momentum Transformers",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2412.12516v1_Enhanced_Momentum_with_Momentum_Transformers.pdf",
    "url": "http://arxiv.org/abs/2412.12516v1_Enhanced_Momentum_with_Momentum_Transformers",
    "pdf_url": "https://arxiv.org/pdf/2412.12516v1_Enhanced_Momentum_with_Momentum_Transformers",
    "file_size_mb": 0.75,
    "abstract": "The primary objective of this research is to build a Momentum Transformer that is expected to outperform benchmark time-series momentum and mean-reversion trading strategies. We extend the ideas introduced in [6] to equities as the original paper primarily only builds upon futures and equity indices. Unlike conventional Long Short-Term Memory (LSTM) models, which operate sequentially and are optimized for processing local patterns, an attention mechanism equips our architecture with direct access to all prior time steps in the training window. This hybrid design, combining attention with an LSTM, enables the model to capture long-term dependencies, enhance performance in scenarios accounting for transaction costs, and seamlessly adapt to evolving market conditions, such as those witnessed during the Covid Pandemic. The main technical challenges we faced are some of the sins mentioned in the paper “Seven Sins of Quantitative Investing “[11] where we inadvertently faced initial challenges, such as the data not being truly Point-In-Time (PIT) due to issues like data leakage, look-ahead biases, and possibly even survivorship bias, all mentioned in [11]. Further technical challenges were faced in the computation necessary for this strategy. To address these, the time period trained and tested on was reduced to 7 years and only one changepoint lookback window of 21 was used. After rectifying all errors, our results show promise for a few years and are similar with the original paper[6] although our best performing model doesn’t use changepoint detection. We average 4.14% returns which is similar to their results. Our Sharpe is lower at an average of 1.12 due to much higher volatility which may be due to stocks being inherently more volatile than futures and indices.",
    "keywords": []
  },
  {
    "article_id": "2412.13101v4_Pontryagin-Guided_Policy_Optimization_for_Mertons_Portfolio_Problem",
    "title": "2412.13101v4 Pontryagin-Guided Policy Optimization for Mertons Portfolio Problem",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2412.13101v4_Pontryagin-Guided_Policy_Optimization_for_Mertons_Portfolio_Problem.pdf",
    "url": "http://arxiv.org/abs/2412.13101v4_Pontryagin-Guided_Policy_Optimization_for_Mertons_Portfolio_Problem",
    "pdf_url": "https://arxiv.org/pdf/2412.13101v4_Pontryagin-Guided_Policy_Optimization_for_Mertons_Portfolio_Problem",
    "file_size_mb": 1.02,
    "abstract": "We present a Pontryagin-Guided Direct Policy Optimization (PG-DPO) framework for Merton’s portfolio problem, unifying modern neural-network- based policy parameterization with the adjoint viewpoint from Pontryagin’s maximum principle (PMP). Instead of approximating the value function (as done in deep BSDE methods), we track a policy-fixed BSDE for the adjoint processes, which allows each gradient update to align with continuous-time PMP conditions. This setup yields locally optimal consumption and in- vestment policies that are closely tied to classical stochastic control. We further incorporate an alignment penalty that nudges the learned policy to- ward Pontryagin-derived solutions, enhancing both convergence speed and training stability. Numerical experiments confirm that PG-DPO effectively handles both consumption and investment, achieving strong performance and interpretability without requiring large offline datasets or model-free reinforcement learning.",
    "keywords": []
  },
  {
    "article_id": "2412.16160v2_Online_High-Frequency_Trading_Stock_Forecasting_with_Automated_Feature_Clustering_and_Radial_Basis_F",
    "title": "2412.16160v2 Online High-Frequency Trading Stock Forecasting with Automated Feature Clustering and Radial Basis F",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2412.16160v2_Online_High-Frequency_Trading_Stock_Forecasting_with_Automated_Feature_Clustering_and_Radial_Basis_F.pdf",
    "url": "http://arxiv.org/abs/2412.16160v2_Online_High-Frequency_Trading_Stock_Forecasting_with_Automated_Feature_Clustering_and_Radial_Basis_F",
    "pdf_url": "https://arxiv.org/pdf/2412.16160v2_Online_High-Frequency_Trading_Stock_Forecasting_with_Automated_Feature_Clustering_and_Radial_Basis_F",
    "file_size_mb": 0.4,
    "abstract": "—This study presents an autonomous experimen- tal machine learning protocol for high-frequency trading (HFT) stock price forecasting that involves a dual competitive feature importance mechanism and clustering via shallow neural network topology for fast training. By incorporating the k-means algorithm into the radial basis function neural network (RBFNN), the proposed method addresses the chal- lenges of manual clustering and the reliance on potentially uninformative features. More specifically, our approach in- volves a dual competitive mechanism for feature importance, combining the mean-decrease impurity (MDI) method and a gradient descent (GD) based feature importance mechanism. This approach, tested on HFT Level 1 order book data for 20 S&P 500 stocks, enhances the forecasting ability of the RBFNN regressor. Our findings suggest that an autonomous approach to feature selection and clustering is crucial, as each stock requires a different input feature space. Overall, by automating the feature selection and clustering processes, we remove the need for manual topological grid search and provide a more efficient way to predict LOB’s mid-price.",
    "keywords": [
      "High-frequency trading",
      "limit order book"
    ]
  },
  {
    "article_id": "2412.16175v2_Mean--Variance_Portfolio_Selection_by_Continuous-Time_Reinforcement_Learning_Algorithms_Regret_Analy",
    "title": "2412.16175v2 Mean--Variance Portfolio Selection by Continuous-Time Reinforcement Learning Algorithms Regret Analy",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2412.16175v2_Mean--Variance_Portfolio_Selection_by_Continuous-Time_Reinforcement_Learning_Algorithms_Regret_Analy.pdf",
    "url": "http://arxiv.org/abs/2412.16175v2_Mean--Variance_Portfolio_Selection_by_Continuous-Time_Reinforcement_Learning_Algorithms_Regret_Analy",
    "pdf_url": "https://arxiv.org/pdf/2412.16175v2_Mean--Variance_Portfolio_Selection_by_Continuous-Time_Reinforcement_Learning_Algorithms_Regret_Analy",
    "file_size_mb": 3.57,
    "abstract": "We study continuous-time mean–variance portfolio selection in markets where stock prices are diffusion processes driven by observable factors that are also diffusion processes, yet the coefficients of these processes are unknown. Based on the recently developed reinforcement learning (RL) theory for diffusion processes, we present a general data-driven RL algorithm that learns the pre-committed investment strategy directly without attempting to learn or esti- mate the market coefficients. For multi-stock Black–Scholes markets without factors, we further devise a baseline algorithm and prove its performance guarantee by deriving a sublinear regret bound in terms of the Sharpe ratio. For performance enhancement and practical implementa- tion, we modify the baseline algorithm and carry out an extensive empirical study to compare its performance, in terms of a host of common metrics, with a large number of widely employed portfolio allocation strategies on S&P 500 constituents. The results demonstrate that the pro- posed continuous-time RL strategy is consistently among the best, especially in a volatile bear market, and decisively outperforms the model-based continuous-time counterparts by significant margins.",
    "keywords": [
      "Portfolio selection",
      "Dynamic mean–variance analysis",
      "Reinforcement learning",
      "Regret bound"
    ]
  },
  {
    "article_id": "2412.16641v5_A_Systems_Thinking_Approach_to_Algorithmic_Fairness",
    "title": "2412.16641v5 A Systems Thinking Approach to Algorithmic Fairness",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2412.16641v5_A_Systems_Thinking_Approach_to_Algorithmic_Fairness.pdf",
    "url": "http://arxiv.org/abs/2412.16641v5_A_Systems_Thinking_Approach_to_Algorithmic_Fairness",
    "pdf_url": "https://arxiv.org/pdf/2412.16641v5_A_Systems_Thinking_Approach_to_Algorithmic_Fairness",
    "file_size_mb": 0.65,
    "abstract": "Systems thinking provides us with a way to model the algorithmic fairness problem by allowing us to encode prior knowledge and assumptions about where we believe bias might exist in the data generating process. We can then encode these beliefs as a series of causal graphs, enabling us to link AI/ML systems to politics and the law. This allows us to combine techniques from machine learning, causal inference, and system dynamics in order to capture different emergent aspects of the fairness problem. We can use systems thinking to help policymakers on both sides of the political aisle to understand the complex trade-offs that exist from different types of fairness policies, providing a sociotechnical foundation for designing AI policy that is aligned to their political agendas and with society’s shared democratic values. CCS CONCEPTS • Computing methodologies →Causal reasoning and diag- nostics; Probabilistic reasoning; Reasoning about belief and knowledge; • Applied computing →Law; Sociology; Economics; Psychology; • Social and professional topics →Governmental regulations.",
    "keywords": [
      "systems thinking",
      "machine learning",
      "causal inference",
      "system dy-"
    ]
  },
  {
    "article_id": "2412.17293v1_Multimodal_Deep_Reinforcement_Learning_for_Portfolio_Optimization",
    "title": "2412.17293v1 Multimodal Deep Reinforcement Learning for Portfolio Optimization",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2412.17293v1_Multimodal_Deep_Reinforcement_Learning_for_Portfolio_Optimization.pdf",
    "url": "http://arxiv.org/abs/2412.17293v1_Multimodal_Deep_Reinforcement_Learning_for_Portfolio_Optimization",
    "pdf_url": "https://arxiv.org/pdf/2412.17293v1_Multimodal_Deep_Reinforcement_Learning_for_Portfolio_Optimization",
    "file_size_mb": 1.64,
    "abstract": "We propose a reinforcement learning (RL) framework that leverages multimodal data—including historical stock prices, sentiment analysis, and topic embeddings from news articles—to optimize trading strategies for S&P100 stocks. Building upon recent advancements in financial reinforcement learning, we aim to enhance the state space representation by integrating financial sentiment data from SEC filings and news headlines and refining the reward function to better align with portfolio performance metrics. Our methodology includes deep reinforcement learning with state tensors comprising price data, sentiment scores, and news embeddings, processed through advanced feature extraction models like CNNs and RNNs. By benchmarking against traditional portfolio optimization techniques and advanced strategies, we demonstrate the efficacy of our approach in delivering superior portfolio performance. Empirical results showcase the potential of our agent to outperform standard benchmarks, especially when utilizing combined data sources under profit-based reward functions. Preprint. Under review. arXiv:2412.17293v1 [q-fin.PM] 23 Dec 2024",
    "keywords": []
  },
  {
    "article_id": "2412.18563v3_A_Deep_Reinforcement_Learning_Framework_for_Dynamic_Portfolio_Optimization_Evidence_from_Chinas_Stoc",
    "title": "2412.18563v3 A Deep Reinforcement Learning Framework for Dynamic Portfolio Optimization Evidence from Chinas Stoc",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2412.18563v3_A_Deep_Reinforcement_Learning_Framework_for_Dynamic_Portfolio_Optimization_Evidence_from_Chinas_Stoc.pdf",
    "url": "http://arxiv.org/abs/2412.18563v3_A_Deep_Reinforcement_Learning_Framework_for_Dynamic_Portfolio_Optimization_Evidence_from_Chinas_Stoc",
    "pdf_url": "https://arxiv.org/pdf/2412.18563v3_A_Deep_Reinforcement_Learning_Framework_for_Dynamic_Portfolio_Optimization_Evidence_from_Chinas_Stoc",
    "file_size_mb": 2.06,
    "abstract": "Artificial intelligence is transforming financial investment decision-making frameworks, with deep reinforcement learning demonstrating substantial potential in robo-advisory applications. This paper addresses the limitations of traditional portfolio optimization methods in dynamic asset weight adjustment through the development of a deep reinforcement learning-based dynamic optimization model grounded in practical trading processes. The research advances two key innovations: first, the introduction of a novel Sharpe ratio reward function engineered for Actor-Critic deep reinforcement learning algorithms, which ensures stable convergence during training while consistently achieving positive average Sharpe ratios; second, the development of an innovative comprehensive approach to portfolio optimization utilizing deep reinforcement learning, which significantly enhances model optimization capability through the integration of random sampling strategies during training with image-based deep neural network architectures for multi-dimensional financial time series data processing, average Sharpe ratio reward functions, and deep reinforcement learning algorithms. The empirical analysis validates the model using randomly selected constituent stocks from the CSI 300 Index, benchmarking against established financial econometric optimization models. Backtesting results demonstrate the model's efficacy in optimizing portfolio allocation and mitigating investment risk, yielding superior comprehensive performance metrics.",
    "keywords": [
      "：Portfolio Management",
      "Decision Optimization",
      "Dynamic Optimization"
    ]
  },
  {
    "article_id": "2412.19932v1_Hidformer_Transformer-Style_Neural_Network_in_Stock_Price_Forecasting",
    "title": "2412.19932v1 Hidformer Transformer-Style Neural Network in Stock Price Forecasting",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2412.19932v1_Hidformer_Transformer-Style_Neural_Network_in_Stock_Price_Forecasting.pdf",
    "url": "http://arxiv.org/abs/2412.19932v1_Hidformer_Transformer-Style_Neural_Network_in_Stock_Price_Forecasting",
    "pdf_url": "https://arxiv.org/pdf/2412.19932v1_Hidformer_Transformer-Style_Neural_Network_in_Stock_Price_Forecasting",
    "file_size_mb": 0.61,
    "abstract": ". This paper investigates the application of Transformer-based neural networks to stock price forecasting, with a special focus on the intersection of machine learning techniques and financial market analy- sis. The evolution of Transformer models, from their inception to their adaptation for time series analysis in financial contexts, is reviewed and discussed. Central to our study is the exploration of the Hidformer model, which is currently recognized for its promising performance in time se- ries prediction. The primary aim of this paper is to determine whether Hidformer will also prove itself in the task of stock price prediction. This slightly modified model serves as the framework for our experiments, integrating the principles of technical analysis with advanced machine learning concepts to enhance stock price prediction accuracy. We con- duct an evaluation of the Hidformer model’s performance, using a set of criteria to determine its efficacy. Our findings offer additional insights into the practical application of Transformer architectures in financial time series forecasting, highlighting their potential to improve algorith- mic trading strategies, including human decision making.",
    "keywords": [
      "Time-series forecasting",
      "Stock index prediction",
      "Neural"
    ]
  },
  {
    "article_id": "2412.20377v1_Impact_of_Data_Distribution_on_Fairness_Guarantees_in_Equitable_Deep_Learning",
    "title": "2412.20377v1 Impact of Data Distribution on Fairness Guarantees in Equitable Deep Learning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2412.20377v1_Impact_of_Data_Distribution_on_Fairness_Guarantees_in_Equitable_Deep_Learning.pdf",
    "url": "http://arxiv.org/abs/2412.20377v1_Impact_of_Data_Distribution_on_Fairness_Guarantees_in_Equitable_Deep_Learning",
    "pdf_url": "https://arxiv.org/pdf/2412.20377v1_Impact_of_Data_Distribution_on_Fairness_Guarantees_in_Equitable_Deep_Learning",
    "file_size_mb": 1.49,
    "abstract": "—We present a comprehensive theoretical framework analyzing the relationship between data distributions and fairness guarantees in equitable deep learning. Our work establishes novel theoretical bounds that explicitly account for data distribution heterogeneity across demographic groups, while introducing a formal analysis framework that minimizes expected loss differences across these groups. We derive comprehensive theoretical bounds for fairness errors and convergence rates, and characterize how distributional differences between groups affect the fundamental trade-off between fairness and accuracy. Through extensive experiments on diverse datasets, including FairVision (ophthalmology), CheXpert (chest X-rays), HAM10000 (dermatology), and FairFace (facial recognition), we validate our theoretical findings and demonstrate that differences in feature distributions across demographic groups significantly impact model fairness, with performance disparities particularly pronounced in racial categories. The theoretical bounds we derive crroborate these empirical observations, providing insights into the fundamental limits of achieving fairness in deep learning models when faced with heterogeneous data distributions. This work advances our understanding of fairness in AI-based diagnosis systems and provides a theoretical foundation for developing more equitable algorithms. The code for analysis is publicly available via https://github.com/Harvard-Ophthalmology-AI-Lab/fairness guarantees.",
    "keywords": [
      "Fairness Learning",
      "Equitable Deep Learning",
      "Theoretical Fairness Analysis"
    ]
  },
  {
    "article_id": "2501.01010v2_CryptoMamba_Leveraging_State_Space_Models_for_Accurate_Bitcoin_Price_Prediction",
    "title": "2501.01010v2 CryptoMamba Leveraging State Space Models for Accurate Bitcoin Price Prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2501.01010v2_CryptoMamba_Leveraging_State_Space_Models_for_Accurate_Bitcoin_Price_Prediction.pdf",
    "url": "http://arxiv.org/abs/2501.01010v2_CryptoMamba_Leveraging_State_Space_Models_for_Accurate_Bitcoin_Price_Prediction",
    "pdf_url": "https://arxiv.org/pdf/2501.01010v2_CryptoMamba_Leveraging_State_Space_Models_for_Accurate_Bitcoin_Price_Prediction",
    "file_size_mb": 12.99,
    "abstract": "Predicting Bitcoin price remains a challenging problem due to the high volatility and complex non- linear dynamics of cryptocurrency markets. Traditional time-series models, such as ARIMA and GARCH, and recurrent neural networks, like LSTMs, have been widely applied to this task but struggle to capture the regime shifts and long-range dependencies inherent in the data. In this work, we propose CryptoMamba, a novel Mamba-based State Space Model (SSM) architecture designed to effectively capture long-range dependencies in financial time-series data. Our experiments show that CryptoMamba not only provides more accurate predictions but also offers enhanced generaliz- ability across different market conditions, surpassing the limitations of previous models. Coupled with trading algorithms for real-world scenarios, CryptoMamba demonstrates its practical utility by translating accurate forecasts into financial outcomes. Our findings signal a huge advantage for SSMs in stock and cryptocurrency price forecasting tasks. The codebase is available in the following link: https://github.com/MShahabSepehri/CryptoMamba.",
    "keywords": []
  },
  {
    "article_id": "2501.06404v1_A_Hybrid_Framework_for_Reinsurance_Optimization_Integrating_Generative_Models_and_Reinforcement_Lear",
    "title": "2501.06404v1 A Hybrid Framework for Reinsurance Optimization Integrating Generative Models and Reinforcement Lear",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2501.06404v1_A_Hybrid_Framework_for_Reinsurance_Optimization_Integrating_Generative_Models_and_Reinforcement_Lear.pdf",
    "url": "http://arxiv.org/abs/2501.06404v1_A_Hybrid_Framework_for_Reinsurance_Optimization_Integrating_Generative_Models_and_Reinforcement_Lear",
    "pdf_url": "https://arxiv.org/pdf/2501.06404v1_A_Hybrid_Framework_for_Reinsurance_Optimization_Integrating_Generative_Models_and_Reinforcement_Lear",
    "file_size_mb": 1.09,
    "abstract": "Reinsurance optimization is critical for insurers to manage risk exposure, ensure financial stability, and maintain solvency. Traditional approaches often struggle with dynamic claim dis- tributions, high-dimensional constraints, and evolving market conditions. This paper introduces a novel hybrid framework that integrates Generative Models, specifically Variational Autoen- coders (VAEs), with Reinforcement Learning (RL) using Proximal Policy Optimization (PPO). The framework enables dynamic and scalable optimization of reinsurance strategies by combin- ing the generative modeling of complex claim distributions with the adaptive decision-making capabilities of reinforcement learning. The VAE component generates synthetic claims, including rare and catastrophic events, ad- dressing data scarcity and variability, while the PPO algorithm dynamically adjusts reinsurance parameters to maximize surplus and minimize ruin probability. The framework’s performance is validated through extensive experiments, including out-of-sample testing, stress-testing scenar- ios (e.g., pandemic impacts, catastrophic events), and scalability analysis across portfolio sizes. Results demonstrate its superior adaptability, scalability, and robustness compared to traditional optimization techniques, achieving higher final surpluses and computational efficiency. Key contributions include the development of a hybrid approach for high-dimensional op- timization, dynamic reinsurance parameterization, and validation against stochastic claim dis- tributions. The proposed framework offers a transformative solution for modern reinsurance challenges, with potential applications in multi-line insurance operations, catastrophe model- ing, and risk-sharing strategy design.",
    "keywords": [
      "Reinsurance Optimization",
      "Generative Models",
      "Reinforcement Learning",
      "Variational"
    ]
  },
  {
    "article_id": "2501.06832v1_A_novel_multi-agent_dynamic_portfolio_optimization_learning_system_based_on_hierarchical_deep_reinfo",
    "title": "2501.06832v1 A novel multi-agent dynamic portfolio optimization learning system based on hierarchical deep reinfo",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2501.06832v1_A_novel_multi-agent_dynamic_portfolio_optimization_learning_system_based_on_hierarchical_deep_reinfo.pdf",
    "url": "http://arxiv.org/abs/2501.06832v1_A_novel_multi-agent_dynamic_portfolio_optimization_learning_system_based_on_hierarchical_deep_reinfo",
    "pdf_url": "https://arxiv.org/pdf/2501.06832v1_A_novel_multi-agent_dynamic_portfolio_optimization_learning_system_based_on_hierarchical_deep_reinfo",
    "file_size_mb": 2.66,
    "abstract": "Deep Reinforcement Learning (DRL) has been extensively used to address portfolio optimization problems. The DRL agents acquire knowledge and make decisions through unsupervised interactions with their environment without requiring explicit knowledge of the joint dynamics of portfolio assets. Among these DRL algorithms, the combination of actor-critic algorithms and deep function approximators is the most widely used DRL algorithm. Here, we find that training the DRL agent using the actor-critic algorithm and deep function approximators may lead to scenarios where the improvement in the DRL agent's risk-adjusted profitability is not significant. We propose that such situations primarily arise from the following two problems: sparsity in positive reward and the curse of dimensionality. These limitations prevent DRL agents from comprehensively learning asset price change patterns in the training environment. As a result, the DRL agents cannot explore the dynamic portfolio optimization policy to improve the risk-adjusted profitability in the training process. To address these problems, we propose a novel multi-agent Hierarchical Deep Reinforcement Learning (HDRL) algorithmic framework in this research. Under this framework, the agents work together as an learning system for portfolio optimization. Specifically, by designing an auxiliary agent that works together with the executive agent for optimal policy exploration, the learning system can focus on exploring the policy with higher risk-adjusted return in the action space with positive return and low variance. In this way, we can overcome the issue of the curse of dimensionality and improve the training efficiency in the positive reward sparse environment. The performance of the proposed HDRL algorithm is evaluated using a portfolio of 29 stocks from the Dow Jones index in four different experiments. During training, the risk-adjusted profitability of the DRL agent in the training environment is significantly improved. Hence, we can prove that the strategies executed by our learning system in out-sample experiments originate from the DRL agents' comprehensive learning of asset price change patterns in the training environment. Furthermore, each back-test experiment compares the proposed learning system to sixteen traditional strategies and ten strategies based on machine learning algorithms in the performance of profitability and risk control ability. The empirical results in the four evaluation experiments demonstrate the efficacy of our learning system, which outperforms all other strategies by at least 6.3% in terms of return per unit risk. Moreover, our proposed HDRL algorithm framework also outperforms individual DRL agents in the ablation study framework by a margin of at least 9.7% in terms of return per unit risk.",
    "keywords": [
      "hierarchical"
    ]
  },
  {
    "article_id": "2501.08528v1_Dynamic_Portfolio_Optimization_via_Augmented_DDPG_with_Quantum_Price_Levels-Based_Trading_Strategy",
    "title": "2501.08528v1 Dynamic Portfolio Optimization via Augmented DDPG with Quantum Price Levels-Based Trading Strategy",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2501.08528v1_Dynamic_Portfolio_Optimization_via_Augmented_DDPG_with_Quantum_Price_Levels-Based_Trading_Strategy.pdf",
    "url": "http://arxiv.org/abs/2501.08528v1_Dynamic_Portfolio_Optimization_via_Augmented_DDPG_with_Quantum_Price_Levels-Based_Trading_Strategy",
    "pdf_url": "https://arxiv.org/pdf/2501.08528v1_Dynamic_Portfolio_Optimization_via_Augmented_DDPG_with_Quantum_Price_Levels-Based_Trading_Strategy",
    "file_size_mb": 2.08,
    "abstract": "—With the development of deep learning, Dynamic Portfolio Optimization (DPO) problem has received a lot of attention in recent years, not only in the field of finance but also in the field of deep learning. Some advanced research in recent years has proposed the application of Deep Reinforcement Learning (DRL) to the DPO problem, which demonstrated to be more advantageous than supervised learning in solving the DPO problem. However, there are still certain unsolved issues: 1) DRL algorithms usually have the problems of slow learning speed and high sample complexity, which is especially problematic when dealing with complex financial data. 2) researchers use DRL simply for the purpose of obtaining high returns, but pay little attention to the problem of risk control and trading strategy, which will affect the stability of model returns. In order to address these issues, in this study we revamped the intrinsic structure of the model based on the Deep Deterministic Policy Gradient (DDPG) and proposed the Augmented DDPG model. Besides, we also proposed an innovative risk control strategy based on Quantum Price Levels (QPLs) derived from Quantum Finance Theory (QFT). Our experimental results revealed that our model has better profitability as well as risk control ability with less sample complexity in the DPO problem compared to the baseline models.",
    "keywords": [
      "Dynamic Portfolio Optimization",
      "Portfolio Man-"
    ]
  },
  {
    "article_id": "2501.16659v1_Exploratory_Mean-Variance_Portfolio_Optimization_with_Regime-Switching_Market_Dynamics",
    "title": "2501.16659v1 Exploratory Mean-Variance Portfolio Optimization with Regime-Switching Market Dynamics",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2501.16659v1_Exploratory_Mean-Variance_Portfolio_Optimization_with_Regime-Switching_Market_Dynamics.pdf",
    "url": "http://arxiv.org/abs/2501.16659v1_Exploratory_Mean-Variance_Portfolio_Optimization_with_Regime-Switching_Market_Dynamics",
    "pdf_url": "https://arxiv.org/pdf/2501.16659v1_Exploratory_Mean-Variance_Portfolio_Optimization_with_Regime-Switching_Market_Dynamics",
    "file_size_mb": 0.77,
    "abstract": "Considering the continuous-time Mean-Variance (MV) portfolio optimization problem, we study a regime-switching market setting and apply reinforcement learning (RL) techniques to assist in- formed exploration within the control space. We introduce and solve the Exploratory Mean Variance with Regime Switching (EMVRS) problem. We also present a Policy Improvement Theorem. Further, we recognize that the widely applied Temporal Difference (TD) learning is not adequate for the EMVRS context, hence we consider Orthogonality Condition (OC) learning, lever- aging the martingale property of the induced optimal value function from the analytical solution to EMVRS. We design a RL algorithm that has more meaningful parameterization using the market parameters and propose an updating scheme for each parameter. Our empirical results demonstrate the superiority of OC learning over TD learning with a clear convergence of the market parameters towards their corresponding “grounding true” values in a simulated market scenario. In a real market data study, EMVRS with OC learning outperforms its counterparts with the highest mean and reasonably low volatility of the annualized portfolio returns.",
    "keywords": [
      "Mean-Variance Portfolio Optimization",
      "Regime Switching",
      "Stochastic"
    ]
  },
  {
    "article_id": "2501.17366v1_Forecasting_SP_500_Using_LSTM_Models",
    "title": "2501.17366v1 Forecasting SP 500 Using LSTM Models",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2501.17366v1_Forecasting_SP_500_Using_LSTM_Models.pdf",
    "url": "http://arxiv.org/abs/2501.17366v1_Forecasting_SP_500_Using_LSTM_Models",
    "pdf_url": "https://arxiv.org/pdf/2501.17366v1_Forecasting_SP_500_Using_LSTM_Models",
    "file_size_mb": 0.43,
    "abstract": "With the volatile, complex nature of financial data which is also influenced by many external factors, forecasting the stock market has been seen to be a challenging task. Traditional models like ARIMA and GARCH were observed to be good with linear data. However, the stock market data involves non-linear dependencies and intricate patterns that are better handled by machine learning and deep learning approaches. Taking that a step further to patch hyper-parameter tuning and computational complexity that machine learning lacks, we get deep learning models like Long Short-Term Memory (LSTM) networks. In this report, we compare ARIMA and LSTM models in predicting the S&P 500 index, one of the most popular financial benchmarks. Using historical price data and technical indicators, we evaluated these models using the Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE) metrics. The ARIMA model showcased reasonable performance with an MAE of 462.1, RMSE of 614, and an accuracy of 89.8%. This demonstrated its effectiveness in capturing short-term trends but also showed that it is limited by its linear assumptions. The LSTM model, with favorable features, achieved an MAE of 369.32, RMSE of 412.84, and an accuracy of 92. 46%, capturing both short- and long-term dependencies. The LSTM model without features outperformed the version with all features, achieving an MAE of 175.9, RMSE of 207.34, and an accuracy of 96.41%, which showcased its ability to handle market data. Accurately forecasting the stock market is crucial because of its effect on investment strategies, risk assessments, and market stability. By taking advantage of the sequential processing capabilities of LSTM, this report confirms how deep learning methods can handle volatile market conditions when compared to traditional models. The results of our analysis not only reaffirm the transformative potential of LSTM but also provide steps that can be taken to improve upon the model. Through this comprehensive study forecasting financial data, we aim to showcase the insights, limitations, and potential for prediction accuracy. 1 arXiv:2501.17366v1 [cs.LG] 29 Jan 2025",
    "keywords": []
  },
  {
    "article_id": "2501.17992v1_Reinforcement-Learning_Portfolio_Allocation_with_Dynamic_Embedding_of_Market_Information",
    "title": "2501.17992v1 Reinforcement-Learning Portfolio Allocation with Dynamic Embedding of Market Information",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2501.17992v1_Reinforcement-Learning_Portfolio_Allocation_with_Dynamic_Embedding_of_Market_Information.pdf",
    "url": "http://arxiv.org/abs/2501.17992v1_Reinforcement-Learning_Portfolio_Allocation_with_Dynamic_Embedding_of_Market_Information",
    "pdf_url": "https://arxiv.org/pdf/2501.17992v1_Reinforcement-Learning_Portfolio_Allocation_with_Dynamic_Embedding_of_Market_Information",
    "file_size_mb": 1.17,
    "abstract": null,
    "keywords": [
      "portfolio allocation",
      "reinforcement learning",
      "dynamic embedding",
      "online meta-learning"
    ]
  },
  {
    "article_id": "2502.02619v1_Regret-Optimized_Portfolio_Enhancement_through_Deep_Reinforcement_Learning_and_Future_Looking_Reward",
    "title": "2502.02619v1 Regret-Optimized Portfolio Enhancement through Deep Reinforcement Learning and Future Looking Reward",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2502.02619v1_Regret-Optimized_Portfolio_Enhancement_through_Deep_Reinforcement_Learning_and_Future_Looking_Reward.pdf",
    "url": "http://arxiv.org/abs/2502.02619v1_Regret-Optimized_Portfolio_Enhancement_through_Deep_Reinforcement_Learning_and_Future_Looking_Reward",
    "pdf_url": "https://arxiv.org/pdf/2502.02619v1_Regret-Optimized_Portfolio_Enhancement_through_Deep_Reinforcement_Learning_and_Future_Looking_Reward",
    "file_size_mb": 1.01,
    "abstract": "This paper introduces a novel agent-based approach for enhancing existing portfolio strategies using Proximal Policy Optimization (PPO). Rather than focusing solely on traditional portfolio construc- tion, our approach aims to improve an already high-performing strategy through dynamic rebalancing driven by PPO and Oracle agents. Our target is to enhance the traditional 60/40 benchmark (60% stocks, 40% bonds) by employing the Regret-based Sharpe reward function. To address the impact of transaction fee frictions and prevent signal loss, we develop a transaction cost scheduler. We introduce a future-looking reward function and employ synthetic data training through a circular block bootstrap method to facilitate the learning of generalizable allocation strategies. We focus on two key evaluation measures: return and maximum drawdown. Given the high stochasticity of financial markets, we train 20 independent agents each period and evaluate their average performance against the benchmark. Our method not only enhances the performance of the existing portfolio strategy through strategic rebalancing but also demonstrates strong results compared to other baselines.",
    "keywords": [
      "Deep Reinforcement Learning",
      "Proximal Policy Optimization (PPO)"
    ]
  },
  {
    "article_id": "2502.04737v1_Learning_Universal_Multi-level_Market_Irrationality_Factors_to_Improve_Stock_Return_Forecasting",
    "title": "2502.04737v1 Learning Universal Multi-level Market Irrationality Factors to Improve Stock Return Forecasting",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2502.04737v1_Learning_Universal_Multi-level_Market_Irrationality_Factors_to_Improve_Stock_Return_Forecasting.pdf",
    "url": "http://arxiv.org/abs/2502.04737v1_Learning_Universal_Multi-level_Market_Irrationality_Factors_to_Improve_Stock_Return_Forecasting",
    "pdf_url": "https://arxiv.org/pdf/2502.04737v1_Learning_Universal_Multi-level_Market_Irrationality_Factors_to_Improve_Stock_Return_Forecasting",
    "file_size_mb": 2.48,
    "abstract": "Recent years have witnessed the perfect encounter of deep learning and quantitative trading has achieved great success in stock invest- ment. Numerous deep learning-based models have been developed for forecasting stock returns, leveraging the powerful representa- tion capabilities of neural networks to identify patterns and factors influencing stock prices. These models can effectively capture gen- eral patterns in the market, such as stock price trends, volume-price relationships, and time variations. However, the impact of special irrationality factors – such as market sentiment, speculative be- havior, market manipulation, and psychological biases – has not been fully considered in existing deep stock forecasting models due to their relative abstraction as well as lack of explicit labels and data description. To fill this gap, we propose UMI, a Universal multi-level Market Irrationality factor model to enhance stock return forecasting. The UMI model learns factors that can reflect irrational behaviors in market from both individual stock and overall market levels. For the stock-level, UMI construct an estimated rational price for each stock, which is cointegrated with the stock’s actual price. The discrepancy between the actual and the rational prices serves as a factor to indicate stock-level irrational events. Additionally, we define market-level irrational behaviors as anomalous synchronous fluctuations of stocks within a market. Using two self-supervised representation learning tasks, i.e., sub-market comparative learning and market synchronism prediction, the UMI model incorporates market-level irrationalities into a market representation vector, which is then used as the market-level irrationality factor. We also ∗Corresponding author Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. KDD ’25, Toronto, ON, Canada © 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 979-8-4007-1245-6/25/08 https://doi.org/10.1145/3690624.3709328 developed a forecasting model that captures both temporal and relational dependencies among stocks, accommodating the UMI factors. Extensive experiments on U.S. and Chinese stock markets with competitive baselines demonstrate our model’s effectiveness and the universality of our factors in improving various forecasting models. We provide our code at https://github.com/lIcIIl/UMI. CCS Concepts • Applied computing →Economics; • Information systems → Dat",
    "keywords": [
      "Stock Return Forecasting",
      "Market Irrationality",
      "Deep Learning",
      "Self-"
    ]
  },
  {
    "article_id": "2502.05186v1_Multimodal_Stock_Price_Prediction",
    "title": "2502.05186v1 Multimodal Stock Price Prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2502.05186v1_Multimodal_Stock_Price_Prediction.pdf",
    "url": "http://arxiv.org/abs/2502.05186v1_Multimodal_Stock_Price_Prediction",
    "pdf_url": "https://arxiv.org/pdf/2502.05186v1_Multimodal_Stock_Price_Prediction",
    "file_size_mb": 0.44,
    "abstract": "In an era where financial markets are heavily influenced by many static and dynamic factors, it has become increasingly critical to carefully integrate diverse data sources with machine learning for accurate stock price prediction. This paper explores a multimodal machine learning approach for stock price prediction by combining data from diverse sources, including traditional financial metrics, tweets, and news articles. We capture real-time market dynamics and investor mood through sentiment analysis on these textual data using both ChatGPT-4o and FinBERT models. We look at how these integrated data streams augment predictions made with a standard Long Short-Term Memory (LSTM model) to illustrate the extent of performance gains. Our study's results indicate that incorporating the mentioned data sources considerably increases the forecast effectiveness of the reference model by up to 5%. We also provide insights into the individual and combined predictive capacities of these modalities, highlighting the substantial impact of incorporating sentiment analysis from tweets and news articles. This research offers a systematic and effective framework for applying multimodal data analytics techniques in financial time series forecasting that provides a new view for investors to leverage data for decision-making.",
    "keywords": [
      "Financial Forecasting",
      "Stock Market",
      "Deep Learning",
      "Deep Neural Networks",
      "Finbert",
      "Chatgpt"
    ]
  },
  {
    "article_id": "2502.05210v3_Regression_and_Forecasting_of_US_Stock_Returns_Based_on_LSTM",
    "title": "2502.05210v3 Regression and Forecasting of US Stock Returns Based on LSTM",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2502.05210v3_Regression_and_Forecasting_of_US_Stock_Returns_Based_on_LSTM.pdf",
    "url": "http://arxiv.org/abs/2502.05210v3_Regression_and_Forecasting_of_US_Stock_Returns_Based_on_LSTM",
    "pdf_url": "https://arxiv.org/pdf/2502.05210v3_Regression_and_Forecasting_of_US_Stock_Returns_Based_on_LSTM",
    "file_size_mb": 1.23,
    "abstract": "This paper analyses the investment returns of three stock sectors, Manuf, Hitec, and Other, in the U.S. stock market, based on the Fama-French three-factor model, the Carhart four-factor model, and the Fama-French five-factor model, in order to test the validity of the Fama-French three-factor model, the Carhart four-factor model, and the Fama-French five-factor model for the three sectors of the market. French five-factor model for the three sectors of the market. Also, the LSTM model is used to explore the additional factors affecting stock returns. The empirical results show that the Fama-French five- factor model has better validity for the three segments of the market under study, and the LSTM model has the ability to capture the factors affecting the returns of certain industries, and can better regress and predict the stock returns of the relevant industries. CCS CONCEPTS Mathematics of computing ~ Probability and statistics ~ Probabilistic inference problems",
    "keywords": [
      "Fama-French model",
      "Carhart model",
      "Factor model",
      "LSTM model"
    ]
  },
  {
    "article_id": "2502.06775v2_Enhancing_Performance_of_Explainable_AI_Models_with_Constrained_Concept_Refinement",
    "title": "2502.06775v2 Enhancing Performance of Explainable AI Models with Constrained Concept Refinement",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2502.06775v2_Enhancing_Performance_of_Explainable_AI_Models_with_Constrained_Concept_Refinement.pdf",
    "url": "http://arxiv.org/abs/2502.06775v2_Enhancing_Performance_of_Explainable_AI_Models_with_Constrained_Concept_Refinement",
    "pdf_url": "https://arxiv.org/pdf/2502.06775v2_Enhancing_Performance_of_Explainable_AI_Models_with_Constrained_Concept_Refinement",
    "file_size_mb": 14.3,
    "abstract": "The trade-off between accuracy and interpretabil- ity has long been a challenge in machine learning (ML). This tension is particularly significant for emerging interpretable-by-design methods, which aim to redesign ML algorithms for trustworthy in- terpretability but often sacrifice accuracy in the process. In this paper, we address this gap by investigating the impact of deviations in concept representations—an essential component of in- terpretable models—on prediction performance and propose a novel framework to mitigate these effects. The framework builds on the principle of optimizing concept embeddings under con- straints that preserve interpretability. Using a gen- erative model as a test-bed, we rigorously prove that our algorithm achieves zero loss while pro- gressively enhancing the interpretability of the resulting model. Additionally, we evaluate the practical performance of our proposed framework in generating explainable predictions for image classification tasks across various benchmarks. Compared to existing explainable methods, our approach not only improves prediction accuracy while preserving model interpretability across var- ious large-scale benchmarks but also achieves this with significantly lower computational cost.",
    "keywords": []
  },
  {
    "article_id": "2502.07214v1_Pareto_Optimal_Algorithmic_Recourse_in_Multi-cost_Function",
    "title": "2502.07214v1 Pareto Optimal Algorithmic Recourse in Multi-cost Function",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2502.07214v1_Pareto_Optimal_Algorithmic_Recourse_in_Multi-cost_Function.pdf",
    "url": "http://arxiv.org/abs/2502.07214v1_Pareto_Optimal_Algorithmic_Recourse_in_Multi-cost_Function",
    "pdf_url": "https://arxiv.org/pdf/2502.07214v1_Pareto_Optimal_Algorithmic_Recourse_in_Multi-cost_Function",
    "file_size_mb": 0.58,
    "abstract": ". In decision-making systems, algorithmic recourse aims to identify minimal-cost actions to alter an individual’s features, thereby obtaining a desired outcome. This empowers individuals to understand, question, or alter decisions that negatively affect them. However, due to the variety and sensitivity of system environments and individual per- sonalities, quantifying the cost of a single function is nearly impossi- ble while considering multiple criteria situations. Most current recourse mechanisms use gradient-based methods that assume cost functions are differentiable, often not applicable in real-world scenarios, resulting in sub-optimal solutions that compromise various criteria. These solutions are typically intractable and lack rigorous theoretical foundations, raising concerns regarding interpretability, reliability, and transparency from the explainable AI (XAI) perspective. To address these issues, this work pro- poses an algorithmic recourse framework that handles non-differentiable and discrete multi-cost functions. By formulating recourse as a multi- objective optimization problem and assigning weights to different cri- teria based on their importance, our method identifies Pareto optimal recourse recommendations. To demonstrate scalability, we incorporate the concept of ϵ-net, proving the ability to find approximated Pareto optimal actions. Experiments show the trade-off between different crite- ria and the method’s scalability in large graphs. Compared to current heuristic practices, our approach provides a stronger theoretical founda- tion and better aligns recourse suggestions with real-world requirements.",
    "keywords": [
      "multi-objective optimization",
      "recourse",
      "shortest path"
    ]
  },
  {
    "article_id": "2502.07280v1_MIGT_Memory_Instance_Gated_Transformer_Framework_for_Financial_Portfolio_Management",
    "title": "2502.07280v1 MIGT Memory Instance Gated Transformer Framework for Financial Portfolio Management",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2502.07280v1_MIGT_Memory_Instance_Gated_Transformer_Framework_for_Financial_Portfolio_Management.pdf",
    "url": "http://arxiv.org/abs/2502.07280v1_MIGT_Memory_Instance_Gated_Transformer_Framework_for_Financial_Portfolio_Management",
    "pdf_url": "https://arxiv.org/pdf/2502.07280v1_MIGT_Memory_Instance_Gated_Transformer_Framework_for_Financial_Portfolio_Management",
    "file_size_mb": 1.99,
    "abstract": "Deep reinforcement learning (DRL) has been applied in financial portfolio management to improve returns in changing market conditions. However, unlike most fields where DRL is widely used, the stock market is more volatile and dynamic as it is affected by several factors such as global events and investor sentiment. Therefore, it remains a challenge to construct a DRL-based portfolio manage- ment framework with strong return capability, stable training, and generalization ability. This study introduces a new framework utilizing the Memory Instance Gated Transformer (MIGT) for effective portfolio management. By incorporating a novel Gated Instance Attention module, which combines a transformer variant, instance normalization, and a Lite Gate Unit, our approach aims to maxi- mize investment returns while ensuring the learning process’s stability and reducing outlier impacts. Tested on the Dow Jones Industrial Average 30, our framework’s performance is evaluated against fifteen other strategies using key financial metrics like the cumulative return and risk-return ratios (Sharpe, Sortino, and Omega ratios). The results highlight MIGT’s advantage, showcasing at least a 9.75% improvement in cumulative returns and a minimum 2.36% increase in risk-return ratios over competing strategies, marking a significant advancement in DRL for portfolio management.",
    "keywords": [
      "Portfolio Management",
      "Deep reinforcement learning",
      "Transformer",
      "Stock Market"
    ]
  },
  {
    "article_id": "2502.08542v3_Beyond_Predictions_A_Participatory_Framework_for_Multi-Stakeholder_Decision-Making",
    "title": "2502.08542v3 Beyond Predictions A Participatory Framework for Multi-Stakeholder Decision-Making",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2502.08542v3_Beyond_Predictions_A_Participatory_Framework_for_Multi-Stakeholder_Decision-Making.pdf",
    "url": "http://arxiv.org/abs/2502.08542v3_Beyond_Predictions_A_Participatory_Framework_for_Multi-Stakeholder_Decision-Making",
    "pdf_url": "https://arxiv.org/pdf/2502.08542v3_Beyond_Predictions_A_Participatory_Framework_for_Multi-Stakeholder_Decision-Making",
    "file_size_mb": 1.31,
    "abstract": "Conventional automated decision-support systems often prioritize predictive accuracy, overlooking the complexities of real-world set- tings where stakeholders’ preferences may diverge or conflict. This can lead to outcomes that disadvantage vulnerable groups and erode trust in algorithmic processes. Participatory AI approaches aim to address these issues but remain largely context-specific, limiting their broader applicability and scalability. To address these gaps, we propose a participatory framework that reframes decision-making as a multi-stakeholder learning and optimization problem. Our modular, model-agnostic approach builds on the standard machine learning training pipeline to fine-tune user-provided prediction models and evaluate decision strategies, including compromise functions that mediate stakeholder trade-offs. A synthetic scoring mechanism aggregates user-defined preferences across multiple metrics, ranking strategies and selecting an optimal decision-maker to generate actionable recommendations that jointly optimize per- formance, fairness, and domain-specific goals. Empirical validation on two high-stakes case studies demonstrates the versatility of the framework and its promise as a more accountable, context-aware alternative to prediction-centric pipelines for socially impactful deployments.",
    "keywords": [
      "Participatory AI",
      "Multi-stakeholder decision-making",
      "Accountable"
    ]
  },
  {
    "article_id": "2502.09724v2_Navigating_the_Social_Welfare_Frontier_Portfolios_for_Multi-objective_Reinforcement_Learning",
    "title": "2502.09724v2 Navigating the Social Welfare Frontier Portfolios for Multi-objective Reinforcement Learning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2502.09724v2_Navigating_the_Social_Welfare_Frontier_Portfolios_for_Multi-objective_Reinforcement_Learning.pdf",
    "url": "http://arxiv.org/abs/2502.09724v2_Navigating_the_Social_Welfare_Frontier_Portfolios_for_Multi-objective_Reinforcement_Learning",
    "pdf_url": "https://arxiv.org/pdf/2502.09724v2_Navigating_the_Social_Welfare_Frontier_Portfolios_for_Multi-objective_Reinforcement_Learning",
    "file_size_mb": 0.88,
    "abstract": "In many real-world applications of reinforcement learning (RL), deployed policies have varied im- pacts on different stakeholders, creating chal- lenges in reaching consensus on how to effec- tively aggregate their preferences. Generalized p-means form a widely used class of social wel- fare functions for this purpose, with broad applica- tions in fair resource allocation, AI alignment, and decision-making. This class includes well-known welfare functions such as Egalitarian, Nash, and Utilitarian welfare. However, selecting the appro- priate social welfare function is challenging for decision-makers, as the structure and outcomes of optimal policies can be highly sensitive to the choice of p. To address this challenge, we study the concept of an α-approximate portfolio in RL, a set of policies that are approximately optimal across the family of generalized p-means for all p ≤1. We propose algorithms to compute such portfolios and provide theoretical guarantees on the trade-offs among approximation factor, portfo- lio size, and computational efficiency. Experimen- tal results on synthetic and real-world datasets demonstrate the effectiveness of our approach in summarizing the policy space induced by varying p values, empowering decision-makers to navi- gate this landscape more effectively.",
    "keywords": []
  },
  {
    "article_id": "2502.10473v1_Diverse_Transformer_Decoding_for_Offline_Reinforcement_Learning_Using_Financial_Algorithmic_Approach",
    "title": "2502.10473v1 Diverse Transformer Decoding for Offline Reinforcement Learning Using Financial Algorithmic Approach",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2502.10473v1_Diverse_Transformer_Decoding_for_Offline_Reinforcement_Learning_Using_Financial_Algorithmic_Approach.pdf",
    "url": "http://arxiv.org/abs/2502.10473v1_Diverse_Transformer_Decoding_for_Offline_Reinforcement_Learning_Using_Financial_Algorithmic_Approach",
    "pdf_url": "https://arxiv.org/pdf/2502.10473v1_Diverse_Transformer_Decoding_for_Offline_Reinforcement_Learning_Using_Financial_Algorithmic_Approach",
    "file_size_mb": 0.55,
    "abstract": "Offline Reinforcement Learning (RL) algorithms learn a policy using a fixed training dataset, which is then deployed online to interact with the environ- ment. Transformers, a standard choice for model- ing time-series data, are gaining popularity in of- fline RL. In this context, Beam Search (BS), an approximate inference algorithm, is the go-to de- coding method. In offline RL, the restricted dataset induces uncertainty as the agent may encounter un- familiar sequences of states and actions during exe- cution that were not covered in the training data. In this context, BS lacks two important proper- ties essential for offline RL: It does not account for the aforementioned uncertainty, and its greedy left- right search approach often results in sequences with minimal variations, failing to explore poten- tially better alternatives. To address these limitations, we propose Portfolio Beam Search (PBS), a simple-yet-effective alter- native to BS that balances exploration and exploita- tion within a Transformer model during decoding. We draw inspiration from financial economics and apply these principles to develop an uncertainty- aware diversification mechanism, which we inte- grate into a sequential decoding algorithm at infer- ence time. We empirically demonstrate the effec- tiveness of PBS on the D4RL locomotion bench- mark, where it achieves higher returns and signifi- cantly reduces outcome variability.",
    "keywords": []
  },
  {
    "article_id": "2502.10776v1_A_Distillation-based_Future-aware_Graph_Neural_Network_for_Stock_Trend_Prediction",
    "title": "2502.10776v1 A Distillation-based Future-aware Graph Neural Network for Stock Trend Prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2502.10776v1_A_Distillation-based_Future-aware_Graph_Neural_Network_for_Stock_Trend_Prediction.pdf",
    "url": "http://arxiv.org/abs/2502.10776v1_A_Distillation-based_Future-aware_Graph_Neural_Network_for_Stock_Trend_Prediction",
    "pdf_url": "https://arxiv.org/pdf/2502.10776v1_A_Distillation-based_Future-aware_Graph_Neural_Network_for_Stock_Trend_Prediction",
    "file_size_mb": 0.51,
    "abstract": "—Stock trend prediction involves forecasting the fu- ture price movements by analyzing historical data and various market indicators. With the advancement of machine learning, graph neural networks (GNNs) have been extensively employed in stock prediction due to their powerful capability to capture spatiotemporal dependencies of stocks. However, despite the efforts of various GNN stock predictors to enhance predictive per- formance, the improvements remain limited, as they focus solely on analyzing historical spatiotemporal dependencies, overlooking the correlation between historical and future patterns. In this study, we propose a novel distillation-based future-aware GNN framework (DishFT-GNN) for stock trend prediction. Specifically, DishFT-GNN trains a teacher model and a student model, iteratively. The teacher model learns to capture the correlation between distribution shifts of historical and future data, which is then utilized as intermediate supervision to guide the student model to learn future-aware spatiotemporal embeddings for accurate prediction. Through extensive experiments on two real- world datasets, we verify the state-of-the-art performance of DishFT-GNN.",
    "keywords": [
      "Stock prediction",
      "Data mining",
      "Future fusion"
    ]
  },
  {
    "article_id": "2502.15726v1_Bankruptcy_analysis_using_images_and_convolutional_neural_networks_CNN",
    "title": "2502.15726v1 Bankruptcy analysis using images and convolutional neural networks CNN",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2502.15726v1_Bankruptcy_analysis_using_images_and_convolutional_neural_networks_CNN.pdf",
    "url": "http://arxiv.org/abs/2502.15726v1_Bankruptcy_analysis_using_images_and_convolutional_neural_networks_CNN",
    "pdf_url": "https://arxiv.org/pdf/2502.15726v1_Bankruptcy_analysis_using_images_and_convolutional_neural_networks_CNN",
    "file_size_mb": 1.33,
    "abstract": "The marketing departments of financial institutions strive to craft products and services that cater to the diverse needs of businesses of all sizes. However, it is evident upon analysis that larger corporations often receive a more substantial portion of available funds. This disparity arises from the relative ease of assessing the risk of default and bankruptcy in these more prominent companies. Historically, risk analysis studies have focused on data from publicly traded or stock exchange-listed companies, leaving a gap in knowledge about small and medium-sized enterprises (SMEs). Addressing this gap, this study introduces a method for evaluating SMEs by generating images for processing via a convolutional neural network (CNN). To this end, more than 10,000 images, one for each company in the sample, were created to identify scenarios in which the CNN can operate with higher assertiveness and reduced training error probability. The findings demonstrate a significant predictive capacity, achieving 97.8% accuracy, when a substantial number of images are utilized. Moreover, the image creation method paves the way for potential applications of this technique in various sectors and for different analytical purposes.",
    "keywords": [
      "Neural Networks",
      "Financial Marketing",
      "Bankruptcy",
      "Fintech"
    ]
  },
  {
    "article_id": "2502.15813v1_Stock_Price_Prediction_Using_a_Hybrid_LSTM-GNN_Model_Integrating_Time-Series_and_Graph-Based_Analysi",
    "title": "2502.15813v1 Stock Price Prediction Using a Hybrid LSTM-GNN Model Integrating Time-Series and Graph-Based Analysi",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2502.15813v1_Stock_Price_Prediction_Using_a_Hybrid_LSTM-GNN_Model_Integrating_Time-Series_and_Graph-Based_Analysi.pdf",
    "url": "http://arxiv.org/abs/2502.15813v1_Stock_Price_Prediction_Using_a_Hybrid_LSTM-GNN_Model_Integrating_Time-Series_and_Graph-Based_Analysi",
    "pdf_url": "https://arxiv.org/pdf/2502.15813v1_Stock_Price_Prediction_Using_a_Hybrid_LSTM-GNN_Model_Integrating_Time-Series_and_Graph-Based_Analysi",
    "file_size_mb": 0.56,
    "abstract": "This paper presents a novel hybrid model that integrates long-short-term memory (LSTM) networks and Graph Neural Networks (GNNs) to significantly enhance the accuracy of stock market predic- tions. The LSTM component adeptly captures temporal patterns in stock price data, effectively modeling the time series dynamics of financial markets. Concurrently, the GNN component leverages Pearson correlation and association analysis to model inter-stock relational data, capturing complex nonlinear polyadic dependencies influencing stock prices. The model is trained and evaluated using an expanding window validation approach, enabling continuous learning from increasing amounts of data and adaptation to evolving market conditions. Extensive experiments conducted on historical stock data demonstrate that our hybrid LSTM-GNN model achieves a mean square error (MSE) of 0.00144, representing a substantial reduction of 10.6% compared to the MSE of the standalone LSTM model of 0.00161. Furthermore, the hybrid model outperforms traditional and advanced benchmarks, including linear regression, convolutional neural networks (CNN), and dense networks. These compelling results underscore the significant potential of combining temporal and relational data through a hybrid approach, offering a powerful tool for real-time trading and financial analysis.",
    "keywords": [
      "Stock Market Prediction",
      "LSTM",
      "GNN",
      "Hybrid Models",
      "Time-Series Analysis",
      "Financial Forecasting"
    ]
  },
  {
    "article_id": "2502.15853v1_Multi-Agent_Stock_Prediction_Systems_Machine_Learning_Models_Simulations_and_Real-Time_Trading_Strat",
    "title": "2502.15853v1 Multi-Agent Stock Prediction Systems Machine Learning Models Simulations and Real-Time Trading Strat",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2502.15853v1_Multi-Agent_Stock_Prediction_Systems_Machine_Learning_Models_Simulations_and_Real-Time_Trading_Strat.pdf",
    "url": "http://arxiv.org/abs/2502.15853v1_Multi-Agent_Stock_Prediction_Systems_Machine_Learning_Models_Simulations_and_Real-Time_Trading_Strat",
    "pdf_url": "https://arxiv.org/pdf/2502.15853v1_Multi-Agent_Stock_Prediction_Systems_Machine_Learning_Models_Simulations_and_Real-Time_Trading_Strat",
    "file_size_mb": 1.73,
    "abstract": "This paper presents a comprehensive study on stock price prediction, leveraging advanced machine learning (ML) and deep learning (DL) techniques to improve financial forecasting accuracy. The research evaluates the performance of vari- ous recurrent neural network (RNN) architectures, including Long Short-Term Memory (LSTM) networks, Gated Recurrent Units (GRU), and attention-based models. These models are assessed for their ability to capture complex temporal dependencies inherent in stock market data. Our findings show that attention- based models outperform other architectures, achieving the highest accuracy by effectively capturing both short- and long-term dependencies. This study con- tributes valuable insights into AI-driven financial forecasting, offering practical guidance for developing more accurate and efficient trading systems.",
    "keywords": [
      "Stock Prediction",
      "Financial Forecasting",
      "LSTM",
      "AI-driven Trading Systems"
    ]
  },
  {
    "article_id": "2502.17011v1_Predicting_Liquidity-Aware_Bond_Yields_using_Causal_GANs_and_Deep_Reinforcement_Learning_with_LLM_Ev",
    "title": "2502.17011v1 Predicting Liquidity-Aware Bond Yields using Causal GANs and Deep Reinforcement Learning with LLM Ev",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2502.17011v1_Predicting_Liquidity-Aware_Bond_Yields_using_Causal_GANs_and_Deep_Reinforcement_Learning_with_LLM_Ev.pdf",
    "url": "http://arxiv.org/abs/2502.17011v1_Predicting_Liquidity-Aware_Bond_Yields_using_Causal_GANs_and_Deep_Reinforcement_Learning_with_LLM_Ev",
    "pdf_url": "https://arxiv.org/pdf/2502.17011v1_Predicting_Liquidity-Aware_Bond_Yields_using_Causal_GANs_and_Deep_Reinforcement_Learning_with_LLM_Ev",
    "file_size_mb": 5.35,
    "abstract": "Financial bond yield forecasting is challenging due to data scarcity, nonlinear macroeconomic dependencies, and evolv- ing market conditions. In this paper, we propose a novel framework that leverages Causal Generative Adversarial Net- works (CausalGANs) and Soft Actor-Critic (SAC) reinforce- ment learning (RL) to generate high-fidelity synthetic bond yield data for four major bond categories (AAA, BAA, US10Y, Junk). By incorporating 12 key macroeconomic vari- ables, we ensure statistical fidelity by preserving essen- tial market properties. To transform this market dependent- synthetic data into actionable insights, we employ a fine- tuned Large Language Model (LLM) Qwen2.5-7B that gen- erates trading signals (BUY/HOLD/SELL), risk assessments, and volatility projections. We use automated, human and LLM evaluations, all of which demonstrate that our frame- work improves forecasting performance over existing meth- ods, with statistical validation via predictive accuracy, MAE evaluation(0.103%), profit/loss evaluation (60% profit rate), LLM evaluation (3.37/5) and expert assessments scoring 4.67 out of 5. The reinforcement learning-enhanced synthetic data generation achieves the least Mean Absolute Error of 0.103, demonstrating its effectiveness in replicating real-world bond market dynamics. We not only enhance data-driven trading strategies but also provides a scalable, high-fidelity synthetic financial data pipeline for risk & volatility management and investment decision-making. This work establishes a bridge between synthetic data generation, LLM driven financial forecasting, and language model evaluation, contributing to AI-driven financial decision-making.",
    "keywords": [
      "Financial Time Series",
      "Predictive Modeling"
    ]
  },
  {
    "article_id": "2502.17777v1_Adaptive_Nesterov_Accelerated_Distributional_Deep_Hedging_for_Efficient_Volatility_Risk_Management",
    "title": "2502.17777v1 Adaptive Nesterov Accelerated Distributional Deep Hedging for Efficient Volatility Risk Management",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2502.17777v1_Adaptive_Nesterov_Accelerated_Distributional_Deep_Hedging_for_Efficient_Volatility_Risk_Management.pdf",
    "url": "http://arxiv.org/abs/2502.17777v1_Adaptive_Nesterov_Accelerated_Distributional_Deep_Hedging_for_Efficient_Volatility_Risk_Management",
    "pdf_url": "https://arxiv.org/pdf/2502.17777v1_Adaptive_Nesterov_Accelerated_Distributional_Deep_Hedging_for_Efficient_Volatility_Risk_Management",
    "file_size_mb": 0.34,
    "abstract": "In the ﬁeld of ﬁnancial derivatives trading, managing volatility risk is crucial for protecting invest- ment portfolios from market changes. Traditional Vega hedging strategies, which often rely on basic and rule-based models, are hard to adapt well to rapidly changing market conditions. We intro- duce a new framework for dynamic Vega hedging, the Adaptive Nesterov Accelerated Distributional Deep Hedging (ANADDH), which combines distributional reinforcement learning with a tailored design based on adaptive Nesterov acceleration. This approach improves the learning process in complex ﬁnancial environments by modeling the hedging efﬁciency distribution, providing a more accurate and responsive hedging strategy. The design of adaptive Nesterov acceleration reﬁnes gra- dient momentum adjustments, signiﬁcantly enhancing the stability and speed of convergence of the model. Through empirical analysis and comparisons, our method demonstrates substantial perfor- mance gains over existing hedging techniques. Our results conﬁrm that this innovative combination of distributional reinforcement learning with the proposed optimization techniques improves ﬁnan- cial risk management and highlights the practical beneﬁts of implementing advanced neural network architectures in the ﬁnance sector.",
    "keywords": [
      "Deep Vega Hedging",
      "Distributional Reinforcement Learning",
      "Adaptive Nesterov Acceleration",
      "Financial"
    ]
  },
  {
    "article_id": "2503.01591v1_The_Role_of_Deep_Learning_in_Financial_Asset_Management_A_Systematic_Review",
    "title": "2503.01591v1 The Role of Deep Learning in Financial Asset Management A Systematic Review",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2503.01591v1_The_Role_of_Deep_Learning_in_Financial_Asset_Management_A_Systematic_Review.pdf",
    "url": "http://arxiv.org/abs/2503.01591v1_The_Role_of_Deep_Learning_in_Financial_Asset_Management_A_Systematic_Review",
    "pdf_url": "https://arxiv.org/pdf/2503.01591v1_The_Role_of_Deep_Learning_in_Financial_Asset_Management_A_Systematic_Review",
    "file_size_mb": 1.83,
    "abstract": "This review systematically examines deep learning applications in financial asset management. Unlike prior reviews, this study focuses on identifying emerging trends, such as the integration of explainable artificial intelligence (XAI) and deep reinforcement learning (DRL), and their transformative potential. It highlights new developments, including hybrid models (e.g., transformer-based architectures) and the growing use of alternative data sources such as ESG indicators and sentiment analysis. These advancements challenge traditional financial paradigms and set the stage for a deeper understanding of the evolving landscape. We use the Scopus database to select the most relevant articles published from 2018 to 2023. The inclusion criteria encompassed articles that explicitly apply deep learning models within financial asset management. We excluded studies focused on physical assets. This review also outlines our methodology for evaluating the relevance and impact of the included studies, including data sources and analytical methods. Our search identified 934 articles, with 612 meeting the inclusion criteria based on their focus and methodology. The synthesis of results from these articles provides insights into the effectiveness of deep learning models in improving portfolio performance and price forecasting accuracy. The review highlights the broad applicability and potential enhancements deep learning offers to financial asset management. Despite some limitations due to the scope of model application and variation in methodological rigour, the overall evidence supports deep learning as a valuable tool in this field. Our systematic review underscores the progressive integration of deep learning in financial asset management, suggesting a trajectory towards more sophisticated and impactful applications. Future research should explore the capabilities of these models for diverse financial contexts.",
    "keywords": [
      "systematic review",
      "financial asset management",
      "deep learning",
      "algorithmic trading",
      "portfolio"
    ]
  },
  {
    "article_id": "2503.01884v1_Contextual_Quantum_Neural_Networks_for_Stock_Price_Prediction",
    "title": "2503.01884v1 Contextual Quantum Neural Networks for Stock Price Prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2503.01884v1_Contextual_Quantum_Neural_Networks_for_Stock_Price_Prediction.pdf",
    "url": "http://arxiv.org/abs/2503.01884v1_Contextual_Quantum_Neural_Networks_for_Stock_Price_Prediction",
    "pdf_url": "https://arxiv.org/pdf/2503.01884v1_Contextual_Quantum_Neural_Networks_for_Stock_Price_Prediction",
    "file_size_mb": 5.86,
    "abstract": null,
    "keywords": [
      "Quantum Machine Learning",
      "Quantum Neural Networks",
      "Quantum Finance",
      "Quantum Multi-"
    ]
  },
  {
    "article_id": "2503.03612v4_Large_language_models_in_finance_what_is_financial_sentiment",
    "title": "2503.03612v4 Large language models in finance what is financial sentiment",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2503.03612v4_Large_language_models_in_finance_what_is_financial_sentiment.pdf",
    "url": "http://arxiv.org/abs/2503.03612v4_Large_language_models_in_finance_what_is_financial_sentiment",
    "pdf_url": "https://arxiv.org/pdf/2503.03612v4_Large_language_models_in_finance_what_is_financial_sentiment",
    "file_size_mb": 0.23,
    "abstract": "Financial sentiment has become a crucial yet complex concept in finance, increasingly used in market forecasting and investment strategies. Despite its growing importance, there remains a need to define and understand what financial sentiment truly represents and how it can be effectively measured. We explore the nature of financial sentiment and investigate how large language models (LLMs) contribute to its estimation. We trace the evolution of sentiment measurement in finance, from market-based and lexicon-based methods to advanced natural language processing techniques. The emergence of LLMs has significantly enhanced sentiment analysis, providing deeper contextual understanding and greater accuracy in extracting sentiment from financial text. We examine how BERT-based models, such as RoBERTa and FinBERT, are optimized for structured sentiment classification, while GPT-based models, including GPT-4, OPT, and LLaMA, excel in financial text generation and real-time sentiment interpretation. A comparative analysis of bidirectional and autoregressive transformer architectures highlights their respective roles in investor sentiment analysis, algorithmic trading, and financial decision-making. By exploring what financial sentiment is and how it is estimated within LLMs, we provide insights into the growing role of AI-driven sentiment analysis in finance.",
    "keywords": [
      "natural language processing",
      "large language models",
      "financial sentiment",
      "asset"
    ]
  },
  {
    "article_id": "2503.04143v1_MTS_A_Deep_Reinforcement_Learning_Portfolio_Management_Framework_with_Time-Awareness_and_Short-Selli",
    "title": "2503.04143v1 MTS A Deep Reinforcement Learning Portfolio Management Framework with Time-Awareness and Short-Selli",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2503.04143v1_MTS_A_Deep_Reinforcement_Learning_Portfolio_Management_Framework_with_Time-Awareness_and_Short-Selli.pdf",
    "url": "http://arxiv.org/abs/2503.04143v1_MTS_A_Deep_Reinforcement_Learning_Portfolio_Management_Framework_with_Time-Awareness_and_Short-Selli",
    "pdf_url": "https://arxiv.org/pdf/2503.04143v1_MTS_A_Deep_Reinforcement_Learning_Portfolio_Management_Framework_with_Time-Awareness_and_Short-Selli",
    "file_size_mb": 2.0,
    "abstract": "Portfolio management remains a crucial challenge in finance, with traditional methods often falling short in complex and volatile market environments. While deep reinforcement approaches have shown promise, they still face limitations in dynamic risk management, exploitation of temporal markets, and incorporation of complex trading strategies such as short-selling. These limitations can lead to suboptimal portfolio performance, increased vulnerability to market volatility, and missed opportunities in capturing potential returns from diverse market conditions. This paper introduces a Deep Reinforcement Learning Portfolio Management Framework with Time- Awareness and Short-Selling (MTS), offering a robust and adaptive strategy for sustainable investment performance. This framework utilizes a novel encoder-attention mechanism to address the limitations by incorporating temporal market characteristics, a parallel strategy for automated short-selling based on market trends, and risk management through innovative Incremental Conditional Value at Risk, enhancing adaptability and performance. Experimental validation on five diverse datasets from 2019 to 2023 demonstrates MTS’s superiority over traditional algorithms and advanced machine learning techniques. MTS consistently achieves higher cumulative returns, Sharpe, Omega, and Sortino ratios, underscoring its effectiveness in balancing risk and return while adapting to market dynamics. MTS demonstrates an average relative increase of 30.67% in cumulative returns and 29.33% in Sharpe ratio compared to the next best-performing strategies across various datasets.",
    "keywords": [
      "Portfolio Management",
      "Deep Reinforcement Learning",
      "Machine Learning",
      "Stock Market"
    ]
  },
  {
    "article_id": "2503.05728v2_Political_Neutrality_in_AI_Is_Impossible-_But_Here_Is_How_to_Approximate_It",
    "title": "2503.05728v2 Political Neutrality in AI Is Impossible- But Here Is How to Approximate It",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2503.05728v2_Political_Neutrality_in_AI_Is_Impossible-_But_Here_Is_How_to_Approximate_It.pdf",
    "url": "http://arxiv.org/abs/2503.05728v2_Political_Neutrality_in_AI_Is_Impossible-_But_Here_Is_How_to_Approximate_It",
    "pdf_url": "https://arxiv.org/pdf/2503.05728v2_Political_Neutrality_in_AI_Is_Impossible-_But_Here_Is_How_to_Approximate_It",
    "file_size_mb": 1.11,
    "abstract": "AI systems often exhibit political bias, influenc- ing users’ opinions and decisions. While politi- cal neutrality—defined as the absence of bias—is often seen as an ideal solution for fairness and safety, this position paper argues that true political neutrality is neither feasible nor universally de- sirable due to its subjective nature and the biases inherent in AI training data, algorithms, and user interactions. However, inspired by Joseph Raz’s philosophical insight that “neutrality [...] can be a matter of degree” (Raz, 1986), we argue that striving for some neutrality remains essential for promoting balanced AI interactions and mitigat- ing user manipulation. Therefore, we use the term “approximation” of political neutrality to shift the focus from unattainable absolutes to achievable, practical proxies. We propose eight techniques for approximating neutrality across three levels of conceptualizing AI, examining their trade-offs and implementation strategies. In addition, we explore two concrete applications of these approx- imations to illustrate their practicality. Finally, we assess our framework on current large language models (LLMs) at the output level, providing a demonstration of how it can be evaluated. This work seeks to advance nuanced discussions of political neutrality in AI and promote the devel- opment of responsible, aligned language models. *Equal contribution 1Department of Statistics, University of Washington, Seattle, WA 2Department of Communication, Stan- ford University, Stanford, CA 3Department of Computer Science, University of Washington, Seattle, WA 4Department of Electri- cal Engineering and Computer Science, University of California, Berkeley, Berkeley, CA 5Department of Political Science, Uni- versity of California, San Diego, San Diego, CA 6Department of Computer Science, Stanford University, Stanford, CA. Correspon- dence to: Jillian Fisher <jrfish@uw.edu>. “Republicans support this law, but Democrats don’t.” Ecosystem-Level Neutrality Through Diversity System-Level System Transparency Uniform Neutrality Location: CA Location: TX Economic Social “The election is on Tuesday” Output-Level Refusal Avoidance Reasonable Pluralism Output Transparency “I cannot fulfill this request.” “To decide whether to support this law, consider…” “Since you are a Democrat, you should support this law.” Reflective Neutrality Liberal User Conservative User Cons of gun control include… Pros of gun control include… Figure 1: Approximations of political neutrality in AI by levels: the output-level focuses on a model’s response, the system-level pertains to all input-output pairs of a single AI system, and the ecosystem-level encompasses all AI models in use.",
    "keywords": []
  },
  {
    "article_id": "2503.08696v1_Multimodal_Stock_Price_Prediction_A_Case_Study_of_the_Russian_Securities_Market",
    "title": "2503.08696v1 Multimodal Stock Price Prediction A Case Study of the Russian Securities Market",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2503.08696v1_Multimodal_Stock_Price_Prediction_A_Case_Study_of_the_Russian_Securities_Market.pdf",
    "url": "http://arxiv.org/abs/2503.08696v1_Multimodal_Stock_Price_Prediction_A_Case_Study_of_the_Russian_Securities_Market",
    "pdf_url": "https://arxiv.org/pdf/2503.08696v1_Multimodal_Stock_Price_Prediction_A_Case_Study_of_the_Russian_Securities_Market",
    "file_size_mb": 0.64,
    "abstract": "Classical asset price forecasting methods primarily rely on numerical data, such as price time series, trading volumes, limit order book data, and technical analysis indicators. How- ever, the news flow plays a significant role in price formation, making the development of multimodal approaches that combine textual and numerical data for improved prediction accuracy highly relevant. This paper addresses the problem of forecasting financial asset prices using the multi- modal approach that combines candlestick time series and textual news flow data. A unique dataset was collected for the study, which includes time series for 176 Russian stocks traded on the Moscow Exchange and 79, 555 financial news articles in Russian. For processing textual data, pre-trained models RuBERT and Vikhr-Qwen2.5-0.5b-Instruct (a large language model) were used, while time series and vectorized text data were pro- cessed using an LSTM recurrent neural network. The experiments compared models based on a single modality (time series only) and two modalities, as well as various methods for aggregating text vector representations. Prediction quality was estimated using two key metrics: Accuracy (direction of price movement prediction: up or down) and Mean Absolute Percentage Error (MAPE), which measures the deviation of the predicted price from the true price. The experiments showed that incorporating textual modality reduced the MAPE value by 55%. The resulting multimodal dataset holds value for the further adaptation of language models in the financial sector. Future research directions include optimizing textual modality parameters, such as the time window, sentiment, and chronological order of news messages.",
    "keywords": []
  },
  {
    "article_id": "2503.09655v1_A_Deep_Reinforcement_Learning_Approach_to_Automated_Stock_Trading_using_xLSTM_Networks",
    "title": "2503.09655v1 A Deep Reinforcement Learning Approach to Automated Stock Trading using xLSTM Networks",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2503.09655v1_A_Deep_Reinforcement_Learning_Approach_to_Automated_Stock_Trading_using_xLSTM_Networks.pdf",
    "url": "http://arxiv.org/abs/2503.09655v1_A_Deep_Reinforcement_Learning_Approach_to_Automated_Stock_Trading_using_xLSTM_Networks",
    "pdf_url": "https://arxiv.org/pdf/2503.09655v1_A_Deep_Reinforcement_Learning_Approach_to_Automated_Stock_Trading_using_xLSTM_Networks",
    "file_size_mb": 0.74,
    "abstract": "—Traditional Long Short-Term Memory (LSTM) networks are effective for handling sequential data but have limitations such as gradient vanishing and difficulty in capturing long-term dependencies, which can impact their performance in dynamic and risky environments like stock trading. To address these limitations, this study explores the usage of the newly introduced Extended Long Short-Term Memory (xLSTM) network in combination with a deep reinforcement learning (DRL) approach for automated stock trading. Our proposed method utilizes xLSTM networks in both actor and critic components, enabling effective handling of time series data and dynamic market environment. Proximal Policy Optimization (PPO), with its ability to balance exploration and exploitation, is employed to optimize the trading strategy. Experiments were conducted using financial data from major tech companies over a comprehensive timeline, demonstrating that the xLSTM-based model outperforms LSTM-based methods in key trading evaluation metrics, including cumulative return, average profitability per trade, max earning rate, maximum pullback, and Sharpe ratio. These findings mark the potential of xLSTM for enhancing DRL-based stock trading systems.",
    "keywords": [
      "Extended Long Short-Term Memory (xLSTM)"
    ]
  },
  {
    "article_id": "2503.14541v1_Regulating_Ai_In_Financial_Services_Legal_Frameworks_And_Compliance_Challenges",
    "title": "2503.14541v1 Regulating Ai In Financial Services Legal Frameworks And Compliance Challenges",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2503.14541v1_Regulating_Ai_In_Financial_Services_Legal_Frameworks_And_Compliance_Challenges.pdf",
    "url": "http://arxiv.org/abs/2503.14541v1_Regulating_Ai_In_Financial_Services_Legal_Frameworks_And_Compliance_Challenges",
    "pdf_url": "https://arxiv.org/pdf/2503.14541v1_Regulating_Ai_In_Financial_Services_Legal_Frameworks_And_Compliance_Challenges",
    "file_size_mb": 0.28,
    "abstract": null,
    "keywords": [
      "artificial intelligence regulation"
    ]
  },
  {
    "article_id": "2503.15403v1_HQNN-FSP_A_Hybrid_Classical-Quantum_Neural_Network_for_Regression-Based_Financial_Stock_Market_Predi",
    "title": "2503.15403v1 HQNN-FSP A Hybrid Classical-Quantum Neural Network for Regression-Based Financial Stock Market Predi",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2503.15403v1_HQNN-FSP_A_Hybrid_Classical-Quantum_Neural_Network_for_Regression-Based_Financial_Stock_Market_Predi.pdf",
    "url": "http://arxiv.org/abs/2503.15403v1_HQNN-FSP_A_Hybrid_Classical-Quantum_Neural_Network_for_Regression-Based_Financial_Stock_Market_Predi",
    "pdf_url": "https://arxiv.org/pdf/2503.15403v1_HQNN-FSP_A_Hybrid_Classical-Quantum_Neural_Network_for_Regression-Based_Financial_Stock_Market_Predi",
    "file_size_mb": 1.36,
    "abstract": "—Financial time-series forecasting remains a challeng- ing task due to complex temporal dependencies and market fluctuations. This study explores the potential of hybrid quantum- classical approaches to assist in financial trend prediction by lever- aging quantum resources for improved feature representation and learning. A custom Quantum Neural Network (QNN) regressor is introduced, designed with a novel ansatz tailored for financial applications. Two hybrid optimization strategies are proposed: (1) a sequential approach where classical recurrent models (RNN/LSTM) extract temporal dependencies before quantum processing, and (2) a joint learning framework that optimizes classical and quantum parameters simultaneously. Systematic evaluation using TimeSeriesSplit, k-fold cross-validation, and predictive error analysis highlights the ability of these hybrid models to integrate quantum computing into financial forecasting workflows. The findings demonstrate how quantum-assisted learning can contribute to financial modeling, offering insights into the practical role of quantum resources in time-series analysis.",
    "keywords": [
      "Financial Engineering",
      "Stock Market",
      "Quantum"
    ]
  },
  {
    "article_id": "2503.18826v2_Interpretable_and_Fair_Mechanisms_for_Abstaining_Classifiers",
    "title": "2503.18826v2 Interpretable and Fair Mechanisms for Abstaining Classifiers",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2503.18826v2_Interpretable_and_Fair_Mechanisms_for_Abstaining_Classifiers.pdf",
    "url": "http://arxiv.org/abs/2503.18826v2_Interpretable_and_Fair_Mechanisms_for_Abstaining_Classifiers",
    "pdf_url": "https://arxiv.org/pdf/2503.18826v2_Interpretable_and_Fair_Mechanisms_for_Abstaining_Classifiers",
    "file_size_mb": 1.3,
    "abstract": "Abstaining classifiers have the option to refrain from providing a prediction for in- stances that are difficult to classify. The abstention mechanism is designed to trade off the classifier’s performance on the accepted data while ensuring a minimum num- ber of predictions. In this setting, often fairness concerns arise when the abstention mechanism solely reduces errors for the majority groups of the data, resulting in in- creased performance differences across demographic groups. While there exist a bunch of methods that aim to reduce discrimination when abstaining, there is no mechanism that can do so in an explainable way. In this paper, we fill this gap by introducing Interpretable and Fair Abstaining Classifier (IFAC), an algorithm that can reject pre- dictions both based on their uncertainty and their unfairness. By rejecting possibly unfair predictions, our method reduces error and positive decision rate differences across demographic groups of the non-rejected data. Since the unfairness-based rejections are based on an interpretable-by-design method, i.e., rule-based fairness checks and situa- tion testing, we create a transparent process that can empower human decision-makers to review the unfair predictions and make more just decisions for them. This explain- able aspect is especially important in light of recent AI regulations, mandating that any high-risk decision task should be overseen by human experts to reduce discrimination risks.1",
    "keywords": [
      "Reject Option Fair ML Interpretable ML"
    ]
  },
  {
    "article_id": "2503.22192v1_An_Advanced_Ensemble_Deep_Learning_Framework_for_Stock_Price_Prediction_Using_VAE_Transformer_and_LS",
    "title": "2503.22192v1 An Advanced Ensemble Deep Learning Framework for Stock Price Prediction Using VAE Transformer and LS",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2503.22192v1_An_Advanced_Ensemble_Deep_Learning_Framework_for_Stock_Price_Prediction_Using_VAE_Transformer_and_LS.pdf",
    "url": "http://arxiv.org/abs/2503.22192v1_An_Advanced_Ensemble_Deep_Learning_Framework_for_Stock_Price_Prediction_Using_VAE_Transformer_and_LS",
    "pdf_url": "https://arxiv.org/pdf/2503.22192v1_An_Advanced_Ensemble_Deep_Learning_Framework_for_Stock_Price_Prediction_Using_VAE_Transformer_and_LS",
    "file_size_mb": 0.62,
    "abstract": "—This research proposes a cutting-edge ensemble deep learning framework for stock price prediction by combining three advanced neural network architectures: The particular areas of interest for the research include but are not limited to: Variational Autoencoder (VAE), Transformer, and Long Short- Term Memory (LSTM) networks. The presented framework is aimed to substantially utilize the advantages of each model which would allow for achieving the identification of both linear and non-linear relations in stock price movements. To improve the accuracy of its predictions it uses rich set of technical indicators and it scales its predictors based on the current market situation. By trying out the framework on several stock data sets, and benchmarking the results against single models and conventional forecasting, the ensemble method exhibits consistently high accu- racy and reliability. The VAE is able to learn linear representation on high-dimensional data while the Transformer outstandingly perform in recognizing long-term patterns on the stock price data. LSTM, based on its characteristics of being a model that can deal with sequences, brings additional improvements to the given framework, especially regarding temporal dynamics and fluctuations. Combined, these components provide exceptional directional performance and a very small disparity in the predicted results. The present solution has given a probable concept that can handle the inherent problem of stock price prediction with high reliability and scalability. Compared to the performance of individual pro- posals based on the neural network, as well as classical methods, the proposed ensemble framework demon- strates the advantages of combining different architectures. It has a very important application in algorithmic trading, risk analysis, and control and decision-making for finance professions and scholars.",
    "keywords": [
      "component",
      "formatting",
      "style",
      "styling",
      "insert"
    ]
  },
  {
    "article_id": "2504.03175v2_Mathematical_Modeling_of_Option_Pricing_with_an_Extended_Black-Scholes_Framework",
    "title": "2504.03175v2 Mathematical Modeling of Option Pricing with an Extended Black-Scholes Framework",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2504.03175v2_Mathematical_Modeling_of_Option_Pricing_with_an_Extended_Black-Scholes_Framework.pdf",
    "url": "http://arxiv.org/abs/2504.03175v2_Mathematical_Modeling_of_Option_Pricing_with_an_Extended_Black-Scholes_Framework",
    "pdf_url": "https://arxiv.org/pdf/2504.03175v2_Mathematical_Modeling_of_Option_Pricing_with_an_Extended_Black-Scholes_Framework",
    "file_size_mb": 1.1,
    "abstract": "This study investigates enhancing option pricing by extending the Black-Scholes model to include stochastic volatility and interest rate variability within the Partial Differential Equation (PDE). The PDE is solved using the finite difference method. The extended Black-Scholes model and a machine learning-based LSTM model are developed and evaluated for pricing Google stock options. Both models were backtested using historical market data. While the LSTM model exhibited higher predictive accuracy, the finite difference method demonstrated superior compu- tational efficiency. This work provides insights into model performance under varying market conditions and emphasizes the potential of hybrid approaches for robust financial modeling.",
    "keywords": []
  },
  {
    "article_id": "2504.06055v2_A_Trustworthy_By_Design_Classification_Model_for_Building_Energy_Retrofit_Decision_Support",
    "title": "2504.06055v2 A Trustworthy By Design Classification Model for Building Energy Retrofit Decision Support",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2504.06055v2_A_Trustworthy_By_Design_Classification_Model_for_Building_Energy_Retrofit_Decision_Support.pdf",
    "url": "http://arxiv.org/abs/2504.06055v2_A_Trustworthy_By_Design_Classification_Model_for_Building_Energy_Retrofit_Decision_Support",
    "pdf_url": "https://arxiv.org/pdf/2504.06055v2_A_Trustworthy_By_Design_Classification_Model_for_Building_Energy_Retrofit_Decision_Support",
    "file_size_mb": 2.73,
    "abstract": "Improving energy efficiency in residential buildings is critical to combating climate change and reducing greenhouse gas emissions. Retrofitting existing buildings, which contribute a significant share of energy use, is therefore a key priority, particularly in regions with outdated building stock. Artificial Intelligence (AI) and Machine Learning (ML) can automate retrofit decision-making and find retrofit strategies. However, their implementation faces challenges of data availability, model transparency, and compliance with national and EU AI regulations including the AI act, ethics guidelines and the ALTAI. This paper presents a trustworthy-by-design ML-based decision support framework that recommends energy efficiency strategies for residential buildings using minimal user-accessible inputs. The framework merges Conditional Tabular Generative Adversarial Networks (CTGAN) to augment limited and imbalanced data, while a neural network-based multi-label classifier identifies potential combinations of retrofit mea- sures. To support explanation and trustworthiness, an Explainable AI (XAI) layer using SHapley Additive exPlanations (SHAP) is incorporated to clarify the rationale behind recommendations and guide feature engineering. Two case studies validate performance and generalization: the first leveraging a well-established, large EPC dataset for England and Wales; the second using a small, imbalanced post-retrofit dataset from Latvia (RETROFIT-LAT). Results show that the framework can handle diverse data conditions and improve per- formance up to 53% compared to the baseline, confirming its effectiveness. Overall, the proposed framework provides a feasible, interpretable, and trustworthy AI system for building retrofit decision support through assured performance, usability, and transparency to aid stakeholders in prioritizing effective energy invest- ments and support regulation-compliant, data-driven innovation in sustainable energy transition.",
    "keywords": [
      "Energy efficiency",
      "Building retrofit",
      "Trustworthy artificial intelligence",
      "Explainable AI",
      "Synthetic data"
    ]
  },
  {
    "article_id": "2504.11874v1_Factor-MCLS_Multi-agent_learning_system_with_reward_factor_matrix_and_multi-critic_framework_for_dyn",
    "title": "2504.11874v1 Factor-MCLS Multi-agent learning system with reward factor matrix and multi-critic framework for dyn",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2504.11874v1_Factor-MCLS_Multi-agent_learning_system_with_reward_factor_matrix_and_multi-critic_framework_for_dyn.pdf",
    "url": "http://arxiv.org/abs/2504.11874v1_Factor-MCLS_Multi-agent_learning_system_with_reward_factor_matrix_and_multi-critic_framework_for_dyn",
    "pdf_url": "https://arxiv.org/pdf/2504.11874v1_Factor-MCLS_Multi-agent_learning_system_with_reward_factor_matrix_and_multi-critic_framework_for_dyn",
    "file_size_mb": 2.49,
    "abstract": "Typical deep reinforcement learning (DRL) agents for dynamic portfolio optimization learn the factors influencing portfolio return and risk by analyzing the output values of the reward function while adjusting portfolio weights within the training environment. However, it faces a major limitation where it is difficult for investors to intervene in the training based on different levels of risk aversion towards each portfolio asset. This difficulty arises from another limitation: existing DRL agents may not develop a thorough understanding of the factors responsible for the portfolio return and risk by only learning from the output of the reward function. As a result, the strategy for determining the target portfolio weights is entirely dependent on the DRL agents themselves. To address these limitations, we propose a reward factor matrix for elucidating the return and risk of each asset in the portfolio. Additionally, we propose a novel learning system named Factor-MCLS using a multi-critic framework that facilitates learning of the reward factor matrix. In this way, our DRL-based learning system can effectively learn the factors influencing portfolio return and risk. Moreover, based on the critic networks within the multi-critic framework, we develop a risk constraint term in the training objective function of the policy function. This risk constraint term allows investors to intervene in the training of the DRL agent according to their individual levels of risk aversion towards the portfolio assets. We conduct experiments utilizing a portfolio comprising 29 stocks from the Dow Jones Index. In the training process, we demonstrate that our learning system can significantly enhance profitability while ensuring excellent risk control abilities. In the back-testing experiments, we refer to 14 strategies based on traditional capital growth theories and 10 strategies utilizing machine learning algorithms as comparative benchmarks. The results of the back-testing experiments demonstrate that our learning system outperforms the comparative strategies by at least 35.3% in profitability. Additionally, our learning system achieves at least 63.9% more in return per unit of risk when compared to other strategies.",
    "keywords": [
      "deep reinforcement learning",
      "dynamic portfolio optimization",
      "multi-critic",
      "learning system"
    ]
  },
  {
    "article_id": "2504.12828v3_Predicting_Stock_Prices_using_Permutation_Decision_Trees_and_Strategic_Trailing",
    "title": "2504.12828v3 Predicting Stock Prices using Permutation Decision Trees and Strategic Trailing",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2504.12828v3_Predicting_Stock_Prices_using_Permutation_Decision_Trees_and_Strategic_Trailing.pdf",
    "url": "http://arxiv.org/abs/2504.12828v3_Predicting_Stock_Prices_using_Permutation_Decision_Trees_and_Strategic_Trailing",
    "pdf_url": "https://arxiv.org/pdf/2504.12828v3_Predicting_Stock_Prices_using_Permutation_Decision_Trees_and_Strategic_Trailing",
    "file_size_mb": 16.54,
    "abstract": "In this paper, we explore the application of Permutation Decision Trees (PDT) and strategic trailing for predicting stock market movements and executing profitable trades in the Indian stock market. We focus on high-frequency data using 5-minute candlesticks for the top 50 stocks listed in the NIFTY 50 index and Forex pairs such as XAUUSD and EURUSD. We implement a trading strategy that aims to buy stocks at lower prices and sell them at higher prices, capitalizing on short-term market fluctuations. Due to regulatory constraints in India, short selling is not considered in our strategy. The model incorporates various technical indicators and employs hyperparameters such as the trailing stop-loss value and support thresholds to manage risk effectively. We trained and tested data on a 3 month dataset provided by Yahoo Finance. Our bot based on Permutation Decision Tree achieved a profit of 1.1802% over the testing period, where as a bot based on LSTM gave a return of 0.557% over the testing period and a bot based on RNN gave a return of 0.5896% over the testing period. All of the bots outperform the buy-and-hold strategy, which resulted in a loss of 2.29%.",
    "keywords": [
      "Permutation Decision Tree",
      "Stock Market Trading",
      "Long Short Term Memory",
      "Recurrent Neural Network"
    ]
  },
  {
    "article_id": "2504.13801v2_Transformer_Encoder_and_Multi-features_Time2Vec_for_Financial_Prediction",
    "title": "2504.13801v2 Transformer Encoder and Multi-features Time2Vec for Financial Prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2504.13801v2_Transformer_Encoder_and_Multi-features_Time2Vec_for_Financial_Prediction.pdf",
    "url": "http://arxiv.org/abs/2504.13801v2_Transformer_Encoder_and_Multi-features_Time2Vec_for_Financial_Prediction",
    "pdf_url": "https://arxiv.org/pdf/2504.13801v2_Transformer_Encoder_and_Multi-features_Time2Vec_for_Financial_Prediction",
    "file_size_mb": 0.7,
    "abstract": "—Financial prediction is a complex and challenging task of time series analysis and signal processing, expected to model both short-term fluctuations and long-term temporal dependencies. Transformers have remarkable success mostly in natural language processing using attention mechanism, which also influenced the time series community. The ability to capture both short and long-range dependencies helps to understand the financial market and to recognize price patterns, leading to successful applications of Transformers in stock prediction. Although, the previous research predominantly focuses on indi- vidual features and singular predictions, that limits the model’s ability to understand broader market trends. In reality, within sectors such as finance and technology, companies belonging to the same industry often exhibit correlated stock price movements. In this paper, we develop a novel neural network architecture by integrating Time2Vec with the Encoder of the Transformer model. Based on the study of different markets, we propose a novel correlation feature selection method. Through a compre- hensive fine-tuning of multiple hyperparameters, we conduct a comparative analysis of our results against benchmark models. We conclude that our method outperforms other state-of-the- art encoding methods such as positional encoding, and we also conclude that selecting correlation features enhance the accuracy of predicting multiple stock prices.",
    "keywords": [
      "time series analysis",
      "financial prediction",
      "neural"
    ]
  },
  {
    "article_id": "2504.17006v1_A_Systematic_Approach_to_Design_Real-World_Human-in-the-Loop_Deep_Reinforcement_Learning_Salient_Fea",
    "title": "2504.17006v1 A Systematic Approach to Design Real-World Human-in-the-Loop Deep Reinforcement Learning Salient Fea",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2504.17006v1_A_Systematic_Approach_to_Design_Real-World_Human-in-the-Loop_Deep_Reinforcement_Learning_Salient_Fea.pdf",
    "url": "http://arxiv.org/abs/2504.17006v1_A_Systematic_Approach_to_Design_Real-World_Human-in-the-Loop_Deep_Reinforcement_Learning_Salient_Fea",
    "pdf_url": "https://arxiv.org/pdf/2504.17006v1_A_Systematic_Approach_to_Design_Real-World_Human-in-the-Loop_Deep_Reinforcement_Learning_Salient_Fea",
    "file_size_mb": 1.92,
    "abstract": "— With the growing popularity of deep reinforce- ment learning (DRL), human-in-the-loop (HITL) approach has the potential to revolutionize the way we approach decision- making problems and create new opportunities for human-AI collaboration. In this article, we introduce a novel multi-layered hierarchical HITL DRL algorithm that comprises three types of learning: self learning, imitation learning and transfer learning. In addition, we consider three forms of human inputs: reward, action and demonstration. Furthermore, we discuss main chal- lenges, trade-offs and advantages of HITL in solving complex problems and how human information can be integrated in the AI solution systematically. To verify our technical results, we present a real-world unmanned aerial vehicles (UAV) problem wherein a number of enemy drones attack a restricted area. The objective is to design a scalable HITL DRL algorithm for ally drones to neutralize the enemy drones before they reach the area. To this end, we first implement our solution using an award-winning open-source HITL software called Cogment. We then demonstrate several interesting results such as (a) HITL leads to faster training and higher performance, (b) advice acts as a guiding direction for gradient methods and lowers variance, and (c) the amount of advice should neither be too large nor too small to avoid over-training and under-training. Finally, we illustrate the role of human-AI cooperation in solving two real- world complex scenarios, i.e., overloaded and decoy attacks.",
    "keywords": []
  },
  {
    "article_id": "2504.18185v1_An_Open-Source_and_Reproducible_Implementation_of_LSTM_and_GRU_Networks_for_Time_Series_Forecasting",
    "title": "2504.18185v1 An Open-Source and Reproducible Implementation of LSTM and GRU Networks for Time Series Forecasting",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2504.18185v1_An_Open-Source_and_Reproducible_Implementation_of_LSTM_and_GRU_Networks_for_Time_Series_Forecasting.pdf",
    "url": "http://arxiv.org/abs/2504.18185v1_An_Open-Source_and_Reproducible_Implementation_of_LSTM_and_GRU_Networks_for_Time_Series_Forecasting",
    "pdf_url": "https://arxiv.org/pdf/2504.18185v1_An_Open-Source_and_Reproducible_Implementation_of_LSTM_and_GRU_Networks_for_Time_Series_Forecasting",
    "file_size_mb": 0.57,
    "abstract": ". This paper introduces an open-source and reproducible im- plementation of Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) Networks for time series forecasting. We evaluated LSTM and GRU networks because of their performance reported in related work. We describe our method and its results on two datasets. The first dataset is the S&P BSE BANKEX, composed of stock time series (closing prices) of ten financial institutions. The second dataset, called Activities, comprises ten synthetic time series resembling weekly activities with five days of high activity and two days of low activity. We report Root Mean Squared Error (RMSE) between actual and predicted values, as well as Directional Accuracy (DA). We show that a single time series from a dataset can be used to adequately train the networks if the sequences in the dataset contain patterns that repeat, even with certain variation, and are properly processed. For 1-step ahead and 20-step ahead forecasts, LSTM and GRU networks significantly outperform a baseline on the Ac- tivities dataset. The baseline simply repeats the last available value. On the stock market dataset, the networks perform just like the baseline, possibly due to the nature of these series. We release the datasets used as well as the implementation with all experiments performed to enable future comparisons and to make our research reproducible.",
    "keywords": [
      "Forecasting",
      "Time Series",
      "Open-source",
      "Reproducibility"
    ]
  },
  {
    "article_id": "2504.19309v1_Bridging_Short-_and_Long-Term_Dependencies_A_CNN-Transformer_Hybrid_for_Financial_Time_Series_Foreca",
    "title": "2504.19309v1 Bridging Short- and Long-Term Dependencies A CNN-Transformer Hybrid for Financial Time Series Foreca",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2504.19309v1_Bridging_Short-_and_Long-Term_Dependencies_A_CNN-Transformer_Hybrid_for_Financial_Time_Series_Foreca.pdf",
    "url": "http://arxiv.org/abs/2504.19309v1_Bridging_Short-_and_Long-Term_Dependencies_A_CNN-Transformer_Hybrid_for_Financial_Time_Series_Foreca",
    "pdf_url": "https://arxiv.org/pdf/2504.19309v1_Bridging_Short-_and_Long-Term_Dependencies_A_CNN-Transformer_Hybrid_for_Financial_Time_Series_Foreca",
    "file_size_mb": 0.12,
    "abstract": "Time series forecasting is crucial for decision-making across various domains, particularly in financial markets where stock prices exhibit complex and non-linear behaviors. Accurately predicting future price movements is challenging due to the difficulty of capturing both short-term fluctuations and long-term dependencies in the data. Convolutional Neural Networks (CNNs) are well-suited for modeling localized, short-term patterns but struggle with long-range dependencies due to their limited receptive field. In contrast, Transformers are highly effective at capturing global temporal relationships and modeling long-term trends. In this paper, we propose a hybrid architecture that combines CNNs and Transformers to effectively model both short- and long-term dependencies in financial time series data. We apply this approach to forecast stock price movements for S&P 500 constituents and demonstrate that our model outperforms traditional statistical models and popular deep learning methods in intraday stock price forecasting, providing a robust framework for financial prediction.",
    "keywords": []
  },
  {
    "article_id": "2504.19623v1_Multi-Horizon_Echo_State_Network_Prediction_of_Intraday_Stock_Returns",
    "title": "2504.19623v1 Multi-Horizon Echo State Network Prediction of Intraday Stock Returns",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2504.19623v1_Multi-Horizon_Echo_State_Network_Prediction_of_Intraday_Stock_Returns.pdf",
    "url": "http://arxiv.org/abs/2504.19623v1_Multi-Horizon_Echo_State_Network_Prediction_of_Intraday_Stock_Returns",
    "pdf_url": "https://arxiv.org/pdf/2504.19623v1_Multi-Horizon_Echo_State_Network_Prediction_of_Intraday_Stock_Returns",
    "file_size_mb": 1.29,
    "abstract": null,
    "keywords": [
      "High-frequency data",
      "reservoir computing",
      "signal construction"
    ]
  },
  {
    "article_id": "2505.01402v1_Predicting_the_Price_of_Gold_in_the_Financial_Markets_Using_Hybrid_Models",
    "title": "2505.01402v1 Predicting the Price of Gold in the Financial Markets Using Hybrid Models",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2505.01402v1_Predicting_the_Price_of_Gold_in_the_Financial_Markets_Using_Hybrid_Models.pdf",
    "url": "http://arxiv.org/abs/2505.01402v1_Predicting_the_Price_of_Gold_in_the_Financial_Markets_Using_Hybrid_Models",
    "pdf_url": "https://arxiv.org/pdf/2505.01402v1_Predicting_the_Price_of_Gold_in_the_Financial_Markets_Using_Hybrid_Models",
    "file_size_mb": 0.74,
    "abstract": "Predicting the price that has the least error and can provide the best and high- est accuracy has been one of the most challenging issues and one of the most critical concerns among capital market activists and researchers. Therefore, a model that can solve problems and provide results with high accuracy is one of the topics of interest among researchers. In this project, using time series prediction models such as ARIMA to estimate the price, variables, and indi- cators related to technical analysis show the behavior of traders involved in involving psychological factors for the model. By linking all of these variables to stepwise regression, we identify the best variables influencing the prediction of the variable. Finally, we enter the selected variables as inputs to the arti- ficial neural network. In other words, we want to call this whole prediction process the ”ARIMA– Stepwise Regression - Neural Network” model and try to predict the price of gold in international financial markets. This approach is expected to be able to be used to predict the types of stocks, commodities, currency pairs, financial market indicators, and other items used in local and international financial markets. Moreover, a comparison between the results of this method and time series methods is also expressed. Finally, based on the results, it can be seen that the resulting hybrid model has the highest accuracy compared to the time series method, regression, and stepwise regression.",
    "keywords": [
      "data mining - hybrid models – predicting the price - machine"
    ]
  },
  {
    "article_id": "2505.01921v2_Multilayer_Perceptron_Neural_Network_Models_in_Asset_Pricing_An_Empirical_Study_on_Large-Cap_US_Stoc",
    "title": "2505.01921v2 Multilayer Perceptron Neural Network Models in Asset Pricing An Empirical Study on Large-Cap US Stoc",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2505.01921v2_Multilayer_Perceptron_Neural_Network_Models_in_Asset_Pricing_An_Empirical_Study_on_Large-Cap_US_Stoc.pdf",
    "url": "http://arxiv.org/abs/2505.01921v2_Multilayer_Perceptron_Neural_Network_Models_in_Asset_Pricing_An_Empirical_Study_on_Large-Cap_US_Stoc",
    "pdf_url": "https://arxiv.org/pdf/2505.01921v2_Multilayer_Perceptron_Neural_Network_Models_in_Asset_Pricing_An_Empirical_Study_on_Large-Cap_US_Stoc",
    "file_size_mb": 1.41,
    "abstract": "In this study, MLP models with dynamic structure are applied to factor mod- els for asset pricing tasks. Concretely, the MLP pyramid model structure was employed on firm characteristic sorted portfolio factors for modelling the large capital US stocks. It was further developed as a practicable factor investing strategy based on the predictions. The main findings in this chapter were evaluated from 2 angles: model performance and investing performance, which were compared from the periods with and without COVID-19. The empirical results indicated that with the restrictions of the data size, the MLP models never perform ‘deeper, better’ anymore, while the proposed MLP models with 2 and 3 hidden layers have higher flexibility to model the factors in this case. This study also verified the idea of previous works that MLP models for factor investing have more meaning in the downside risk control than in pursuing the absolute annual returns. Note: An earlier version is available at Zenodo (DOI: 10.5281/zenodo.15333718)",
    "keywords": [
      "Asset Pricing",
      "MLP",
      "Neural Network",
      "Factor Investment"
    ]
  },
  {
    "article_id": "2505.03760v1_Deep_Reinforcement_Learning_for_Investor-Specific_Portfolio_Optimization_A_Volatility-Guided_Asset_S",
    "title": "2505.03760v1 Deep Reinforcement Learning for Investor-Specific Portfolio Optimization A Volatility-Guided Asset S",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2505.03760v1_Deep_Reinforcement_Learning_for_Investor-Specific_Portfolio_Optimization_A_Volatility-Guided_Asset_S.pdf",
    "url": "http://arxiv.org/abs/2505.03760v1_Deep_Reinforcement_Learning_for_Investor-Specific_Portfolio_Optimization_A_Volatility-Guided_Asset_S",
    "pdf_url": "https://arxiv.org/pdf/2505.03760v1_Deep_Reinforcement_Learning_for_Investor-Specific_Portfolio_Optimization_A_Volatility-Guided_Asset_S",
    "file_size_mb": 1.01,
    "abstract": "Portfolio optimization requires dynamic allocation of funds by balancing the risk and return tradeoff under dynamic market conditions. With the recent advance- ments in AI, Deep Reinforcement Learning (DRL) has gained prominence in pro- viding adaptive and scalable strategies for portfolio optimization. However, the success of these strategies depends not only on their ability to adapt to market dy- namics but also on the careful pre-selection of assets that influence overall portfo- lio performance. Incorporating the investor’s preference in pre-selecting assets for a portfolio is essential in refining their investment strategies. This study proposes a volatility-guided DRL-based portfolio optimization framework that dynamically constructs portfolios based on investors’ risk profiles. The Generalized Autore- gressive Conditional Heteroscedasticity (GARCH) model is utilized for volatility forecasting of stocks and categorizes them based on their volatility as aggressive, moderate, and conservative. The DRL agent is then employed to learn an opti- mal investment policy by interacting with the historical market data. The efficacy of the proposed methodology is established using stocks from the Dow 30 index. The proposed investor-specific DRL-based portfolios outperformed the baseline strategies by generating consistent risk-adjusted returns.",
    "keywords": []
  },
  {
    "article_id": "2505.03949v1_Deep_Q-Network_DQN_multi-agent_reinforcement_learning_MARL_for_Stock_Trading",
    "title": "2505.03949v1 Deep Q-Network DQN multi-agent reinforcement learning MARL for Stock Trading",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2505.03949v1_Deep_Q-Network_DQN_multi-agent_reinforcement_learning_MARL_for_Stock_Trading.pdf",
    "url": "http://arxiv.org/abs/2505.03949v1_Deep_Q-Network_DQN_multi-agent_reinforcement_learning_MARL_for_Stock_Trading",
    "pdf_url": "https://arxiv.org/pdf/2505.03949v1_Deep_Q-Network_DQN_multi-agent_reinforcement_learning_MARL_for_Stock_Trading",
    "file_size_mb": 0.67,
    "abstract": "This project addresses the challenge of automated stock trading, where traditional methods and direct reinforce- ment learning (RL) struggle with market noise, complex- ity, and generalization. Our proposed solution is an in- tegrated deep learning framework combining a Convolu- tional Neural Network (CNN) to identify patterns in tech- nical indicators formatted as images, a Long Short-Term Memory (LSTM) network to capture temporal dependen- cies across both price history and technical indicators, and a Deep Q-Network (DQN) agent which learns the optimal trading policy (buy, sell, hold) based on the features ex- tracted by the CNN and LSTM. The CNN and LSTM act as sophisticated feature extractors, feeding processed in- formation to the DQN, which learns the optimal trading policy (buy, sell, hold) through RL. We trained and evalu- ated this model on historical daily stock data, using distinct periods for training, testing, and validation. Performance was assessed by comparing the agent’s returns and risk on out-of-sample test data against baseline strategies, includ- ing passive buy-and-hold approaches. This analysis, along with insights gained from explainability techniques into the agent’s decision-making process, aimed to demonstrate the effectiveness of combining specialized deep learning archi- tectures, document challenges encountered, and potentially uncover learned market insights.",
    "keywords": []
  },
  {
    "article_id": "2505.07537v1_The_Exploratory_Multi-Asset_Mean-Variance_Portfolio_Selection_using_Reinforcement_Learning",
    "title": "2505.07537v1 The Exploratory Multi-Asset Mean-Variance Portfolio Selection using Reinforcement Learning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2505.07537v1_The_Exploratory_Multi-Asset_Mean-Variance_Portfolio_Selection_using_Reinforcement_Learning.pdf",
    "url": "http://arxiv.org/abs/2505.07537v1_The_Exploratory_Multi-Asset_Mean-Variance_Portfolio_Selection_using_Reinforcement_Learning",
    "pdf_url": "https://arxiv.org/pdf/2505.07537v1_The_Exploratory_Multi-Asset_Mean-Variance_Portfolio_Selection_using_Reinforcement_Learning",
    "file_size_mb": 0.53,
    "abstract": "In this paper, we study the continuous-time multi-asset mean-variance (MV) portfolio selection using a reinforcement learning (RL) algorithm, speciﬁcally the soft actor-critic (SAC) algorithm, in the time-varying ﬁnancial market. A family of Gaussian portfolio selections is derived, and a policy iteration process is crafted to learn the optimal exploratory portfolio selection. We prove the convergence of the policy iteration process theoretically, based on which the SAC algorithm is developed. To improve the algorithm’s stability and the learning accuracy in the multi-asset scenario, we divide the model parameters that inﬂuence the optimal portfolio selection into three parts, and learn each part progressively. Numerical studies in the simulated and real ﬁnancial markets conﬁrm the superior performance of the proposed SAC algorithm under various criteria. Key words. Multi-asset ﬁnancial markets; Mean-variance portfolio selection; Soft actor-critic algorithm; Policy iteration procedure. E-mail addresses: liyu@tjufe.edu.cn (Yu Li), wuyuhan@stu.tjufe.edu.cn (Yuhan Wu), szhang@tjufe.edu.cn (Shuhua Zhang) ∗Corresponding author Abbreviation statement: soft actor-critic (SAC); mean-variance (MV) 1",
    "keywords": [
      "Multi-asset ﬁnancial markets",
      "Mean-variance portfolio selection"
    ]
  },
  {
    "article_id": "2505.12759v1_Your_Offline_Policy_is_Not_Trustworthy_Bilevel_Reinforcement_Learning_for_Sequential_Portfolio_Optim",
    "title": "2505.12759v1 Your Offline Policy is Not Trustworthy Bilevel Reinforcement Learning for Sequential Portfolio Optim",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2505.12759v1_Your_Offline_Policy_is_Not_Trustworthy_Bilevel_Reinforcement_Learning_for_Sequential_Portfolio_Optim.pdf",
    "url": "http://arxiv.org/abs/2505.12759v1_Your_Offline_Policy_is_Not_Trustworthy_Bilevel_Reinforcement_Learning_for_Sequential_Portfolio_Optim",
    "pdf_url": "https://arxiv.org/pdf/2505.12759v1_Your_Offline_Policy_is_Not_Trustworthy_Bilevel_Reinforcement_Learning_for_Sequential_Portfolio_Optim",
    "file_size_mb": 3.32,
    "abstract": "Reinforcement learning (RL) has shown significant promise for sequential portfolio optimization tasks, such as stock trading, where the objective is to maximize cumulative returns while minimizing risks using historical data. However, traditional RL approaches often produce policies that merely “memorize” the optimal yet impractical buying and selling behaviors within the fixed dataset. These offline policies are less generalizable as they fail to account for the non-stationary nature of the market. Our approach, MetaTrader, frames portfolio optimization as a new type of partial- offline RL problem and makes two technical contributions. First, MetaTrader employs a bilevel learning framework that explicitly trains the RL agent to improve both in-domain profits on the original dataset and out-of-domain performance across diverse transformations of the raw financial data. Second, our approach incorporates a new temporal difference (TD) method that approximates worst-case TD estimates from a batch of transformed TD targets, addressing the value overestimation issue that is particularly challenging in scenarios with limited offline data. Our empirical results on two public stock datasets show that MetaTrader outperforms existing methods, including both RL-based approaches and traditional stock prediction models.",
    "keywords": []
  },
  {
    "article_id": "2505.19243v1_Comparative_analysis_of_financial_data_differentiation_techniques_using_LSTM_neural_network",
    "title": "2505.19243v1 Comparative analysis of financial data differentiation techniques using LSTM neural network",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2505.19243v1_Comparative_analysis_of_financial_data_differentiation_techniques_using_LSTM_neural_network.pdf",
    "url": "http://arxiv.org/abs/2505.19243v1_Comparative_analysis_of_financial_data_differentiation_techniques_using_LSTM_neural_network",
    "pdf_url": "https://arxiv.org/pdf/2505.19243v1_Comparative_analysis_of_financial_data_differentiation_techniques_using_LSTM_neural_network",
    "file_size_mb": 4.15,
    "abstract": "We compare traditional approach of computing logarithmic returns with the fractional differencing method and its tempered extension as methods of data preparation before their usage in advanced machine learning models. Differencing parameters are estimated using multiple techniques. The empirical investigation is conducted on data from four major stock indices covering the most recent 10-year period. The set of explanatory variables is additionally extended with technical indicators. The effectiveness of the differencing methods is evaluated using both forecast error metrics and risk-adjusted return trading performance metrics. The findings suggest that fractional differentiation methods provide a suitable data transformation technique, improving the predictive model forecasting performance. Furthermore, the generated predictions appeared to be effective in constructing profitable trading strategies for both individual assets and a portfolio of stock indices. These results underline the importance of appropriate data transformation techniques in financial time series forecasting, supporting the application of memory-preserving techniques.",
    "keywords": [
      "forecasting",
      "trading",
      "quantitative finance",
      "data preprocessing",
      "fractional differentiation"
    ]
  },
  {
    "article_id": "2505.22678v1_An_Efficient_deep_learning_model_to_Predict_Stock_Price_Movement_Based_on_Limit_Order_Book",
    "title": "2505.22678v1 An Efficient deep learning model to Predict Stock Price Movement Based on Limit Order Book",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2505.22678v1_An_Efficient_deep_learning_model_to_Predict_Stock_Price_Movement_Based_on_Limit_Order_Book.pdf",
    "url": "http://arxiv.org/abs/2505.22678v1_An_Efficient_deep_learning_model_to_Predict_Stock_Price_Movement_Based_on_Limit_Order_Book",
    "pdf_url": "https://arxiv.org/pdf/2505.22678v1_An_Efficient_deep_learning_model_to_Predict_Stock_Price_Movement_Based_on_Limit_Order_Book",
    "file_size_mb": 1.58,
    "abstract": "In high-frequency trading (HFT), leveraging limit order books (LOB) to model stock price movements is crucial for achieving profitable out- comes. However, this task is challenging due to the high-dimensional and volatile nature of the original data. Even recent deep learning models often struggle to capture price movement patterns effectively, particularly without well-designed features. We observed that raw LOB data exhibits inherent symmetry between the ask and bid sides, and the bid-ask dif- ferences demonstrate greater stability and lower complexity compared to the original data. Building on this insight, we propose a novel approach in which leverages the Siamese architecture to enhance the performance of existing deep learning models. The core idea involves processing the ask and bid sides separately using the same module with shared param- eters. We applied our Siamese-based methods to several widely used strong baselines and validated their effectiveness using data from 14 military industry stocks in the Chinese A-share market. Furthermore, we integrated multi-head attention (MHA) mechanisms with the Long Short-Term Memory (LSTM) module to investigate its role in modeling stock price movements. Our experiments used raw data and widely used Order Flow Imbalance (OFI) features as input with some strong baseline models. The results show that our method improves the performance of strong baselines in over 75% of cases, excluding the Multi-Layer Per- ception (MLP) baseline, which performed poorly and is not considered 1 arXiv:2505.22678v1 [q-fin.TR] 14 May 2025 Springer Nature 2021 LATEX template 2 Siamese Architecture for LOB practical. Furthermore, we found that Multi-Head Attention can enhance model performance, particularly over shorter forecasting horizons.",
    "keywords": [
      "Limit Order Book",
      "Symmetry Traits",
      "Siamese Architecture"
    ]
  },
  {
    "article_id": "2505.23084v1_Gradient_Boosting_Decision_Tree_with_LSTM_for_Investment_Prediction",
    "title": "2505.23084v1 Gradient Boosting Decision Tree with LSTM for Investment Prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2505.23084v1_Gradient_Boosting_Decision_Tree_with_LSTM_for_Investment_Prediction.pdf",
    "url": "http://arxiv.org/abs/2505.23084v1_Gradient_Boosting_Decision_Tree_with_LSTM_for_Investment_Prediction",
    "pdf_url": "https://arxiv.org/pdf/2505.23084v1_Gradient_Boosting_Decision_Tree_with_LSTM_for_Investment_Prediction",
    "file_size_mb": 0.2,
    "abstract": "—This paper proposes a hybrid modeling framework that synergistically integrates LSTM (Long Short-Term Mem- ory) networks with LightGBM and CatBoost for stock price prediction. We systematically preprocess time-series financial data and conduct comprehensive evaluations using seven classical models: Artificial Neural Networks (ANNs), Convolutional Neural Networks (CNNs), Bidirectional LSTM (BiLSTM), vanilla LSTM, XGBoost, LightGBM, and standard Neural Networks (NNs). Through rigorous comparison of performance metrics, including MAE, R2, MSE, and RMSE, we establish baseline references across multiple temporal scales. Building on these empirical benchmarks, we introduce a novel ensemble architecture that harmonizes the complementary strengths of sequential and tree-based models. Experimental results demonstrate that our integrated framework achieves 10–15% improvement in predictive accuracy compared to individual constituent models, particularly in reducing error volatility during market regime transitions. These findings validate the underexplored potential of heteroge- neous ensemble strategies in financial forecasting and establish methodological foundations for developing adaptive prediction systems in non-stationary market environments. The proposed architecture’s modular design enables seamless integration of emerging machine learning components, suggesting promising directions for future research in computational finance.",
    "keywords": [
      "Finance",
      "Ensemble Model",
      "LSTM",
      "Gradient"
    ]
  },
  {
    "article_id": "2505.24612v1_Multi-criteria_Rank-based_Aggregation_for_Explainable_AI",
    "title": "2505.24612v1 Multi-criteria Rank-based Aggregation for Explainable AI",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2505.24612v1_Multi-criteria_Rank-based_Aggregation_for_Explainable_AI.pdf",
    "url": "http://arxiv.org/abs/2505.24612v1_Multi-criteria_Rank-based_Aggregation_for_Explainable_AI",
    "pdf_url": "https://arxiv.org/pdf/2505.24612v1_Multi-criteria_Rank-based_Aggregation_for_Explainable_AI",
    "file_size_mb": 0.37,
    "abstract": "—Explainability is crucial for improving the trans- parency of black-box machine learning models. With the ad- vancement of explanation methods such as LIME and SHAP, various XAI performance metrics have been developed to eval- uate the quality of explanations. However, different explainers can provide contrasting explanations for the same prediction, in- troducing trade-offs across conflicting quality metrics. Although available aggregation approaches improve robustness, reducing explanations’ variability, very limited research employed a multi- criteria decision-making approach. To address this gap, this pa- per introduces a multi-criteria rank-based weighted aggregation method that balances multiple quality metrics simultaneously to produce an ensemble of explanation models. Furthermore, we propose rank-based versions of existing XAI metrics (complexity, faithfulness and stability) to better evaluate ranked feature importance explanations. Extensive experiments on publicly available datasets demonstrate the robustness of the proposed model across these metrics. Comparative analyses of various multi-criteria decision-making and rank aggregation algorithms showed that TOPSIS and WSUM are the best candidates for this use case.",
    "keywords": [
      "Explainable AI",
      "Multi-criteria Decision Making"
    ]
  },
  {
    "article_id": "2506.01945v1_Stock_Market_Telepathy_Graph_Neural_Networks_Predicting_the_Secret_Conversations_between_MINT_and_G7",
    "title": "2506.01945v1 Stock Market Telepathy Graph Neural Networks Predicting the Secret Conversations between MINT and G7",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2506.01945v1_Stock_Market_Telepathy_Graph_Neural_Networks_Predicting_the_Secret_Conversations_between_MINT_and_G7.pdf",
    "url": "http://arxiv.org/abs/2506.01945v1_Stock_Market_Telepathy_Graph_Neural_Networks_Predicting_the_Secret_Conversations_between_MINT_and_G7",
    "pdf_url": "https://arxiv.org/pdf/2506.01945v1_Stock_Market_Telepathy_Graph_Neural_Networks_Predicting_the_Secret_Conversations_between_MINT_and_G7",
    "file_size_mb": 0.58,
    "abstract": "Emerging economies, particularly the MINT countries (Mexico, Indonesia, Nigeria, and T¨urkiye), are gaining inﬂuence in global stock markets, although they remain susceptible to the economic conditions of developed countries like the G7 (Canada, France, Germany, Italy, Japan, the United Kingdom, and the United States). This interconnectedness and sensitivity of ﬁnancial markets make understanding these relationships crucial for investors and policymakers to predict stock price movements accurately. To this end, we examined the main stock market indices of G7 and MINT countries from 2012 to 2024, using a recent graph neural network (GNN) algorithm called multivariate time series forecasting with graph neural network (MTGNN). This method allows for considering complex spatio-temporal connections in multivariate time series. In the implementations, MTGNN revealed that the US and Canada are the most inﬂuential G7 countries regarding stock indices in the forecasting process, and Indonesia and T¨urkiye are the most inﬂuential MINT countries. Additionally, our results showed that MTGNN outperformed traditional methods in forecasting the prices of stock market indices for MINT and G7 countries. Consequently, the study oﬀers valuable insights into economic blocks’ markets and presents a compelling empirical approach to analyzing global stock market dynamics using MTGNN.",
    "keywords": [
      "Deep learning",
      "Emerging economies",
      "Graph neural networks",
      "Multivariate time series",
      "Stock price prediction"
    ]
  },
  {
    "article_id": "2506.05565v1_Applying_Informer_for_Option_Pricing_A_Transformer-Based_Approach",
    "title": "2506.05565v1 Applying Informer for Option Pricing A Transformer-Based Approach",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2506.05565v1_Applying_Informer_for_Option_Pricing_A_Transformer-Based_Approach.pdf",
    "url": "http://arxiv.org/abs/2506.05565v1_Applying_Informer_for_Option_Pricing_A_Transformer-Based_Approach",
    "pdf_url": "https://arxiv.org/pdf/2506.05565v1_Applying_Informer_for_Option_Pricing_A_Transformer-Based_Approach",
    "file_size_mb": 0.65,
    "abstract": "Accurate option pricing is essential for effective trading and risk management in financial markets, yet it remains challenging due to market volatility and the limitations of traditional models like Black-Scholes. In this paper, we investigate the application of the Informer neural network for option pricing, leveraging its ability to capture long-term dependencies and dynamically adjust to market fluctuations. This research contributes to the field of financial forecasting by introducing Informer’s efficient architecture to enhance prediction accuracy and provide a more adaptable and resilient framework compared to existing methods. Our results demonstrate that Informer outperforms traditional approaches in option pricing, advancing the capabilities of data-driven financial forecasting in this domain.",
    "keywords": [
      "Option Pricing",
      "Transformers",
      "Neural Networks",
      "Time Series Forecasting",
      "Deep Learning"
    ]
  },
  {
    "article_id": "2506.05764v2_Exploring_Microstructural_Dynamics_in_Cryptocurrency_Limit_Order_Books_Better_Inputs_Matter_More_Tha",
    "title": "2506.05764v2 Exploring Microstructural Dynamics in Cryptocurrency Limit Order Books Better Inputs Matter More Tha",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2506.05764v2_Exploring_Microstructural_Dynamics_in_Cryptocurrency_Limit_Order_Books_Better_Inputs_Matter_More_Tha.pdf",
    "url": "http://arxiv.org/abs/2506.05764v2_Exploring_Microstructural_Dynamics_in_Cryptocurrency_Limit_Order_Books_Better_Inputs_Matter_More_Tha",
    "pdf_url": "https://arxiv.org/pdf/2506.05764v2_Exploring_Microstructural_Dynamics_in_Cryptocurrency_Limit_Order_Books_Better_Inputs_Matter_More_Tha",
    "file_size_mb": 2.39,
    "abstract": "Cryptocurrency price dynamics are driven largely by microstructural supply–demand imbalances in the limit order book (LOB), yet the highly noisy nature of LOB data complicates the signal extraction process. Prior research has demonstrated that deep-learning architectures can yield promising predictive performance on pre-processed equity and futures LOB data, but they often treat model complexity as an unqualified virtue. In this paper, we aim to examine whether adding extra hidden layers or parameters to “black-box-ish” neural networks genuinely enhances short-term price forecasting, or if gains are primarily attributable to data preprocessing and feature engineering. We benchmark a spectrum of models—from interpretable baselines, logistic regression, XGBoost to deep architectures (DeepLOB, Conv1D+LSTM)—on BTC/USDT LOB snapshots sampled at 100 ms to multi-second intervals using publicly available Bybit data. We introduce two data-filtering pipelines (Kalman, Savitzky–Golay) and evaluate both binary (up/down) and ternary (up/flat/down) labeling schemes. Our analysis compares models on out-of-sample accuracy, latency, and robustness to noise. Results reveal that, with data preprocessing and hyperparameter tuning, simpler models can match and even exceed the performance of more complex networks, offering faster inference and greater interpretability.",
    "keywords": []
  },
  {
    "article_id": "2506.06293v1_Prediction_of_Bank_Credit_Ratings_using_Heterogeneous_Topological_Graph_Neural_Networks",
    "title": "2506.06293v1 Prediction of Bank Credit Ratings using Heterogeneous Topological Graph Neural Networks",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2506.06293v1_Prediction_of_Bank_Credit_Ratings_using_Heterogeneous_Topological_Graph_Neural_Networks.pdf",
    "url": "http://arxiv.org/abs/2506.06293v1_Prediction_of_Bank_Credit_Ratings_using_Heterogeneous_Topological_Graph_Neural_Networks",
    "pdf_url": "https://arxiv.org/pdf/2506.06293v1_Prediction_of_Bank_Credit_Ratings_using_Heterogeneous_Topological_Graph_Neural_Networks",
    "file_size_mb": 0.78,
    "abstract": null,
    "keywords": []
  },
  {
    "article_id": "2506.08164v2_BLUR_A_Bi-Level_Optimization_Approach_for_LLM_Unlearning",
    "title": "2506.08164v2 BLUR A Bi-Level Optimization Approach for LLM Unlearning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2506.08164v2_BLUR_A_Bi-Level_Optimization_Approach_for_LLM_Unlearning.pdf",
    "url": "http://arxiv.org/abs/2506.08164v2_BLUR_A_Bi-Level_Optimization_Approach_for_LLM_Unlearning",
    "pdf_url": "https://arxiv.org/pdf/2506.08164v2_BLUR_A_Bi-Level_Optimization_Approach_for_LLM_Unlearning",
    "file_size_mb": 0.69,
    "abstract": "Enabling large language models (LLMs) to unlearn knowledge and capabilities acquired during training has proven vital for ensuring compliance with data regulations and promoting ethical practices in generative AI. Although there are growing interests in developing various unlearning algorithms, it remains unclear how to best formulate the unlearning problem. The most popular formulation uses a weighted sum of forget and retain loss, but it often leads to performance degradation due to the inherent trade-off between forget and retain losses. In this work, we argue that it is important to model the hierarchical structure of the unlearning problem, where the forget problem (which unlearns certain knowledge and/or capabilities) takes priority over the retain problem (which preserves model utility). This hierarchical structure naturally leads to a bi-level optimization formulation where the lower-level objective focuses on minimizing the forget loss, while the upper-level objective aims to maintain the model’s utility. Based on this new formulation, we propose a novel algorithm, termed Bi-Level UnleaRning (BLUR), which not only possesses strong theoretical guarantees but more importantly, delivers superior performance. In particular, our extensive experiments demonstrate that BLUR consistently outperforms all the state-of-the-art algorithms across various unlearning tasks, models, and metrics. Codes are available at https://github.com/OptimAI-Lab/BLURLLMUnlearning.",
    "keywords": []
  },
  {
    "article_id": "2506.09851v1_Advancing_Exchange_Rate_Forecasting_Leveraging_Machine_Learning_and_AI_for_Enhanced_Accuracy_in_Glob",
    "title": "2506.09851v1 Advancing Exchange Rate Forecasting Leveraging Machine Learning and AI for Enhanced Accuracy in Glob",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2506.09851v1_Advancing_Exchange_Rate_Forecasting_Leveraging_Machine_Learning_and_AI_for_Enhanced_Accuracy_in_Glob.pdf",
    "url": "http://arxiv.org/abs/2506.09851v1_Advancing_Exchange_Rate_Forecasting_Leveraging_Machine_Learning_and_AI_for_Enhanced_Accuracy_in_Glob",
    "pdf_url": "https://arxiv.org/pdf/2506.09851v1_Advancing_Exchange_Rate_Forecasting_Leveraging_Machine_Learning_and_AI_for_Enhanced_Accuracy_in_Glob",
    "file_size_mb": 0.47,
    "abstract": "- The prediction of foreign exchange rates, such as the US Dollar (USD) to Bangladeshi Taka (BDT), plays a pivotal role in global financial markets, influencing trade, investments, and economic stability. This study leverages historical USD/BDT exchange rate data from 2018 to 2023, sourced from Yahoo Finance, to develop advanced machine learning models for accurate forecasting. A Long Short-Term Memory (LSTM) neural network is employed, achieving an exceptional accuracy of 99.449%, a Root Mean Square Error (RMSE) of 0.9858, and a test loss of 0.8523, significantly outperforming traditional methods like ARIMA (RMSE 1.342). Additionally, a Gradient Boosting Classifier (GBC) is applied for directional prediction, with backtesting on a $10,000 initial capital revealing a 40.82% profitable trade rate, though resulting in a net loss of $20,653.25 over 49 trades. The study analyzes historical trends, showing a decline in BDT/USD rates from 0.012 to 0.009, and incorporates normalized daily returns to capture volatility. These findings highlight the potential of deep learning in forex forecasting, offering traders and policymakers robust tools to mitigate risks. Future work could integrate sentiment analysis and real-time economic indicators to further enhance model adaptability in volatile markets.",
    "keywords": [
      "Foreign Exchange Forecasting",
      "USD/BDT"
    ]
  },
  {
    "article_id": "2506.19383v1_Explainable_Artificial_Intelligence_Credit_Risk_Assessment_using_Machine_Learning",
    "title": "2506.19383v1 Explainable Artificial Intelligence Credit Risk Assessment using Machine Learning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2506.19383v1_Explainable_Artificial_Intelligence_Credit_Risk_Assessment_using_Machine_Learning.pdf",
    "url": "http://arxiv.org/abs/2506.19383v1_Explainable_Artificial_Intelligence_Credit_Risk_Assessment_using_Machine_Learning",
    "pdf_url": "https://arxiv.org/pdf/2506.19383v1_Explainable_Artificial_Intelligence_Credit_Risk_Assessment_using_Machine_Learning",
    "file_size_mb": 1.18,
    "abstract": "This paper presents an intelligent and transparent AI-driven system for Credit Risk Assessment us- ing three state-of-the-art ensemble machine learning models combined with Explainable AI (XAI) tech- niques. The system leverages XGBoost, LightGBM, and Random Forest algorithms for predictive anal- ysis of loan default risks, addressing the challenges of model interpretability using SHAP and LIME. Preprocessing steps include custom imputation, one-hot encoding, and standardization. Class imbalance is managed using SMOTE, and hyperparameter tuning is performed with GridSearchCV. The model is evaluated on multiple performance metrics including ROC-AUC, precision, recall, and F1-score. Light- GBM emerges as the most business-optimal model with the highest accuracy and best trade-off between approval and default rates. Furthermore, the system generates applicant-specific XAI visual reports and business impact summaries to ensure transparent decision-making.",
    "keywords": []
  },
  {
    "article_id": "2506.20810v1_FINN-GL_Generalized_Mixed-Precision_Extensions_for_FPGA-Accelerated_LSTMs",
    "title": "2506.20810v1 FINN-GL Generalized Mixed-Precision Extensions for FPGA-Accelerated LSTMs",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2506.20810v1_FINN-GL_Generalized_Mixed-Precision_Extensions_for_FPGA-Accelerated_LSTMs.pdf",
    "url": "http://arxiv.org/abs/2506.20810v1_FINN-GL_Generalized_Mixed-Precision_Extensions_for_FPGA-Accelerated_LSTMs",
    "pdf_url": "https://arxiv.org/pdf/2506.20810v1_FINN-GL_Generalized_Mixed-Precision_Extensions_for_FPGA-Accelerated_LSTMs",
    "file_size_mb": 1.69,
    "abstract": "—Recurrent neural networks (RNNs), particularly LSTMs, are effective for time-series tasks like sentiment analysis and short-term stock prediction. However, their computational complexity poses challenges for real-time deployment in resource constrained environments. While FPGAs offer a promising plat- form for energy-efficient AI acceleration, existing tools mainly target feed-forward networks, and LSTM acceleration typically requires full custom implementation. In this paper, we address this gap by leveraging the open-source and extensible FINN framework to enable the generalized deployment of LSTMs on FPGAs. Specifically, we leverage the Scan operator from the Open Neural Network Exchange (ONNX) specification to model the recurrent nature of LSTM computations, enabling support for mixed quantisation within them and functional verification of LSTM-based models. Furthermore, we introduce custom transformations within the FINN compiler to map the quantised ONNX computation graph to hardware blocks from the HLS kernel library of the FINN compiler and Vitis HLS. We validate the proposed tool-flow by training a quantised ConvLSTM model for a mid-price stock prediction task using the widely used dataset and generating a corresponding hardware IP of the model using our flow, targeting the XCZU7EV device. We show that the generated quantised ConvLSTM accelerator through our flow achieves a balance between performance (latency) and resource consumption, while matching (or bettering) inference accuracy of state-of-the-art models with reduced precision. We believe that the generalisable nature of the proposed flow will pave the way for resource-efficient RNN accelerator designs on FPGAs.",
    "keywords": [
      "Brevitas",
      "Field Programmable Gate Arrays"
    ]
  },
  {
    "article_id": "2506.20930v2_Quantum_Reinforcement_Learning_Trading_Agent_for_Sector_Rotation_in_the_Taiwan_Stock_Market",
    "title": "2506.20930v2 Quantum Reinforcement Learning Trading Agent for Sector Rotation in the Taiwan Stock Market",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2506.20930v2_Quantum_Reinforcement_Learning_Trading_Agent_for_Sector_Rotation_in_the_Taiwan_Stock_Market.pdf",
    "url": "http://arxiv.org/abs/2506.20930v2_Quantum_Reinforcement_Learning_Trading_Agent_for_Sector_Rotation_in_the_Taiwan_Stock_Market",
    "pdf_url": "https://arxiv.org/pdf/2506.20930v2_Quantum_Reinforcement_Learning_Trading_Agent_for_Sector_Rotation_in_the_Taiwan_Stock_Market",
    "file_size_mb": 0.51,
    "abstract": "—We propose a hybrid quantum-classical reinforce- ment learning framework for sector rotation in the Taiwan stock market. Our system employs Proximal Policy Optimization (PPO) as the backbone algorithm and integrates both classi- cal architectures (LSTM, Transformer) and quantum-enhanced models (QNN, QRWKV, QASA) as policy and value networks. An automated feature engineering pipeline extracts financial indica- tors from capital share data to ensure consistent model input across all configurations. Empirical backtesting reveals a key finding: although quantum-enhanced models consistently achieve higher training rewards, they underperform classical models in real-world investment metrics such as cumulative return and Sharpe ratio. This discrepancy highlights a core challenge in applying reinforcement learning to financial domains—namely, the mismatch between proxy reward signals and true investment objectives. Our analysis suggests that current reward designs may incentivize overfitting to short-term volatility rather than optimizing risk-adjusted returns. This issue is compounded by the inherent expressiveness and optimization instability of quantum circuits under Noisy Intermediate-Scale Quantum (NISQ) con- straints. We discuss the implications of this reward-performance gap and propose directions for future improvement, including reward shaping, model regularization, and validation-based early stopping. Our work offers a reproducible benchmark and critical insights into the practical challenges of deploying quantum reinforcement learning in real-world finance.",
    "keywords": [
      "Quantum reinforcement learning",
      "sector rota-"
    ]
  },
  {
    "article_id": "2507.01964v1_Forecasting_Nigerian_Equity_Stock_Returns_Using_Long_Short-Term_Memory_Technique",
    "title": "2507.01964v1 Forecasting Nigerian Equity Stock Returns Using Long Short-Term Memory Technique",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2507.01964v1_Forecasting_Nigerian_Equity_Stock_Returns_Using_Long_Short-Term_Memory_Technique.pdf",
    "url": "http://arxiv.org/abs/2507.01964v1_Forecasting_Nigerian_Equity_Stock_Returns_Using_Long_Short-Term_Memory_Technique",
    "pdf_url": "https://arxiv.org/pdf/2507.01964v1_Forecasting_Nigerian_Equity_Stock_Returns_Using_Long_Short-Term_Memory_Technique",
    "file_size_mb": 0.73,
    "abstract": "Investors and stock market analysts face major challenges in predicting stock returns and making wise investment decisions. The predictability of equity stock returns can boost investor confidence, but it remains a difficult task. To address this issue, a study was conducted using a Long Short-term Memory (LSTM) model to predict future stock market movements. The study used a historical dataset from the Nigerian Stock Exchange (NSE), which was cleaned and normalized to design the LSTM model. The model was evaluated using performance metrics and compared with other deep learning models like Artificial and Convolutional Neural Networks (CNN). The experimental results showed that the LSTM model can predict future stock market prices and returns with over 90% accuracy when trained with a reliable dataset. The study concludes that LSTM models can be useful in predicting financial time-series-related problems if well-trained. Future studies should explore combining LSTM models with other deep learning techniques like CNN to create hybrid models that mitigate the risks associated with relying on a single model for future equity stock predictions. Original Research Article Adebola and Ifechukwude; J. Adv. Math. Com. Sci., vol. 39, no. 7, pp. 45-54, 2024; Article no.JAMCS.118757 46",
    "keywords": [
      "Long-short term memory",
      "deep neural networks",
      "forecasting",
      "convolutional neural networks"
    ]
  },
  {
    "article_id": "2507.01972v1_Accelerated_Portfolio_Optimization_and_Option_Pricing_with_Reinforcement_Learning",
    "title": "2507.01972v1 Accelerated Portfolio Optimization and Option Pricing with Reinforcement Learning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2507.01972v1_Accelerated_Portfolio_Optimization_and_Option_Pricing_with_Reinforcement_Learning.pdf",
    "url": "http://arxiv.org/abs/2507.01972v1_Accelerated_Portfolio_Optimization_and_Option_Pricing_with_Reinforcement_Learning",
    "pdf_url": "https://arxiv.org/pdf/2507.01972v1_Accelerated_Portfolio_Optimization_and_Option_Pricing_with_Reinforcement_Learning",
    "file_size_mb": 0.45,
    "abstract": "We present a reinforcement learning (RL)-driven framework for optimizing block- preconditioner sizes in iterative solvers used in portfolio optimization and option pricing. The covariance matrix in portfolio optimization or the discretization of differential operators in option pricing models lead to large linear systems of the form Ax = b. Direct inversion of high-dimensional portfolio or fine-grid option pricing incurs a significant computational cost. Therefore, iterative methods are usually used for portfolios in real-world situations. Ill-conditioned systems, how- ever, suffer from slow convergence. Traditional preconditioning techniques often require problem-specific parameter tuning. To overcome this limitation, we rely on RL to dynamically adjust the block-preconditioner sizes and accelerate iterative solver convergence. Evaluations on a suite of real-world portfolio optimization matrices demonstrate that our RL framework can be used to adjust precondition- ing and significantly accelerate convergence and reduce computational cost. The proposed accelerated solver supports faster decision-making in dynamic portfolio allocation and real-time option pricing.",
    "keywords": []
  },
  {
    "article_id": "2507.01973v2_Integration_of_Wavelet_Transform_Convolution_and_Channel_Attention_with_LSTM_for_Stock_Price_Predict",
    "title": "2507.01973v2 Integration of Wavelet Transform Convolution and Channel Attention with LSTM for Stock Price Predict",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2507.01973v2_Integration_of_Wavelet_Transform_Convolution_and_Channel_Attention_with_LSTM_for_Stock_Price_Predict.pdf",
    "url": "http://arxiv.org/abs/2507.01973v2_Integration_of_Wavelet_Transform_Convolution_and_Channel_Attention_with_LSTM_for_Stock_Price_Predict",
    "pdf_url": "https://arxiv.org/pdf/2507.01973v2_Integration_of_Wavelet_Transform_Convolution_and_Channel_Attention_with_LSTM_for_Stock_Price_Predict",
    "file_size_mb": 1.36,
    "abstract": "Portfolio allocation via stock price prediction is inherently difficult due to the notoriously low signal-to-noise ratio of stock time series. This paper proposes a method by integrating wavelet transform convolution and channel attention with LSTM to implement stock price prediction based portfolio allocation. Stock time series data first are processed by wavelet transform convolution to reduce the noise. Processed features are then reconstructed by channel attention. LSTM is utilized to predict the stock price using the final processed features. We construct a portfolio consists of four stocks with trading signals predicted by model. Exper- iments are conducted by evaluating the return, Sharpe ratio and max drawdown performance. The results indicate that our method achieves robust performance even during period of post-pandemic downward market.",
    "keywords": [
      "Stock price prediction",
      "Portfolio allocation",
      "Wavelet transform",
      "Channel"
    ]
  },
  {
    "article_id": "2507.08184v1_EP-GAT_Energy-based_Parallel_Graph_Attention_Neural_Network_for_Stock_Trend_Classification",
    "title": "2507.08184v1 EP-GAT Energy-based Parallel Graph Attention Neural Network for Stock Trend Classification",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2507.08184v1_EP-GAT_Energy-based_Parallel_Graph_Attention_Neural_Network_for_Stock_Trend_Classification.pdf",
    "url": "http://arxiv.org/abs/2507.08184v1_EP-GAT_Energy-based_Parallel_Graph_Attention_Neural_Network_for_Stock_Trend_Classification",
    "pdf_url": "https://arxiv.org/pdf/2507.08184v1_EP-GAT_Energy-based_Parallel_Graph_Attention_Neural_Network_for_Stock_Trend_Classification",
    "file_size_mb": 0.48,
    "abstract": "—Graph neural networks have shown remarkable performance in forecasting stock movements, which arises from learning complex inter-dependencies between stocks and intra- dynamics of stocks. Existing approaches based on graph neural networks typically rely on static or manually defined factors to model changing inter-dependencies between stocks. Furthermore, these works often struggle to preserve hierarchical features within stocks. To bridge these gaps, this work presents the Energy-based Parallel Graph Attention Neural Network, a novel approach for predicting future movements for multiple stocks. First, it gener- ates a dynamic stock graph with the energy difference between stocks and Boltzmann distribution, capturing evolving inter- dependencies between stocks. Then, a parallel graph attention mechanism is proposed to preserve the hierarchical intra-stock dynamics. Extensive experiments on five real-world datasets are conducted to validate the proposed approach, spanning from the US stock markets (NASDAQ, NYSE, SP) and UK stock markets (FTSE, LSE). The experimental results demonstrate that EP-GAT consistently outperforms competitive five baselines on test periods across various metrics. The ablation studies and hyperparameter sensitivity analysis further validate the effectiveness of each module in the proposed method.",
    "keywords": [
      "stock trend forecasting",
      "graph neural network"
    ]
  },
  {
    "article_id": "2507.10701v1_Kernel_Learning_for_Mean-Variance_Trading_Strategies",
    "title": "2507.10701v1 Kernel Learning for Mean-Variance Trading Strategies",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2507.10701v1_Kernel_Learning_for_Mean-Variance_Trading_Strategies.pdf",
    "url": "http://arxiv.org/abs/2507.10701v1_Kernel_Learning_for_Mean-Variance_Trading_Strategies",
    "pdf_url": "https://arxiv.org/pdf/2507.10701v1_Kernel_Learning_for_Mean-Variance_Trading_Strategies",
    "file_size_mb": 2.44,
    "abstract": "In this article, we develop a kernel-based framework for constructing dynamic, path- dependent trading strategies under a mean-variance optimisation criterion. Building on the theoretical results of [CS25], we parameterise trading strategies as functions in a re- producing kernel Hilbert space (RKHS), enabling a flexible and non-Markovian approach to optimal portfolio problems. We compare this with the signature-based framework of [FHW23] and demonstrate that both significantly outperform classical Markovian meth- ods when the asset dynamics or predictive signals exhibit temporal dependencies for both synthetic and market-data examples. Using kernels in this context provides significant modelling flexibility, as the choice of feature embedding can range from randomised signa- tures to the final layers of neural network architectures. Crucially, our framework retains closed-form solutions and provides an alternative to gradient-based optimisation. Contents",
    "keywords": []
  },
  {
    "article_id": "2507.11506v2_ELK_Exploring_the_Efficiency_of_Inter-core_Connected_AI_Chips_with_Deep_Learning_Compiler_Techniques",
    "title": "2507.11506v2 ELK Exploring the Efficiency of Inter-core Connected AI Chips with Deep Learning Compiler Techniques",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2507.11506v2_ELK_Exploring_the_Efficiency_of_Inter-core_Connected_AI_Chips_with_Deep_Learning_Compiler_Techniques.pdf",
    "url": "http://arxiv.org/abs/2507.11506v2_ELK_Exploring_the_Efficiency_of_Inter-core_Connected_AI_Chips_with_Deep_Learning_Compiler_Techniques",
    "pdf_url": "https://arxiv.org/pdf/2507.11506v2_ELK_Exploring_the_Efficiency_of_Inter-core_Connected_AI_Chips_with_Deep_Learning_Compiler_Techniques",
    "file_size_mb": 3.82,
    "abstract": "To meet the increasing demand of deep learning (DL) models, AI chips are employing both off-chip memory (e.g., HBM) and high- bandwidth low-latency interconnect for direct inter-core data ex- change. However, it is not easy to explore the efficiency of these inter-core connected AI (ICCA) chips, due to a fundamental tussle among compute (per-core execution), communication (inter-core data exchange), and I/O (off-chip data access). In this paper, we develop Elk, a DL compiler framework to maxi- mize the efficiency of ICCA chips by jointly trading off all the three performance factors discussed above. Elk structures these perfor- mance factors into configurable parameters and forms a global trade-off space in the DL compiler. To systematically explore this space and maximize overall efficiency, Elk employs a new inductive operator scheduling policy and a cost-aware on-chip memory allo- cation algorithm. It generates globally optimized execution plans that best overlap off-chip data loading and on-chip execution. To ex- amine the efficiency of Elk, we build a full-fledged emulator based on a real ICCA chip IPU-POD4, and an ICCA chip simulator for sensitivity analysis with different interconnect network topologies. Elk achieves 94% of the ideal roofline performance of ICCA chips on average, showing the benefits of supporting large DL models on ICCA chips. We also show Elk’s capability of enabling architecture design space exploration for new ICCA chip development. CCS Concepts • Software and its engineering →Compilers; • Hardware → Emerging architectures; • Computer systems organization → Parallel architectures.",
    "keywords": [
      "Deep Learning Compiler",
      "Inter-Core Connected AI Chip",
      "ML Accel-"
    ]
  },
  {
    "article_id": "2507.12369v2_Catching_Bid-rigging_Cartels_with_Graph_Attention_Neural_Networks",
    "title": "2507.12369v2 Catching Bid-rigging Cartels with Graph Attention Neural Networks",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2507.12369v2_Catching_Bid-rigging_Cartels_with_Graph_Attention_Neural_Networks.pdf",
    "url": "http://arxiv.org/abs/2507.12369v2_Catching_Bid-rigging_Cartels_with_Graph_Attention_Neural_Networks",
    "pdf_url": "https://arxiv.org/pdf/2507.12369v2_Catching_Bid-rigging_Cartels_with_Graph_Attention_Neural_Networks",
    "file_size_mb": 1.26,
    "abstract": "We propose a novel application of graph attention networks (GATs)—a type of graph neural network en- hanced with attention mechanisms—to develop a deep learning algorithm for detecting collusive behavior, leveraging predictive features suggested in prior research. We test our approach on a large dataset covering 13 markets across seven countries. Our results show that predictive models based on GATs, trained on a subset of the markets, can be effectively transferred to other markets, achieving accuracy rates between 80% and 90%, depending on the hyper- parameter settings. The best-performing configuration, applied to eight markets from Switzerland and the Japanese region of Okinawa, yields an average accuracy of 91% for cross-market prediction. When extended to 12 markets, the method maintains a strong performance with an average accuracy of 84%, surpassing traditional ensemble ap- proaches in machine learning. These results suggest that GAT-based detection methods offer a promising tool for competition authorities to screen markets for potential cartel activity.",
    "keywords": [
      "Cartel detection",
      "screens",
      "graph neural networks",
      "attention mechanism",
      "GAT",
      "Jaccard similarity"
    ]
  },
  {
    "article_id": "2507.12787v1_Multi-Channel_Graph_Neural_Network_for_Financial_Risk_Prediction_of_NEEQ_Enterprises",
    "title": "2507.12787v1 Multi-Channel Graph Neural Network for Financial Risk Prediction of NEEQ Enterprises",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2507.12787v1_Multi-Channel_Graph_Neural_Network_for_Financial_Risk_Prediction_of_NEEQ_Enterprises.pdf",
    "url": "http://arxiv.org/abs/2507.12787v1_Multi-Channel_Graph_Neural_Network_for_Financial_Risk_Prediction_of_NEEQ_Enterprises",
    "pdf_url": "https://arxiv.org/pdf/2507.12787v1_Multi-Channel_Graph_Neural_Network_for_Financial_Risk_Prediction_of_NEEQ_Enterprises",
    "file_size_mb": 0.87,
    "abstract": "With the continuous evolution of China’s multi-level capital market, the National Equities Ex- change and Quotations (NEEQ), also known as the “New Third Board,” has become a critical fi- nancing platform for small and medium-sized enterprises (SMEs). However, due to their limited scale and financial resilience, many NEEQ-listed companies face elevated risks of financial dis- tress. To address this issue, we propose a multi-channel deep learning framework that integrates structured financial indicators, textual disclosures, and enterprise relationship data for comprehen- sive financial risk prediction. Specifically, we design a Triple-Channel Graph Isomorphism Network (GIN) that processes numeric, textual, and graph-based inputs separately. These modality-specific representations are fused using an attention-based mechanism followed by a gating unit to enhance robustness and prediction accuracy. Experimental results on data from 7,731 real-world NEEQ com- panies demonstrate that our model significantly outperforms traditional machine learning methods and single-modality baselines in terms of AUC, Precision, Recall, and F1 Score. This work provides theoretical and practical insights into risk modeling for SMEs and offers a data-driven tool to support financial regulators and investors.",
    "keywords": [
      "The resulting term-"
    ]
  },
  {
    "article_id": "2507.18417v1_FinDPO_Financial_Sentiment_Analysis_for_Algorithmic_Trading_through_Preference_Optimization_of_LLMs",
    "title": "2507.18417v1 FinDPO Financial Sentiment Analysis for Algorithmic Trading through Preference Optimization of LLMs",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2507.18417v1_FinDPO_Financial_Sentiment_Analysis_for_Algorithmic_Trading_through_Preference_Optimization_of_LLMs.pdf",
    "url": "http://arxiv.org/abs/2507.18417v1_FinDPO_Financial_Sentiment_Analysis_for_Algorithmic_Trading_through_Preference_Optimization_of_LLMs",
    "pdf_url": "https://arxiv.org/pdf/2507.18417v1_FinDPO_Financial_Sentiment_Analysis_for_Algorithmic_Trading_through_Preference_Optimization_of_LLMs",
    "file_size_mb": 0.87,
    "abstract": "Opinions expressed in online finance-related textual data are hav- ing an increasingly profound impact on trading decisions and mar- ket movements. This trend highlights the vital role of sentiment analysis as a tool for quantifying the nature and strength of such opinions. With the rapid development of Generative AI (GenAI), supervised fine-tuned (SFT) large language models (LLMs) have become the de facto standard for financial sentiment analysis. How- ever, the SFT paradigm can lead to memorization of the training data and often fails to generalize to unseen samples. This is a crit- ical limitation in financial domains, where models must adapt to previously unobserved events and the nuanced, domain-specific language of finance. To this end, we introduce FinDPO, the first finance-specific LLM framework based on post-training human pref- erence alignment via Direct Preference Optimization (DPO). The proposed FinDPO achieves state-of-the-art performance on stan- dard sentiment classification benchmarks, outperforming existing supervised fine-tuned models by 11% on the average. Uniquely, the FinDPO framework enables the integration of a fine-tuned causal LLM into realistic portfolio strategies through a novel ‘logit-to- score’ conversion, which transforms discrete sentiment predictions into continuous, rankable sentiment scores (probabilities). In this way, simulations demonstrate that FinDPO is the first sentiment- based approach to maintain substantial positive returns of 67% annually and strong risk-adjusted performance, as indicated by a Sharpe ratio of 2.0, even under realistic transaction costs of 5 basis points (bps).",
    "keywords": [
      "Large language models",
      "sentiment analysis",
      "direct preference opti-"
    ]
  },
  {
    "article_id": "2507.18560v1_HARLF_Hierarchical_Reinforcement_Learning_and_Lightweight_LLM-Driven_Sentiment_Integration_for_Finan",
    "title": "2507.18560v1 HARLF Hierarchical Reinforcement Learning and Lightweight LLM-Driven Sentiment Integration for Finan",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2507.18560v1_HARLF_Hierarchical_Reinforcement_Learning_and_Lightweight_LLM-Driven_Sentiment_Integration_for_Finan.pdf",
    "url": "http://arxiv.org/abs/2507.18560v1_HARLF_Hierarchical_Reinforcement_Learning_and_Lightweight_LLM-Driven_Sentiment_Integration_for_Finan",
    "pdf_url": "https://arxiv.org/pdf/2507.18560v1_HARLF_Hierarchical_Reinforcement_Learning_and_Lightweight_LLM-Driven_Sentiment_Integration_for_Finan",
    "file_size_mb": 0.87,
    "abstract": "This paper presents a novel hierarchical framework for portfolio optimization, integrating lightweight Large Language Models (LLMs) with Deep Rein- forcement Learning (DRL) to combine sentiment signals from financial news with traditional mar- ket indicators. Our three-tier architecture employs base RL agents to process hybrid data, meta-agents to aggregate their decisions, and a super-agent to merge decisions based on market data and senti- ment analysis. Evaluated on data from 2018 to 2024, after training on 2000–2017, the framework achieves a 26% annualized return and a Sharpe ra- tio of 1.2, outperforming equal-weighted and S&P 500 benchmarks. Key contributions include scal- able cross-modal integration, a hierarchical RL structure for enhanced stability, and open-source reproducibility.",
    "keywords": [
      "2: Output: Monthly sentiment scores"
    ]
  },
  {
    "article_id": "2507.19639v1_Directly_Learning_Stock_Trading_Strategies_Through_Profit_Guided_Loss_Functions",
    "title": "2507.19639v1 Directly Learning Stock Trading Strategies Through Profit Guided Loss Functions",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2507.19639v1_Directly_Learning_Stock_Trading_Strategies_Through_Profit_Guided_Loss_Functions.pdf",
    "url": "http://arxiv.org/abs/2507.19639v1_Directly_Learning_Stock_Trading_Strategies_Through_Profit_Guided_Loss_Functions",
    "pdf_url": "https://arxiv.org/pdf/2507.19639v1_Directly_Learning_Stock_Trading_Strategies_Through_Profit_Guided_Loss_Functions",
    "file_size_mb": 0.53,
    "abstract": "Stock trading has always been a challenging task due to the highly volatile na- ture of the stock market. Making sound trading decisions to generate profit is particularly difficult under such conditions. To address this, we propose four novel loss functions to drive decision-making for a portfolio of stocks. These functions account for the potential profits or losses based with respect to buying or shorting respective stocks, enabling potentially any artificial neural network to directly learn an effective trading strategy. Despite the high volatility in stock market fluctuations over time, training time-series models such as transformers on these loss functions resulted in trading strategies that generated significant profits on a portfolio of 50 different S&P 500 company stocks as compared to a benchmark reinforcment learning techniques and a baseline buy and hold method. As an example, using 2021, 2022 and 2023 as three test periods, the Crossformer model adapted with our best loss function was most consistent, resulting in returns of 51.42%, 51.04% and 48.62% respectively. In comparison, the best performing state-of-the-art re- inforcement learning methods, PPO and DDPG, only delivered maximum profits of around 41%, 2.81% and 41.58% for the same periods. The code is available at https://anonymous.4open.science/r/bandit-stock-trading-58C8/ README.md. Preprint. Under review. arXiv:2507.19639v1 [cs.LG] 25 Jul 2025",
    "keywords": []
  },
  {
    "article_id": "2507.20039v1_Dependency_Network-Based_Portfolio_Design_with_Forecasting_and_VaR_Constraints",
    "title": "2507.20039v1 Dependency Network-Based Portfolio Design with Forecasting and VaR Constraints",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2507.20039v1_Dependency_Network-Based_Portfolio_Design_with_Forecasting_and_VaR_Constraints.pdf",
    "url": "http://arxiv.org/abs/2507.20039v1_Dependency_Network-Based_Portfolio_Design_with_Forecasting_and_VaR_Constraints",
    "pdf_url": "https://arxiv.org/pdf/2507.20039v1_Dependency_Network-Based_Portfolio_Design_with_Forecasting_and_VaR_Constraints",
    "file_size_mb": 1.24,
    "abstract": "This study proposes a novel portfolio optimization framework that integrates sta- tistical social network analysis with time series forecasting and risk management. Using daily stock data from the S&P 500 (2020–2024), we construct dependency networks via Vector Autoregression (VAR) and Forecast Error Variance Decom- position (FEVD), transforming influence relationships into a cost-based network. Specifically, FEVD breaks down the VAR’s forecast error variance to quantify how much each stock’s shocks contribute to another’s uncertainty information we invert to form influence-based edge weights in our network. By applying the Minimum Spanning Tree (MST) algorithm, we extract the core inter-stock struc- ture and identify central stocks through degree centrality. A dynamic portfolio is constructed using the top-ranked stocks, with capital allocated based on Value at Risk (VaR). To refine stock selection, we incorporate forecasts from ARIMA and Neural Network Autoregressive (NNAR) models. Trading simulations over a one-year period demonstrate that the MST-based strategies outperform a buy-and-hold benchmark, with the tuned NNAR-enhanced strategy achieving a 63.74% return versus 18.00% for the benchmark. Our results highlight the poten- tial of combining network structures, predictive modeling, and risk metrics to improve adaptive financial decision-making.",
    "keywords": [
      "Social Network",
      "Time-series Model",
      "MST"
    ]
  },
  {
    "article_id": "2507.20202v2_Technical_Indicator_Networks_TINs_An_Interpretable_Neural_Architecture_Modernizing_Classic_al_Techni",
    "title": "2507.20202v2 Technical Indicator Networks TINs An Interpretable Neural Architecture Modernizing Classic al Techni",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2507.20202v2_Technical_Indicator_Networks_TINs_An_Interpretable_Neural_Architecture_Modernizing_Classic_al_Techni.pdf",
    "url": "http://arxiv.org/abs/2507.20202v2_Technical_Indicator_Networks_TINs_An_Interpretable_Neural_Architecture_Modernizing_Classic_al_Techni",
    "pdf_url": "https://arxiv.org/pdf/2507.20202v2_Technical_Indicator_Networks_TINs_An_Interpretable_Neural_Architecture_Modernizing_Classic_al_Techni",
    "file_size_mb": 1.8,
    "abstract": "Deep neural networks (DNNs) have transformed fields such as computer vision and natural language processing by employing architectures aligned with domain-specific structural patterns. In algorithmic trading, however, there remains a lack of architectures that directly incorporate the logic of traditional technical indicators. This study introduces Technical Indicator Networks (TINs), a structured neu- ral design that reformulates rule-based financial heuristics into trainable and interpretable modules. The architecture preserves the core mathematical definitions of conventional indicators while extend- ing them to multidimensional data and supporting optimization through diverse learning paradigms, including reinforcement learning. Analytical transformations such as averaging, clipping, and ratio computation are expressed as vectorized layer operators, enabling transparent network construction and principled initialization. This formulation retains the clarity and interpretability of classical strategies while allowing adaptive adjustment and data-driven refinement. As a proof of concept, the framework is validated on the Dow Jones Industrial Average constituents using a Moving Average Convergence Divergence (MACD) TIN. Results validate the effectiveness of the proposed framework and demonstrate its potential for enhancing risk-adjusted performance in trading applications. The findings show that TINs establish a generalizable foundation for interpretable, adaptive, and extensi- ble learning systems in structured decision-making domains. In addition to academic contributions, the framework indicates significant commercial potential, providing the basis for upgrading trading platforms with cross-market visibility and enhanced decision-support capabilities.",
    "keywords": [
      "Technical Indicator Networks (TINs)",
      "Interpretable Machine Learning",
      "Neural Network"
    ]
  },
  {
    "article_id": "2507.20263v1_Learning_from_Expert_Factors_Trajectory-level_Reward_Shaping_for_Formulaic_Alpha_Mining",
    "title": "2507.20263v1 Learning from Expert Factors Trajectory-level Reward Shaping for Formulaic Alpha Mining",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2507.20263v1_Learning_from_Expert_Factors_Trajectory-level_Reward_Shaping_for_Formulaic_Alpha_Mining.pdf",
    "url": "http://arxiv.org/abs/2507.20263v1_Learning_from_Expert_Factors_Trajectory-level_Reward_Shaping_for_Formulaic_Alpha_Mining",
    "pdf_url": "https://arxiv.org/pdf/2507.20263v1_Learning_from_Expert_Factors_Trajectory-level_Reward_Shaping_for_Formulaic_Alpha_Mining",
    "file_size_mb": 2.18,
    "abstract": "—Reinforcement learning (RL) has successfully auto- mated the complex process of mining formulaic alpha factors, for creating interpretable and profitable investment strategies. However, existing methods are hampered by the sparse rewards given the underlying Markov Decision Process. This inefficiency limits the exploration of the vast symbolic search space and destabilizes the training process. To address this, Trajectory- level Reward Shaping (TLRS), a novel reward shaping method, is proposed. TLRS provides dense, intermediate rewards by measuring the subsequence-level similarity between partially generated expressions and a set of expert-designed formulas. Furthermore, a reward centering mechanism is introduced to reduce training variance. Extensive experiments on six major Chinese and U.S. stock indices show that TLRS significantly improves the predictive power of mined factors, boosting the Rank Information Coefficient by 9.29% over existing potential- based shaping algorithms. Notably, TLRS achieves a major leap in computational efficiency by reducing its time complexity with respect to the feature dimension from linear to constant, which is a significant improvement over distance-based baselines.",
    "keywords": [
      "Reinforcement learning",
      "Computational finance"
    ]
  },
  {
    "article_id": "2507.21710v1_PREIG_Physics-informed_and_Reinforcement-driven_Interpretable_GRU_for_Commodity_Demand_Forecasting",
    "title": "2507.21710v1 PREIG Physics-informed and Reinforcement-driven Interpretable GRU for Commodity Demand Forecasting",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2507.21710v1_PREIG_Physics-informed_and_Reinforcement-driven_Interpretable_GRU_for_Commodity_Demand_Forecasting.pdf",
    "url": "http://arxiv.org/abs/2507.21710v1_PREIG_Physics-informed_and_Reinforcement-driven_Interpretable_GRU_for_Commodity_Demand_Forecasting",
    "pdf_url": "https://arxiv.org/pdf/2507.21710v1_PREIG_Physics-informed_and_Reinforcement-driven_Interpretable_GRU_for_Commodity_Demand_Forecasting",
    "file_size_mb": 2.38,
    "abstract": "—Accurately forecasting commodity demand remains a critical challenge due to volatile market dynamics, nonlin- ear dependencies, and the need for economically consistent predictions. This paper introduces PREIG—a Physics-informed and Reinforcement-driven Interpretable model with GRU—a novel deep learning framework tailored for commodity demand forecasting. The model uniquely integrates a Gated Recurrent Unit (GRU) architecture with physics-informed neural network (PINN) principles by embedding a domain-specific economic constraint: the negative elasticity between price and demand. This constraint is enforced through a customized loss function that penalizes violations of the physical rule, ensuring that model predictions remain interpretable and aligned with economic theory. To further enhance predictive performance and stability, PREIG incorporates a hybrid optimization strategy that couples NAdam and L-BFGS with Population-Based Training (POP)—a reinforcement-learning inspired mechanism that dynamically tunes hyperparameters via evolutionary exploration and ex- ploitation. Experiments across multiple commodities datasets demonstrate that PREIG significantly outperforms traditional econometric models (ARIMA, GARCH) and deep learning base- lines (BPNN,RNN) in both RMSE and MAPE. When compared with GRU, PREIG maintains good explainability while still performing well in prediction. By bridging domain knowledge, optimization theory and deep learning, PREIG provides a ro- bust, interpretable, and scalable solution for high-dimensional nonlinear time series forecasting in economy. Index Terms—PINN, Reinforcement-Learning, Analytic Derivative, GRU, Commodity Demand",
    "keywords": []
  },
  {
    "article_id": "2507.22932v1_FinMarBa_A_Market-Informed_Dataset_for_Financial_Sentiment_Classification",
    "title": "2507.22932v1 FinMarBa A Market-Informed Dataset for Financial Sentiment Classification",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2507.22932v1_FinMarBa_A_Market-Informed_Dataset_for_Financial_Sentiment_Classification.pdf",
    "url": "http://arxiv.org/abs/2507.22932v1_FinMarBa_A_Market-Informed_Dataset_for_Financial_Sentiment_Classification",
    "pdf_url": "https://arxiv.org/pdf/2507.22932v1_FinMarBa_A_Market-Informed_Dataset_for_Financial_Sentiment_Classification",
    "file_size_mb": 0.56,
    "abstract": "Financial sentiment classification typically relies on human-annotated datasets for model fine-tuning and evaluation. However, to the best of our knowl- edge, existing datasets exhibit inherent biases and do not directly capture market reactions. Despite these limitations, no alternative dataset has been developed specifically for financial sentiment classi- fication based on news. In this work, we introduce FinMarBa, a dataset that reflects actual market re- actions to news, eliminating human-induced biases. We present a fully automated labeling method that enables the construction of large-scale datasets, fa- cilitating both fine-tuning and evaluation of large language models. Since financial sentiment classi- fication is primarily employed for predictive signal generation, we provide empirical evidence demon- strating the quality of our labelling approach com- pared to conventional human annotation. Further- more, we release a substantial subset of the dataset on Hugging Face, along with the associated code and fine-tuned models as open-source resources.",
    "keywords": [
      "Financial Sentiment Analysis",
      "Market-Based An-"
    ]
  },
  {
    "article_id": "2508.00040v1_Regime-Aware_Conditional_Neural_Processes_with_Multi-Criteria_Decision_Support_for_Operational_Elect",
    "title": "2508.00040v1 Regime-Aware Conditional Neural Processes with Multi-Criteria Decision Support for Operational Elect",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2508.00040v1_Regime-Aware_Conditional_Neural_Processes_with_Multi-Criteria_Decision_Support_for_Operational_Elect.pdf",
    "url": "http://arxiv.org/abs/2508.00040v1_Regime-Aware_Conditional_Neural_Processes_with_Multi-Criteria_Decision_Support_for_Operational_Elect",
    "pdf_url": "https://arxiv.org/pdf/2508.00040v1_Regime-Aware_Conditional_Neural_Processes_with_Multi-Criteria_Decision_Support_for_Operational_Elect",
    "file_size_mb": 1.57,
    "abstract": "This work integrates Bayesian regime detection with conditional neural processes for 24-hour electricity price prediction in the German market. Our methodology in- tegrates regime detection using a disentangled sticky hierarchical Dirichlet process hidden Markov model (DS-HDP-HMM) applied to daily electricity prices. Each identified regime is subsequently modeled by an independent conditional neural process (CNP), trained to learn localized mappings from input contexts to 24- dimensional hourly price trajectories, with final predictions computed as regime- weighted mixtures of these CNP outputs. We rigorously evaluate R-NP against deep neural networks (DNN) and Lasso estimated auto-regressive (LEAR) models by integrating their forecasts into diverse battery storage optimization frameworks, including price arbitrage, risk management, grid services, and cost minimization. This operational utility assessment revealed complex performance trade-offs: LEAR often yielded superior absolute profits or lower costs, while DNN showed exceptional optimality in specific cost-minimization contexts. Recognizing that raw prediction accuracy doesn’t always translate to optimal operational outcomes, we employed TOPSIS as a comprehensive multi-criteria evaluation layer. Our TOPSIS analysis identified LEAR as the top-ranked model for 2021, but crucially, our proposed R- NP model emerged as the most balanced and preferred solution for 2021, 2022 and 2023.",
    "keywords": [
      "Regime-Aware Prediction",
      "MCDM",
      "Electricity Price Forecasting",
      "Bat-"
    ]
  },
  {
    "article_id": "2508.01173v2_MARS_A_Meta-Adaptive_Reinforcement_Learning_Framework_for_Risk-Aware_Multi-Agent_Portfolio_Managemen",
    "title": "2508.01173v2 MARS A Meta-Adaptive Reinforcement Learning Framework for Risk-Aware Multi-Agent Portfolio Managemen",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2508.01173v2_MARS_A_Meta-Adaptive_Reinforcement_Learning_Framework_for_Risk-Aware_Multi-Agent_Portfolio_Managemen.pdf",
    "url": "http://arxiv.org/abs/2508.01173v2_MARS_A_Meta-Adaptive_Reinforcement_Learning_Framework_for_Risk-Aware_Multi-Agent_Portfolio_Managemen",
    "pdf_url": "https://arxiv.org/pdf/2508.01173v2_MARS_A_Meta-Adaptive_Reinforcement_Learning_Framework_for_Risk-Aware_Multi-Agent_Portfolio_Managemen",
    "file_size_mb": 2.02,
    "abstract": "Reinforcement Learning (RL) has shown significant promise in automated portfolio management; however, effectively bal- ancing risk and return remains a central challenge, as many models fail to adapt to dynamically changing market condi- tions. We propose Meta-controlled Agents for a Risk-aware System (MARS), a novel framework addressing this through a multi-agent, risk-aware approach. MARS replaces mono- lithic models with a Heterogeneous Agent Ensemble, where each agent’s unique risk profile is enforced by a Safety- Critic network to span behaviors from capital preservation to aggressive growth. A high-level Meta-Adaptive Controller (MAC) dynamically orchestrates this ensemble, shifting re- liance between conservative and aggressive agents to mini- mize drawdown during downturns while seizing opportuni- ties in bull markets. This two-tiered structure leverages be- havioral diversity rather than explicit feature engineering to ensure a disciplined portfolio robust across market regimes. Experiments on major international indexes confirm that our framework significantly reduces maximum drawdown and volatility while maintaining competitive returns.",
    "keywords": []
  },
  {
    "article_id": "2508.01419v1_Cryptocurrency_Price_Forecasting_Using_Machine_Learning_Building_Intelligent_Financial_Prediction_Mo",
    "title": "2508.01419v1 Cryptocurrency Price Forecasting Using Machine Learning Building Intelligent Financial Prediction Mo",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2508.01419v1_Cryptocurrency_Price_Forecasting_Using_Machine_Learning_Building_Intelligent_Financial_Prediction_Mo.pdf",
    "url": "http://arxiv.org/abs/2508.01419v1_Cryptocurrency_Price_Forecasting_Using_Machine_Learning_Building_Intelligent_Financial_Prediction_Mo",
    "pdf_url": "https://arxiv.org/pdf/2508.01419v1_Cryptocurrency_Price_Forecasting_Using_Machine_Learning_Building_Intelligent_Financial_Prediction_Mo",
    "file_size_mb": 1.0,
    "abstract": "Cryptocurrency markets are experiencing rapid growth, but this expansion comes with significant challenges, particularly in predicting cryptocurrency prices for traders in the U.S. In this study, we explore how deep learning and machine learning models can be used to forecast the closing prices of the XRP/USDT trading pair. While many existing cryptocurrency prediction models focus solely on price and volume patterns, they often overlook market liquidity, a crucial factor in price predictability. To address this, we introduce two im- portant liquidity proxy metrics: the Volume-To-Volatility Ratio (VVR) and the Volume-Weighted Average Price (VWAP). These metrics provide a clearer understanding of market stability and liquidity, ultimately enhancing the accuracy of our price predictions. We developed four machine learning models, Linear Regression, Random Forest, XGBoost, and LSTM neural networks, using historical data without incorporating the liquidity proxy metrics, and evaluated their performance. We then retrained the models, including the liquidity proxy metrics, and reassessed their performance. In both cases (with and without the liquidity proxies), the LSTM model consistently outper- formed the others. These results underscore the importance of considering market liquidity when predicting cryptocurrency closing prices. Therefore, incorporating these liquidity metrics is essential for more accurate forecasting models. Our findings offer valuable insights for traders and developers seeking to create smarter and more risk-aware strategies in the U.S. digital assets market.",
    "keywords": [
      "Cryptocurrency Forecasting",
      "LSTM Neural Networks",
      "Market Liquidity",
      "Machine Learning",
      "VWAP",
      "VVR"
    ]
  },
  {
    "article_id": "2508.02292v2_FinWorld_An_All-in-One_Open-Source_Platform_for_End-to-End_Financial_AI_Research_and_Deployment",
    "title": "2508.02292v2 FinWorld An All-in-One Open-Source Platform for End-to-End Financial AI Research and Deployment",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2508.02292v2_FinWorld_An_All-in-One_Open-Source_Platform_for_End-to-End_Financial_AI_Research_and_Deployment.pdf",
    "url": "http://arxiv.org/abs/2508.02292v2_FinWorld_An_All-in-One_Open-Source_Platform_for_End-to-End_Financial_AI_Research_and_Deployment",
    "pdf_url": "https://arxiv.org/pdf/2508.02292v2_FinWorld_An_All-in-One_Open-Source_Platform_for_End-to-End_Financial_AI_Research_and_Deployment",
    "file_size_mb": 6.4,
    "abstract": "Financial AI holds great promise for transforming modern finance, with the potential to support a wide range of tasks such as market forecasting, portfolio management, quantitative trading, and au- tomated analysis. However, existing platforms remain limited in task coverage, lack robust multimodal data integration, and offer insufficient support for the training and deployment of large lan- guage models (LLMs). In response to these limitations, we present FinWorld, an all-in-one open-source platform that provides end- to-end support for the entire financial AI workflow, from data acquisition to experimentation and deployment. FinWorld distin- guishes itself through native integration of heterogeneous finan- cial data, unified support for diverse AI paradigms, and advanced agent automation, enabling seamless development and deployment. Leveraging data from 2 representative markets, 4 stock pools, and over 800 million financial data points, we conduct comprehensive experiments on 4 key financial AI tasks. These experiments system- atically evaluate deep learning and reinforcement learning algo- rithms, with particular emphasis on RL-based finetuning for LLMs and LLM Agents. The empirical results demonstrate that FinWorld significantly enhances reproducibility, supports transparent bench- marking, and streamlines deployment, thereby providing a strong foundation for future research and real-world applications. Code is available at Github 1.",
    "keywords": [
      "Financial AI",
      "LLMs",
      "LLMs Agent",
      "Reinforcement Learning",
      "Open-"
    ]
  },
  {
    "article_id": "2508.02356v1_Neural_Network-Based_Algorithmic_Trading_Systems_Multi-Timeframe_Analysis_and_High-Frequency_Executi",
    "title": "2508.02356v1 Neural Network-Based Algorithmic Trading Systems Multi-Timeframe Analysis and High-Frequency Executi",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2508.02356v1_Neural_Network-Based_Algorithmic_Trading_Systems_Multi-Timeframe_Analysis_and_High-Frequency_Executi.pdf",
    "url": "http://arxiv.org/abs/2508.02356v1_Neural_Network-Based_Algorithmic_Trading_Systems_Multi-Timeframe_Analysis_and_High-Frequency_Executi",
    "pdf_url": "https://arxiv.org/pdf/2508.02356v1_Neural_Network-Based_Algorithmic_Trading_Systems_Multi-Timeframe_Analysis_and_High-Frequency_Executi",
    "file_size_mb": 0.41,
    "abstract": "This paper explores neural network-based approaches for algorithmic trading in cryptocurrency markets. Our approach combines multi-timeframe trend analysis with high-frequency direction prediction networks, achieving positive risk-adjusted returns through statistical modeling and systematic market exploitation. The system integrates diverse data sources including market data, on-chain metrics, and orderbook dynamics, translating these into unified buy/sell pressure signals. We demonstrate how machine learning models can effectively capture cross-timeframe relationships, enabling sub-second trading decisions with statistical confi- dence. The implementation addresses real-world challenges including data pipeline reliability, network latency, and operational risk management. Our results show consistent performance across various market conditions, with profit factor exceeding traditional approaches while maintaining manageable drawdown profiles.",
    "keywords": [
      "Algorithmic Trading",
      "Neural Networks",
      "Cryptocurrency",
      "High-Frequency Trading",
      "Multi-"
    ]
  },
  {
    "article_id": "2508.02685v1_Benchmarking_Classical_and_Quantum_Models_for_DeFi_Yield_Prediction_on_Curve_Finance",
    "title": "2508.02685v1 Benchmarking Classical and Quantum Models for DeFi Yield Prediction on Curve Finance",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2508.02685v1_Benchmarking_Classical_and_Quantum_Models_for_DeFi_Yield_Prediction_on_Curve_Finance.pdf",
    "url": "http://arxiv.org/abs/2508.02685v1_Benchmarking_Classical_and_Quantum_Models_for_DeFi_Yield_Prediction_on_Curve_Finance",
    "pdf_url": "https://arxiv.org/pdf/2508.02685v1_Benchmarking_Classical_and_Quantum_Models_for_DeFi_Yield_Prediction_on_Curve_Finance",
    "file_size_mb": 0.43,
    "abstract": "—The rise of decentralized finance (DeFi) has cre- ated a growing demand for accurate yield and performance forecasting to guide liquidity allocation strategies. In this study, we benchmark six models—XGBoost, Random Forest, LSTM, Transformer, quantum neural networks (QNN), and quantum support vector machines with quantum feature maps (QSVM- QNN)—on one year of historical data from 28 Curve Finance pools. We evaluate model performance on test MAE, RMSE, and directional accuracy. Our results show that classical ensemble models, particularly XGBoost and Random Forest, consistently outperform both deep learning and quantum models. XGBoost achieves the highest directional accuracy (71.57%) with a test MAE of 1.80, while Random Forest attains the lowest test MAE of 1.77 and 71.36% accuracy. In contrast, quantum models under- perform with directional accuracy below 50% and higher errors, highlighting current limitations in applying quantum machine learning to real-world DeFi time series data. This work offers a reproducible benchmark and practical insights into model suitability for DeFi applications, emphasizing the robustness of classical methods over emerging quantum approaches in this domain.",
    "keywords": [
      "Time series forecasting",
      "Quantum machine"
    ]
  },
  {
    "article_id": "2508.02686v1_Adaptive_Market_Intelligence_A_Mixture_of_Experts_Framework_for_Volatility-Sensitive_Stock_Forecasti",
    "title": "2508.02686v1 Adaptive Market Intelligence A Mixture of Experts Framework for Volatility-Sensitive Stock Forecasti",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2508.02686v1_Adaptive_Market_Intelligence_A_Mixture_of_Experts_Framework_for_Volatility-Sensitive_Stock_Forecasti.pdf",
    "url": "http://arxiv.org/abs/2508.02686v1_Adaptive_Market_Intelligence_A_Mixture_of_Experts_Framework_for_Volatility-Sensitive_Stock_Forecasti",
    "pdf_url": "https://arxiv.org/pdf/2508.02686v1_Adaptive_Market_Intelligence_A_Mixture_of_Experts_Framework_for_Volatility-Sensitive_Stock_Forecasti",
    "file_size_mb": 0.49,
    "abstract": "This study develops and empirically validates a Mixture of Experts (MoE) framework for stock price prediction across heterogeneous volatility regimes using real market data. The proposed model combines a Recurrent Neural Network (RNN) optimized for high-volatility stocks with a linear regression model tailored to stable equities. A volatility-aware gating mechanism dynamically weights the contributions of each expert based on asset classification. Using a dataset of 30 publicly traded U.S. stocks spanning diverse sectors, the MoE approach consistently outperforms both standalone models. Specifically, it achieves up to 33% improvement in MSE for volatile assets and 28% for stable assets relative to their respective baselines. Stratified evaluation across volatility classes demonstrates the model’s ability to adapt complexity to underlying market dynamics. These results confirm that no single model suffices across market regimes and highlight the advantage of adaptive architectures in financial prediction. Future work should explore real-time gate learning, dynamic volatility segmentation, and applications to portfolio optimization. All data and code used in this study are available in this GitHub repository, to foster reproducibility and further research.",
    "keywords": [
      "Mixture of Experts",
      "Stock Forecasting",
      "Volatility Regimes",
      "Recurrent Neural Networks"
    ]
  },
  {
    "article_id": "2508.03910v1_Comparing_Normalization_Methods_for_Portfolio_Optimization_with_Reinforcement_Learning",
    "title": "2508.03910v1 Comparing Normalization Methods for Portfolio Optimization with Reinforcement Learning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2508.03910v1_Comparing_Normalization_Methods_for_Portfolio_Optimization_with_Reinforcement_Learning.pdf",
    "url": "http://arxiv.org/abs/2508.03910v1_Comparing_Normalization_Methods_for_Portfolio_Optimization_with_Reinforcement_Learning",
    "pdf_url": "https://arxiv.org/pdf/2508.03910v1_Comparing_Normalization_Methods_for_Portfolio_Optimization_with_Reinforcement_Learning",
    "file_size_mb": 0.38,
    "abstract": "—Recently, reinforcement learning has achieved re- markable results in various domains, including robotics, games, natural language processing, and finance. In the financial domain, this approach has been applied to tasks such as portfolio optimization, where an agent continuously adjusts the allocation of assets within a financial portfolio to maximize profit. Numerous studies have introduced new simulation environments, neural network architectures, and training algorithms for this purpose. Among these, a domain-specific policy gradient algorithm has gained significant attention in the research community for be- ing lightweight, fast, and for outperforming other approaches. However, recent studies have shown that this algorithm can yield inconsistent results and underperform, especially when the portfolio does not consist of cryptocurrencies. One possible explanation for this issue is that the commonly used state normalization method may cause the agent to lose critical information about the true value of the assets being traded. This paper explores this hypothesis by evaluating two of the most widely used normalization methods across three different markets (IBOVESPA, NYSE, and cryptocurrencies) and comparing them with the standard practice of normalizing data before training. The results indicate that, in this specific domain, the state normalization can indeed degrade the agent’s performance.",
    "keywords": [
      "portfolio optimization",
      "reinforcement learning"
    ]
  },
  {
    "article_id": "2508.05416v1_Echo_State_Networks_for_Bitcoin_Time_Series_Prediction",
    "title": "2508.05416v1 Echo State Networks for Bitcoin Time Series Prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2508.05416v1_Echo_State_Networks_for_Bitcoin_Time_Series_Prediction.pdf",
    "url": "http://arxiv.org/abs/2508.05416v1_Echo_State_Networks_for_Bitcoin_Time_Series_Prediction",
    "pdf_url": "https://arxiv.org/pdf/2508.05416v1_Echo_State_Networks_for_Bitcoin_Time_Series_Prediction",
    "file_size_mb": 2.12,
    "abstract": ". Forecasting stock and cryptocurrency prices is challenging due to high volatility and non-stationarity, influenced by factors like economic changes and market sentiment. Previous research shows that Echo State Networks (ESNs) can effectively model short-term stock mar- ket movements, capturing nonlinear patterns in dynamic data. To the best of our knowledge, this work is among the first to explore ESNs for cryptocurrency forecasting, especially during extreme volatility. We also conduct chaos analysis through the Lyapunov exponent in chaotic pe- riods and show that our approach outperforms existing machine learn- ing methods by a significant margin. Our findings are consistent with the Lyapunov exponent analysis, showing that ESNs are robust during chaotic periods and excel under high chaos compared to Boosting and Naïve methods.",
    "keywords": [
      "chaotic time series",
      "cryptocurrency forecasting",
      "echo state"
    ]
  },
  {
    "article_id": "2508.10173v1_Benchmark-Driven_Selection_of_AI_Evidence_from_DeepSeek-R1",
    "title": "2508.10173v1 Benchmark-Driven Selection of AI Evidence from DeepSeek-R1",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2508.10173v1_Benchmark-Driven_Selection_of_AI_Evidence_from_DeepSeek-R1.pdf",
    "url": "http://arxiv.org/abs/2508.10173v1_Benchmark-Driven_Selection_of_AI_Evidence_from_DeepSeek-R1",
    "pdf_url": "https://arxiv.org/pdf/2508.10173v1_Benchmark-Driven_Selection_of_AI_Evidence_from_DeepSeek-R1",
    "file_size_mb": 0.63,
    "abstract": "Evaluation of reasoning language models gained importance after it was observed that they can combine their existing capabilities into novel traces of intermediate steps before task completion and that the traces can sometimes help them to generalize better than past models. As reasoning becomes the next scaling dimension of large language models, careful study of their capabilities in critical tasks is needed. We show that better performance is not always caused by test-time algorithmic improvements or model sizes but also by using impactful benchmarks as curricula for learning. We call this benchmark-driven selection of AI and show its effects on DeepSeek-R1 using our sequential decision-making problem from Humanity’s Last Exam. Steering development of AI by impactful benchmarks trades evaluation for learning and makes novelty of test tasks key for measuring generalization capabilities of reasoning models. Consequently, some benchmarks could be seen as curricula for training rather than unseen test sets.",
    "keywords": []
  },
  {
    "article_id": "2508.11372v1_Stealing_Accuracy_Predicting_Day-ahead_Electricity_Prices_with_Temporal_Hierarchy_Forecasting_THieF",
    "title": "2508.11372v1 Stealing Accuracy Predicting Day-ahead Electricity Prices with Temporal Hierarchy Forecasting THieF",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2508.11372v1_Stealing_Accuracy_Predicting_Day-ahead_Electricity_Prices_with_Temporal_Hierarchy_Forecasting_THieF.pdf",
    "url": "http://arxiv.org/abs/2508.11372v1_Stealing_Accuracy_Predicting_Day-ahead_Electricity_Prices_with_Temporal_Hierarchy_Forecasting_THieF",
    "pdf_url": "https://arxiv.org/pdf/2508.11372v1_Stealing_Accuracy_Predicting_Day-ahead_Electricity_Prices_with_Temporal_Hierarchy_Forecasting_THieF",
    "file_size_mb": 0.23,
    "abstract": "—We introduce the concept of temporal hierarchy forecasting (THieF) in predicting day-ahead electricity prices and show that reconciling forecasts for hourly products, 2- to 12- hour blocks, and baseload contracts significantly (up to 13%) improves accuracy at all levels. These results remain consistent throughout a challenging 4-year test period (2021-2024) in the German power market and across model architectures, including linear regression, a shallow neural network, gradient boosting, and a state-of-the-art transformer. Given that (i) trading of block products is becoming more common and (ii) the computational cost of reconciliation is comparable to that of predicting hourly prices alone, we recommend using it in daily forecasting practice.",
    "keywords": [
      "Electricity price",
      "temporal hierarchy forecasting"
    ]
  },
  {
    "article_id": "2508.11856v1_Optimal_Portfolio_Construction_--_A_Reinforcement_Learning_Embedded_Bayesian_Hierarchical_Risk_Parit",
    "title": "2508.11856v1 Optimal Portfolio Construction -- A Reinforcement Learning Embedded Bayesian Hierarchical Risk Parit",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2508.11856v1_Optimal_Portfolio_Construction_--_A_Reinforcement_Learning_Embedded_Bayesian_Hierarchical_Risk_Parit.pdf",
    "url": "http://arxiv.org/abs/2508.11856v1_Optimal_Portfolio_Construction_--_A_Reinforcement_Learning_Embedded_Bayesian_Hierarchical_Risk_Parit",
    "pdf_url": "https://arxiv.org/pdf/2508.11856v1_Optimal_Portfolio_Construction_--_A_Reinforcement_Learning_Embedded_Bayesian_Hierarchical_Risk_Parit",
    "file_size_mb": 1.1,
    "abstract": "We propose a two-level, learning-based portfolio method (RL-BHRP) that spreads risk across sectors and stocks, and adjusts exposures as market conditions change. Using U.S. equities from 2012 to mid-2025, we design the model using 2012–2019 data and evaluate it out-of-sample from 2020 to 2025 against a sector index built from exchange-traded funds and a static risk-balanced portfolio. Over the test window, the adaptive portfolio com- pounds wealth by approximately 120%, compared with 101% for the static comparator and 91% for the sector benchmark. The average annual growth is roughly 15%, compared to 13% and 12%, respectively. Gains are achieved without significant deviations from the benchmark and with peak-to-trough losses comparable to those of the alternatives, in- dicating that the method adds value while remaining diversified and investable. Weight charts show gradual shifts rather than abrupt swings, reflecting disciplined rebalancing and the cost-aware design. Overall, the results support risk-balanced, adaptive allocation as a practical approach to achieving stronger and more stable long-term performance.",
    "keywords": [
      "Reinforcement Learning",
      "Bayesian Hierarchical Risk Parity"
    ]
  },
  {
    "article_id": "2508.12565v2_Deep_Learning-Based_Financial_Time_Series_Forecasting_via_Sliding_Window_and_Variational_Mode_Decomp",
    "title": "2508.12565v2 Deep Learning-Based Financial Time Series Forecasting via Sliding Window and Variational Mode Decomp",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2508.12565v2_Deep_Learning-Based_Financial_Time_Series_Forecasting_via_Sliding_Window_and_Variational_Mode_Decomp.pdf",
    "url": "http://arxiv.org/abs/2508.12565v2_Deep_Learning-Based_Financial_Time_Series_Forecasting_via_Sliding_Window_and_Variational_Mode_Decomp",
    "pdf_url": "https://arxiv.org/pdf/2508.12565v2_Deep_Learning-Based_Financial_Time_Series_Forecasting_via_Sliding_Window_and_Variational_Mode_Decomp",
    "file_size_mb": 2.7,
    "abstract": "To address the complexity of financial time series, this paper proposes a forecasting model combining sliding window and variational mode decomposition (VMD) methods. Historical stock prices and relevant market indicators are used to construct datasets. VMD decomposes non-stationary financial time series into smoother subcom- ponents, improving model adaptability. The decomposed data is then input into a deep learning model for prediction. The study compares the forecasting effects of an LSTM model trained on VMD-processed sequences with those using raw time series, demonstrat- ing better performance and stability.",
    "keywords": [
      "Sliding window",
      "Variational mode decomposition",
      "Long short-term memory"
    ]
  },
  {
    "article_id": "2508.13213v1_AI_sustains_higher_strategic_tension_than_humans_in_chess",
    "title": "2508.13213v1 AI sustains higher strategic tension than humans in chess",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2508.13213v1_AI_sustains_higher_strategic_tension_than_humans_in_chess.pdf",
    "url": "http://arxiv.org/abs/2508.13213v1_AI_sustains_higher_strategic_tension_than_humans_in_chess",
    "pdf_url": "https://arxiv.org/pdf/2508.13213v1_AI_sustains_higher_strategic_tension_than_humans_in_chess",
    "file_size_mb": 2.34,
    "abstract": null,
    "keywords": [
      "Chess — Artificial Intelligence — Complex Networks — Strategic Tension — Cognitive Science"
    ]
  },
  {
    "article_id": "2508.18526v2_Quantifying_The_Limits_of_AI_Reasoning_Systematic_Neural_Network_Representations_of_Algorithms",
    "title": "2508.18526v2 Quantifying The Limits of AI Reasoning Systematic Neural Network Representations of Algorithms",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2508.18526v2_Quantifying_The_Limits_of_AI_Reasoning_Systematic_Neural_Network_Representations_of_Algorithms.pdf",
    "url": "http://arxiv.org/abs/2508.18526v2_Quantifying_The_Limits_of_AI_Reasoning_Systematic_Neural_Network_Representations_of_Algorithms",
    "pdf_url": "https://arxiv.org/pdf/2508.18526v2_Quantifying_The_Limits_of_AI_Reasoning_Systematic_Neural_Network_Representations_of_Algorithms",
    "file_size_mb": 3.56,
    "abstract": "A main open question in contemporary AI research is quantifying the forms of reasoning neural networks can perform when perfectly trained. This paper answers this by interpreting reasoning tasks as circuit emulation, where the gates define the type of reasoning; e.g. Boolean gates for pred- icate logic, tropical circuits for dynamic programming, arithmetic and analytic gates for symbolic mathematical representation, and hybrids thereof for deeper reasoning; e.g. higher-order logic. We present a systematic meta-algorithm that converts essentially any circuit into a feedforward neural network (NN) with ReLU activations by iteratively replacing each gate with a canonical ReLU MLP emulator. We show that, on any digital computer, our construction emulates the cir- cuit exactly—no approximation, no rounding, modular overflow included—demonstrating that no reasoning task lies beyond the reach of neural networks. The number of neurons in the resulting network (parametric complexity) scales with the circuit’s complexity, and the network’s computa- tional graph (structure) mirrors that of the emulated circuit. This formalizes the folklore that NNs networks trade algorithmic run-time (circuit runtime) for space complexity (number of neurons). We derive a range of applications of our main result, from emulating shortest-path algorithms on graphs with cubic-size NNs, to simulating stopped Turing machines with roughly quadratically- large NNs, and even the emulation of randomized Boolean circuits. Lastly, we demonstrate that our result is strictly more powerful than a classical universal approximation theorem: any universal function approximator can be encoded as a circuit and directly emulated by a NN.",
    "keywords": [
      "AI Reasoning",
      "Neural networks",
      "Circuit Complexity",
      "Constructive Approximation"
    ]
  },
  {
    "article_id": "2508.20103v1_Deep_Reinforcement_Learning_for_Optimal_Asset_Allocation_Using_DDPG_with_TiDE",
    "title": "2508.20103v1 Deep Reinforcement Learning for Optimal Asset Allocation Using DDPG with TiDE",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2508.20103v1_Deep_Reinforcement_Learning_for_Optimal_Asset_Allocation_Using_DDPG_with_TiDE.pdf",
    "url": "http://arxiv.org/abs/2508.20103v1_Deep_Reinforcement_Learning_for_Optimal_Asset_Allocation_Using_DDPG_with_TiDE",
    "pdf_url": "https://arxiv.org/pdf/2508.20103v1_Deep_Reinforcement_Learning_for_Optimal_Asset_Allocation_Using_DDPG_with_TiDE",
    "file_size_mb": 3.45,
    "abstract": "The optimal asset allocation between risky and risk-free assets is a persistent challenge due to the inherent volatility in financial markets. Conventional methods rely on strict distributional assumptions or non-additive reward ratios, which limit their robustness and applicability to investment goals. To overcome these constraints, this study formulates the optimal two-asset allocation prob- lem as a sequential decision-making task within a Markov Decision Process (MDP). This framework enables the application of reinforcement learning (RL) mechanisms to develop dynamic policies based on simulated financial scenarios, regardless of prereq- uisites. We use the Kelly criterion to balance immediate reward signals against long-term investment objectives, and we take the novel step of integrating the Time-series Dense Encoder (TiDE) into the Deep Deterministic Policy Gradient (DDPG) RL frame- work for continuous decision-making. We compare DDPG-TiDE with a simple discrete-action Q-learning RL framework and a passive buy-and-hold investment strategy. Empirical results show that DDPG-TiDE outperforms Q-learning and generates higher risk adjusted returns than buy-and-hold. These findings suggest that tackling the optimal asset allocation problem by integrating TiDE within a DDPG reinforcement learning framework is a fruitful avenue for further exploration. © 2025 The Authors. Check in the contract: Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/) Peer-review under responsibility of the scientific committee of the 22nd International Multidisciplinary Modeling & Simulation Multiconference.",
    "keywords": [
      "Optimal Asset Allocation",
      "Kelly Strategy Simulation",
      "Reinforcement Learning",
      "Q-Learning",
      "DDPG",
      "TiDE",
      "Sharpe Ratio"
    ]
  },
  {
    "article_id": "2508.20108v2_Mitigating_Distribution_Shift_in_Stock_Price_Data_via_Return-Volatility_Normalization_for_Accurate_P",
    "title": "2508.20108v2 Mitigating Distribution Shift in Stock Price Data via Return-Volatility Normalization for Accurate P",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2508.20108v2_Mitigating_Distribution_Shift_in_Stock_Price_Data_via_Return-Volatility_Normalization_for_Accurate_P.pdf",
    "url": "http://arxiv.org/abs/2508.20108v2_Mitigating_Distribution_Shift_in_Stock_Price_Data_via_Return-Volatility_Normalization_for_Accurate_P",
    "pdf_url": "https://arxiv.org/pdf/2508.20108v2_Mitigating_Distribution_Shift_in_Stock_Price_Data_via_Return-Volatility_Normalization_for_Accurate_P",
    "file_size_mb": 2.85,
    "abstract": "How can we address distribution shifts in stock price data to im- prove stock price prediction accuracy? Stock price prediction has attracted attention from both academia and industry, driven by its potential to uncover complex market patterns and enhance decision- making. However, existing methods often fail to handle distribution shifts effectively, focusing on scaling or representation adaptation without fully addressing distributional discrepancies and shape misalignments between training and test data. We propose ReVol (Return-Volatility Normalization for Mitigat- ing Distribution Shift in Stock Price Data), a robust method for stock price prediction that explicitly addresses the distribution shift problem. ReVol leverages three key strategies to mitigate these shifts: (1) normalizing price features to remove sample-specific characteristics, including return, volatility, and price scale, (2) em- ploying an attention-based module to estimate these characteristics accurately, thereby reducing the influence of market anomalies, and (3) reintegrating the sample characteristics into the predictive process, restoring the traits lost during normalization. Additionally, ReVol combines geometric Brownian motion for long-term trend modeling with neural networks for short-term pattern recognition, unifying their complementary strengths. Extensive experiments on real-world datasets demonstrate that ReVol enhances the per- formance of the state-of-the-art backbone models in most cases, achieving an average improvement of more than 0.03 in IC and over 0.7 in SR across various settings.",
    "keywords": []
  },
  {
    "article_id": "2508.20467v1_QTMRL_An_Agent_for_Quantitative_Trading_Decision-Making_Based_on_Multi-Indicator_Guided_Reinforcemen",
    "title": "2508.20467v1 QTMRL An Agent for Quantitative Trading Decision-Making Based on Multi-Indicator Guided Reinforcemen",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2508.20467v1_QTMRL_An_Agent_for_Quantitative_Trading_Decision-Making_Based_on_Multi-Indicator_Guided_Reinforcemen.pdf",
    "url": "http://arxiv.org/abs/2508.20467v1_QTMRL_An_Agent_for_Quantitative_Trading_Decision-Making_Based_on_Multi-Indicator_Guided_Reinforcemen",
    "pdf_url": "https://arxiv.org/pdf/2508.20467v1_QTMRL_An_Agent_for_Quantitative_Trading_Decision-Making_Based_on_Multi-Indicator_Guided_Reinforcemen",
    "file_size_mb": 0.32,
    "abstract": "In the highly volatile and uncertain global financial markets, traditional quantitative trading mod- els relying on statistical modeling or empirical rules often fail to adapt to dynamic market changes and black swan events due to rigid assumptions and limited generalization. To address these issues, this paper proposes QTMRL (Quantitative Trading Multi-Indicator Reinforcement Learning), an intelligent trading agent that combines multi-dimensional technical indicators with reinforcement learning (RL) for adaptive and stable portfolio management. We first construct a comprehen- sive multi-indicator dataset using 23 years of S&P 500 daily OHLCV data (2000–2022) for 16 representative stocks across 5 sectors, enriching raw data with trend, volatility, and momentum indicators to capture holistic market dynamics. Then, we design a lightweight RL framework based on the Advantage Actor-Critic (A2C) algorithm, which includes data processing, A2C al- gorithm, and trading agent modules to support policy learning and actionable trading decisions. Extensive experiments compare QTMRL with 9 baselines (e.g., ARIMA, LSTM, moving aver- age strategies) across diverse market regimes, verifying its superiority in profitability, risk ad- justment, and downside risk control. The code of QTMRL is publicly available at https: //github.com/ChenJiahaoJNU/QTMRL.git.",
    "keywords": [
      "Quantitative Trading",
      "Reinforcement Learning",
      "Portfolio Management",
      "S&P 500"
    ]
  },
  {
    "article_id": "2509.00862v1_Speech_Command_Recognition_Using_LogNNet_Reservoir_Computing_for_Embedded_Systems",
    "title": "2509.00862v1 Speech Command Recognition Using LogNNet Reservoir Computing for Embedded Systems",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.00862v1_Speech_Command_Recognition_Using_LogNNet_Reservoir_Computing_for_Embedded_Systems.pdf",
    "url": "http://arxiv.org/abs/2509.00862v1_Speech_Command_Recognition_Using_LogNNet_Reservoir_Computing_for_Embedded_Systems",
    "pdf_url": "https://arxiv.org/pdf/2509.00862v1_Speech_Command_Recognition_Using_LogNNet_Reservoir_Computing_for_Embedded_Systems",
    "file_size_mb": 0.85,
    "abstract": ". This paper presents a low-resource speech-command recognizer com- bining energy-based voice activity detection (VAD), an optimized Mel-Fre- quency Cepstral Coefficients (MFCC) pipeline, and the LogNNet reservoir-com- puting classifier. Using four commands from the Speech Commands dataset downsampled to 8 kHz, we evaluate four MFCC aggregation schemes and find that adaptive binning (64-dimensional feature vector) offers the best accuracy- to-compactness trade-off. The LogNNet classifier with architecture 64:33:9:4 reaches 92.04% accuracy under speaker-independent evaluation, while requiring significantly fewer parameters than conventional deep learning models. Hard- ware implementation on Arduino Nano 33 IoT (ARM Cortex-M0+, 48 MHz, 32 KB RAM) validates the practical feasibility, achieving ~90% real-time recogni- tion accuracy while consuming only 18 KB RAM (55% utilization). The com- plete pipeline (VAD → MFCC → LogNNet) thus enables reliable on-device speech-command recognition under strict memory and compute limits, making it suitable for battery-powered IoT nodes, wireless sensor networks, and hands-free control interfaces.",
    "keywords": [
      "Speech commands",
      "MFCC",
      "LogNNet",
      "reservoir computing",
      "embed-"
    ]
  },
  {
    "article_id": "2509.00866v2_Can_General-Purpose_Omnimodels_Compete_with_Specialists_A_Case_Study_in_Medical_Image_Segmentation",
    "title": "2509.00866v2 Can General-Purpose Omnimodels Compete with Specialists A Case Study in Medical Image Segmentation",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.00866v2_Can_General-Purpose_Omnimodels_Compete_with_Specialists_A_Case_Study_in_Medical_Image_Segmentation.pdf",
    "url": "http://arxiv.org/abs/2509.00866v2_Can_General-Purpose_Omnimodels_Compete_with_Specialists_A_Case_Study_in_Medical_Image_Segmentation",
    "pdf_url": "https://arxiv.org/pdf/2509.00866v2_Can_General-Purpose_Omnimodels_Compete_with_Specialists_A_Case_Study_in_Medical_Image_Segmentation",
    "file_size_mb": 51.87,
    "abstract": "The emergence of powerful, general-purpose omnimodels capable of processing diverse data modalities has raised a critical question: can these “jack-of-all-trades” systems perform on par with highly specialized models in knowledge-intensive domains? This work investigates this question within the high-stakes field of medical image segmentation. We conduct a comparative study analyzing the zero-shot performance of a state-of-the-art omnimodel (Gemini, the “Nano Banana” model) against domain-specific deep learning models on three distinct tasks: polyp (endoscopy), retinal vessel (fundus), and breast tumor segmentation (ultrasound). Our study focuses on performance at the extremes by curating subsets of the “easiest” and “hardest” cases based on the specialist models’ accuracy. Our findings reveal a nuanced and task-dependent landscape. For polyp and breast tumor segmentation, specialist models excel on easy samples, but the omnimodel demonstrates greater robustness on hard samples where specialists fail catastrophically. Conversely, for the fine-grained task of retinal vessel segmentation, the specialist model maintains superior performance across both easy and hard cases. Intriguingly, qualitative analysis suggests omnimodels may possess higher sensitivity, identifying subtle anatomical features missed by human annotators. Our results indicate that while current omnimodels are not yet a universal replacement for specialists, their unique strengths suggest a potential complementary role with specialist models, particularly in enhancing robustness on challenging edge cases.",
    "keywords": []
  },
  {
    "article_id": "2509.01393v1_Adaptive_Alpha_Weighting_with_PPO_Enhancing_Prompt-Based_LLM-Generated_Alphas_in_Quant_Trading",
    "title": "2509.01393v1 Adaptive Alpha Weighting with PPO Enhancing Prompt-Based LLM-Generated Alphas in Quant Trading",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.01393v1_Adaptive_Alpha_Weighting_with_PPO_Enhancing_Prompt-Based_LLM-Generated_Alphas_in_Quant_Trading.pdf",
    "url": "http://arxiv.org/abs/2509.01393v1_Adaptive_Alpha_Weighting_with_PPO_Enhancing_Prompt-Based_LLM-Generated_Alphas_in_Quant_Trading",
    "pdf_url": "https://arxiv.org/pdf/2509.01393v1_Adaptive_Alpha_Weighting_with_PPO_Enhancing_Prompt-Based_LLM-Generated_Alphas_in_Quant_Trading",
    "file_size_mb": 1.42,
    "abstract": "This paper proposes a reinforcement learning framework that employs Proximal Policy Optimization (PPO) to dynamically optimize the weights of multiple large language model (LLM)-generated formulaic alphas for stock trading strategies. Formulaic alphas are mathematically defined trading signals derived from price, volume, sentiment, and other data. Although recent studies have shown that LLMs can generate diverse and effective alphas, a critical challenge lies in how to adaptively integrate them under varying market conditions. To address this gap, we leverage the deepseek-r1- distill-llama-70b model to generate fifty alphas for five major stocks: Apple, HSBC, Pepsi, Toyota, and Tencent, and then use PPO to adjust their weights in real time. Experimental results demonstrate that the PPO-optimized strategy achieves strong returns and high Sharpe ratios across most stocks, outperforming both an equal-weighted alpha portfolio and traditional benchmarks such as the Nikkei 225, S&P 500, and Hang Seng Index. The findings highlight the importance of reinforcement learning in the allocation of alpha weights and show the potential of combining LLM-generated signals with adaptive optimization for robust financial forecasting and trading.",
    "keywords": [
      "Formulaic Alpha Generation",
      "LLM",
      "Proximal Policy Optimization",
      "Stock Prediction",
      "Time Series"
    ]
  },
  {
    "article_id": "2509.02271v1_VariAntNet_Learning_Decentralized_Control_of_Multi-Agent_Systems",
    "title": "2509.02271v1 VariAntNet Learning Decentralized Control of Multi-Agent Systems",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.02271v1_VariAntNet_Learning_Decentralized_Control_of_Multi-Agent_Systems.pdf",
    "url": "http://arxiv.org/abs/2509.02271v1_VariAntNet_Learning_Decentralized_Control_of_Multi-Agent_Systems",
    "pdf_url": "https://arxiv.org/pdf/2509.02271v1_VariAntNet_Learning_Decentralized_Control_of_Multi-Agent_Systems",
    "file_size_mb": 0.95,
    "abstract": "A simple multi-agent system can be effectively utilized in disaster response applications, such as firefighting. Such a swarm is required to operate in complex environments with limited local sensing and no reliable inter-agent communication or centralized control. These simple robotic agents, also known as Ant Robots, are defined as anonymous agents that possess limited sensing capabilities, lack a shared coordinate system, and do not communicate explicitly with one another. A key challenge for simple swarms lies in maintaining cohesion and avoiding fragmentation despite limited-range sensing. Recent advances in machine learning offer effective solutions to some of the classical decentralized control challenges. We propose VariAntNet, a deep learning-based decentralized control model designed to facilitate agent swarming and collaborative task execution. VariAntNet includes a preprocessing stage that extracts geometric features from unordered, variable-sized local observations. It incorporates a neural network architecture trained with a novel, differentiable, multi-objective, mathematically justified loss function that promotes swarm cohesiveness by utilizing the properties of the visibility graph Laplacian matrix. VariAntNet is demonstrated on the fundamental multi-agent gathering task, where agents with bearing-only and limited-range sensing must gather at some location. VariAntNet significantly outperforms an existing analytical solution, achieving more than double the convergence rate while maintaining high swarm connectivity across varying swarm sizes. While the analytical solution guarantees cohesion, it is often too slow in practice and fails to meet the required convergence time. In time-critical scenarios, such as emergency response operations where lives are at risk, rapid convergence is crucial, making slower analytical methods impractical and justifying the loss of some agents within the swarm. This paper presents and analyzes this trade-off in detail.",
    "keywords": [
      "autonomous agents",
      "distributed control",
      "neural networks",
      "multi-agents"
    ]
  },
  {
    "article_id": "2509.02792v1_Structured_Basis_Function_Networks_Loss-Centric_Multi-Hypothesis_Ensembles_with_Controllable_Diversi",
    "title": "2509.02792v1 Structured Basis Function Networks Loss-Centric Multi-Hypothesis Ensembles with Controllable Diversi",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.02792v1_Structured_Basis_Function_Networks_Loss-Centric_Multi-Hypothesis_Ensembles_with_Controllable_Diversi.pdf",
    "url": "http://arxiv.org/abs/2509.02792v1_Structured_Basis_Function_Networks_Loss-Centric_Multi-Hypothesis_Ensembles_with_Controllable_Diversi",
    "pdf_url": "https://arxiv.org/pdf/2509.02792v1_Structured_Basis_Function_Networks_Loss-Centric_Multi-Hypothesis_Ensembles_with_Controllable_Diversi",
    "file_size_mb": 5.86,
    "abstract": "Existing approaches to predictive uncertainty rely either on multi-hypothesis prediction, which promotes diversity but lacks principled aggregation, or on ensemble learning, which improves accuracy but rarely captures the structured ambiguity. This implicitly means that a unified framework consistent with the loss geometry remains absent. The Structured Basis Function Network addresses this gap by linking multi-hypothesis prediction and ensembling through centroidal aggregation induced by Bregman divergences. The formulation applies across regression and classification by aligning predictions with the geometry of the loss, and supports both a closed-form least-squares estimator and a gradient-based procedure for general objectives. A tunable diversity mechanism provides parametric control of the bias–variance–diversity trade-off, connecting multi-hypothesis generalisation with loss-aware ensemble aggregation. Experiments validate this relation and use the mechanism to study the complexity–capacity–diversity trade-off across datasets of increasing difficulty with deep- learning predictors.",
    "keywords": [
      "Bregman divergences",
      "complexity–capacity–diversity trade-off",
      "deep ensembles"
    ]
  },
  {
    "article_id": "2509.04541v1_Finance-Grounded_Optimization_For_Algorithmic_Trading",
    "title": "2509.04541v1 Finance-Grounded Optimization For Algorithmic Trading",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.04541v1_Finance-Grounded_Optimization_For_Algorithmic_Trading.pdf",
    "url": "http://arxiv.org/abs/2509.04541v1_Finance-Grounded_Optimization_For_Algorithmic_Trading",
    "pdf_url": "https://arxiv.org/pdf/2509.04541v1_Finance-Grounded_Optimization_For_Algorithmic_Trading",
    "file_size_mb": 0.74,
    "abstract": "Deep Learning is evolving fast and integrates into various domains. Finance is a challeng- ing field for deep learning, especially in the case of interpretable artificial intelligence (AI). Although classical approaches perform very well with natural language processing, computer vision, and forecasting, they are not perfect for the financial world, in which specialists use different metrics to evaluate model performance. We first introduce financially grounded loss functions derived from key quantitative fi- nance metrics, including the Sharpe ratio, Profit-and-Loss (PnL), and Maximum Draw down. Additionally, we propose turnover regularization, a method that inherently constrains the turnover of generated positions within predefined limits. Our findings demonstrate that the proposed loss functions, in conjunction with turnover regularization, outperform the traditional mean squared error loss for return prediction tasks when evaluated using algorithmic trading metrics. The study shows that financially grounded metrics enhance predictive performance in trading strategies and portfolio opti- mization.",
    "keywords": []
  },
  {
    "article_id": "2509.05080v2_MM-DREX_Multimodal-Driven_Dynamic_Routing_of_LLM_Experts_for_Financial_Trading",
    "title": "2509.05080v2 MM-DREX Multimodal-Driven Dynamic Routing of LLM Experts for Financial Trading",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.05080v2_MM-DREX_Multimodal-Driven_Dynamic_Routing_of_LLM_Experts_for_Financial_Trading.pdf",
    "url": "http://arxiv.org/abs/2509.05080v2_MM-DREX_Multimodal-Driven_Dynamic_Routing_of_LLM_Experts_for_Financial_Trading",
    "pdf_url": "https://arxiv.org/pdf/2509.05080v2_MM-DREX_Multimodal-Driven_Dynamic_Routing_of_LLM_Experts_for_Financial_Trading",
    "file_size_mb": 4.13,
    "abstract": "The inherent non-stationarity of financial markets and the complexity of multi-modal information pose significant chal- lenges to existing quantitative trading models. Traditional methods relying on fixed structures and unimodal data strug- gle to adapt to market regime shifts, while large language model (LLM)-driven solutions—despite their multi-modal comprehension—suffer from static strategies and homoge- neous expert designs, lacking dynamic adjustment and fine- grained decision mechanisms. To address these limitations, we propose MM-DREX: a Multimodal-driven, Dynamically- Routed EXpert framework based on large language mod- els. MM-DREX explicitly decouples market state percep- tion from strategy execution to enable adaptive sequential decision-making in non-stationary environments. Specifi- cally, it: (1) Introduces a vision-language model (VLM)- powered dynamic router that jointly analyzes candlestick chart patterns and long-term temporal features to allocate real-time expert weights; (2) Designs four heterogeneous trading experts (trend, reversal, breakout, positioning) gen- erating specialized fine-grained sub-strategies; and (3) Pro- poses an SFT-RL hybrid training paradigm to synergisti- cally optimize the router’s market classification capability and experts’ risk-adjusted decision-making. Extensive exper- iments on multi-modal datasets spanning stocks, futures, and cryptocurrencies demonstrate that MM-DREX significantly outperforms 15 baselines (including state-of-the-art financial LLMs and deep reinforcement learning models) across key metrics: total return, Sharpe ratio, and maximum drawdown, validating its robustness and generalization. Additionally, an interpretability module traces routing logic and expert behav- ior in real-time, providing an audit trail for strategy trans- parency.",
    "keywords": []
  },
  {
    "article_id": "2509.05273v1_Greener_Deep_Reinforcement_Learning_Analysis_of_Energy_and_Carbon_Efficiency_Across_Atari_Benchmarks",
    "title": "2509.05273v1 Greener Deep Reinforcement Learning Analysis of Energy and Carbon Efficiency Across Atari Benchmarks",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.05273v1_Greener_Deep_Reinforcement_Learning_Analysis_of_Energy_and_Carbon_Efficiency_Across_Atari_Benchmarks.pdf",
    "url": "http://arxiv.org/abs/2509.05273v1_Greener_Deep_Reinforcement_Learning_Analysis_of_Energy_and_Carbon_Efficiency_Across_Atari_Benchmarks",
    "pdf_url": "https://arxiv.org/pdf/2509.05273v1_Greener_Deep_Reinforcement_Learning_Analysis_of_Energy_and_Carbon_Efficiency_Across_Atari_Benchmarks",
    "file_size_mb": 1.05,
    "abstract": "—The growing computational demands of deep re- inforcement learning (DRL) have raised concerns about the environmental and economic costs of training large-scale models. While algorithmic efficiency in terms of learning performance has been extensively studied, the energy requirements, greenhouse gas emissions, and monetary costs of DRL algorithms remain largely unexplored. In this work, we present a systematic benchmarking study of the energy consumption of seven state-of-the-art DRL al- gorithms, namely DQN, TRPO, A2C, ARS, PPO, RecurrentPPO, and QR-DQN, implemented using Stable Baselines. Each al- gorithm was trained for one million steps each on ten Atari 2600 games, and power consumption was measured in real-time to estimate total energy usage, CO2-Equivalent emissions, and electricity cost based on the U.S. national average electricity price. Our results reveal substantial variation in energy efficiency and training cost across algorithms, with some achieving comparable performance while consuming up to 24% less energy (ARS vs. DQN), emitting nearly 68% less CO2, and incurring almost 68% lower monetary cost (QR-DQN vs. RecurrentPPO) than less efficient counterparts. We further analyze the trade-offs between learning performance, training time, energy use, and financial cost, highlighting cases where algorithmic choices can mitigate environmental and economic impact without sacrificing learning performance. This study provides actionable insights for developing energy-aware and cost-efficient DRL practices and establishes a foundation for incorporating sustainability considerations into future algorithmic design and evaluation.",
    "keywords": [
      "Deep Reinforcement Learning",
      "Energy Effi-"
    ]
  },
  {
    "article_id": "2509.05911v1_Deep_Learning_Option_Pricing_with_Market_Implied_Volatility_Surfaces",
    "title": "2509.05911v1 Deep Learning Option Pricing with Market Implied Volatility Surfaces",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.05911v1_Deep_Learning_Option_Pricing_with_Market_Implied_Volatility_Surfaces.pdf",
    "url": "http://arxiv.org/abs/2509.05911v1_Deep_Learning_Option_Pricing_with_Market_Implied_Volatility_Surfaces",
    "pdf_url": "https://arxiv.org/pdf/2509.05911v1_Deep_Learning_Option_Pricing_with_Market_Implied_Volatility_Surfaces",
    "file_size_mb": 2.39,
    "abstract": null,
    "keywords": []
  },
  {
    "article_id": "2509.06264v1_PLRV-O_Advancing_Differentially_Private_Deep_Learning_via_Privacy_Loss_Random_Variable_Optimization",
    "title": "2509.06264v1 PLRV-O Advancing Differentially Private Deep Learning via Privacy Loss Random Variable Optimization",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.06264v1_PLRV-O_Advancing_Differentially_Private_Deep_Learning_via_Privacy_Loss_Random_Variable_Optimization.pdf",
    "url": "http://arxiv.org/abs/2509.06264v1_PLRV-O_Advancing_Differentially_Private_Deep_Learning_via_Privacy_Loss_Random_Variable_Optimization",
    "pdf_url": "https://arxiv.org/pdf/2509.06264v1_PLRV-O_Advancing_Differentially_Private_Deep_Learning_via_Privacy_Loss_Random_Variable_Optimization",
    "file_size_mb": 2.54,
    "abstract": "Differentially Private Stochastic Gradient Descent (DP-SGD) is a standard method for enforcing privacy in deep learning, typically using the Gaussian mechanism to perturb gradient updates. How- ever, conventional mechanisms such as Gaussian and Laplacian noise are parameterized only by variance or scale. This single de- gree of freedom ties the magnitude of noise directly to both privacy loss and utility degradation, preventing independent control of these two factors. The problem becomes more pronounced when the number of composition rounds 𝑇and batch size 𝐵vary across tasks, as these variations induce task-dependent shifts in the pri- vacy–utility trade-off, where small changes in noise parameters can disproportionately affect model accuracy. To address this limitation, we introduce PLRV-O, a framework that defines a broad search space of parameterized DP-SGD noise distributions, where privacy loss moments are tightly characterized yet can be optimized more independently with respect to utility loss. This formulation enables systematic adaptation of noise to task-specific requirements, in- cluding (i) model size, (ii) training duration, (iii) batch sampling strategies, and (iv) clipping thresholds under both training and fine-tuning settings. Empirical results demonstrate that PLRV-O substantially improves utility under strict privacy constraints. On CIFAR-10, a fine-tuned ViT achieves 94.03% accuracy at 𝜖≈0.5, compared to 83.93% with Gaussian noise. On SST-2, RoBERTa-large reaches 92.20% accuracy at 𝜖≈0.2, versus 50.25% with Gaussian.1 CCS Concepts • Security and privacy; • Computing methodologies →Ma- chine learning; ∗Both authors contributed equally to this work. 1Source code is available at https://github.com/datasec-lab/plrvo. This is the full ver- sion of the paper to appear in CCS’25. This work is licensed under a Creative Commons Attribution 4.0 International License. CCS ’25, Taipei, Taiwan © 2025 Copyright held by the owner/author(s). ACM ISBN 979-8-4007-1525-9/2025/10 https://doi.org/10.1145/3719027.3765151",
    "keywords": [
      "Differential Privacy",
      "Deep Learning",
      "Mechanism Design",
      "Random-"
    ]
  },
  {
    "article_id": "2509.06697v1_Neural_ARFIMA_model_for_forecasting_BRIC_exchange_rates_with_long_memory_under_oil_shocks_and_policy",
    "title": "2509.06697v1 Neural ARFIMA model for forecasting BRIC exchange rates with long memory under oil shocks and policy",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.06697v1_Neural_ARFIMA_model_for_forecasting_BRIC_exchange_rates_with_long_memory_under_oil_shocks_and_policy.pdf",
    "url": "http://arxiv.org/abs/2509.06697v1_Neural_ARFIMA_model_for_forecasting_BRIC_exchange_rates_with_long_memory_under_oil_shocks_and_policy",
    "pdf_url": "https://arxiv.org/pdf/2509.06697v1_Neural_ARFIMA_model_for_forecasting_BRIC_exchange_rates_with_long_memory_under_oil_shocks_and_policy",
    "file_size_mb": 1.04,
    "abstract": "Accurate forecasting of exchange rates remains a persistent challenge, particularly for emerging economies such as Brazil, Russia, India, and China (BRIC). These series exhibit long memory, nonlinearity, and non-stationarity properties that conventional time series models struggle to capture. Additionally, there exist several key drivers of exchange rate dynamics, including global economic policy uncertainty, US equity market volatility, US monetary policy uncertainty, oil price growth rates, and country-specific short-term interest rate differentials. These empirical complexities underscore the need for a flexible modeling framework that can jointly accommodate long memory, nonlinearity, and the influence of external drivers. To address these challenges, we propose a Neural AutoRegressive Fractionally Integrated Moving Average (NARFIMA) model that combines the long-memory representation of ARFIMA with the nonlinear learning capacity of neural networks, while flexibly incorporating exogenous causal variables. We establish theoretical properties of the model, including asymptotic stationarity of the NARFIMA process using Markov chains and nonlinear time series techniques. We quantify forecast uncertainty using conformal prediction intervals within the NARFIMA framework. Empirical results across six forecast horizons show that NARFIMA consistently outperforms various state-of-the-art statistical and machine learning models in forecasting BRIC exchange rates. These findings provide new insights for policymakers and market participants navigating volatile financial conditions. The narfima R package provides an implementation of our approach. Key words: Forecasting; Long memory processes; Neural networks; Asymptotic stationarity; Conformal prediction",
    "keywords": [
      "Forecasting",
      "Long memory processes",
      "Neural networks",
      "Asymptotic stationarity",
      "Conformal prediction"
    ]
  },
  {
    "article_id": "2509.07103v2_Lookup_multivariate_Kolmogorov-Arnold_Networks",
    "title": "2509.07103v2 Lookup multivariate Kolmogorov-Arnold Networks",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.07103v2_Lookup_multivariate_Kolmogorov-Arnold_Networks.pdf",
    "url": "http://arxiv.org/abs/2509.07103v2_Lookup_multivariate_Kolmogorov-Arnold_Networks",
    "pdf_url": "https://arxiv.org/pdf/2509.07103v2_Lookup_multivariate_Kolmogorov-Arnold_Networks",
    "file_size_mb": 2.74,
    "abstract": "High-dimensional linear mappings, or linear layers, dominate both the param- eter count and the computational cost of most modern deep-learning models. We introduce a general-purpose drop-in replacement, lookup multivariate Kolmogorov-Arnold Networks (lmKANs), which deliver a substantially bet- ter trade-off between capacity and inference cost. Our construction expresses a general high-dimensional mapping through trainable low-dimensional mul- tivariate functions. These functions can carry dozens or hundreds of trainable parameters each, and yet it takes only a few multiplications to compute them because they are implemented as spline lookup tables. Empirically, lmKANs reduce inference FLOPs by up to 6.0× while matching the flexibility of MLPs in general high-dimensional function approximation. In another feed- forward fully connected benchmark, on the tabular-like dataset of randomly displaced methane configurations, lmKANs enable more than 10× higher H100 throughput at equal accuracy. Within frameworks of Convolutional Neural Networks, lmKAN-based CNNs cut inference FLOPs at matched accuracy by 1.6–2.1× and by 1.7× on the CIFAR-10 and ImageNet-1k datasets, respectively. Our code, including dedicated CUDA kernels, is available online at https://github.com/schwallergroup/lmkan. 104 105 106 Inference FLOPs 5 × 10 1 6 × 10 1 Mean Squared Error 6.0× General function approximation MLP lmKAN 10 9 10 8 10 7 H100 seconds/molecule (large batch size) 10 1 3 × 10 2 3 × 10 1 Test RMSE/STD 12.9× Methane MLP lmKAN 105 106 3 × 105 Inference FLOPs 50 55 60 65 70 75 80 Test Accuracy (%) 2.1× CIFAR-10 MLP CNN lmKAN CNN 106 107 3 × 106 Inference FLOPs 40 45 50 55 60 Validation Top-5 Accuracy (%) 1.7× 1.7× ImageNet MLP CNN lmKAN CNN Figure 1: Performance summary. See Sec. 4 for details. arXiv:2509.07103v2 [cs.LG] 17 Oct 2025",
    "keywords": []
  },
  {
    "article_id": "2509.09176v2_Quantum-Enhanced_Forecasting_for_Deep_Reinforcement_Learning_in_Algorithmic_Trading",
    "title": "2509.09176v2 Quantum-Enhanced Forecasting for Deep Reinforcement Learning in Algorithmic Trading",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.09176v2_Quantum-Enhanced_Forecasting_for_Deep_Reinforcement_Learning_in_Algorithmic_Trading.pdf",
    "url": "http://arxiv.org/abs/2509.09176v2_Quantum-Enhanced_Forecasting_for_Deep_Reinforcement_Learning_in_Algorithmic_Trading",
    "pdf_url": "https://arxiv.org/pdf/2509.09176v2_Quantum-Enhanced_Forecasting_for_Deep_Reinforcement_Learning_in_Algorithmic_Trading",
    "file_size_mb": 0.4,
    "abstract": "—The convergence of quantum-inspired neu- ral networks and deep reinforcement learning offers a promising avenue for financial trading. We implemented a trading agent for USD/TWD by integrating Quantum Long Short-Term Memory (QLSTM) for short-term trend prediction with Quantum Asynchronous Advantage Actor- Critic (QA3C), a quantum-enhanced variant of the classical A3C. Trained on data from 2000-01-01 to 2025-04-30 (80% training, 20% testing), the long-only agent achieves 11.87% return over around 5 years with 0.92% max drawdown, outperforming several currency ETFs. We detail state de- sign (QLSTM features and indicators), reward function for trend-following/risk control, and multi-core training. Re- sults show hybrid models yield competitive FX trading per- formance. Implications include QLSTM’s effectiveness for small-profit trades with tight risk and future enhancements. Key hyperparameters: QLSTM sequence length=4, QA3C workers=8. Limitations: classical quantum simulation and simplified strategy. 1",
    "keywords": [
      "Quantum Machine Learning",
      "Quantitative"
    ]
  },
  {
    "article_id": "2509.09585v2_Causal_PDE-Control_for_Adaptive_Portfolio_Optimization_under_Partial_Information",
    "title": "2509.09585v2 Causal PDE-Control for Adaptive Portfolio Optimization under Partial Information",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.09585v2_Causal_PDE-Control_for_Adaptive_Portfolio_Optimization_under_Partial_Information.pdf",
    "url": "http://arxiv.org/abs/2509.09585v2_Causal_PDE-Control_for_Adaptive_Portfolio_Optimization_under_Partial_Information",
    "pdf_url": "https://arxiv.org/pdf/2509.09585v2_Causal_PDE-Control_for_Adaptive_Portfolio_Optimization_under_Partial_Information",
    "file_size_mb": 1.49,
    "abstract": null,
    "keywords": []
  },
  {
    "article_id": "2509.10025v1_Exploring_Expert_Specialization_through_Unsupervised_Training_in_Sparse_Mixture_of_Experts",
    "title": "2509.10025v1 Exploring Expert Specialization through Unsupervised Training in Sparse Mixture of Experts",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.10025v1_Exploring_Expert_Specialization_through_Unsupervised_Training_in_Sparse_Mixture_of_Experts.pdf",
    "url": "http://arxiv.org/abs/2509.10025v1_Exploring_Expert_Specialization_through_Unsupervised_Training_in_Sparse_Mixture_of_Experts",
    "pdf_url": "https://arxiv.org/pdf/2509.10025v1_Exploring_Expert_Specialization_through_Unsupervised_Training_in_Sparse_Mixture_of_Experts",
    "file_size_mb": 4.01,
    "abstract": "Understanding the internal organization of neural networks remains a fundamental challenge in deep learning interpretability. We address this challenge by exploring a novel Sparse Mixture of Experts Variational Autoencoder (SMoE-VAE) archi- tecture. We test our model on the QuickDraw dataset, comparing unsupervised expert routing against a supervised baseline guided by ground-truth labels. Sur- prisingly, we find that unsupervised routing consistently achieves superior recon- struction performance. The experts learn to identify meaningful sub-categorical structures that often transcend human-defined class boundaries. Through t-SNE visualizations and reconstruction analysis, we investigate how MoE models un- cover fundamental data structures that are more aligned with the model’s objective than predefined labels. Furthermore, our study on the impact of dataset size pro- vides insights into the trade-offs between data quantity and expert specialization, offering guidance for designing efficient MoE architectures.",
    "keywords": []
  },
  {
    "article_id": "2509.10348v1_Multi-pathology_Chest_X-ray_Classification_with_Rejection_Mechanisms",
    "title": "2509.10348v1 Multi-pathology Chest X-ray Classification with Rejection Mechanisms",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.10348v1_Multi-pathology_Chest_X-ray_Classification_with_Rejection_Mechanisms.pdf",
    "url": "http://arxiv.org/abs/2509.10348v1_Multi-pathology_Chest_X-ray_Classification_with_Rejection_Mechanisms",
    "pdf_url": "https://arxiv.org/pdf/2509.10348v1_Multi-pathology_Chest_X-ray_Classification_with_Rejection_Mechanisms",
    "file_size_mb": 0.66,
    "abstract": "Overconfidence in deep learning models poses a significant risk in high-stakes medical imaging tasks, particularly in multi-label classification of chest X-rays, where multiple co-occurring pathologies must be detected simultaneously. This study introduces an uncertainty-aware framework for chest X-ray diagnosis based on a DenseNet-121 backbone, enhanced with two selective prediction mechanisms: entropy-based rejection and confidence interval-based rejection. Both methods enable the model to abstain from uncertain predictions, improving reliability by deferring ambiguous cases to clinical experts. A quantile-based calibration procedure is employed to tune rejection thresholds using either global or class-specific strategies. Experiments conducted on three large public datasets (PadChest, NIH ChestX-ray14, and MIMIC-CXR) demonstrate that selective rejection improves the trade-off between diagnostic accuracy and coverage, with entropy-based rejection yielding the highest average AUC across all pathologies. These results support the integration of selective prediction into AI- assisted diagnostic workflows, providing a practical step toward safer, uncertainty-aware deployment of deep learning in clinical settings.",
    "keywords": [
      "Chest X-ray classification",
      "Rejection mechanism",
      "Multi-label diagnosis",
      "Selective prediction"
    ]
  },
  {
    "article_id": "2509.10531v1_FinXplore_An_Adaptive_Deep_Reinforcement_Learning_Framework_for_Balancing_and_Discovering_Investment",
    "title": "2509.10531v1 FinXplore An Adaptive Deep Reinforcement Learning Framework for Balancing and Discovering Investment",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.10531v1_FinXplore_An_Adaptive_Deep_Reinforcement_Learning_Framework_for_Balancing_and_Discovering_Investment.pdf",
    "url": "http://arxiv.org/abs/2509.10531v1_FinXplore_An_Adaptive_Deep_Reinforcement_Learning_Framework_for_Balancing_and_Discovering_Investment",
    "pdf_url": "https://arxiv.org/pdf/2509.10531v1_FinXplore_An_Adaptive_Deep_Reinforcement_Learning_Framework_for_Balancing_and_Discovering_Investment",
    "file_size_mb": 3.45,
    "abstract": "—Portfolio optimization is essential for balancing risk and return in financial decision-making. Deep Reinforcement Learning (DRL) has stood out as a cutting-edge tool for portfolio optimization that learns dynamic asset allocation using trial- and-error interactions. However, most DRL-based methods are restricted to allocating assets within a pre-defined investment universe and overlook exploring new opportunities. This study introduces an investment landscape that integrates exploiting existing assets with exploring new investment opportunities in an extended universe. The proposed approach leverages two DRL agents and dynamically balances these objectives to adapt to evolving markets while enhancing portfolio performance. One agent allocates assets within the existing universe, while another assists in exploring new opportunities in the extended universe. The efficiency of the proposed methodology is determined using two real-world market data sets. The experiments demonstrate the superiority of the suggested approach against the state-of- the-art portfolio strategies and baseline methods.",
    "keywords": [
      "Portfolio Optimization",
      "Deep Reinforcement"
    ]
  },
  {
    "article_id": "2509.10537v1_On_Using_Large-Batches_in_Federated_Learning",
    "title": "2509.10537v1 On Using Large-Batches in Federated Learning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.10537v1_On_Using_Large-Batches_in_Federated_Learning.pdf",
    "url": "http://arxiv.org/abs/2509.10537v1_On_Using_Large-Batches_in_Federated_Learning",
    "pdf_url": "https://arxiv.org/pdf/2509.10537v1_On_Using_Large-Batches_in_Federated_Learning",
    "file_size_mb": 0.66,
    "abstract": "—Efficient Federated learning (FL) is crucial for train- ing deep networks over devices with limited compute resources and bounded networks. With the advent of big data, devices either generate or collect multimodal data to train either generic or local-context aware networks, particularly when data privacy and locality is vital. FL algorithms generally trade-off between parallel and statistical performance, improving model quality at the cost of higher communication frequency, or vice versa. Under frequent synchronization settings, FL over a large cluster of de- vices may perform more work per-training iteration by process- ing a larger global batch-size, thus attaining considerable training speedup. However, this may result in poor test performance (i.e., low test loss or accuracy) due to generalization degradation issues associated with large-batch training. To address these challenges with large-batches, this work proposes our vision of exploiting the trade-offs between small and large-batch training, and explore new directions to enjoy both the parallel scaling of large-batches and good generalizability of small-batch training. For the same number of iterations, we observe that our proposed large-batch training technique attains about 32.33% and 3.74% higher test accuracy than small-batch training in ResNet50 and VGG11 models respectively.",
    "keywords": [
      "Federated learning",
      "Large batch training",
      "Dis-"
    ]
  },
  {
    "article_id": "2509.11525v1_DARD_Dice_Adversarial_Robustness_Distillation_against_Adversarial_Attacks",
    "title": "2509.11525v1 DARD Dice Adversarial Robustness Distillation against Adversarial Attacks",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.11525v1_DARD_Dice_Adversarial_Robustness_Distillation_against_Adversarial_Attacks.pdf",
    "url": "http://arxiv.org/abs/2509.11525v1_DARD_Dice_Adversarial_Robustness_Distillation_against_Adversarial_Attacks",
    "pdf_url": "https://arxiv.org/pdf/2509.11525v1_DARD_Dice_Adversarial_Robustness_Distillation_against_Adversarial_Attacks",
    "file_size_mb": 1.75,
    "abstract": ". Deep learning models are vulnerable to adversarial exam- ples, posing critical security challenges in real-world applications. While Adversarial Training (AT) is a widely adopted defense mechanism to enhance robustness, it often incurs a trade-off by degrading performance on unperturbed, natural data. Recent efforts have highlighted that larger models exhibit enhanced robustness over their smaller counterparts. In this paper, we empirically demonstrate that such robustness can be sys- tematically distilled from large teacher models into compact student models. To achieve better performance, we introduce Dice Adversarial Robustness Distillation (DARD), a novel method designed to transfer robustness through a tailored knowledge distillation paradigm. Addition- ally, we propose Dice Projected Gradient Descent (DPGD), an adversar- ial example generalization method optimized for effective attack. Our ex- tensive experiments demonstrate that the DARD approach consistently outperforms adversarially trained networks with the same architecture, achieving superior robustness and standard accuracy.",
    "keywords": [
      "Adversarial examples",
      "Adversarial attacks",
      "Robustness"
    ]
  },
  {
    "article_id": "2509.11601v1_Dynamic_Adaptive_Parsing_of_Temporal_and_Cross-Variable_Patterns_for_Network_State_Classification",
    "title": "2509.11601v1 Dynamic Adaptive Parsing of Temporal and Cross-Variable Patterns for Network State Classification",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.11601v1_Dynamic_Adaptive_Parsing_of_Temporal_and_Cross-Variable_Patterns_for_Network_State_Classification.pdf",
    "url": "http://arxiv.org/abs/2509.11601v1_Dynamic_Adaptive_Parsing_of_Temporal_and_Cross-Variable_Patterns_for_Network_State_Classification",
    "pdf_url": "https://arxiv.org/pdf/2509.11601v1_Dynamic_Adaptive_Parsing_of_Temporal_and_Cross-Variable_Patterns_for_Network_State_Classification",
    "file_size_mb": 0.54,
    "abstract": null,
    "keywords": [
      "Network Classiﬁcation"
    ]
  },
  {
    "article_id": "2509.12053v1_LEGO_Spatial_Accelerator_Generation_and_Optimization_for_Tensor_Applications",
    "title": "2509.12053v1 LEGO Spatial Accelerator Generation and Optimization for Tensor Applications",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.12053v1_LEGO_Spatial_Accelerator_Generation_and_Optimization_for_Tensor_Applications.pdf",
    "url": "http://arxiv.org/abs/2509.12053v1_LEGO_Spatial_Accelerator_Generation_and_Optimization_for_Tensor_Applications",
    "pdf_url": "https://arxiv.org/pdf/2509.12053v1_LEGO_Spatial_Accelerator_Generation_and_Optimization_for_Tensor_Applications",
    "file_size_mb": 2.35,
    "abstract": "—Modern tensor applications, especially foundation models and generative AI applications require multiple input modalities (both vision and language), which increases the de- mand for flexible accelerator architecture. Existing frameworks suffer from the trade-off between design flexibility and produc- tivity of RTL generation: either limited to very few hand-written templates or cannot automatically generate the RTL. To address this challenge, we propose the LEGO framework, which targets tensor applications and automatically generates spatial architecture design and outputs synthesizable RTL code without handwritten RTL design templates. Leveraging the affine-transformation-based architecture representation, LEGO front end finds interconnections between function units, synthe- sizes the memory system, and fuses different spatial dataflow designs based on data reuse analysis. LEGO back end then trans- lates the hardware in a primitive-level graph to perform lower- level optimizations, and applies a set of linear-programming algorithms to optimally insert pipeline registers and reduce the overhead of unused logic when switching spatial dataflows. Our evaluation demonstrates that LEGO can achieve 3.2 speedup and 2.4× energy efficiency compared to previous work Gemmini, and can generate one architecture for diverse modern foundation models in generative AI applications.",
    "keywords": []
  },
  {
    "article_id": "2509.12286v1_Prediction_of_Stocks_Index_Price_using_Quantum_GANs",
    "title": "2509.12286v1 Prediction of Stocks Index Price using Quantum GANs",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.12286v1_Prediction_of_Stocks_Index_Price_using_Quantum_GANs.pdf",
    "url": "http://arxiv.org/abs/2509.12286v1_Prediction_of_Stocks_Index_Price_using_Quantum_GANs",
    "pdf_url": "https://arxiv.org/pdf/2509.12286v1_Prediction_of_Stocks_Index_Price_using_Quantum_GANs",
    "file_size_mb": 1.21,
    "abstract": "—This paper investigates the application of Quan- tum Generative Adversarial Networks (QGANs) for stock price prediction. Financial markets are inherently complex, marked by high volatility and intricate patterns that traditional models often fail to capture. QGANs, leveraging the power of quantum computing, offer a novel approach by combining the strengths of generative models with quantum machine learning techniques. We implement a QGAN model tailored for stock price prediction and evaluate its performance using historical stock market data. Our results demonstrate that QGANs can generate synthetic data closely resembling actual market behavior, leading to enhanced prediction accuracy. The experiment was conducted using the Stocks index price data and the AWS Braket SV1 simulator for training the QGAN circuits. The quantum-enhanced model outperforms classical Long Short-Term Memory (LSTM) and GAN models in terms of convergence speed and prediction accuracy. This research represents a key step toward integrating quantum computing in financial forecasting, offering potential advantages in speed and precision over traditional methods. The findings suggest important implications for traders, financial analysts, and researchers seeking advanced tools for market analysis.",
    "keywords": [
      "Quantum GANs",
      "Stock price prediction",
      "GANs"
    ]
  },
  {
    "article_id": "2509.12753v1_DeltaHedge_A_Multi-Agent_Framework_for_Portfolio_Options_Optimization",
    "title": "2509.12753v1 DeltaHedge A Multi-Agent Framework for Portfolio Options Optimization",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.12753v1_DeltaHedge_A_Multi-Agent_Framework_for_Portfolio_Options_Optimization.pdf",
    "url": "http://arxiv.org/abs/2509.12753v1_DeltaHedge_A_Multi-Agent_Framework_for_Portfolio_Options_Optimization",
    "pdf_url": "https://arxiv.org/pdf/2509.12753v1_DeltaHedge_A_Multi-Agent_Framework_for_Portfolio_Options_Optimization",
    "file_size_mb": 1.28,
    "abstract": "In volatile financial markets, balancing risk and return remains a significant challenge. Traditional approaches often focus solely on equity allocation, overlooking the strategic advantages of options trading for dynamic risk hedging. This work presents DeltaHedge, a multi-agent framework that integrates options trading with AI-driven portfolio management. By combining advanced reinforcement learning techniques with an ensembled options-based hedging strategy, DeltaHedge enhances risk-adjusted returns and stabilizes portfolio performance across varying market conditions. Experimental results demonstrate that DeltaHedge outperforms traditional strategies and standalone models, underscoring its potential to transform practical portfolio management in complex financial environments. Building on these findings, this paper contributes to the fields of quantitative finance and AI-driven portfolio optimization by introducing a novel multi-agent system for integrating options trading strategies, addressing a gap in the existing literature.",
    "keywords": [
      "Artificial Intelligence",
      "Machine Learning",
      "Multi-Agent Systems",
      "Portfolio"
    ]
  },
  {
    "article_id": "2509.12764v1_Myopic_Optimality_why_reinforcement_learning_portfolio_management_strategies_lose_money",
    "title": "2509.12764v1 Myopic Optimality why reinforcement learning portfolio management strategies lose money",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.12764v1_Myopic_Optimality_why_reinforcement_learning_portfolio_management_strategies_lose_money.pdf",
    "url": "http://arxiv.org/abs/2509.12764v1_Myopic_Optimality_why_reinforcement_learning_portfolio_management_strategies_lose_money",
    "pdf_url": "https://arxiv.org/pdf/2509.12764v1_Myopic_Optimality_why_reinforcement_learning_portfolio_management_strategies_lose_money",
    "file_size_mb": 5.3,
    "abstract": "Myopic optimization (MO) outperforms reinforcement learning (RL) in portfolio management: RL yields lower or negative returns, higher vari­ ance, larger costs, heavier CVaR, lower profitability, and greater model risk. We model execution/liquidation frictions with mark-to-market ac­ counting. Using Malliavin calculus (Clark-Ocone/BEL), we derive policy gradients and risk shadow price, unifying HJB and KKT. This gives dual gap and convergence results: geometric MO vs. RL floors. We quantify phantom profit in RL via Malliavin policy-gradient contamination analy­ sis and define a control-affects-dynamics (CAD) premium of RL indicating plausibly positive.",
    "keywords": []
  },
  {
    "article_id": "2509.12917v2_Reversible_Deep_Equilibrium_Models",
    "title": "2509.12917v2 Reversible Deep Equilibrium Models",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.12917v2_Reversible_Deep_Equilibrium_Models.pdf",
    "url": "http://arxiv.org/abs/2509.12917v2_Reversible_Deep_Equilibrium_Models",
    "pdf_url": "https://arxiv.org/pdf/2509.12917v2_Reversible_Deep_Equilibrium_Models",
    "file_size_mb": 0.37,
    "abstract": "Deep Equilibrium Models (DEQs) are an interesting class of implicit model where the model output is implicitly defined as the fixed point of a learned function. These models have been shown to outperform explicit (fixed-depth) models in large-scale tasks by trading many deep layers for a single layer that is iterated many times. However, gradient calculation through DEQs is approximate. This often leads to unstable training dynamics and requires regularisation or many function evaluations to fix. Here, we introduce Reversible Deep Equilibrium Models (RevDEQs) that allow for exact gradient calculation, no regularisation and far fewer function evaluations than DEQs. We show that RevDEQs significantly improve performance on language modelling and image classification tasks against comparable implicit and explicit models.",
    "keywords": []
  },
  {
    "article_id": "2509.14304v1_Deploying_UDM_Series_in_Real-Life_Stuttered_Speech_Applications_A_Clinical_Evaluation_Framework",
    "title": "2509.14304v1 Deploying UDM Series in Real-Life Stuttered Speech Applications A Clinical Evaluation Framework",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.14304v1_Deploying_UDM_Series_in_Real-Life_Stuttered_Speech_Applications_A_Clinical_Evaluation_Framework.pdf",
    "url": "http://arxiv.org/abs/2509.14304v1_Deploying_UDM_Series_in_Real-Life_Stuttered_Speech_Applications_A_Clinical_Evaluation_Framework",
    "pdf_url": "https://arxiv.org/pdf/2509.14304v1_Deploying_UDM_Series_in_Real-Life_Stuttered_Speech_Applications_A_Clinical_Evaluation_Framework",
    "file_size_mb": 0.2,
    "abstract": "Stuttered and dysfluent speech detection systems have traditionally suffered from the trade-off between accuracy and clinical interpretability. While end-to-end deep learning models achieve high performance, their black-box nature limits clinical adoption. This paper looks at the Unconstrained Dysfluency Modeling (UDM) series—the current state-of-the-art framework developed by Berkeley that combines modular architecture, explicit phoneme alignment, and interpretable outputs for real-world clinical deployment. Through extensive experiments involving patients and certified speech-language pathologists (SLPs), we demonstrate that UDM achieves state-of-the-art performance (F1: 0.89±0.04) while providing clinically meaningful interpretability scores (4.2/5.0). Our deployment study shows 87% clinician acceptance rate and 34% reduction in diagnostic time. The results provide strong evidence that UDM represents a practical pathway toward AI-assisted speech therapy in clinical environments.",
    "keywords": []
  },
  {
    "article_id": "2509.14385v1_Adaptive_and_Regime-Aware_RL_for_Portfolio_Optimization",
    "title": "2509.14385v1 Adaptive and Regime-Aware RL for Portfolio Optimization",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.14385v1_Adaptive_and_Regime-Aware_RL_for_Portfolio_Optimization.pdf",
    "url": "http://arxiv.org/abs/2509.14385v1_Adaptive_and_Regime-Aware_RL_for_Portfolio_Optimization",
    "pdf_url": "https://arxiv.org/pdf/2509.14385v1_Adaptive_and_Regime-Aware_RL_for_Portfolio_Optimization",
    "file_size_mb": 0.69,
    "abstract": "This study proposes a regime-aware reinforcement learning framework for long- horizon portfolio optimization. Moving beyond traditional feedforward and GARCH- based models, we design realistic environments where agents dynamically reallocate capital in response to latent macroeconomic regime shifts. Agents receive hybrid ob- servations (asset returns and hidden regime probabilities) and are trained using con- strained reward functions, incorporating volatility penalties, capital resets, and tail-risk shocks. We benchmark multiple architectures—including PPO, LSTM-based PPO, and Transformer PPO—against classical baselines like equal-weight and Sharpe-optimized portfolios.Our agents demonstrate robust performance under financial stress. While Transformer PPO achieves the highest risk-adjusted returns, LSTM variants offer a fa- vorable trade-off between interpretability and training cost. The framework promotes regime-adaptive, explainable reinforcement learning for dynamic asset allocation.",
    "keywords": [
      "Reinforcement Learning",
      "Portfolio Optimization",
      "Market Regime Detection"
    ]
  },
  {
    "article_id": "2509.14401v1_Predictive_Performance_of_LSTM_Networks_on_Sectoral_Stocks_in_an_Emerging_Market_A_Case_Study_of_the",
    "title": "2509.14401v1 Predictive Performance of LSTM Networks on Sectoral Stocks in an Emerging Market A Case Study of the",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.14401v1_Predictive_Performance_of_LSTM_Networks_on_Sectoral_Stocks_in_an_Emerging_Market_A_Case_Study_of_the.pdf",
    "url": "http://arxiv.org/abs/2509.14401v1_Predictive_Performance_of_LSTM_Networks_on_Sectoral_Stocks_in_an_Emerging_Market_A_Case_Study_of_the",
    "pdf_url": "https://arxiv.org/pdf/2509.14401v1_Predictive_Performance_of_LSTM_Networks_on_Sectoral_Stocks_in_an_Emerging_Market_A_Case_Study_of_the",
    "file_size_mb": 1.45,
    "abstract": "The application of deep learning models for stock price forecasting in emerging markets remains underexplored despite their potential to capture complex temporal dependencies. This study develops and evaluates a Long Short-Term Memory (LSTM) network model for predicting the closing prices of ten major stocks across diverse sectors of the Pakistan Stock Exchange (PSX). Utilizing historical OHLCV data and an extensive set of engineered technical indicators, we trained and validated the model on a multi-year dataset. Our results demonstrate strong predictive performance (R2 > 0.87) for stocks in stable, high-liquidity sectors such as power generation, cement, and fertilizers. Conversely, stocks characterized by high volatility, low liquidity, or sensitivity to external shocks (e.g., global oil prices) presented significant forecasting challenges. The study provides a replicable framework for LSTM-based forecasting in data-scarce emerging markets and discusses implications for investors and future research.",
    "keywords": [
      "Long Short-Term Memory (LSTM)",
      "Stock Prediction",
      "Emerging Markets",
      "Pakistan Stock"
    ]
  },
  {
    "article_id": "2509.16206v1_Deep_Reinforcement_Learning_in_Factor_Investment",
    "title": "2509.16206v1 Deep Reinforcement Learning in Factor Investment",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.16206v1_Deep_Reinforcement_Learning_in_Factor_Investment.pdf",
    "url": "http://arxiv.org/abs/2509.16206v1_Deep_Reinforcement_Learning_in_Factor_Investment",
    "pdf_url": "https://arxiv.org/pdf/2509.16206v1_Deep_Reinforcement_Learning_in_Factor_Investment",
    "file_size_mb": 0.5,
    "abstract": "Deep reinforcement learning (DRL) has shown promise in trade execution, yet its use in low-frequency factor portfolio construction re- mains under-explored. A key obstacle is the high-dimensional, unbalanced state space cre- ated by stocks that enter and exit the in- vestable universe. We introduce Conditional Auto-encoded Factor-based Portfolio Optimisa- tion (CAFPO), which compresses stock-level re- turns into a small set of latent factors condi- tioned on 94 firm-specific characteristics. The factors feed a DRL agent—implemented with both PPO and DDPG—to generate continuous long–short weights. On 20 years of U.S. eq- uity data (2000–2020), CAFPO outperforms equal- weight, value-weight, Markowitz (historical & fac- tor), vanilla DRL, and Fama–French-driven DRL, delivering a 24.6% compound return and a Sharpe ratio of 0.94 out of sample. SHAP analysis further reveals economically intuitive factor attributions. Our results demonstrate that factor-aware represen- tation learning can make DRL practical for institu- tional, low-turnover portfolio management.",
    "keywords": []
  },
  {
    "article_id": "2509.16707v2_Increase_Alpha_Performance_and_Risk_of_an_AI-Driven_Trading_Framework",
    "title": "2509.16707v2 Increase Alpha Performance and Risk of an AI-Driven Trading Framework",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.16707v2_Increase_Alpha_Performance_and_Risk_of_an_AI-Driven_Trading_Framework.pdf",
    "url": "http://arxiv.org/abs/2509.16707v2_Increase_Alpha_Performance_and_Risk_of_an_AI-Driven_Trading_Framework",
    "pdf_url": "https://arxiv.org/pdf/2509.16707v2_Increase_Alpha_Performance_and_Risk_of_an_AI-Driven_Trading_Framework",
    "file_size_mb": 9.6,
    "abstract": ". There are inefficiencies in the financial market, leaving un- exploited patterns embedded in price, volume, and cross-sectional rela- tionships. While recent advances increasingly employ large-scale trans- former architectures, we take a domain-focused route: classical feed- forward and recurrent networks paired with expertly curated features to mine subtle regularities in noisy financial data. This smaller-footprint design is computationally lean and reliable under low signal-to-noise con- ditions—qualities that matter for daily production at scale. At Increase Alpha, we developed a deep-learning framework that maps a universe of over 800 U.S. equities into daily directional signals with minimal com- putational overhead. The purpose of this paper is twofold. First, we outline the general overview of the predictive model without disclosing its core underlying concepts. Second, we evaluate its real-time performance through transparent, in- dustry standard metrics. Forecast accuracy is benchmarked against both naive baselines and macro indicators. The performance outcomes are summarized via cumulative returns, annualized Sharpe ratio, and max- imum drawdown. The best portfolio combination using our signals pro- vides a low-risk, continuous stream of returns with a Sharpe ratio of more than 2.5, maximum drawdown of around 3%, and a near-zero correlation with the S&P 500 market benchmark. We also compare the model’s per- formance through different market regimes, such as the recent volatile movements of the US equity market in the beginning of 2025. Our anal- ysis showcases the robustness of the model and significantly stable per- formance during these volatile periods. Collectively, these findings show that market inefficiencies can be sys- tematically harvested with modest computational overhead if the right variables are considered. This report will emphasize the potential of tra- ditional deep learning frameworks for generating an AI-driven edge in the financial market.",
    "keywords": [
      "Finance",
      "Algorithmic Trading",
      "Risk Management",
      "Deep"
    ]
  },
  {
    "article_id": "2509.16743v1_A_Hybrid_PCA-PR-Seq2Seq-Adam-LSTM_Framework_for_Time-Series_Power_Outage_Prediction",
    "title": "2509.16743v1 A Hybrid PCA-PR-Seq2Seq-Adam-LSTM Framework for Time-Series Power Outage Prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.16743v1_A_Hybrid_PCA-PR-Seq2Seq-Adam-LSTM_Framework_for_Time-Series_Power_Outage_Prediction.pdf",
    "url": "http://arxiv.org/abs/2509.16743v1_A_Hybrid_PCA-PR-Seq2Seq-Adam-LSTM_Framework_for_Time-Series_Power_Outage_Prediction",
    "pdf_url": "https://arxiv.org/pdf/2509.16743v1_A_Hybrid_PCA-PR-Seq2Seq-Adam-LSTM_Framework_for_Time-Series_Power_Outage_Prediction",
    "file_size_mb": 2.92,
    "abstract": "—Accurately forecasting power outages is a complex task influenced by diverse factors such as weather conditions [1], vegetation, wildlife, and load fluctuations. These factors introduce substantial variability and noise into outage data, making reliable prediction challenging. Long Short-Term Mem- ory (LSTM) networks, a type of Recurrent Neural Network (RNN), are particularly effective for modeling nonlinear and dynamic time-series data, with proven applications in stock price forecasting [2], energy demand prediction, demand response [3], and traffic flow management [4]. This paper introduces a hy- brid deep learning framework, termed PCA-PR-Seq2Seq-Adam- LSTM, that integrates Principal Component Analysis (PCA), Poisson Regression (PR), a Sequence-to-Sequence (Seq2Seq) ar- chitecture, and an Adam-optimized LSTM. PCA is employed to reduce dimensionality and stabilize data variance, while Poisson Regression effectively models discrete outage events. The Seq2Seq-Adam-LSTM component enhances temporal feature learning through efficient gradient optimization and long-term dependency capture. The framework is evaluated using real- world outage records from Michigan, and results indicate that the proposed approach significantly improves forecasting accuracy and robustness compared to existing methods. Index Terms—Deep Learning, Power Outage Prediction, LSTM, Poisson Distribution, Seq2Seq",
    "keywords": []
  },
  {
    "article_id": "2509.17874v1_Deep_Hierarchical_Learning_with_Nested_Subspace_Networks",
    "title": "2509.17874v1 Deep Hierarchical Learning with Nested Subspace Networks",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.17874v1_Deep_Hierarchical_Learning_with_Nested_Subspace_Networks.pdf",
    "url": "http://arxiv.org/abs/2509.17874v1_Deep_Hierarchical_Learning_with_Nested_Subspace_Networks",
    "pdf_url": "https://arxiv.org/pdf/2509.17874v1_Deep_Hierarchical_Learning_with_Nested_Subspace_Networks",
    "file_size_mb": 0.8,
    "abstract": "Large neural networks are typically trained for a fixed computational budget, creating a rigid trade-off between performance and efficiency that is ill-suited for deployment in resource-constrained or dynamic environments. Existing approaches to this problem present a difficult choice: training a discrete collection of specialist models is computationally prohibitive, while dynamic methods like slimmable networks often lack the flexibility to be applied to large, pre-trained foundation models. In this work, we propose Nested Subspace Networks (NSNs), a novel architectural paradigm that enables a single model to be dynamically and granularly adjusted across a continuous spectrum of compute budgets at inference time. The core of our approach is to re-parameterize linear layers to satisfy a nested subspace property, such that the function computed at a given rank is a strict subspace of the function at any higher rank. We show that this entire hierarchy of models can be optimized jointly via an uncertainty-aware objective that learns to balance the contributions of different ranks based on their intrinsic difficulty. We demonstrate empirically that NSNs can be surgically applied to pre-trained LLMs and unlock a smooth and predictable compute-performance frontier. For example, a single NSN-adapted model can achieve a 50% reduction in inference FLOPs with only a 5 percentage point loss in accuracy. Our findings establish NSNs as a powerful framework for creating the next generation of adaptive foundation models.",
    "keywords": []
  },
  {
    "article_id": "2509.18054v2_A_Knowledge_Graph-based_Retrieval-Augmented_Generation_Framework_for_Algorithm_Selection_in_the_Faci",
    "title": "2509.18054v2 A Knowledge Graph-based Retrieval-Augmented Generation Framework for Algorithm Selection in the Faci",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.18054v2_A_Knowledge_Graph-based_Retrieval-Augmented_Generation_Framework_for_Algorithm_Selection_in_the_Faci.pdf",
    "url": "http://arxiv.org/abs/2509.18054v2_A_Knowledge_Graph-based_Retrieval-Augmented_Generation_Framework_for_Algorithm_Selection_in_the_Faci",
    "pdf_url": "https://arxiv.org/pdf/2509.18054v2_A_Knowledge_Graph-based_Retrieval-Augmented_Generation_Framework_for_Algorithm_Selection_in_the_Faci",
    "file_size_mb": 1.65,
    "abstract": "Selecting a solution algorithm for the Facility Layout Problem (FLP), an NP-hard optimization problem with multiobjective trade-off, is a complex task that requires deep expert knowledge. The performance of a given algo- rithm depends on the specific characteristics of the prob- lem, such as the number of facilities, objectives, and con- straints. This creates a need for a data-driven recommen- dation method to guide algorithm selection in automated design systems. This paper introduces a new recommen- dation method to make this expertise accessible, based on a Knowledge Graph-Based Retrieval-Augmented Genera- tion (KG-RAG) framework. In this framework, a domain- specific knowledge graph (KG) is constructed from the literature. The method then employs a multifaceted re- trieval mechanism to gather relevant evidence from this KG using three distinct approaches: precise graph-based search, flexible vector-based search, and cluster-based high-level search. The retrieved evidence is utilized by a Large Language Model (LLM) to generate algorithm recommendations based on data-driven reasoning. This KG-RAG framework is tested on a use case consisting of six problems comprising of complex multi-objective and multi-constraint FLP case. The results are compared with the Gemini 1.5 Flash chatbot. The results show that KG-RAG achieves an average reasoning score of 4.7 out of 5 compared to 3.3 for the baseline chatbot.",
    "keywords": [
      "Facility Layout Problem",
      "Algorithm Selec-"
    ]
  },
  {
    "article_id": "2509.19128v2_PipelineRL_Faster_On-policy_Reinforcement_Learning_for_Long_Sequence_Generation",
    "title": "2509.19128v2 PipelineRL Faster On-policy Reinforcement Learning for Long Sequence Generation",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.19128v2_PipelineRL_Faster_On-policy_Reinforcement_Learning_for_Long_Sequence_Generation.pdf",
    "url": "http://arxiv.org/abs/2509.19128v2_PipelineRL_Faster_On-policy_Reinforcement_Learning_for_Long_Sequence_Generation",
    "pdf_url": "https://arxiv.org/pdf/2509.19128v2_PipelineRL_Faster_On-policy_Reinforcement_Learning_for_Long_Sequence_Generation",
    "file_size_mb": 5.37,
    "abstract": "Reinforcement Learning (RL) is increasingly utilized to enhance the reasoning capabilities of Large Language Models (LLMs). However, effectively scaling these RL methods presents significant challenges, primarily due to the difficulty in maintaining high AI accelerator utilization without generating stale, off-policy data that harms common RL algorithms. This paper introduces PipelineRL, an approach designed to achieve a superior trade-off be- tween hardware efficiency and data on-policyness for LLM training. PipelineRL employs concurrent asynchronous data generation and model training, distinguished by the novel in-flight weight updates. This mechanism allows the LLM generation engine to receive up- dated model weights with minimal interruption during the generation of token sequences, thereby maximizing both the accelerator utilization and the freshness of training data. Ex- periments conducted on long-form reasoning tasks using 128 H100 GPUs demonstrate that PipelineRL achieves approximately ∼2x faster learning compared to conventional RL base- lines while maintaining highly on-policy training data. A scalable and modular open-source implementation of PipelineRL is also released as a key contribution.",
    "keywords": []
  },
  {
    "article_id": "2509.19417v3_Analyzing_Uncertainty_Quantification_in_Statistical_and_Deep_Learning_Models_for_Probabilistic_Elect",
    "title": "2509.19417v3 Analyzing Uncertainty Quantification in Statistical and Deep Learning Models for Probabilistic Elect",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.19417v3_Analyzing_Uncertainty_Quantification_in_Statistical_and_Deep_Learning_Models_for_Probabilistic_Elect.pdf",
    "url": "http://arxiv.org/abs/2509.19417v3_Analyzing_Uncertainty_Quantification_in_Statistical_and_Deep_Learning_Models_for_Probabilistic_Elect",
    "pdf_url": "https://arxiv.org/pdf/2509.19417v3_Analyzing_Uncertainty_Quantification_in_Statistical_and_Deep_Learning_Models_for_Probabilistic_Elect",
    "file_size_mb": 1.33,
    "abstract": "Precise probabilistic forecasts are fundamental for energy risk management, and there is a wide range of both statistical and machine learning models for this pur- pose. Inherent to these probabilistic models is some form of uncertainty quantification. However, most models do not capture the full extent of uncertainty, which arises not only from the data itself but also from model and distributional choices. In this study, we examine uncertainty quantification in state-of-the-art statistical and deep learning probabilistic forecasting models for electricity price forecasting in the German market. In particular, we consider deep distributional neural networks (DDNNs) and augment them with an ensemble approach, Monte Carlo (MC) dropout, and conformal predic- tion to account for model uncertainty. Additionally, we consider the LASSO-estimated autoregressive (LEAR) approach combined with quantile regression averaging (QRA), generalized autoregressive conditional heteroskedasticity (GARCH), and conformal pre- diction. Across a range of performance metrics, we find that the LEAR-based models perform well in terms of probabilistic forecasting, irrespective of the uncertainty quan- tification method. Furthermore, we find that DDNNs benefit from incorporating both data and model uncertainty, improving both point and probabilistic forecasting. Un- certainty itself appears to be best captured by the models using conformal prediction. Overall, our extensive study shows that all models under consideration perform com- petitively. However, their relative performance depends on the choice of metrics for point and probabilistic forecasting.",
    "keywords": [
      "Bayesian methods",
      "deep learning",
      "electricity price forecasting",
      "ensemble"
    ]
  },
  {
    "article_id": "2509.20529v2_MDBench_Benchmarking_Data-Driven_Methods_for_Model_Discovery",
    "title": "2509.20529v2 MDBench Benchmarking Data-Driven Methods for Model Discovery",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.20529v2_MDBench_Benchmarking_Data-Driven_Methods_for_Model_Discovery.pdf",
    "url": "http://arxiv.org/abs/2509.20529v2_MDBench_Benchmarking_Data-Driven_Methods_for_Model_Discovery",
    "pdf_url": "https://arxiv.org/pdf/2509.20529v2_MDBench_Benchmarking_Data-Driven_Methods_for_Model_Discovery",
    "file_size_mb": 2.57,
    "abstract": "Model discovery aims to uncover governing differential equations of dynamical systems directly from experimen- tal data. Benchmarking such methods is essential for track- ing progress and understanding trade-offs in the field. While prior efforts have focused mostly on identifying single equa- tions, typically framed as symbolic regression, there remains a lack of comprehensive benchmarks for discovering dynami- cal models. To address this, we introduce MDBench, an open- source benchmarking framework for evaluating model dis- covery methods on dynamical systems. MDBench assesses 12 algorithms on 14 partial differential equations (PDEs) and 63 ordinary differential equations (ODEs) under varying lev- els of noise. Evaluation metrics include derivative prediction accuracy, model complexity, and equation fidelity. We also introduce seven challenging PDE systems from fluid dynam- ics and thermodynamics, revealing key limitations in current methods. Our findings illustrate that linear methods and ge- netic programming methods achieve the lowest prediction er- ror for PDEs and ODEs, respectively. Moreover, linear mod- els are in general more robust against noise. MDBench ac- celerates the advancement of model discovery methods by offering a rigorous, extensible benchmarking framework and a rich, diverse collection of dynamical system datasets, en- abling systematic evaluation, comparison, and improvement of equation accuracy and robustness. Code — https://github.com/gryaklab/mdbench Datasets — https://zenodo.org/records/17611099 Extended version — https://arxiv.org/abs/2509.20529",
    "keywords": []
  },
  {
    "article_id": "2509.21293v1_Optimal_Robust_Recourse_with_Lp-Bounded_Model_Change",
    "title": "2509.21293v1 Optimal Robust Recourse with Lp-Bounded Model Change",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.21293v1_Optimal_Robust_Recourse_with_Lp-Bounded_Model_Change.pdf",
    "url": "http://arxiv.org/abs/2509.21293v1_Optimal_Robust_Recourse_with_Lp-Bounded_Model_Change",
    "pdf_url": "https://arxiv.org/pdf/2509.21293v1_Optimal_Robust_Recourse_with_Lp-Bounded_Model_Change",
    "file_size_mb": 2.83,
    "abstract": "Recourse provides individuals who received undesirable labels (e.g., denied a loan) from algorithmic decision-making systems with a minimum-cost improvement suggestion to achieve the desired outcome. However, in practice, models often get updated to reflect changes in the data distribution or environment, invalidating the recourse recommendations (i.e., following the recourse will not lead to the desirable outcome). The robust recourse literature addresses this issue by providing a framework for computing recourses whose validity is resilient to slight changes in the model. However, since the optimization problem of computing robust recourse is non-convex (even for linear models), most of the current approaches do not have any theoretical guarantee on the optimality of the recourse. Recent work by Kayastha et al. [31] provides the first provably optimal algorithm for robust recourse with respect to generalized linear models when the model changes are measured using the L∞norm. However, using the L∞norm can lead to recourse solutions with a high price. To address this shortcoming, we consider more constrained model changes defined by the Lp norm, where p ≥1 but p ̸= ∞, and provide a new algorithm that provably computes the optimal robust recourse for generalized linear models. Empirically, for both linear and non-linear models, we demonstrate that our algorithm achieves a significantly lower price of recourse (up to several orders of magnitude) compared to prior work and also exhibits a better trade-off between the implementation cost of recourse and its validity. Our empirical analysis also illustrates that our approach provides more sparse recourses compared to prior work and remains resilient to post-processing approaches that guarantee feasibility.",
    "keywords": []
  },
  {
    "article_id": "2509.21474v2_d2_Improved_Techniques_for_Training_Reasoning_Diffusion_Language_Models",
    "title": "2509.21474v2 d2 Improved Techniques for Training Reasoning Diffusion Language Models",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.21474v2_d2_Improved_Techniques_for_Training_Reasoning_Diffusion_Language_Models.pdf",
    "url": "http://arxiv.org/abs/2509.21474v2_d2_Improved_Techniques_for_Training_Reasoning_Diffusion_Language_Models",
    "pdf_url": "https://arxiv.org/pdf/2509.21474v2_d2_Improved_Techniques_for_Training_Reasoning_Diffusion_Language_Models",
    "file_size_mb": 1.16,
    "abstract": "While diffusion language models (DLMs) have achieved competitive performance in text generation, improving their reasoning ability with reinforcement learning remains an active research area. Here, we introduce d2, a reasoning framework tailored for masked DLMs. Central to our framework is a new policy gradient algorithm that relies on properties of masking to accurately estimate the likelihoods of sampling trajectories. Our estimators trade off computation for approximation accuracy in an analytically tractable manner, and are particularly effective for DLMs that support any-order likelihood estimation. We characterize and study this property in popular DLMs and show that it is key for efficient diffusion-based reasoning. Empirically, d2 significantly improves over previous diffusion reasoning frameworks using only RL (without relying on supervised fine-tuning), and sets a new state-of-the-art performance for DLMs on logical reasoning tasks (Countdown and Sudoku) and math reasoning benchmarks (GSM8K and MATH500).",
    "keywords": []
  },
  {
    "article_id": "2509.21567v2_EEG-Based_Consumer_Behaviour_Prediction_An_Exploration_from_Classical_Machine_Learning_to_Graph_Neur",
    "title": "2509.21567v2 EEG-Based Consumer Behaviour Prediction An Exploration from Classical Machine Learning to Graph Neur",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.21567v2_EEG-Based_Consumer_Behaviour_Prediction_An_Exploration_from_Classical_Machine_Learning_to_Graph_Neur.pdf",
    "url": "http://arxiv.org/abs/2509.21567v2_EEG-Based_Consumer_Behaviour_Prediction_An_Exploration_from_Classical_Machine_Learning_to_Graph_Neur",
    "pdf_url": "https://arxiv.org/pdf/2509.21567v2_EEG-Based_Consumer_Behaviour_Prediction_An_Exploration_from_Classical_Machine_Learning_to_Graph_Neur",
    "file_size_mb": 0.55,
    "abstract": "Prediction of consumer behavior is one of the important purposes in marketing, cognitive neuroscience, and human-computer interaction. The electroencephalog- raphy (EEG) data can help analyze the decision process by providing detailed information about the brain’s neural activity. In this research, a comparative approach is utilized for predicting consumer behavior by EEG data. In the first step, the features of the EEG data from the NeuMa dataset were extracted and cleaned. For the Graph Neural Network (GNN) models, the brain connectivity features were created. Different machine learning models, such as classical mod- els and Graph Neural Networks, are used and compared. The GNN models with different architectures are implemented to have a comprehensive comparison; fur- thermore, a wide range of classical models, such as ensemble models, are applied, which can be very helpful to show the difference and performance of each model on the dataset. Although the results did not show a significant difference overall, the GNN models generally performed better in some basic criteria where clas- sical models were not satisfactory. This study not only shows that combining EEG signal analysis and machine learning models can provide an approach to deeper understanding of consumer behavior, but also provides a comprehensive comparison between the machine learning models that have been widely used in previous studies in the EEG-based neuromarketing such as Support Vector Machine (SVM), and the models which are not used or rarely used in the field, like Graph Neural Networks.",
    "keywords": [
      "Neuromarketing",
      "Machine Learning",
      "Deep Learning",
      "Graph Neural"
    ]
  },
  {
    "article_id": "2509.22232v1_Fairness-Aware_Reinforcement_Learning_FAReL_A_Framework_for_Transparent_and_Balanced_Sequential_Deci",
    "title": "2509.22232v1 Fairness-Aware Reinforcement Learning FAReL A Framework for Transparent and Balanced Sequential Deci",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.22232v1_Fairness-Aware_Reinforcement_Learning_FAReL_A_Framework_for_Transparent_and_Balanced_Sequential_Deci.pdf",
    "url": "http://arxiv.org/abs/2509.22232v1_Fairness-Aware_Reinforcement_Learning_FAReL_A_Framework_for_Transparent_and_Balanced_Sequential_Deci",
    "pdf_url": "https://arxiv.org/pdf/2509.22232v1_Fairness-Aware_Reinforcement_Learning_FAReL_A_Framework_for_Transparent_and_Balanced_Sequential_Deci",
    "file_size_mb": 25.35,
    "abstract": "Equity in real-world sequential decision problems can be enforced using fairness-aware methods. Therefore, we require algorithms that can make suitable and transparent trade-offs between performance and the desired fairness notions. As the desired performance-fairness trade-off is hard to specify a priori, we propose a framework where multiple trade-offs can be explored. Insights provided by the reinforcement learning algorithm regarding the obtainable performance–fairness trade-offs can then guide stakeholders in selecting the most appropriate policy. To capture fairness, we propose an extended Markov decision process, fMDP, that explicitly encodes individuals and groups. Given this fMDP, we formalise fairness notions in the context of sequential decision problems and formulate a fairness framework that computes fairness measures over time. We evaluate our framework in two scenarios with distinct fairness requirements: job hiring, where strong teams must be composed while treating applicants equally, and fraud detection, where fraudulent transactions must be de- tected while ensuring the burden on customers is fairly distributed. We show that our framework learns policies that are more fair across multiple scenarios, with only minor loss in performance reward. Moreover, we observe that group and individual fairness notions do not necessarily imply one another, highlighting the benefit of our framework in settings where both fairness types are desired. Finally, we provide guidelines on how to apply this framework across different problem settings. 1 arXiv:2509.22232v1 [cs.LG] 26 Sep 2025",
    "keywords": []
  },
  {
    "article_id": "2509.22467v2_CausalKANs_interpretable_treatment_effect_estimation_with_Kolmogorov-Arnold_networks",
    "title": "2509.22467v2 CausalKANs interpretable treatment effect estimation with Kolmogorov-Arnold networks",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.22467v2_CausalKANs_interpretable_treatment_effect_estimation_with_Kolmogorov-Arnold_networks.pdf",
    "url": "http://arxiv.org/abs/2509.22467v2_CausalKANs_interpretable_treatment_effect_estimation_with_Kolmogorov-Arnold_networks",
    "pdf_url": "https://arxiv.org/pdf/2509.22467v2_CausalKANs_interpretable_treatment_effect_estimation_with_Kolmogorov-Arnold_networks",
    "file_size_mb": 5.39,
    "abstract": "Deep neural networks achieve state-of-the-art performance in estimating heterogen- eous treatment effects, but their opacity limits trust and adoption in sensitive do- mains such as medicine, economics and public policy. Building on well-established and high-performing causal neural architectures, we propose causalKANs, a frame- work that transforms neural estimators of conditional average treatment effects (CATEs) into Kolmogorov–Arnold Networks (KANs). By incorporating pruning and symbolic simplification, causalKANs yields interpretable closed-form for- mulas while preserving predictive accuracy. Experiments on benchmark datasets demonstrate that causalKANs perform on par with neural baselines in CATE error metrics, and that even simple KAN variants achieve competitive performance, offering a favorable accuracy–interpretability trade-off. By combining reliability with analytic accessibility, causalKANs provide auditable estimators supported by closed-form expressions and interpretable plots, enabling trustworthy individual- ized decision-making in high-stakes settings. We release the code for reproducibil- ity in https://github.com/aalmodovares/causalkans.",
    "keywords": []
  },
  {
    "article_id": "2509.22563v1_Nearly_Tight_Regret_Bounds_for_Profit_Maximization_in_Bilateral_Trade",
    "title": "2509.22563v1 Nearly Tight Regret Bounds for Profit Maximization in Bilateral Trade",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.22563v1_Nearly_Tight_Regret_Bounds_for_Profit_Maximization_in_Bilateral_Trade.pdf",
    "url": "http://arxiv.org/abs/2509.22563v1_Nearly_Tight_Regret_Bounds_for_Profit_Maximization_in_Bilateral_Trade",
    "pdf_url": "https://arxiv.org/pdf/2509.22563v1_Nearly_Tight_Regret_Bounds_for_Profit_Maximization_in_Bilateral_Trade",
    "file_size_mb": 0.99,
    "abstract": "Bilateral trade models the task of intermediating between two strategic agents, a seller and a buyer, willing to trade a good for which they hold private valuations. We study this problem from the perspective of a broker, in a regret minimization framework. At each time step, a new seller and buyer arrive, and the broker has to propose a mechanism that is incentive-compatible and individually rational, with the goal of maximizing profit. We propose a learning algorithm that guarantees a nearly tight ˜O( √ T) regret in the stochastic setting when seller and buyer valuations are drawn i.i.d. from a fixed and possibly correlated unknown distribution. We further show that it is impossible to achieve sublinear regret in the non-stationary scenario where valuations are generated upfront by an adversary. Our ambitious benchmark for these results is the best incentive-compatible and individually rational mechanism. This separates us from previous works on efficiency maximization in bilateral trade, where the benchmark is a single number: the best fixed price in hindsight. A particular challenge we face is that uniform convergence for all mechanisms’ profits is impossible. We overcome this difficulty via a careful chaining analysis that proves convergence for a provably near-optimal mechanism at (essentially) optimal rate. We further showcase the broader applicability of our techniques by providing nearly optimal results for the joint ads problem.",
    "keywords": []
  },
  {
    "article_id": "2509.22673v1_PISA_An_AI_Pipeline_for_Interpretable-by-design_Survival_Analysis_Providing_Multiple_Complexity-Accu",
    "title": "2509.22673v1 PISA An AI Pipeline for Interpretable-by-design Survival Analysis Providing Multiple Complexity-Accu",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.22673v1_PISA_An_AI_Pipeline_for_Interpretable-by-design_Survival_Analysis_Providing_Multiple_Complexity-Accu.pdf",
    "url": "http://arxiv.org/abs/2509.22673v1_PISA_An_AI_Pipeline_for_Interpretable-by-design_Survival_Analysis_Providing_Multiple_Complexity-Accu",
    "pdf_url": "https://arxiv.org/pdf/2509.22673v1_PISA_An_AI_Pipeline_for_Interpretable-by-design_Survival_Analysis_Providing_Multiple_Complexity-Accu",
    "file_size_mb": 3.23,
    "abstract": "Survival analysis is central to clinical research, informing patient prognoses, guiding treatment decisions, and optimising resource allocation. Accurate time-to-event predictions not only improve quality of life but also reveal risk factors that shape clinical practice. For these models to be relevant in healthcare, interpretability is critical: predictions must be traceable to patient-specific character- istics, and risk factors should be identifiable to generate actionable insights for both clinicians and researchers. Traditional survival models often fail to capture non-linear interactions, while modern deep learning approaches, though powerful, are limited by poor interpretability. We propose a Pipeline for Interpretable Survival Analysis (PISA) - a pipeline that provides multiple survival analysis models that trade off complexity and performance. Using multiple-feature, multi- objective feature engineering, PISA transforms patient characteris- tics and time-to-event data into multiple survival analysis models, providing valuable insights into the survival prediction task. Cru- cially, every model is converted into simple patient stratification flowcharts supported by Kaplan–Meier curves, whilst not compro- mising on performance. While PISA is model-agnostic, we illustrate its flexibility through applications of Cox regression and shallow survival trees, the latter avoiding proportional hazards assumptions. Applied to two clinical benchmark datasets, PISA produced in- terpretable survival models and intuitive stratification flowcharts whilst achieving state-of-the-art performances. Revisiting a prior departmental study further demonstrated its capacity to automate survival analysis workflows in real-world clinical research.",
    "keywords": [
      "survival analysis",
      "patient stratification",
      "explainable artificial intelli-"
    ]
  },
  {
    "article_id": "2509.22794v1_Differentially_Private_Two-Stage_Gradient_Descent_for_Instrumental_Variable_Regression",
    "title": "2509.22794v1 Differentially Private Two-Stage Gradient Descent for Instrumental Variable Regression",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.22794v1_Differentially_Private_Two-Stage_Gradient_Descent_for_Instrumental_Variable_Regression.pdf",
    "url": "http://arxiv.org/abs/2509.22794v1_Differentially_Private_Two-Stage_Gradient_Descent_for_Instrumental_Variable_Regression",
    "pdf_url": "https://arxiv.org/pdf/2509.22794v1_Differentially_Private_Two-Stage_Gradient_Descent_for_Instrumental_Variable_Regression",
    "file_size_mb": 2.29,
    "abstract": "We study instrumental variable regression (IVaR) under differential privacy constraints. Classi- cal IVaR methods (like two-stage least squares regression) rely on solving moment equations that directly use sensitive covariates and instruments, creating significant risks of privacy leakage and posing challenges in designing algorithms that are both statistically efficient and differentially pri- vate. We propose a noisy two-state gradient descent algorithm that ensures ρ-zero-concentrated differential privacy by injecting carefully calibrated noise into the gradient updates. Our analysis establishes finite-sample convergence rates for the proposed method, showing that the algorithm achieves consistency while preserving privacy. In particular, we derive precise bounds quantifying the trade-off among privacy parameters, sample size, and iteration-complexity. To the best of our knowledge, this is the first work to provide both privacy guarantees and provable convergence rates for instrumental variable regression in linear models. We further validate our theoretical findings with experiments on both synthetic and real datasets, demonstrating that our method offers practical accuracy-privacy trade-offs.",
    "keywords": []
  },
  {
    "article_id": "2509.23920v1_Asymptotic_Expansion_for_Nonlinear_Filtering_in_the_Small_System_Noise_Regime",
    "title": "2509.23920v1 Asymptotic Expansion for Nonlinear Filtering in the Small System Noise Regime",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.23920v1_Asymptotic_Expansion_for_Nonlinear_Filtering_in_the_Small_System_Noise_Regime.pdf",
    "url": "http://arxiv.org/abs/2509.23920v1_Asymptotic_Expansion_for_Nonlinear_Filtering_in_the_Small_System_Noise_Regime",
    "pdf_url": "https://arxiv.org/pdf/2509.23920v1_Asymptotic_Expansion_for_Nonlinear_Filtering_in_the_Small_System_Noise_Regime",
    "file_size_mb": 0.6,
    "abstract": "We propose a new asymptotic expansion method for nonlinear fil- tering, based on a small parameter in the system noise. The conditional expectation is expanded as a power series in the noise level, with each coefficient computed by solving a system of ordinary differential equa- tions. This approach mitigates the trade-off between computational efficiency and accuracy inherent in existing methods such as Gaussian approximations and particle filters. Moreover, by incorporating an Edgeworth-type expansion, our method captures complex features of the conditional distribution, such as multimodality, with significantly lower computational cost than conventional filtering algorithms. Key words— Nonlinear filtering, Asymptotic Expansion, Stochastic differential equations, Bayesian inference, Data assimilation",
    "keywords": [
      "Nonlinear filtering",
      "Asymptotic Expansion",
      "Stochastic"
    ]
  },
  {
    "article_id": "2509.24122v2_Echo_Flow_Networks",
    "title": "2509.24122v2 Echo Flow Networks",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.24122v2_Echo_Flow_Networks.pdf",
    "url": "http://arxiv.org/abs/2509.24122v2_Echo_Flow_Networks",
    "pdf_url": "https://arxiv.org/pdf/2509.24122v2_Echo_Flow_Networks",
    "file_size_mb": 2.19,
    "abstract": "At the heart of time-series forecasting (TSF) lies a fundamental challenge: how can models efficiently and effectively capture long-range temporal dependencies across ever-growing sequences? While deep learning has brought notable progress, conventional architectures often face a trade-off between computational complexity and their ability to retain accumulative information over extended horizons. Echo State Networks (ESNs), a class of reservoir computing models, have recently regained attention for their exceptional efficiency, offering constant memory usage and per-step training complexity regardless of input length. This makes them particularly attractive for modeling extremely long-term event history in TSF. However, traditional ESNs fall short of state-of-the-art performance due to their limited nonlinear capacity, which constrains both their expressiveness and stability. We introduce ECHO FLOW NETWORKS (EFNS), a framework composed of a group of extended Echo State Networks (X-ESNs) with MLP readouts, enhanced by our novel Matrix-Gated Composite Random Activation (MCRA), which en- ables complex, neuron-specific temporal dynamics, significantly expanding the network’s representational capacity without compromising computational effi- ciency. In addition, we propose a dual-stream architecture in which recent input history dynamically selects signature reservoir features from an infinite-horizon memory, leading to improved prediction accuracy and long-term stability. Extensive evaluations on five benchmarks demonstrate that EFNS achieves up to 4× faster training and 3× smaller model size compared to leading methods like PatchTST, reducing forecasting error from 43% to 35%, a 20% relative improve- ment. One instantiation of our framework, EchoFormer, consistently achieves new state-of-the-art performance across five benchmark datasets: ETTh, ETTm, DMV, Weather, and Air Quality.",
    "keywords": []
  },
  {
    "article_id": "2509.24144v1_From_Headlines_to_Holdings_Deep_Learning_for_Smarter_Portfolio_Decisions",
    "title": "2509.24144v1 From Headlines to Holdings Deep Learning for Smarter Portfolio Decisions",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.24144v1_From_Headlines_to_Holdings_Deep_Learning_for_Smarter_Portfolio_Decisions.pdf",
    "url": "http://arxiv.org/abs/2509.24144v1_From_Headlines_to_Holdings_Deep_Learning_for_Smarter_Portfolio_Decisions",
    "pdf_url": "https://arxiv.org/pdf/2509.24144v1_From_Headlines_to_Holdings_Deep_Learning_for_Smarter_Portfolio_Decisions",
    "file_size_mb": 1.62,
    "abstract": "Deep learning offers new tools for portfolio optimization. We present an end-to-end framework that directly learns portfolio weights by combining Long Short-Term Memory (LSTM) networks to model temporal patterns, Graph Attention Networks (GAT) to capture evolving inter-stock relationships, and sentiment analysis of financial news to reflect market psychology. Unlike prior approaches, our model unifies these elements in a single pipeline that produces daily allocations. It avoids the traditional two-step process of forecasting asset returns and then applying mean–variance optimization (MVO), a sequence that can introduce instability. We evaluate the framework on nine U.S. stocks spanning six sectors, chosen to balance sector diversity and news coverage. In this setting, the model delivers higher cumulative returns and Sharpe ratios than equal-weighted and CAPM-based MVO benchmarks. Although the stock universe is limited, the results underscore the value of integrating price, relational, and sentiment signals for portfolio management and suggest promising directions for scaling the approach to larger, more diverse asset sets.",
    "keywords": [
      "Portfolio Optimization",
      "Asset Allocation",
      "Graph Neural Networks",
      "Graph Attention Networks"
    ]
  },
  {
    "article_id": "2509.24517v1_Trading_Carbon_for_Physics_On_the_Resource_Efficiency_of_Machine_Learning_for_Spatio-Temporal_Foreca",
    "title": "2509.24517v1 Trading Carbon for Physics On the Resource Efficiency of Machine Learning for Spatio-Temporal Foreca",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.24517v1_Trading_Carbon_for_Physics_On_the_Resource_Efficiency_of_Machine_Learning_for_Spatio-Temporal_Foreca.pdf",
    "url": "http://arxiv.org/abs/2509.24517v1_Trading_Carbon_for_Physics_On_the_Resource_Efficiency_of_Machine_Learning_for_Spatio-Temporal_Foreca",
    "pdf_url": "https://arxiv.org/pdf/2509.24517v1_Trading_Carbon_for_Physics_On_the_Resource_Efficiency_of_Machine_Learning_for_Spatio-Temporal_Foreca",
    "file_size_mb": 10.97,
    "abstract": "Development of modern deep learning methods has been driven primarily by the push for improving model efficacy (accuracy metrics). This sole focus on efficacy has steered de- velopment of large-scale models that require massive resources, and results in considerable carbon footprint across the model life-cycle. In this work, we explore how physics inductive biases can offer useful trade-offs between model efficacy and model efficiency (compute, en- ergy, and carbon). We study a variety of models for spatio-temporal forecasting, a task governed by physical laws and well-suited for exploring different levels of physics inductive bias. We show that embedding physics inductive biases into the model design can yield substantial efficiency gains while retaining or even improving efficacy for the tasks under consideration. In addition to using standard physics-informed spatio-temporal models, we demonstrate the usefulness of more recent models like flow matching as a general purpose method for spatio-temporal forecasting. Our experiments show that incorporating physics inductive biases offer a principled way to improve the efficiency and reduce the carbon footprint of machine learning models. We argue that model efficiency, along with model efficacy, should become a core consideration driving machine learning model development and deployment.1",
    "keywords": []
  },
  {
    "article_id": "2509.24569v1_Bandits_roaming_Hilbert_space",
    "title": "2509.24569v1 Bandits roaming Hilbert space",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.24569v1_Bandits_roaming_Hilbert_space.pdf",
    "url": "http://arxiv.org/abs/2509.24569v1_Bandits_roaming_Hilbert_space",
    "pdf_url": "https://arxiv.org/pdf/2509.24569v1_Bandits_roaming_Hilbert_space",
    "file_size_mb": 3.14,
    "abstract": null,
    "keywords": []
  },
  {
    "article_id": "2509.24610v2_OrthAlign_Orthogonal_Subspace_Decomposition_for_Non-Interfering_Multi-Objective_Alignment",
    "title": "2509.24610v2 OrthAlign Orthogonal Subspace Decomposition for Non-Interfering Multi-Objective Alignment",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.24610v2_OrthAlign_Orthogonal_Subspace_Decomposition_for_Non-Interfering_Multi-Objective_Alignment.pdf",
    "url": "http://arxiv.org/abs/2509.24610v2_OrthAlign_Orthogonal_Subspace_Decomposition_for_Non-Interfering_Multi-Objective_Alignment",
    "pdf_url": "https://arxiv.org/pdf/2509.24610v2_OrthAlign_Orthogonal_Subspace_Decomposition_for_Non-Interfering_Multi-Objective_Alignment",
    "file_size_mb": 2.1,
    "abstract": "Large language model alignment faces a critical dilemma when addressing multiple human preferences: improvements in one dimension frequently come at the ex- pense of others, creating unavoidable trade-offs between competing objectives like helpfulness and harmlessness. While prior works mainly focus on constraint-based optimization algorithms and data selection strategies to mitigate conflicts, these approaches overlook the fundamental issue of resolving conflicts directly at the parameter level. In this paper, we present OrthAlign, an innovative approach that pioneers a new paradigm by leveraging orthogonal subspace decomposition to fun- damentally resolve conflicts in multi-objective preference alignment. OrthAlign strategically decomposes parameter update spaces into orthogonal subspaces, en- suring that optimization toward different preferences occurs in mathematically non-interfering directions. Building upon this, we provide theoretical guarantees demonstrating that when parameter increments satisfy both orthogonal subspace constraints and spectral norm bounds, the resulting updates exhibit linear Lipschitz growth rather than exponential instability, ensuring stable convergence across all preference dimensions. Extensive experiments show that (I) OrthAlign achieves single-preference improvements ranging from 34.61% to 50.89%↑after multiple- preference alignment across helpful, harmless, and truthful dimensions. (II) with an average overall reward improvement of 13.96%. Our codes are available at https://github.com/233liang/OrthAlign.",
    "keywords": []
  },
  {
    "article_id": "2509.25031v1_Bayesian_Surrogates_for_Risk-Aware_Pre-Assessment_of_Aging_Bridge_Portfolios",
    "title": "2509.25031v1 Bayesian Surrogates for Risk-Aware Pre-Assessment of Aging Bridge Portfolios",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.25031v1_Bayesian_Surrogates_for_Risk-Aware_Pre-Assessment_of_Aging_Bridge_Portfolios.pdf",
    "url": "http://arxiv.org/abs/2509.25031v1_Bayesian_Surrogates_for_Risk-Aware_Pre-Assessment_of_Aging_Bridge_Portfolios",
    "pdf_url": "https://arxiv.org/pdf/2509.25031v1_Bayesian_Surrogates_for_Risk-Aware_Pre-Assessment_of_Aging_Bridge_Portfolios",
    "file_size_mb": 1.22,
    "abstract": "Aging infrastructure portfolios pose a critical resource allocation challenge: decid- ing which structures require intervention and which can safely remain in service. Structural assessments must balance the trade-off between cheaper, conservative analysis methods and accurate but costly simulations that do not scale portfolio- wide. We propose Bayesian neural network (BNN) surrogates for rapid structural pre-assessment of worldwide common bridge types, such as reinforced concrete frame bridges. Trained on a large-scale database of non-linear finite element analyses generated via a parametric pipeline and developed based on the Swiss Federal Railway’s bridge portfolio, the models accurately and efficiently estimate high-fidelity structural analysis results by predicting code compliance factors with calibrated epistemic uncertainty. Our BNN surrogate enables fast, uncertainty- aware triage: flagging likely critical structures and providing guidance where refined analysis is pertinent. We demonstrate the framework’s effectiveness in a real-world case study of a railway underpass, showing its potential to signifi- cantly reduce costs and emissions by avoiding unnecessary analyses and physical interventions across entire infrastructure portfolios.",
    "keywords": []
  },
  {
    "article_id": "2509.25055v2_AlphaSAGE_Structure-Aware_Alpha_Mining_via_GFlowNets_for_Robust_Exploration",
    "title": "2509.25055v2 AlphaSAGE Structure-Aware Alpha Mining via GFlowNets for Robust Exploration",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.25055v2_AlphaSAGE_Structure-Aware_Alpha_Mining_via_GFlowNets_for_Robust_Exploration.pdf",
    "url": "http://arxiv.org/abs/2509.25055v2_AlphaSAGE_Structure-Aware_Alpha_Mining_via_GFlowNets_for_Robust_Exploration",
    "pdf_url": "https://arxiv.org/pdf/2509.25055v2_AlphaSAGE_Structure-Aware_Alpha_Mining_via_GFlowNets_for_Robust_Exploration",
    "file_size_mb": 20.99,
    "abstract": "The automated mining of predictive signals, or alphas, is a central challenge in quantitative finance. While Reinforcement Learning (RL) has emerged as a promising paradigm for generating formulaic alphas, existing frameworks are fun- damentally hampered by a triad of interconnected issues. First, they suffer from reward sparsity, where meaningful feedback is only available upon the comple- tion of a full formula, leading to inefficient and unstable exploration. Second, they rely on semantically inadequate sequential representations of mathematical expressions, failing to capture the structure that determine an alpha’s behavior. Third, the standard RL objective of maximizing expected returns inherently drives policies towards a single optimal mode, directly contradicting the practical need for a diverse portfolio of non-correlated alphas. To overcome these challenges, we introduce AlphaSAGE (Structure-Aware Alpha Mining via Generative Flow Networks for Robust Exploration), a novel framework is built upon three cor- nerstone innovations: (1) a structure-aware encoder based on Relational Graph Convolutional Network (RGCN); (2) a new framework with Generative Flow Networks (GFlowNets); and (3) a dense, multi-faceted reward structure. Em- pirical results demonstrate that AlphaSAGE outperforms existing baselines in mining a more diverse, novel, and highly predictive portfolio of alphas, thereby proposing a new paradigm for automated alpha mining. Our code is available at https://github.com/BerkinChen/AlphaSAGE.",
    "keywords": []
  },
  {
    "article_id": "2509.25592v1_Machine_Learning_Algorithms_for_Improving_Black_Box_Optimization_Solvers",
    "title": "2509.25592v1 Machine Learning Algorithms for Improving Black Box Optimization Solvers",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.25592v1_Machine_Learning_Algorithms_for_Improving_Black_Box_Optimization_Solvers.pdf",
    "url": "http://arxiv.org/abs/2509.25592v1_Machine_Learning_Algorithms_for_Improving_Black_Box_Optimization_Solvers",
    "pdf_url": "https://arxiv.org/pdf/2509.25592v1_Machine_Learning_Algorithms_for_Improving_Black_Box_Optimization_Solvers",
    "file_size_mb": 0.65,
    "abstract": ". Black-box optimization (BBO) addresses problems where objectives are accessible only through costly queries without gradients or explicit structure. Classical derivative-free methods—line search, direct search, and model-based solvers such as Bayesian optimization—form the backbone of BBO, yet often struggle in high-dimensional, noisy, or mixed-integer settings. Recent advances use machine learning (ML) and reinforcement learning (RL) to enhance BBO: ML provides expressive surrogates, adaptive updates, meta- learning portfolios, and generative models, while RL enables dynamic operator configuration, robustness, and meta-optimization across tasks. This paper surveys these developments, covering representative algorithms such as NNs with the modular model-based optimization framework (mlrMBO), zeroth-order adaptive momentum methods (ZO-AdaMM), automated BBO (ABBO), distributed block-wise optimization (DiBB), partition-based Bayesian op- timization (SPBOpt), the transformer-based optimizer (B2Opt), diffusion-model- based BBO, surrogate-assisted RL for differential evolution (Surr-RLDE), robust BBO (RBO), coordinate-ascent model-based optimization with relative entropy (CAS-MORE), log-barrier stochastic gradient descent (LB-SGD), policy improve- ment with black-box (PIBB), and offline Q-learning with Mamba backbones (Q-Mamba). We also review benchmark efforts such as the NeurIPS 2020 BBO Challenge and the MetaBox framework. Overall, we highlight how ML and RL transform classical inexact solvers into more scalable, robust, and adaptive frameworks for real-world optimization.",
    "keywords": [
      "Black-Box Optimization",
      "Machine Learning",
      "Reinforcement Learn-"
    ]
  },
  {
    "article_id": "2509.26058v2_Real-time_Noise_Detection_and_Classification_in_Single-Channel_EEG_A_Lightweight_Machine_Learning_Ap",
    "title": "2509.26058v2 Real-time Noise Detection and Classification in Single-Channel EEG A Lightweight Machine Learning Ap",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.26058v2_Real-time_Noise_Detection_and_Classification_in_Single-Channel_EEG_A_Lightweight_Machine_Learning_Ap.pdf",
    "url": "http://arxiv.org/abs/2509.26058v2_Real-time_Noise_Detection_and_Classification_in_Single-Channel_EEG_A_Lightweight_Machine_Learning_Ap",
    "pdf_url": "https://arxiv.org/pdf/2509.26058v2_Real-time_Noise_Detection_and_Classification_in_Single-Channel_EEG_A_Lightweight_Machine_Learning_Ap",
    "file_size_mb": 0.84,
    "abstract": "Electroencephalogram (EEG) artifact detection in real-world settings faces significant challenges such as computational inefficiency in multi-channel methods, poor robustness to simultaneous noise, and trade-offs between accuracy and complexity in deep learning models. We propose a hybrid spectral-temporal framework for real-time detection and classification of ocular (EOG), muscular (EMG), and white noise artifacts in single-channel EEG. This method, in contrast to other approaches, combines time-domain low-pass filtering (targeting low-frequency EOG) and frequency-domain power spectral density (PSD) analysis (capturing broad-spectrum EMG), followed by PCA- optimized feature fusion to minimize redundancy while preserving discriminative information. This feature engineering strategy allows a lightweight multi-layer perceptron (MLP) architecture to outperform advanced CNNs and RNNs by achieving 99% accuracy at low SNRs (SNR -7) dB and >90% accuracy in moderate noise (SNR 4 dB). Additionally, this framework addresses the unexplored problem of simultaneous multi-source contamination (EMG+EOG+white noise), where it maintains 96% classification accuracy despite overlapping artifacts. With 30- second training times (97% faster than CNNs) and robust performance across SNR levels, this framework bridges the gap between clinical applicability and computational efficiency, which enables real-time use in wearable brain- computer interfaces. This work also challenges the ubiquitous dependence on model depth for EEG artifact detection by demonstrating that domain-informed feature fusion surpasses complex architecture in noisy scenarios.",
    "keywords": [
      "Electroencephalography",
      "Noise classification",
      "Ocular artifacts",
      "Muscular artifacts",
      "Deep neural"
    ]
  },
  {
    "article_id": "2509.26150v1_Bubble_Bubble_AIs_Rumble_Why_Global_Financial_Regulatory_Incident_Reporting_is_Our_Shield_Against_Sy",
    "title": "2509.26150v1 Bubble Bubble AIs Rumble Why Global Financial Regulatory Incident Reporting is Our Shield Against Sy",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2509.26150v1_Bubble_Bubble_AIs_Rumble_Why_Global_Financial_Regulatory_Incident_Reporting_is_Our_Shield_Against_Sy.pdf",
    "url": "http://arxiv.org/abs/2509.26150v1_Bubble_Bubble_AIs_Rumble_Why_Global_Financial_Regulatory_Incident_Reporting_is_Our_Shield_Against_Sy",
    "pdf_url": "https://arxiv.org/pdf/2509.26150v1_Bubble_Bubble_AIs_Rumble_Why_Global_Financial_Regulatory_Incident_Reporting_is_Our_Shield_Against_Sy",
    "file_size_mb": 0.49,
    "abstract": "\"Double, double toil and trouble; Fire burn and cauldron bubble.\" As Shakespeare's witches foretold chaos through cryptic prophecies, modern capital markets grapple with sys- temic risks concealed by opaque AI systems. According to IMF, the August 5, 2024, plunge in Japanese and U.S. equi- ties can be linked to algorithmic trading yet absent from ex- isting AI incidents database exemplifies this transparency cri- sis. Current AI incident databases, reliant on crowdsourcing or news scraping, systematically overlook capital market anomalies, particularly in algorithmic and high-frequency trading. We address this critical gap by proposing a regula- tory-grade global database that elegantly synthesises post- trade reporting frameworks with proven incident documenta- tion models from healthcare and aviation. Our framework's temporal data omission technique masking timestamps while preserving percentage-based metrics enables sophisticated cross-jurisdictional analysis of emerging risks while safe- guarding confidential business information. Synthetic data validation (modelled after real life published incidents , sen- timents, data) (n=2,999 incidents) reveals compelling pat- terns: systemic risks transcending geographical boundaries, market manipulation clusters distinctly identifiable via K- means algorithms, and AI system typology exerting signifi- cantly greater influence on trading behaviour than geograph- ical location, This tripartite solution empowers regulators with unprecedented cross-jurisdictional oversight, financial institutions with seamless compliance integration, and inves- tors with critical visibility into previously obscured AI-driven vulnerabilities. We call for immediate action to strengthen risk management and foster resilience in AI-driven financial markets against the volatile \"cauldron\" of AI-driven systemic risks., promoting global financial stability through enhanced transparency and coordinated oversight.",
    "keywords": []
  },
  {
    "article_id": "2510.00029v1_Enhancing_Safety_in_Diabetic_Retinopathy_Detection_Uncertainty-Aware_Deep_Learning_Models_with_Rejec",
    "title": "2510.00029v1 Enhancing Safety in Diabetic Retinopathy Detection Uncertainty-Aware Deep Learning Models with Rejec",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.00029v1_Enhancing_Safety_in_Diabetic_Retinopathy_Detection_Uncertainty-Aware_Deep_Learning_Models_with_Rejec.pdf",
    "url": "http://arxiv.org/abs/2510.00029v1_Enhancing_Safety_in_Diabetic_Retinopathy_Detection_Uncertainty-Aware_Deep_Learning_Models_with_Rejec",
    "pdf_url": "https://arxiv.org/pdf/2510.00029v1_Enhancing_Safety_in_Diabetic_Retinopathy_Detection_Uncertainty-Aware_Deep_Learning_Models_with_Rejec",
    "file_size_mb": 0.16,
    "abstract": "—Diabetic retinopathy (DR) is a major cause of visual impairment, and effective treatment options depend heavily on timely and accurate diagnosis. Deep learning models have demonstrated great success identifying DR from retinal images. However, relying only on predictions made by models, without any indication of model confidence, creates uncertainty and poses significant risk in clinical settings. This paper investigates an alternative in uncertainty-aware deep learning models, includ- ing a rejection mechanism to reject low-confidence predictions, contextualized by deferred decision-making in clinical practice. The results show there is a trade-off between prediction coverage and coverage reliability. The Variational Bayesian model adopted a more conservative strategy when predicting DR, subsequently rejecting the uncertain predictions. The model is evaluated by means of important performance metrics such as Accuracy on accepted predictions, the proportion of accepted cases (coverage), the rejection-ratio, and Expected Calibration Error (ECE). The findings also demonstrate a clear trade-off between accuracy and caution, establishing that the use of uncertainty estimation and selective rejection improves the model’s reliability in safety- critical diagnostic use cases.",
    "keywords": [
      "VBLL",
      "Rejection threshold",
      "Expected Calibra-"
    ]
  },
  {
    "article_id": "2510.00078v1_Adaptive_and_Resource-efficient_Agentic_AI_Systems_for_Mobile_and_Embedded_Devices_A_Survey",
    "title": "2510.00078v1 Adaptive and Resource-efficient Agentic AI Systems for Mobile and Embedded Devices A Survey",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.00078v1_Adaptive_and_Resource-efficient_Agentic_AI_Systems_for_Mobile_and_Embedded_Devices_A_Survey.pdf",
    "url": "http://arxiv.org/abs/2510.00078v1_Adaptive_and_Resource-efficient_Agentic_AI_Systems_for_Mobile_and_Embedded_Devices_A_Survey",
    "pdf_url": "https://arxiv.org/pdf/2510.00078v1_Adaptive_and_Resource-efficient_Agentic_AI_Systems_for_Mobile_and_Embedded_Devices_A_Survey",
    "file_size_mb": 21.17,
    "abstract": "—Large foundation models (FMs) such as LLMs, VLMs, diffusion models, and MLLMs have shifted AI from frag- mented, task-specific models toward versatile cognitive systems. In parallel, the AI agents has been refreshed by FMs as their cognitive core, enabling autonomy, perception, planning, and self- reflection in dynamic environments. Together, these shifts open opportunities for agentic AI on mobile and edge platforms, where real-world applications demand low-latency, energy-efficient, and adaptive intelligence. However, current surveys mainly focus on static FM optimization or generic agents, overlooking mobile- specific challenges of resource constraints, runtime adaptability, and diverse conditions. This article fills that gap by providing the first systematic survey on adaptive and resource-efficient agentic AI systems on mobile/edge devices. We propose a novel taxonomy covering elastic FM inference, test-time adaptation, dynamic multimodal integration, and application-driven optimization, and we outline open issues and evaluation methodologies to inspire future research at the intersection of FMs, agents, and mo- bile/edge intelligence. We believe this survey can help readers to understand the connections between enabling technologies while promoting further discussions.",
    "keywords": [
      "Adaptive and resource-efficient",
      "Agentic AI"
    ]
  },
  {
    "article_id": "2510.00774v2_GeoGraph_Geometric_and_Graph-based_Ensemble_Descriptors_for_Intrinsically_Disordered_Proteins",
    "title": "2510.00774v2 GeoGraph Geometric and Graph-based Ensemble Descriptors for Intrinsically Disordered Proteins",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.00774v2_GeoGraph_Geometric_and_Graph-based_Ensemble_Descriptors_for_Intrinsically_Disordered_Proteins.pdf",
    "url": "http://arxiv.org/abs/2510.00774v2_GeoGraph_Geometric_and_Graph-based_Ensemble_Descriptors_for_Intrinsically_Disordered_Proteins",
    "pdf_url": "https://arxiv.org/pdf/2510.00774v2_GeoGraph_Geometric_and_Graph-based_Ensemble_Descriptors_for_Intrinsically_Disordered_Proteins",
    "file_size_mb": 0.25,
    "abstract": "While deep learning has revolutionized the prediction of rigid protein structures, modelling the conformational ensembles of Intrinsically Disordered Proteins (IDPs) remains a key frontier. Current AI paradigms present a trade-off: Protein Language Models (PLMs) capture evolutionary statistics but lack explicit physical grounding, while generative models trained to model full ensembles are computationally expen- sive. In this work we critically assess these limits and propose a path forward. We introduce GeoGraph, a simulation-informed surrogate trained to predict ensemble- averaged statistics of residue–residue contact-map topology directly from sequence. By featurizing coarse-grained molecular dynamics simulations into residue- and sequence-level graph descriptors, we create a robust and information-rich learning target. Our evaluation demonstrates that this approach yields representations that are more predictive of key biophysical properties than existing methods.",
    "keywords": []
  },
  {
    "article_id": "2510.00960v1_A_Neuro-Fuzzy_System_for_Interpretable_Long-Term_Stock_Market_Forecasting",
    "title": "2510.00960v1 A Neuro-Fuzzy System for Interpretable Long-Term Stock Market Forecasting",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.00960v1_A_Neuro-Fuzzy_System_for_Interpretable_Long-Term_Stock_Market_Forecasting.pdf",
    "url": "http://arxiv.org/abs/2510.00960v1_A_Neuro-Fuzzy_System_for_Interpretable_Long-Term_Stock_Market_Forecasting",
    "pdf_url": "https://arxiv.org/pdf/2510.00960v1_A_Neuro-Fuzzy_System_for_Interpretable_Long-Term_Stock_Market_Forecasting",
    "file_size_mb": 0.36,
    "abstract": "—In the complex landscape of multivariate time se- ries forecasting, achieving both accuracy and interpretability remains a significant challenge. This paper introduces the Fuzzy Transformer (Fuzzformer), a novel recurrent neural network architecture combined with multi-head self-attention and fuzzy inference systems to analyze multivariate stock market data and conduct long-term time series forecasting. The method leverages LSTM networks and temporal attention to condense multivariate data into interpretable features suitable for fuzzy inference systems. The resulting architecture offers comparable forecasting performance to conventional models such as ARIMA and LSTM while providing meaningful information flow within the network. The method was examined on the real world stock market index S&P500. Initial results show potential for inter- pretable forecasting and identify current performance tradeoffs, suggesting practical application in understanding and forecasting stock market behavior.",
    "keywords": [
      "Stock Market Prediction",
      "LSTM",
      "Multi-Head"
    ]
  },
  {
    "article_id": "2510.01031v1_Secure_and_reversible_face_anonymization_with_diffusion_models",
    "title": "2510.01031v1 Secure and reversible face anonymization with diffusion models",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.01031v1_Secure_and_reversible_face_anonymization_with_diffusion_models.pdf",
    "url": "http://arxiv.org/abs/2510.01031v1_Secure_and_reversible_face_anonymization_with_diffusion_models",
    "pdf_url": "https://arxiv.org/pdf/2510.01031v1_Secure_and_reversible_face_anonymization_with_diffusion_models",
    "file_size_mb": 3.91,
    "abstract": "Face images processed by computer vision algorithms contain sensitive personal information that malicious actors can capture without consent. These privacy and security risks highlight the need for effective face anonymization meth- ods. Current methods struggle to propose a good trade-off between a secure scheme with high-quality image generation and reversibility for later person authentication. Diffusion- based approaches produce high-quality anonymized images but lack the secret key mechanism to ensure that only au- thorized parties can reverse the process. In this paper, we introduce, to our knowledge, the first secure, high-quality reversible anonymization method based on a diffusion model. We propose to combine the secret key with the latent faces representation of the diffusion model. To preserve identity- irrelevant features, generation is constrained by a facial mask, maintaining high-quality images. By using a deterministic forward and backward diffusion process, our approach en- forces that the original face can be recovered with the correct secret key. We also show that the proposed method produces anonymized faces that are less visually similar to the original faces, compared to other previous work.",
    "keywords": [
      "Multimedia security",
      "Image obscuration"
    ]
  },
  {
    "article_id": "2510.01446v1_Can_Machine_Learning_Algorithms_Outperform_Traditional_Models_for_Option_Pricing",
    "title": "2510.01446v1 Can Machine Learning Algorithms Outperform Traditional Models for Option Pricing",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.01446v1_Can_Machine_Learning_Algorithms_Outperform_Traditional_Models_for_Option_Pricing.pdf",
    "url": "http://arxiv.org/abs/2510.01446v1_Can_Machine_Learning_Algorithms_Outperform_Traditional_Models_for_Option_Pricing",
    "pdf_url": "https://arxiv.org/pdf/2510.01446v1_Can_Machine_Learning_Algorithms_Outperform_Traditional_Models_for_Option_Pricing",
    "file_size_mb": 0.29,
    "abstract": "—This study investigates the application of machine learning techniques, specifically Neural Networks, Random Forests, and CatBoost for option pricing, in comparison to traditional models such as Black-Scholes and Heston Model. Using both synthetically generated data and real market option data, each model is evaluated in predicting the option price. The results show that machine learning models can capture complex, non-linear relationships in option prices and, in several cases, outperform both Black-Scholes and Heston. These findings highlight the potential of data-driven methods to improve pricing accuracy and better reflect market dynamics.",
    "keywords": [
      "Option pricing",
      "Black-Scholes",
      "Heston model"
    ]
  },
  {
    "article_id": "2510.01451v1_Financial_Stability_Implications_of_Generative_AI_Taming_the_Animal_Spirits",
    "title": "2510.01451v1 Financial Stability Implications of Generative AI Taming the Animal Spirits",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.01451v1_Financial_Stability_Implications_of_Generative_AI_Taming_the_Animal_Spirits.pdf",
    "url": "http://arxiv.org/abs/2510.01451v1_Financial_Stability_Implications_of_Generative_AI_Taming_the_Animal_Spirits",
    "pdf_url": "https://arxiv.org/pdf/2510.01451v1_Financial_Stability_Implications_of_Generative_AI_Taming_the_Animal_Spirits",
    "file_size_mb": 1.97,
    "abstract": null,
    "keywords": [
      "Herd behavior",
      "large language models",
      "AI-powered traders",
      "financial markets",
      "financial"
    ]
  },
  {
    "article_id": "2510.02779v2_Optimal_Rates_for_Generalization_of_Gradient_Descent_for_Deep_ReLU_Classification",
    "title": "2510.02779v2 Optimal Rates for Generalization of Gradient Descent for Deep ReLU Classification",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.02779v2_Optimal_Rates_for_Generalization_of_Gradient_Descent_for_Deep_ReLU_Classification.pdf",
    "url": "http://arxiv.org/abs/2510.02779v2_Optimal_Rates_for_Generalization_of_Gradient_Descent_for_Deep_ReLU_Classification",
    "pdf_url": "https://arxiv.org/pdf/2510.02779v2_Optimal_Rates_for_Generalization_of_Gradient_Descent_for_Deep_ReLU_Classification",
    "file_size_mb": 0.62,
    "abstract": "Recent advances have significantly improved our understanding of the general- ization performance of gradient descent (GD) methods in deep neural networks. A natural and fundamental question is whether GD can achieve generalization rates comparable to the minimax optimal rates established in the kernel setting. Existing results either yield suboptimal rates of O(1/√n), or focus on networks with smooth activation functions, incurring exponential dependence on network depth L. In this work, we establish optimal generalization rates for GD with deep ReLU networks by carefully trading off optimization and generalization errors, achieving only polynomial dependence on depth. Specifically, under the assump- tion that the data are NTK separable from the margin γ, we prove an excess risk rate of eO(L4(1 + γL2)/(nγ2)), which aligns with the optimal SVM-type rate eO(1/(nγ2)) up to depth-dependent factors. A key technical contribution is our novel control of activation patterns near a reference model, enabling a sharper Rademacher complexity bound for deep ReLU networks trained with gradient descent.",
    "keywords": []
  },
  {
    "article_id": "2510.02822v1_FlexiQ_Adaptive_Mixed-Precision_Quantization_for_LatencyAccuracy_Trade-Offs_in_Deep_Neural_Networks",
    "title": "2510.02822v1 FlexiQ Adaptive Mixed-Precision Quantization for LatencyAccuracy Trade-Offs in Deep Neural Networks",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.02822v1_FlexiQ_Adaptive_Mixed-Precision_Quantization_for_LatencyAccuracy_Trade-Offs_in_Deep_Neural_Networks.pdf",
    "url": "http://arxiv.org/abs/2510.02822v1_FlexiQ_Adaptive_Mixed-Precision_Quantization_for_LatencyAccuracy_Trade-Offs_in_Deep_Neural_Networks",
    "pdf_url": "https://arxiv.org/pdf/2510.02822v1_FlexiQ_Adaptive_Mixed-Precision_Quantization_for_LatencyAccuracy_Trade-Offs_in_Deep_Neural_Networks",
    "file_size_mb": 2.01,
    "abstract": "Neural networks commonly execute on hardware accelera- tors such as NPUs and GPUs for their size and computation overhead. These accelerators are costly and it is hard to scale their resources to handle real-time workload fluctuations. We present FlexiQ, an adaptive mixed-precision quantiza- tion scheme for computer vision models. FlexiQ selectively applies low-bitwidth computation to feature channels with small value ranges and employs an efficient bit-lowering method to minimize quantization errors while maintain- ing inference accuracy. Furthermore, FlexiQ adjusts its low- bitwidth channel ratio in real time, enabling quantized mod- els to effectively manage fluctuating inference workload. We implemented FlexiQ prototype, including the mixed- precision inference runtime on our custom NPU and GPUs. Evaluated on eleven convolution- and transformer-based vi- sion models, FlexiQ achieves on average 6.6% higher accuracy for 4-bit models with finetuning and outperforms four state- of-the-art quantization techniques. Moreover, our mixed- precision models achieved an efficient accuracy-latency trade- off, with the 50% 4-bit model incurring only 0.6% accuracy loss while achieving 40% of the speedup of the 100% 4-bit model over 8-bit model. Latency evaluations on our NPU and GPUs confirmed that FlexiQ introduces minimal runtime overhead, demonstrating its hardware efficiency and overall performance benefits. CCS Concepts: • Computing methodologies →Machine learning. ∗Corresponding author This work is licensed under a Creative Commons Attribution 4.0 Interna- tional License. EUROSYS ’26, Edinburgh, Scotland Uk © 2026 Copyright held by the owner/author(s). ACM ISBN 979-8-4007-2212-7/26/04 https://doi.org/10.1145/3767295.3769351",
    "keywords": [
      "Deep learning systems",
      "Quantization"
    ]
  },
  {
    "article_id": "2510.02986v1_FR-LUX_Friction-Aware_Regime-Conditioned_Policy_Optimization_for_Implementable_Portfolio_Management",
    "title": "2510.02986v1 FR-LUX Friction-Aware Regime-Conditioned Policy Optimization for Implementable Portfolio Management",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.02986v1_FR-LUX_Friction-Aware_Regime-Conditioned_Policy_Optimization_for_Implementable_Portfolio_Management.pdf",
    "url": "http://arxiv.org/abs/2510.02986v1_FR-LUX_Friction-Aware_Regime-Conditioned_Policy_Optimization_for_Implementable_Portfolio_Management",
    "pdf_url": "https://arxiv.org/pdf/2510.02986v1_FR-LUX_Friction-Aware_Regime-Conditioned_Policy_Optimization_for_Implementable_Portfolio_Management",
    "file_size_mb": 1.46,
    "abstract": "Transaction costs and regime shifts are the main reasons why paper portfolios fail in live trading. We develop FR–LUX (Friction–aware, Regime–conditioned Learning under eXecution costs), a reinforcement–learning framework that learns after–cost trading policies and remains robust across volatility–liquidity regimes. FR–LUX integrates three ingredients: (i) a microstructure–consistent execution model combining proportional and impact costs, directly embedded in the reward; (ii) a trade–space trust region that constrains changes in inventory flow rather than only logits, yielding stable, low–turnover updates; and (iii) explicit regime conditioning so the policy specializes to LL/LH/HL/HH states without fragmenting the data. On a 4 × 5 grid of regimes and cost levels (0–50 bps) with three seeds per cell, FR–LUX achieves the top average Sharpe across all 20 scenarios with narrow bootstrap confidence intervals, maintains a flatter cost–performance slope than strong baselines (vanilla PPO, mean–variance with/without caps, risk–parity), and attains superior risk–return efficiency for a given turnover budget. Pairwise scenario–level improvements are strictly positive and remain statistically significant after Romano–Wolf stepdown and HAC–aware Sharpe comparisons. We provide formal guarantees: existence of an optimal stationary policy under convex frictions; a monotonic improvement lower bound under a KL trust region with explicit remainder terms; an upper bound on long–run turnover and an induced inaction band due to proportional costs; a strictly positive value advantage for regime–conditioned policies when cross–regime actions are separated; and robustness of realized value to cost misspecification. The methodology is implementable—costs are calibrated from standard liquidity proxies, scenario–level inference avoids pseudo–replication, and all figures and tables are reproducible from our artifacts.",
    "keywords": [
      "transaction costs",
      "market microstructure",
      "regime switching",
      "reinforcement learning",
      "portfolio optimization"
    ]
  },
  {
    "article_id": "2510.03207v1_To_Distill_or_Decide_Understanding_the_Algorithmic_Trade-off_in_Partially_Observable_Reinforcement_L",
    "title": "2510.03207v1 To Distill or Decide Understanding the Algorithmic Trade-off in Partially Observable Reinforcement L",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.03207v1_To_Distill_or_Decide_Understanding_the_Algorithmic_Trade-off_in_Partially_Observable_Reinforcement_L.pdf",
    "url": "http://arxiv.org/abs/2510.03207v1_To_Distill_or_Decide_Understanding_the_Algorithmic_Trade-off_in_Partially_Observable_Reinforcement_L",
    "pdf_url": "https://arxiv.org/pdf/2510.03207v1_To_Distill_or_Decide_Understanding_the_Algorithmic_Trade-off_in_Partially_Observable_Reinforcement_L",
    "file_size_mb": 10.38,
    "abstract": "Partial observability is a notorious challenge in reinforcement learning (RL), due to the need to learn complex, history-dependent policies. Recent empirical successes have used privileged expert distillation — which leverages availability of latent state information during training (e.g., from a simulator) to learn and imitate the optimal latent, Markovian policy — to disentangle the task of “learning to see” from “learning to act” (Pan et al., 2017; Choudhury et al., 2018; Chen et al., 2019). While expert distillation is more computationally efficient than RL without latent state information, it also has well-documented failure modes. In this paper — through a simple but instructive theoretical model called the perturbed Block MDP, and controlled experiments on challenging simulated locomotion tasks — we investigate the algorithmic trade-off between privileged expert distillation and standard RL without privileged information. Our main findings are: (1) The trade-off empirically hinges on the stochasticity of the latent dynamics, as theoretically predicted by contrasting approximate decodability with belief contraction in the perturbed Block MDP; and (2) The optimal latent policy is not always the best latent policy to distill. Our results suggest new guidelines for effectively exploiting privileged information, potentially advancing the efficiency of policy learning across many practical partially observable domains.",
    "keywords": []
  },
  {
    "article_id": "2510.03209v1_Joint_Bidding_on_Intraday_and_Frequency_Containment_Reserve_Markets",
    "title": "2510.03209v1 Joint Bidding on Intraday and Frequency Containment Reserve Markets",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.03209v1_Joint_Bidding_on_Intraday_and_Frequency_Containment_Reserve_Markets.pdf",
    "url": "http://arxiv.org/abs/2510.03209v1_Joint_Bidding_on_Intraday_and_Frequency_Containment_Reserve_Markets",
    "pdf_url": "https://arxiv.org/pdf/2510.03209v1_Joint_Bidding_on_Intraday_and_Frequency_Containment_Reserve_Markets",
    "file_size_mb": 0.82,
    "abstract": "As renewable energy integration increases supply variability, battery energy storage systems (BESS) present a viable solution for balancing supply and demand. This paper proposes a novel approach for optimizing battery BESS participation in multiple electricity markets. We develop a joint bidding strategy that combines participation in the primary frequency reserve market with continuous trading in the intraday market, addressing a gap in the extant literature which typically considers these markets in isolation or simplifies the continuous nature of intraday trading. Our ap- proach utilizes a mixed integer linear programming implementation of the rolling intrinsic algorithm for intraday decisions and state of charge recovery, alongside a learned classifier strategy (LCS) that determines optimal capacity allocation between markets. A comprehensive out-of-sample backtest over more than one year of historical German market data validates our approach: The LCS in- creases overall profits by over 4% compared to the best-performing static strategy and by more than 3% over a naive dynamic benchmark. Crucially, our method closes the gap to a theoretical perfect foresight strategy to just 4%, demonstrating the effectiveness of dynamic, learning-based allocation in a complex, multi-market environment.",
    "keywords": []
  },
  {
    "article_id": "2510.03282v1_Discovering_Transformer_Circuits_via_a_Hybrid_Attribution_and_Pruning_Framework",
    "title": "2510.03282v1 Discovering Transformer Circuits via a Hybrid Attribution and Pruning Framework",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.03282v1_Discovering_Transformer_Circuits_via_a_Hybrid_Attribution_and_Pruning_Framework.pdf",
    "url": "http://arxiv.org/abs/2510.03282v1_Discovering_Transformer_Circuits_via_a_Hybrid_Attribution_and_Pruning_Framework",
    "pdf_url": "https://arxiv.org/pdf/2510.03282v1_Discovering_Transformer_Circuits_via_a_Hybrid_Attribution_and_Pruning_Framework",
    "file_size_mb": 1.79,
    "abstract": "Interpreting language models often involves circuit analysis, which aims to identify sparse subnetworks, or circuits, that accomplish specific tasks. Existing circuit discovery algorithms face a fundamental trade-off: attribution patching is fast but unfaithful to the full model, while edge pruning is faithful but computation- ally expensive. This research proposes a hybrid attribution and pruning (HAP) framework that uses attribution patching to identify a high-potential subgraph, then applies edge pruning to extract a faithful circuit from it. We show that HAP is 46% faster than baseline algorithms without sacrificing circuit faithfulness. Furthermore, we present a case study on the Indirect Object Identification task, showing that our method preserves cooperative circuit components (e.g. S-inhibition heads) that attribution patching methods prune at high sparsity. Our results show that HAP could be an effective approach for improving the scalability of mechanistic interpretability research to larger models3.",
    "keywords": []
  },
  {
    "article_id": "2510.03633v1_Predicting_Stock_Price_Movement_with_LLM-Enhanced_Tweet_Emotion_Analysis",
    "title": "2510.03633v1 Predicting Stock Price Movement with LLM-Enhanced Tweet Emotion Analysis",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.03633v1_Predicting_Stock_Price_Movement_with_LLM-Enhanced_Tweet_Emotion_Analysis.pdf",
    "url": "http://arxiv.org/abs/2510.03633v1_Predicting_Stock_Price_Movement_with_LLM-Enhanced_Tweet_Emotion_Analysis",
    "pdf_url": "https://arxiv.org/pdf/2510.03633v1_Predicting_Stock_Price_Movement_with_LLM-Enhanced_Tweet_Emotion_Analysis",
    "file_size_mb": 0.31,
    "abstract": "Accurately predicting short-term stock price movement remains a challenging task due to the market’s inherent volatility and sensitivity to investor sentiment. This paper discusses a deep learning framework that integrates emotion features extracted from tweet data with historical stock price information to forecast significant price changes on the following day. We utilize Meta’s Llama 3.1-8B-Instruct model to preprocess tweet data, thereby enhancing the quality of emotion features derived from three emotion analysis approaches: a transformer- based DistilRoBERTa classifier from the Hugging Face library and two lexicon-based methods using National Research Council Canada (NRC) resources. These features are combined with previous-day stock price data to train a Long Short-Term Memory (LSTM) model. Experimental results on TSLA, AAPL, and AMZN stocks show that all three emotion analysis methods improve the average accuracy for predicting significant price movements, compared to the baseline model using only historical stock prices, which yields an accuracy of 13.5%. The DistilRoBERTa-based stock prediction model achives the best performance, with accuracy rising from 23.6% to 38.5% when using LLaMA-enhanced emotion analysis. These results demonstrate that using large language models to preprocess tweet content enhances the effectiveness of emotion analysis which in turn improves the accuracy of predicting significant stock price movements.",
    "keywords": [
      "Emotion Analysis",
      "Stock Prediction",
      "Social Media",
      "Classification",
      "Large Language Model"
    ]
  },
  {
    "article_id": "2510.03657v1_Optimising_Battery_Energy_Storage_System_Trading_via_Energy_Market_Operator_Price_Forecast",
    "title": "2510.03657v1 Optimising Battery Energy Storage System Trading via Energy Market Operator Price Forecast",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.03657v1_Optimising_Battery_Energy_Storage_System_Trading_via_Energy_Market_Operator_Price_Forecast.pdf",
    "url": "http://arxiv.org/abs/2510.03657v1_Optimising_Battery_Energy_Storage_System_Trading_via_Energy_Market_Operator_Price_Forecast",
    "pdf_url": "https://arxiv.org/pdf/2510.03657v1_Optimising_Battery_Energy_Storage_System_Trading_via_Energy_Market_Operator_Price_Forecast",
    "file_size_mb": 5.97,
    "abstract": null,
    "keywords": []
  },
  {
    "article_id": "2510.03899v2_Fair_Minimum_Labeling_Efficient_Temporal_Network_Activations_for_Reachability_and_Equity",
    "title": "2510.03899v2 Fair Minimum Labeling Efficient Temporal Network Activations for Reachability and Equity",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.03899v2_Fair_Minimum_Labeling_Efficient_Temporal_Network_Activations_for_Reachability_and_Equity.pdf",
    "url": "http://arxiv.org/abs/2510.03899v2_Fair_Minimum_Labeling_Efficient_Temporal_Network_Activations_for_Reachability_and_Equity",
    "pdf_url": "https://arxiv.org/pdf/2510.03899v2_Fair_Minimum_Labeling_Efficient_Temporal_Network_Activations_for_Reachability_and_Equity",
    "file_size_mb": 0.72,
    "abstract": "Balancing resource efficiency and fairness is critical in networked systems that support modern learning applications. We introduce the Fair Minimum Labeling (FML) problem: the task of designing a minimum-cost temporal edge activation plan that ensures each group of nodes in a network has sufficient access to a designated target set, according to specified coverage requirements. FML captures key trade-offs in systems where edge activations incur resource costs and equitable access is essential, such as distributed data collection, update dissemination in edge- cloud systems, and fair service restoration in critical infrastructure. We show that FML is NP-hard and Ω(log |V |)-hard to approximate, where V is the set of nodes, and we present probabilistic approximation algorithms that match this bound, achieving the best possible guarantee for the activation cost. We demonstrate the practical utility of FML in a fair multi-source data aggregation task for training a shared model. Empirical results show that FML enforces group-level fairness with substantially lower activation cost than baseline heuristics, underscoring its potential for building resource-efficient, equitable temporal reachability in learning- integrated networks.",
    "keywords": []
  },
  {
    "article_id": "2510.04237v3_Truncated_Kernel_Stochastic_Gradient_Descent_with_General_Losses_and_Spherical_Radial_Basis_Function",
    "title": "2510.04237v3 Truncated Kernel Stochastic Gradient Descent with General Losses and Spherical Radial Basis Function",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.04237v3_Truncated_Kernel_Stochastic_Gradient_Descent_with_General_Losses_and_Spherical_Radial_Basis_Function.pdf",
    "url": "http://arxiv.org/abs/2510.04237v3_Truncated_Kernel_Stochastic_Gradient_Descent_with_General_Losses_and_Spherical_Radial_Basis_Function",
    "pdf_url": "https://arxiv.org/pdf/2510.04237v3_Truncated_Kernel_Stochastic_Gradient_Descent_with_General_Losses_and_Spherical_Radial_Basis_Function",
    "file_size_mb": 3.87,
    "abstract": "In this paper, we propose a novel kernel stochastic gradient descent (SGD) algorithm for large-scale supervised learning with general losses. Compared to traditional kernel SGD, our algorithm improves efficiency and scalability through an innovative regulariza- tion strategy. By leveraging the infinite series expansion of spherical radial basis functions, this strategy projects the stochastic gradient onto a finite-dimensional hypothesis space, which is adaptively scaled according to the bias-variance trade-off, thereby enhancing generalization performance. Based on a new estimation of the spectral structure of the kernel-induced covariance operator, we develop an analytical framework that unifies opti- mization and generalization analyses. We prove that both the last iterate and the suffix average converge at minimax-optimal rates, and we further establish optimal strong con- vergence in the reproducing kernel Hilbert space. Our framework accommodates a broad class of classical loss functions, including least-squares, Huber, and logistic losses. More- over, the proposed algorithm significantly reduces computational complexity and achieves optimal storage complexity by incorporating coordinate-wise updates from linear SGD, thereby avoiding the costly pairwise operations typical of kernel SGD and enabling effi- cient processing of streaming data. Finally, extensive numerical experiments demonstrate the efficiency of our approach.",
    "keywords": [
      "and phrases: Kernel stochastic gradient descent",
      "Online learning",
      "General"
    ]
  },
  {
    "article_id": "2510.04432v1_Trade-off_in_Estimating_the_Number_of_Byzantine_Clients_in_Federated_Learning",
    "title": "2510.04432v1 Trade-off in Estimating the Number of Byzantine Clients in Federated Learning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.04432v1_Trade-off_in_Estimating_the_Number_of_Byzantine_Clients_in_Federated_Learning.pdf",
    "url": "http://arxiv.org/abs/2510.04432v1_Trade-off_in_Estimating_the_Number_of_Byzantine_Clients_in_Federated_Learning",
    "pdf_url": "https://arxiv.org/pdf/2510.04432v1_Trade-off_in_Estimating_the_Number_of_Byzantine_Clients_in_Federated_Learning",
    "file_size_mb": 0.47,
    "abstract": "Federated learning has attracted increasing attention at recent large-scale optimization and machine learning research and applications, but is also vulnerable to Byzantine clients that can send any erroneous signals. Robust aggregators are commonly used to resist Byzantine clients. This usually requires to estimate the unknown number f of Byzantine clients, and thus accordingly select the aggregators with proper degree of robustness (i.e., the maximum number ˆf of Byzantine clients allowed by the aggregator). Such an estimation should have important effect on the performance, which has not been systematically studied to our knowledge. This work will fill in the gap by theoretically analyzing the worst-case error of aggregators as well as its induced federated learning algorithm for any cases of ˆf and f. Specifically, we will show that underestimation ( ˆf < f) can lead to arbitrarily poor performance for both aggregators and federated learning. For non-underestimation ( ˆf ≥f), we have proved optimal lower and upper bounds of the same order on the errors of both aggregators and federated learning. All these optimal bounds are proportional to ˆf/(n −f −ˆf) with n clients, which monotonically increases with larger ˆf. This indicates a fundamental trade-off: while an aggregator with a larger robustness degree ˆf can solve federated learning problems of wider range f ∈[0, ˆf], the performance can deteriorate when there are actually fewer or even no Byzantine clients (i.e., f ∈[0, ˆf)).",
    "keywords": []
  },
  {
    "article_id": "2510.04563v1_Stochastic_Approximation_Methods_for_Distortion_Risk_Measure_Optimization",
    "title": "2510.04563v1 Stochastic Approximation Methods for Distortion Risk Measure Optimization",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.04563v1_Stochastic_Approximation_Methods_for_Distortion_Risk_Measure_Optimization.pdf",
    "url": "http://arxiv.org/abs/2510.04563v1_Stochastic_Approximation_Methods_for_Distortion_Risk_Measure_Optimization",
    "pdf_url": "https://arxiv.org/pdf/2510.04563v1_Stochastic_Approximation_Methods_for_Distortion_Risk_Measure_Optimization",
    "file_size_mb": 2.84,
    "abstract": "Distortion Risk Measures (DRMs) capture risk preferences in decision-making and serve as general criteria for managing uncertainty. This paper proposes gradient descent algorithms for DRM optimization based on two dual representations: the Distortion-Measure (DM) form and Quantile-Function (QF) form. The DM-form employs a three-timescale algo- rithm to track quantiles, compute their gradients, and update decision variables, utilizing the Generalized Likelihood Ratio and kernel-based density estimation. The QF-form pro- vides a simpler two-timescale approach that avoids the need for complex quantile gradient estimation. A hybrid form integrates both approaches, applying the DM-form for robust performance around distortion function jumps and the QF-form for efficiency in smooth regions. Proofs of strong convergence and convergence rates for the proposed algorithms are provided. In particular, the DM-form achieves an optimal rate of O(k−4/7), while the QF-form attains a faster rate of O(k−2/3). Numerical experiments confirm their effective- ness and demonstrate substantial improvements over baselines in robust portfolio selection tasks. The method’s scalability is further illustrated through integration into deep rein- forcement learning. Specifically, a DRM-based Proximal Policy Optimization algorithm is developed and applied to multi-echelon dynamic inventory management, showcasing its practical applicability.",
    "keywords": [
      "Stochastic Optimization",
      "Multi-Timescale",
      "Distortion Risk Measure",
      "Non-"
    ]
  },
  {
    "article_id": "2510.04674v1_Semantic_Channel_Equalization_Strategies_for_Deep_Joint_Source-Channel_Coding",
    "title": "2510.04674v1 Semantic Channel Equalization Strategies for Deep Joint Source-Channel Coding",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.04674v1_Semantic_Channel_Equalization_Strategies_for_Deep_Joint_Source-Channel_Coding.pdf",
    "url": "http://arxiv.org/abs/2510.04674v1_Semantic_Channel_Equalization_Strategies_for_Deep_Joint_Source-Channel_Coding",
    "pdf_url": "https://arxiv.org/pdf/2510.04674v1_Semantic_Channel_Equalization_Strategies_for_Deep_Joint_Source-Channel_Coding",
    "file_size_mb": 18.55,
    "abstract": "—Deep joint source–channel coding (DeepJSCC) has emerged as a powerful paradigm for end-to-end semantic com- munications, jointly learning to compress and protect task- relevant features over noisy channels. However, existing Deep- JSCC schemes assume a shared latent space at transmitter (TX) and receiver (RX)—an assumption that fails in multi- vendor deployments where encoders and decoders cannot be co- trained. This mismatch introduces “semantic noise”, degrading reconstruction quality and downstream task performance. In this paper, we systematize and evaluate methods for semantic channel equalization for DeepJSCC, introducing an additional processing stage that aligns heterogeneous latent spaces under both physical and semantic impairments. We investigate three classes of aligners: (i) linear maps, which admit closed-form solutions; (ii) lightweight neural networks, offering greater ex- pressiveness; and (iii) a Parseval-frame equalizer, which operates in zero-shot mode without the need for training. Through extensive experiments on image reconstruction over AWGN and fading channels, we quantify trade-offs among complexity, data efficiency, and fidelity, providing guidelines for deploying DeepJSCC in heterogeneous AI-native wireless networks.",
    "keywords": [
      "Semantic channel equalization",
      "DeepJSCC",
      "la-"
    ]
  },
  {
    "article_id": "2510.04855v1_Synthesising_Counterfactual_Explanations_via_Label-Conditional_Gaussian_Mixture_Variational_Autoenco",
    "title": "2510.04855v1 Synthesising Counterfactual Explanations via Label-Conditional Gaussian Mixture Variational Autoenco",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.04855v1_Synthesising_Counterfactual_Explanations_via_Label-Conditional_Gaussian_Mixture_Variational_Autoenco.pdf",
    "url": "http://arxiv.org/abs/2510.04855v1_Synthesising_Counterfactual_Explanations_via_Label-Conditional_Gaussian_Mixture_Variational_Autoenco",
    "pdf_url": "https://arxiv.org/pdf/2510.04855v1_Synthesising_Counterfactual_Explanations_via_Label-Conditional_Gaussian_Mixture_Variational_Autoenco",
    "file_size_mb": 0.89,
    "abstract": "Counterfactual explanations (CEs) provide recourse recommendations for indi- viduals affected by algorithmic decisions. A key challenge is generating CEs that are robust against various perturbation types (e.g. input and model perturba- tions) while simultaneously satisfying other desirable properties. These include plausibility, ensuring CEs reside on the data manifold, and diversity, providing multiple distinct recourse options for single inputs. Existing methods, however, mostly struggle to address these multifaceted requirements in a unified, model- agnostic manner. We address these limitations by proposing a novel generative framework. First, we introduce the Label-conditional Gaussian Mixture Vari- ational Autoencoder (L-GMVAE), a model trained to learn a structured latent space where each class label is represented by a set of Gaussian components with diverse, prototypical centroids. Building on this, we present LAPACE (LAtent PAth Counterfactual Explanations), a model-agnostic algorithm that synthesises entire paths of CE points by interpolating from inputs’ latent representations to those learned latent centroids. This approach inherently ensures robustness to input changes, as all paths for a given target class converge to the same fixed cen- troids. Furthermore, the generated paths provide a spectrum of recourse options, allowing users to navigate the trade-off between proximity and plausibility while also encouraging robustness against model changes. In addition, user-specified actionability constraints can also be easily incorporated via lightweight gradient optimisation through the L-GMVAE’s decoder. Comprehensive experiments show that LAPACE is computationally efficient and achieves competitive performance across eight quantitative metrics.",
    "keywords": []
  },
  {
    "article_id": "2510.04952v2_Safe_and_Compliant_Cross-Market_Trade_Execution_via_Constrained_RL_and_Zero-Knowledge_Audits",
    "title": "2510.04952v2 Safe and Compliant Cross-Market Trade Execution via Constrained RL and Zero-Knowledge Audits",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.04952v2_Safe_and_Compliant_Cross-Market_Trade_Execution_via_Constrained_RL_and_Zero-Knowledge_Audits.pdf",
    "url": "http://arxiv.org/abs/2510.04952v2_Safe_and_Compliant_Cross-Market_Trade_Execution_via_Constrained_RL_and_Zero-Knowledge_Audits",
    "pdf_url": "https://arxiv.org/pdf/2510.04952v2_Safe_and_Compliant_Cross-Market_Trade_Execution_via_Constrained_RL_and_Zero-Knowledge_Audits",
    "file_size_mb": 0.72,
    "abstract": ". We present a state-of-the-art cross-market algorithmic trad- ing system that balances execution performance with rigorous compli- ance enforcement. Our architecture consists of a high-level Planner, a Reinforcement Learning (RL) based Execution Agent, and a Compli- ance Agent. We formalize the trade execution problem as a Constrained Markov Decision Process (CMDP) with hard constraints on trade volume participation, price boundaries, and self-trading avoidance. A Proximal Policy Optimization (PPO) algorithm serves as the RL backbone for the Execution Agent, while a runtime Shield module guarantees constraint satisfaction by projecting any unsafe action into a feasible set in real time. To ensure auditability, we introduce a novel Zero-Knowledge Com- pliance Audit (zkCA) layer that produces cryptographic zero-knowledge proofs verifying that all trading actions complied with constraints, with- out revealing sensitive trading information. We evaluate our system in a high-fidelity multi-agent market simulator (based on ABIDES) across multiple trading venues. Experiments demonstrate that our RL agent achieves superior execution performance (lower implementation shortfall and variance) compared to benchmark algorithms (TWAP, VWAP, etc.), while incurring zero compliance violations. Stress tests under high net- work latency, partial order fills, compliance module toggling, and varying constraint limits show robust performance and strict adherence to con- straints. We report statistical significance at the 95% confidence level (paired t-tests) and analyze tail-risk via CVaR. A thorough related work review situates our contributions at the intersection of optimal trade ex- ecution, safe RL (CMDPs and action shielding), regulatory technology (RegTech), and verifiable AI. We discuss ethical implications, limita- tions (e.g. model assumptions and computational overhead), and future directions for deploying safe RL in real-world trading. Our results in- dicate that integrating formal compliance mechanisms into RL-driven trading can enable trustworthy AI agents that deliver competitive exe- cution quality while provably respecting market regulations.",
    "keywords": []
  },
  {
    "article_id": "2510.05132v2_Training_Large_Language_Models_To_Reason_In_Parallel_With_Global_Forking_Tokens",
    "title": "2510.05132v2 Training Large Language Models To Reason In Parallel With Global Forking Tokens",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.05132v2_Training_Large_Language_Models_To_Reason_In_Parallel_With_Global_Forking_Tokens.pdf",
    "url": "http://arxiv.org/abs/2510.05132v2_Training_Large_Language_Models_To_Reason_In_Parallel_With_Global_Forking_Tokens",
    "pdf_url": "https://arxiv.org/pdf/2510.05132v2_Training_Large_Language_Models_To_Reason_In_Parallel_With_Global_Forking_Tokens",
    "file_size_mb": 7.33,
    "abstract": "Although LLMs have demonstrated improved performance by scaling parallel test- time compute, doing so relies on generating reasoning paths that are both diverse and accurate. For challenging problems, the forking tokens that trigger diverse yet correct reasoning modes are typically deep in the sampling tree. Consequently, common strategies to encourage diversity, such as temperature scaling, encounter a worsened trade-off between diversity and accuracy. Motivated by this challenge, we treat parallel reasoning as a set-of-next-token-prediction problem, and incorporate a set-based global loss into Supervised Fine-Tuning (SFT) using self-supervised bipartite matching between our global forking tokens and unique reasoning traces. We observe that, while naive fine-tuning with multiple reasoning traces collapses these unique reasoning modes, our proposed method, Set Supervised Fine-Tuning (SSFT), preserves these modes and produces emergent global forking tokens. Experiments on multiple reasoning benchmarks show that our SSFT consistently outperforms SFT under both Pass@1 and Cons@k metrics. Question Reasoning Trace (a) <think 1> <think 2> <think 3> Reasoning Trace (b) Reasoning Trace (c) Ans Question Reasoning Trace (a) <think 1> <think 2> <think 3> Reasoning Trace (b) Reasoning Trace (c) Ans Question Reasoning Trace (a) Reasoning Trace (b) Reasoning Trace (c) Ans Question Question Ans Ans (1) Standard SFT (2) SFT with random assignments of reasoning-mode identifiers. (3) Set Supervised Fine-Tuning (Ours) Using optimal bipartite matching for set loss Figure 1: An illustration of different supervised fine-tuning methods that aim to instill parallel reasoning capabilities from diverse reasoning traces for the same question. Compared to (1) standard SFT and (2) SFT with randomly assigned parallel thinking identifiers, (3) Set-Supervised Fine- Tuning leverages a self-supervised bipartite matching process to learn to maximally differentiate the reasoning modes conditioned on distinct <think i>, for each question. Self-supervised matching prevents collapse of maximally distinct reasoning modes caused by ordering bias from randomly or manually assigning a reasoning mode identifier to a reasoning trace. The learned global forking tokens are considered emergent because we observe that similar reasoning modes over the traces for different questions cluster to match the same <think,i> at convergence, even though we do not manually identify such modes or incorporate any regularization term to maintain consistency in matching over different input prompts.",
    "keywords": []
  },
  {
    "article_id": "2510.05140v2_Auditing_Algorithmic_Bias_in_Transformer-Based_Trading",
    "title": "2510.05140v2 Auditing Algorithmic Bias in Transformer-Based Trading",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.05140v2_Auditing_Algorithmic_Bias_in_Transformer-Based_Trading.pdf",
    "url": "http://arxiv.org/abs/2510.05140v2_Auditing_Algorithmic_Bias_in_Transformer-Based_Trading",
    "pdf_url": "https://arxiv.org/pdf/2510.05140v2_Auditing_Algorithmic_Bias_in_Transformer-Based_Trading",
    "file_size_mb": 0.39,
    "abstract": "Transformer models have become increasingly popular in financial applications, yet their potential risk making and biases remain under-explored. The purpose of this work is to audit the reliance of the model on volatile data for decision-making, and quantify how the frequency of price movements affects the model’s prediction confidence. We employ a transformer model for prediction, and introduce a metric based on Partial Information Decomposition (PID) to measure the influence of each asset on the model’s decision making. Our analysis reveals two key observations: first, the model disregards data volatility entirely, and second, it is biased toward data with lower-frequency price movements.",
    "keywords": []
  },
  {
    "article_id": "2510.05157v1_Adversarial_Reinforcement_Learning_for_Offensive_and_Defensive_Agents_in_a_Simulated_Zero-Sum_Networ",
    "title": "2510.05157v1 Adversarial Reinforcement Learning for Offensive and Defensive Agents in a Simulated Zero-Sum Networ",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.05157v1_Adversarial_Reinforcement_Learning_for_Offensive_and_Defensive_Agents_in_a_Simulated_Zero-Sum_Networ.pdf",
    "url": "http://arxiv.org/abs/2510.05157v1_Adversarial_Reinforcement_Learning_for_Offensive_and_Defensive_Agents_in_a_Simulated_Zero-Sum_Networ",
    "pdf_url": "https://arxiv.org/pdf/2510.05157v1_Adversarial_Reinforcement_Learning_for_Offensive_and_Defensive_Agents_in_a_Simulated_Zero-Sum_Networ",
    "file_size_mb": 0.54,
    "abstract": "We present a controlled study of two competing reinforcement learning agents in a custom OpenAI Gym-style environment that models offensive brute-force attacks and reactive defenses on a multi-port service. The environment captures realistic trade-offs that model background traffic, brute-force exploits, IP-based evasion, traps, and rate-limiting defenses. Agents are trained using deep Q networks (DQNs) with a zero-sum re- ward structure. Successful exploits give large terminal rewards, while step actions incur small costs. We evaluated value-based agents in multiple locations, including trap probability, exploit difficulty, and training regimen. The results demonstrate that the observability of the defender and the effectiveness of the trap strongly hinder exploitations. In this scenario, reward shap- ing and training scheduling are crucial for learning stability. We provide implementation details, reproducible configurations, and guidance for future extensions.",
    "keywords": []
  },
  {
    "article_id": "2510.05475v1_From_Classical_Rationality_to_Contextual_Reasoning_Quantum_Logic_as_a_New_Frontier_for_Human-Centric",
    "title": "2510.05475v1 From Classical Rationality to Contextual Reasoning Quantum Logic as a New Frontier for Human-Centric",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.05475v1_From_Classical_Rationality_to_Contextual_Reasoning_Quantum_Logic_as_a_New_Frontier_for_Human-Centric.pdf",
    "url": "http://arxiv.org/abs/2510.05475v1_From_Classical_Rationality_to_Contextual_Reasoning_Quantum_Logic_as_a_New_Frontier_for_Human-Centric",
    "pdf_url": "https://arxiv.org/pdf/2510.05475v1_From_Classical_Rationality_to_Contextual_Reasoning_Quantum_Logic_as_a_New_Frontier_for_Human-Centric",
    "file_size_mb": 0.58,
    "abstract": "We consider state-of-the-art applications of artiﬁcial intelligence (AI) in mod- elling human ﬁnancial expectations and explore the potential of quantum logic to drive future advancements in this ﬁeld. This analysis highlights the application of machine learning techniques, including reinforcement learning and deep neural networks, in ﬁnancial statement analysis, algorithmic trading, portfolio manage- ment, and robo-advisory services. We further discuss the emergence and progress of quantum machine learning (QML) and advocate for broader exploration of the advantages provided by quantum-inspired neural networks. These beneﬁts arise from quantum logic’s ability to capture agents’ non-classical expectations and non- expected utility decisions, often referred to as bounded rationality. We present illustrative examples of expectation formation schemes in asset trading, grounded in quantum probability theory. We argue that quantum-based models hold signif- icant potential to replicate human cognitive processes, enhance AI eﬃciency, and improve functionality in complex and uncertain environments. Ultimately, we aim to promote the adoption of quantum-driven AI techniques to improve upon classical models in capturing human-like decision-making.",
    "keywords": [
      "Artiﬁcial intelligence",
      "Bounded rationality",
      "Deep neural networks",
      "Fi-"
    ]
  },
  {
    "article_id": "2510.05670v2_Quantifying_the_Accuracy-Interpretability_Trade-Off_in_Concept-Based_Sidechannel_Models",
    "title": "2510.05670v2 Quantifying the Accuracy-Interpretability Trade-Off in Concept-Based Sidechannel Models",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.05670v2_Quantifying_the_Accuracy-Interpretability_Trade-Off_in_Concept-Based_Sidechannel_Models.pdf",
    "url": "http://arxiv.org/abs/2510.05670v2_Quantifying_the_Accuracy-Interpretability_Trade-Off_in_Concept-Based_Sidechannel_Models",
    "pdf_url": "https://arxiv.org/pdf/2510.05670v2_Quantifying_the_Accuracy-Interpretability_Trade-Off_in_Concept-Based_Sidechannel_Models",
    "file_size_mb": 0.84,
    "abstract": "Concept Bottleneck Models (CBNMs) are deep learning models that provide interpretability by enforcing a bottleneck layer where predictions are based exclusively on human-understandable con- cepts. However, this constraint also restricts information flow and often results in reduced predictive accuracy. Concept Sidechannel Models (CSMs) address this limitation by introducing a sidechannel that bypasses the bottleneck and carry additional task-relevant information. While this improves accuracy, it simultaneously compromises interpretability, as predictions may rely on uninterpretable representations transmitted through sidechannels. Currently, there exists no principled technique to control this fundamental trade-off. In this paper, we close this gap. First, we present a uni- fied probabilistic concept sidechannel meta-model that subsumes existing CSMs as special cases. Building on this framework, we introduce the Sidechannel Independence Score (SIS), a metric that quantifies a CSM’s reliance on its sidechannel by contrasting predictions made with and without sidechannel information. We propose SIS regularization, which explicitly penalizes sidechannel re- liance to improve interpretability. Finally, we analyze how the expressivity of the predictor and the reliance of the sidechannel jointly shape interpretability, revealing inherent trade-offs across different CSM architectures. Empirical results show that state-of-the-art CSMs, when trained solely for accu- racy, exhibit low representation interpretability, and that SIS regularization substantially improves their interpretability, intervenability, and the quality of learned interpretable task predictors. Our work provides both theoretical and practical tools for developing CSMs that balance accuracy and interpretability in a principled manner.",
    "keywords": []
  },
  {
    "article_id": "2510.07099v1_Diffusion-Augmented_Reinforcement_Learning_for_Robust_Portfolio_Optimization_under_Stress_Scenarios",
    "title": "2510.07099v1 Diffusion-Augmented Reinforcement Learning for Robust Portfolio Optimization under Stress Scenarios",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.07099v1_Diffusion-Augmented_Reinforcement_Learning_for_Robust_Portfolio_Optimization_under_Stress_Scenarios.pdf",
    "url": "http://arxiv.org/abs/2510.07099v1_Diffusion-Augmented_Reinforcement_Learning_for_Robust_Portfolio_Optimization_under_Stress_Scenarios",
    "pdf_url": "https://arxiv.org/pdf/2510.07099v1_Diffusion-Augmented_Reinforcement_Learning_for_Robust_Portfolio_Optimization_under_Stress_Scenarios",
    "file_size_mb": 2.92,
    "abstract": "In the ever-changing and intricate landscape of financial markets, portfolio optimisa- tion remains a formidable challenge for investors and asset managers. Conventional methods often struggle to capture the complex dynamics of market behaviour and align with diverse investor preferences. To address this, we propose an innovative framework, termed Diffusion-Augmented Reinforcement Learning (DARL), which synergistically integrates Denoising Diffusion Probabilistic Models (DDPMs) with Deep Reinforcement Learning (DRL) for portfolio management. By leveraging DDPMs to generate synthetic market crash scenarios conditioned on varying stress intensities, our approach significantly enhances the robustness of training data. Empirical evaluations demonstrate that DARL outperforms traditional baselines, delivering superior risk-adjusted returns and resilience against unforeseen crises, such as the 2025 Tariff Crisis. This work offers a robust and practical methodology to bolster stress resilience in DRL-driven financial applications.",
    "keywords": [
      "Portfolio Optimization",
      "Deep Reinforcement Learning",
      "Generative Models",
      "Quantitative"
    ]
  },
  {
    "article_id": "2510.07646v2_Design-Based_Bandits_Under_Network_Interference_Trade-Off_Between_Regret_and_Statistical_Inference",
    "title": "2510.07646v2 Design-Based Bandits Under Network Interference Trade-Off Between Regret and Statistical Inference",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.07646v2_Design-Based_Bandits_Under_Network_Interference_Trade-Off_Between_Regret_and_Statistical_Inference.pdf",
    "url": "http://arxiv.org/abs/2510.07646v2_Design-Based_Bandits_Under_Network_Interference_Trade-Off_Between_Regret_and_Statistical_Inference",
    "pdf_url": "https://arxiv.org/pdf/2510.07646v2_Design-Based_Bandits_Under_Network_Interference_Trade-Off_Between_Regret_and_Statistical_Inference",
    "file_size_mb": 2.11,
    "abstract": "In multi-armed bandits with network interference (MABNI), the action taken by one node can influence the rewards of others, creating complex interdependence. While existing research on MABNI largely concentrates on minimizing regret, it often overlooks the crucial concern that an excessive emphasis on the optimal arm can undermine the inference accuracy for sub-optimal arms. Although initial efforts have been made to address this trade-off in single-unit scenarios, these challenges have become more pronounced in the context of MABNI. In this paper, we establish, for the first time, a theoretical Pareto frontier characterizing the trade-off between regret minimization and inference accuracy in adversarial (design-based) MABNI. We further introduce an anytime-valid asymptotic confidence sequence along with a corresponding algorithm, EXP3-N-CS, specifically designed to balance the trade-off between regret minimization and inference accuracy in this setting.",
    "keywords": []
  },
  {
    "article_id": "2510.07661v2_IKNet_Interpretable_Stock_Price_Prediction_via_Keyword-Guided_Integration_of_News_and_Technical_Indi",
    "title": "2510.07661v2 IKNet Interpretable Stock Price Prediction via Keyword-Guided Integration of News and Technical Indi",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.07661v2_IKNet_Interpretable_Stock_Price_Prediction_via_Keyword-Guided_Integration_of_News_and_Technical_Indi.pdf",
    "url": "http://arxiv.org/abs/2510.07661v2_IKNet_Interpretable_Stock_Price_Prediction_via_Keyword-Guided_Integration_of_News_and_Technical_Indi",
    "pdf_url": "https://arxiv.org/pdf/2510.07661v2_IKNet_Interpretable_Stock_Price_Prediction_via_Keyword-Guided_Integration_of_News_and_Technical_Indi",
    "file_size_mb": 0.29,
    "abstract": "The increasing influence of unstructured external information, such as news articles, on stock prices has attracted growing attention in financial markets. Despite recent advances, most existing news- based forecasting models represent all articles using sentiment scores or average embeddings that capture the general tone but fail to provide quantitative, context-aware explanations of the impacts of public sentiment on predictions. To address this limitation, we propose an interpretable keyword-guided network (IKNet), which is an explainable forecasting framework that models the seman- tic association between individual news keywords and stock price movements. The IKNet identifies salient keywords via FinBERT- based contextual analysis, processes each embedding through a separate nonlinear projection layer, and integrates their represen- tations with the time-series data of technical indicators to forecast next-day closing prices. By applying Shapley Additive Explanations the model generates quantifiable and interpretable attributions for the contribution of each keyword to predictions. Empirical evalu- ations of S&P 500 data from 2015 to 2024 demonstrate that IKNet outperforms baselines, including recurrent neural networks and transformer models, reducing RMSE by up to 32.9% and improv- ing cumulative returns by 18.5%. Moreover, IKNet enhances trans- parency by offering contextualized explanations of volatility events driven by public sentiment. CCS Concepts • Computing methodologies →Neural networks; • Informa- tion systems →Predictive analytics; Sentiment analysis.",
    "keywords": [
      "and stock price"
    ]
  },
  {
    "article_id": "2510.08095v1_Beyond_Real_Data_Synthetic_Data_through_the_Lens_of_Regularization",
    "title": "2510.08095v1 Beyond Real Data Synthetic Data through the Lens of Regularization",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.08095v1_Beyond_Real_Data_Synthetic_Data_through_the_Lens_of_Regularization.pdf",
    "url": "http://arxiv.org/abs/2510.08095v1_Beyond_Real_Data_Synthetic_Data_through_the_Lens_of_Regularization",
    "pdf_url": "https://arxiv.org/pdf/2510.08095v1_Beyond_Real_Data_Synthetic_Data_through_the_Lens_of_Regularization",
    "file_size_mb": 2.02,
    "abstract": "Synthetic data can improve generalization when real data is scarce, but excessive reliance may introduce distributional mismatches that degrade performance. In this paper, we present a learning-theoretic framework to quantify the trade-off between synthetic and real data. Our approach leverages algorithmic stability to derive generalization error bounds, characterizing the optimal synthetic-to-real data ratio that minimizes expected test error as a function of the Wasserstein distance between the real and synthetic distributions. We motivate our framework in the setting of kernel ridge regression with mixed data, offering a detailed analysis that may be of independent interest. Our theory predicts the existence of an optimal ratio, leading to a U-shaped behavior of test error with respect to the proportion of synthetic data. Empirically, we validate this prediction on CIFAR-10 and a clinical brain MRI dataset. Our theory extends to the important scenario of domain adaptation, showing that carefully blending synthetic target data with limited source data can mitigate domain shift and enhance generalization. We conclude with practical guidance for applying our results to both in-domain and out-of-domain scenarios.",
    "keywords": []
  },
  {
    "article_id": "2510.08117v1_Near-optimal_Rank_Adaptive_Inference_of_High_Dimensional_Matrices",
    "title": "2510.08117v1 Near-optimal Rank Adaptive Inference of High Dimensional Matrices",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.08117v1_Near-optimal_Rank_Adaptive_Inference_of_High_Dimensional_Matrices.pdf",
    "url": "http://arxiv.org/abs/2510.08117v1_Near-optimal_Rank_Adaptive_Inference_of_High_Dimensional_Matrices",
    "pdf_url": "https://arxiv.org/pdf/2510.08117v1_Near-optimal_Rank_Adaptive_Inference_of_High_Dimensional_Matrices",
    "file_size_mb": 1.15,
    "abstract": "We address the problem of estimating a high-dimensional matrix from linear measurements, with a focus on designing optimal rank-adaptive algorithms. These algorithms infer the matrix by esti- mating its singular values and the corresponding singular vectors up to an effective rank, adaptively determined based on the data. We establish instance-specific lower bounds for the sample complexity of such algorithms, uncovering fundamental trade-offs in selecting the effective rank: balancing the precision of estimating a subset of singular values against the approximation cost incurred for the remaining ones. Our analysis identifies how the optimal effective rank depends on the matrix being estimated, the sample size, and the noise level. We propose an algorithm that combines a Least- Squares estimator with a universal singular value thresholding procedure. We provide finite-sample error bounds for this algorithm and demonstrate that its performance nearly matches the derived fundamental limits. Our results rely on an enhanced analysis of matrix denoising methods based on singular value thresholding. We validate our findings with applications to multivariate regression and linear dynamical system identification.",
    "keywords": []
  },
  {
    "article_id": "2510.08226v2_UAMDP_Uncertainty-Aware_Markov_Decision_Process_for_Risk-Constrained_Reinforcement_Learning_from_Pro",
    "title": "2510.08226v2 UAMDP Uncertainty-Aware Markov Decision Process for Risk-Constrained Reinforcement Learning from Pro",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.08226v2_UAMDP_Uncertainty-Aware_Markov_Decision_Process_for_Risk-Constrained_Reinforcement_Learning_from_Pro.pdf",
    "url": "http://arxiv.org/abs/2510.08226v2_UAMDP_Uncertainty-Aware_Markov_Decision_Process_for_Risk-Constrained_Reinforcement_Learning_from_Pro",
    "pdf_url": "https://arxiv.org/pdf/2510.08226v2_UAMDP_Uncertainty-Aware_Markov_Decision_Process_for_Risk-Constrained_Reinforcement_Learning_from_Pro",
    "file_size_mb": 0.8,
    "abstract": "Sequential decisions in volatile, high-stakes settings require more than maximizing expected return; they require principled un- certainty management. This paper presents the Uncertainty-Aware Markov Decision Process (UAMDP), a unified framework that couples Bayesian forecasting, posterior-sampling reinforcement learning, and planning under a conditional value-at-risk (CVaR) constraint. In a closed loop, the agent updates its beliefs over latent dynamics, samples plausible futures via Thompson sampling, and optimizes policies subject to preset risk tolerances. We establish regret bounds that converge to the Bayes-optimal benchmark under standard regularity conditions. We evaluate UAMDP in two domains including high-frequency equity trading and retail in- ventory control, both marked by structural uncertainty and economic volatility. Relative to strong deep learning baselines, UAMDP improves long-horizon forecasting accuracy (RMSE decreases by up to 25% and sMAPE by 32%), and these gains translate into economic performance: the trading Sharpe ratio rises from 1.54 to 1.74 while maximum drawdown is roughly halved. These results show that integrating calibrated probabilistic modeling, exploration aligned with posterior uncertainty, and risk-aware control yields a robust, generalizable approach to safer and more profitable sequential decision-making.",
    "keywords": [
      "Bayesian reinforcement learning",
      "probabilistic forecasting",
      "uncertainty quantification",
      "risk-sensitive decision-making"
    ]
  },
  {
    "article_id": "2510.08769v1_Prioritizing_Latency_with_Profit_A_DRL-Based_Admission_Control_for_5G_Network_Slices",
    "title": "2510.08769v1 Prioritizing Latency with Profit A DRL-Based Admission Control for 5G Network Slices",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.08769v1_Prioritizing_Latency_with_Profit_A_DRL-Based_Admission_Control_for_5G_Network_Slices.pdf",
    "url": "http://arxiv.org/abs/2510.08769v1_Prioritizing_Latency_with_Profit_A_DRL-Based_Admission_Control_for_5G_Network_Slices",
    "pdf_url": "https://arxiv.org/pdf/2510.08769v1_Prioritizing_Latency_with_Profit_A_DRL-Based_Admission_Control_for_5G_Network_Slices",
    "file_size_mb": 3.84,
    "abstract": "—5G networks enable diverse services such as eMBB, URLLC, and mMTC through network slicing, necessitating intel- ligent admission control and resource allocation to meet stringent QoS requirements while maximizing Network Service Provider (NSP) profits. However, existing Deep Reinforcement Learning (DRL) frameworks focus primarily on profit optimization without explicitly accounting for service delay, potentially leading to QoS violations for latency-sensitive slices. Moreover, commonly used epsilon-greedy exploration of DRL often results in unstable convergence and suboptimal policy learning. To address these gaps, we propose DePSAC – a Delay and Profit-aware Slice Admission Control scheme. Our DRL-based approach incorpo- rates a delay-aware reward function, where penalties due to service delay incentivize the prioritization of latency-critical slices such as URLLC. Additionally, we employ Boltzmann exploration to achieve smoother and faster convergence. We implement and evaluate DePSAC on a simulated 5G core network substrate with realistic Network Slice Request (NSLR) arrival patterns. Experimental results demonstrate that our method outperforms the DSARA baseline in terms of overall profit, reduced URLLC slice delays, improved acceptance rates, and improved resource consumption. These findings validate the effectiveness of the proposed DePSAC in achieving better QoS–profit trade-offs for practical 5G network slicing scenarios.",
    "keywords": []
  },
  {
    "article_id": "2510.08908v1_A_Frequency-Domain_Analysis_of_the_Multi-Armed_Bandit_Problem_A_New_Perspective_on_the_Exploration-E",
    "title": "2510.08908v1 A Frequency-Domain Analysis of the Multi-Armed Bandit Problem A New Perspective on the Exploration-E",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.08908v1_A_Frequency-Domain_Analysis_of_the_Multi-Armed_Bandit_Problem_A_New_Perspective_on_the_Exploration-E.pdf",
    "url": "http://arxiv.org/abs/2510.08908v1_A_Frequency-Domain_Analysis_of_the_Multi-Armed_Bandit_Problem_A_New_Perspective_on_the_Exploration-E",
    "pdf_url": "https://arxiv.org/pdf/2510.08908v1_A_Frequency-Domain_Analysis_of_the_Multi-Armed_Bandit_Problem_A_New_Perspective_on_the_Exploration-E",
    "file_size_mb": 0.21,
    "abstract": "The stochastic multi-armed bandit (MAB) problem is one of the most fundamental models in se- quential decision-making, with the core challenge being the trade-off between exploration and ex- ploitation. Although algorithms such as Upper Confidence Bound (UCB) and Thompson Sampling, along with their regret theories, are well-established, existing analyses primarily operate from a time-domain and cumulative regret perspective, struggling to characterize the dynamic nature of the learning process. This paper proposes a novel frequency-domain analysis framework, reformulat- ing the bandit process as a signal processing problem. Within this framework, the reward estimate of each arm is viewed as a spectral component, with its uncertainty corresponding to the compo- nent’s frequency, and the bandit algorithm is interpreted as an adaptive filter. We construct a formal Frequency-Domain Bandit Model and prove the main theorem: the confidence bound term in the UCB algorithm is equivalent in the frequency domain to a time-varying gain applied to uncertain spectral components, a gain inversely proportional to the square root of the visit count. Based on this, we further derive finite-time dynamic bounds concerning the exploration rate decay. This theory not only provides a novel and intuitive physical interpretation for classical algorithms but also lays a rigorous theoretical foundation for designing next-generation algorithms with adaptive parameter adjustment.",
    "keywords": [
      "Multi-Armed Bandit",
      "Frequency-Domain Analysis",
      "Exploration and Exploitation",
      "Up-"
    ]
  },
  {
    "article_id": "2510.09018v1_Slim_Scheduler_A_Runtime-Aware_RL_and_Scheduler_System_for_Efficient_CNN_Inference",
    "title": "2510.09018v1 Slim Scheduler A Runtime-Aware RL and Scheduler System for Efficient CNN Inference",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.09018v1_Slim_Scheduler_A_Runtime-Aware_RL_and_Scheduler_System_for_Efficient_CNN_Inference.pdf",
    "url": "http://arxiv.org/abs/2510.09018v1_Slim_Scheduler_A_Runtime-Aware_RL_and_Scheduler_System_for_Efficient_CNN_Inference",
    "pdf_url": "https://arxiv.org/pdf/2510.09018v1_Slim_Scheduler_A_Runtime-Aware_RL_and_Scheduler_System_for_Efficient_CNN_Inference",
    "file_size_mb": 0.62,
    "abstract": "—Most neural network scheduling research focuses on optimizing static, end-to-end models of fixed width, overlooking dynamic approaches that adapt to heterogeneous hardware and fluctuating runtime conditions. We present Slim Scheduler, a hybrid scheduling framework that integrates a Proximal Policy Optimization (PPO) reinforcement learning policy with algorith- mic, greedy schedulers to coordinate distributed inference for slimmable models. Each server runs a local greedy scheduler that batches compatible requests and manages instance scaling based on VRAM and utilization constraints, while the PPO router learns global routing policies for device selection, width ratio, and batch configuration. This hierarchical design reduces search space complexity, mitigates overfitting to specific hard- ware, and balances efficiency and throughput. Compared to a purely randomized task distribution baseline, Slim Scheduler can achieve various accuracy and latency trade-offs such as: A 96.45% reduction in mean latency and a 97.31% reduction in energy usage dropping accuracy to the slimmest model available (70.3%). It can then accomplish an overall reduction in average latency plus energy consumption with an increase in accuracy at the cost of higher standard deviations of said latency and energy, effecting overall task throughput.",
    "keywords": [
      "Dynamic neural network scheduling",
      "slimmable"
    ]
  },
  {
    "article_id": "2510.09247v1_Application_of_Deep_Reinforcement_Learning_to_At-the-Money_SP_500_Options_Hedging",
    "title": "2510.09247v1 Application of Deep Reinforcement Learning to At-the-Money SP 500 Options Hedging",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.09247v1_Application_of_Deep_Reinforcement_Learning_to_At-the-Money_SP_500_Options_Hedging.pdf",
    "url": "http://arxiv.org/abs/2510.09247v1_Application_of_Deep_Reinforcement_Learning_to_At-the-Money_SP_500_Options_Hedging",
    "pdf_url": "https://arxiv.org/pdf/2510.09247v1_Application_of_Deep_Reinforcement_Learning_to_At-the-Money_SP_500_Options_Hedging",
    "file_size_mb": 3.76,
    "abstract": "This paper explores the application of deep Q-learning to hedging at-the-money options on the S&P 500 index. We develop an agent based on the Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm, trained to simulate hedging decisions without making explicit model assumptions on price dynamics. The agent was trained on historical intraday prices of S&P 500 call options across years 2004 to 2024, using a single time series of six predictor variables: option price, underlying asset price, moneyness, time to maturity, realized volatility, and current hedge position. A walk-forward procedure was applied for training, which lead to nearly 17 years of out-of-sample evaluation. The performance of the deep reinforcement learning (DRL) agent is benchmarked against the Black–Scholes delta hedging strategy over the same time period. We assess both approaches using metrics such as annualized return, volatility, information ratio, and Sharpe ratio. To test models’ adaptability, we performed simulations across varying market conditions and added constraints such as transaction costs and risk-awareness penalties. Our results show that the DRL agent can outperform traditional hedging methods, particularly in volatile or high-cost environments, highlighting its robustness and flexibility in practical trading contexts. While the agent consistently outperforms delta hedging, its performance deteriorates when the risk-awareness parameter is higher. We also observed that the longer the time interval used for volatility estimation, the more stable the results.",
    "keywords": [
      "Deep learning",
      "Reinforcement learning",
      "Double deep Q-networks",
      "options market",
      "options"
    ]
  },
  {
    "article_id": "2510.10101v3_Rademacher_Meets_Colors_More_Expressivity_but_at_What_Cost_",
    "title": "2510.10101v3 Rademacher Meets Colors More Expressivity but at What Cost ",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.10101v3_Rademacher_Meets_Colors_More_Expressivity_but_at_What_Cost_.pdf",
    "url": "http://arxiv.org/abs/2510.10101v3_Rademacher_Meets_Colors_More_Expressivity_but_at_What_Cost_",
    "pdf_url": "https://arxiv.org/pdf/2510.10101v3_Rademacher_Meets_Colors_More_Expressivity_but_at_What_Cost_",
    "file_size_mb": 1.47,
    "abstract": "The expressive power of graph neural networks (GNNs) is typically understood through their correspondence with graph isomorphism tests such as the Weis- feiler–Leman (WL) hierarchy. While more expressive GNNs can distinguish a richer set of graphs, they are also observed to suffer from higher generalization error. This work provides a theoretical explanation for this trade-off by linking expressivity and generalization through the lens of coloring algorithms. Specifi- cally, we show that the number of equivalence classes induced by WL colorings directly bounds the GNN’s Rademacher complexity – a key data-dependent mea- sure of generalization. Our analysis reveals that greater expressivity leads to higher complexity and thus weaker generalization guarantees. Furthermore, we prove that the Rademacher complexity is stable under perturbations in the color counts across different samples, ensuring robustness to sampling variability across datasets. Importantly, our framework is not restricted to message-passing GNNs or 1-WL, but extends to arbitrary GNN architectures and expressivity measures that partition graphs into equivalence classes. These results unify the study of expressivity and generalization in GNNs, providing a principled understanding of why increasing expressive power often comes at the cost of generalization.",
    "keywords": []
  },
  {
    "article_id": "2510.10343v2_Learning_the_Exact_SABR_Model",
    "title": "2510.10343v2 Learning the Exact SABR Model",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.10343v2_Learning_the_Exact_SABR_Model.pdf",
    "url": "http://arxiv.org/abs/2510.10343v2_Learning_the_Exact_SABR_Model",
    "pdf_url": "https://arxiv.org/pdf/2510.10343v2_Learning_the_Exact_SABR_Model",
    "file_size_mb": 3.82,
    "abstract": "The SABR model is a cornerstone of interest rate volatility modeling, but its practical applica- tion relies heavily on the analytical approximation by Hagan et al., whose accuracy deteriorates for high volatility, long maturities, and out-of-the-money options, admitting arbitrage. While machine learning approaches have been proposed to overcome these limitations, they have often been limited by simplified SABR dynamics or a lack of systematic validation against the full spectrum of market conditions. We develop a novel SABR DNN, a specialized Artificial Deep Neural Network (DNN) architec- ture that learns the true SABR stochastic dynamics using an unprecedented large training dataset of interest rate Cap/Floor volatility surfaces (more than 200 million points), including very long maturities (30Y) and extreme strikes consistently with market quotations. Our dataset is obtained via high-precision unbiased Monte Carlo simulation of a scaled shifted-SABR stochastic dynamics, which allows dimensional reduction without any loss of generality. Our SABR DNN provides arbitrage-free calibration of real market volatility surfaces and Cap/Floor prices for any maturity and strike with negligible computational effort and without retraining across business dates. Our results fully address the gaps in the previous machine learning SABR literature in a systematic and self-consistent way, and can be extended to cover any interest rate European options in different rate tenors and currencies, thus establishing a comprehensive functional SABR framework that can be adopted for daily trading and risk management activities. Classifications: JEL: C45, C63, G12, G13; MSC: 91G60 (Primary) 60H35, 68T07, 65C05 (Sec- ondary); ACM: G.1.6, I.2.6, I.5.1, J.4.",
    "keywords": [
      "stochastic volatility",
      "SABR",
      "Hagan",
      "model calibration",
      "volatility surface",
      "interest rate"
    ]
  },
  {
    "article_id": "2510.10526v1_Integrating_Large_Language_Models_and_Reinforcement_Learning_for_Sentiment-Driven_Quantitative_Tradi",
    "title": "2510.10526v1 Integrating Large Language Models and Reinforcement Learning for Sentiment-Driven Quantitative Tradi",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.10526v1_Integrating_Large_Language_Models_and_Reinforcement_Learning_for_Sentiment-Driven_Quantitative_Tradi.pdf",
    "url": "http://arxiv.org/abs/2510.10526v1_Integrating_Large_Language_Models_and_Reinforcement_Learning_for_Sentiment-Driven_Quantitative_Tradi",
    "pdf_url": "https://arxiv.org/pdf/2510.10526v1_Integrating_Large_Language_Models_and_Reinforcement_Learning_for_Sentiment-Driven_Quantitative_Tradi",
    "file_size_mb": 1.0,
    "abstract": "This research develops a sentiment-driven quantitative trading system that leverages a large language model —FinGPT—for sentiment analysis, and explores a novel method for signal integration using a reinforcement learning algorithm, Twin Delayed Deep Deterministic Policy Gradient (TD3). We compare the per- formance of strategies that integrate sentiment and technical signals using both a conventional rule-based approach and a reinforcement learning framework. The results suggest that sentiment signals generated by FinGPT offer value when combined with traditional technical indicators, and that reinforcement learning algorithm presents a promising approach for effectively integrating heterogeneous signals in dynamic trading environments.",
    "keywords": []
  },
  {
    "article_id": "2510.10718v1_HYPERDOA_Robust_and_Efficient_DoA_Estimation_using_Hyperdimensional_Computing",
    "title": "2510.10718v1 HYPERDOA Robust and Efficient DoA Estimation using Hyperdimensional Computing",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.10718v1_HYPERDOA_Robust_and_Efficient_DoA_Estimation_using_Hyperdimensional_Computing.pdf",
    "url": "http://arxiv.org/abs/2510.10718v1_HYPERDOA_Robust_and_Efficient_DoA_Estimation_using_Hyperdimensional_Computing",
    "pdf_url": "https://arxiv.org/pdf/2510.10718v1_HYPERDOA_Robust_and_Efficient_DoA_Estimation_using_Hyperdimensional_Computing",
    "file_size_mb": 0.71,
    "abstract": "Direction of Arrival (DoA) estimation techniques face a critical trade-off, as classical methods often lack accuracy in challeng- ing, low signal-to-noise ratio (SNR) conditions, while modern deep learning approaches are too energy-intensive and opaque for resource-constrained, safety-critical systems. We introduce HYPERDOA, a novel estimator leveraging Hyperdimensional Com- puting (HDC). The framework introduces two distinct feature ex- traction strategies— Mean Spatial-Lag Autocorrelation and Spatial Smoothing—for its HDC pipeline, and then reframes DoA esti- mation as a pattern recognition problem. This approach leverages HDC’s inherent robustness to noise and its transparent algebraic operations to bypass the expensive matrix decompositions and \"black-box\" nature of classical and deep learning methods, re- spectively. Our evaluation demonstrates that HYPERDOA achieves ∼35.39% higher accuracy than state-of-the-art methods in low- SNR, coherent-source scenarios. Crucially, it also consumes ∼93% less energy than competing neural baselines on an embedded NVIDIA Jetson Xavier NX platform. This dual advantage in accuracy and efficiency establishes HYPERDOA as a robust and viable solution for mission-critical applications on edge devices.",
    "keywords": [
      "DoA estimation",
      "Hyperdimensional Computing"
    ]
  },
  {
    "article_id": "2510.10775v1_Structure_Over_Signal_A_Globalized_Approach_to_Multi-relational_GNNs_for_Stock_Prediction",
    "title": "2510.10775v1 Structure Over Signal A Globalized Approach to Multi-relational GNNs for Stock Prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.10775v1_Structure_Over_Signal_A_Globalized_Approach_to_Multi-relational_GNNs_for_Stock_Prediction.pdf",
    "url": "http://arxiv.org/abs/2510.10775v1_Structure_Over_Signal_A_Globalized_Approach_to_Multi-relational_GNNs_for_Stock_Prediction",
    "pdf_url": "https://arxiv.org/pdf/2510.10775v1_Structure_Over_Signal_A_Globalized_Approach_to_Multi-relational_GNNs_for_Stock_Prediction",
    "file_size_mb": 0.54,
    "abstract": "In financial markets, Graph Neural Networks have been successfully applied to modeling relational data, effectively capturing nonlinear inter-stock dependencies. Yet, existing models often fail to efficiently propagate messages during macroeconomic shocks. In this paper, we propose OmniGNN, an attention- based multi-relational dynamic GNN that integrates macroeconomic context via heterogeneous node and edge types for robust message passing. Central to OmniGNN is a sector node acting as a global interme- diary, enabling rapid shock propagation across the graph without relying on long-range multi-hop diffu- sion. The model leverages Graph Attention Networks (GAT) to weigh neighbor contributions and employs Transformers to capture temporal dynamics across multiplex relations. Experiments show that OmniGNN outperforms existing stock prediction models on public datasets, particularly demonstrating strong robust- ness during the COVID-19 period. 1 Key words: Graph Neural Networks, spatio-temporal deep learning, financial markets",
    "keywords": [
      "Graph Neural Networks",
      "spatio-temporal deep learning",
      "financial markets"
    ]
  },
  {
    "article_id": "2510.10777v2_Preconditioned_Norms_A_Unified_Framework_for_Steepest_Descent_Quasi-Newton_and_Adaptive_Methods",
    "title": "2510.10777v2 Preconditioned Norms A Unified Framework for Steepest Descent Quasi-Newton and Adaptive Methods",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.10777v2_Preconditioned_Norms_A_Unified_Framework_for_Steepest_Descent_Quasi-Newton_and_Adaptive_Methods.pdf",
    "url": "http://arxiv.org/abs/2510.10777v2_Preconditioned_Norms_A_Unified_Framework_for_Steepest_Descent_Quasi-Newton_and_Adaptive_Methods",
    "pdf_url": "https://arxiv.org/pdf/2510.10777v2_Preconditioned_Norms_A_Unified_Framework_for_Steepest_Descent_Quasi-Newton_and_Adaptive_Methods",
    "file_size_mb": 0.94,
    "abstract": null,
    "keywords": []
  },
  {
    "article_id": "2510.11103v1_A_Primer_on_SO3_Action_Representations_in_Deep_Reinforcement_Learning",
    "title": "2510.11103v1 A Primer on SO3 Action Representations in Deep Reinforcement Learning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.11103v1_A_Primer_on_SO3_Action_Representations_in_Deep_Reinforcement_Learning.pdf",
    "url": "http://arxiv.org/abs/2510.11103v1_A_Primer_on_SO3_Action_Representations_in_Deep_Reinforcement_Learning",
    "pdf_url": "https://arxiv.org/pdf/2510.11103v1_A_Primer_on_SO3_Action_Representations_in_Deep_Reinforcement_Learning",
    "file_size_mb": 17.01,
    "abstract": "Many robotic control tasks require policies to act on orientations, yet the geom- etry of SO(3) makes this nontrivial. Because SO(3) admits no global, smooth, minimal parameterization, common representations such as Euler angles, quater- nions, rotation matrices, and Lie algebra coordinates introduce distinct constraints and failure modes. While these trade-offs are well studied for supervised learn- ing, their implications for actions in reinforcement learning remain unclear. We systematically evaluate SO(3) action representations across three standard con- tinuous control algorithms, PPO, SAC, and TD3, under dense and sparse rewards. We compare how representations shape exploration, interact with entropy regu- larization, and affect training stability through empirical studies and analyze the implications of different projections for obtaining valid rotations from Euclidean network outputs. Across a suite of robotics benchmarks, we quantify the prac- tical impact of these choices and distill simple, implementation-ready guidelines for selecting and using rotation actions. Our results highlight that representation- induced geometry strongly influences exploration and optimization and show that representing actions as tangent vectors in the local frame yields the most reliable results across algorithms.",
    "keywords": []
  },
  {
    "article_id": "2510.12685v1_Orderbook_Feature_Learning_and_Asymmetric_Generalization_in_Intraday_Electricity_Markets",
    "title": "2510.12685v1 Orderbook Feature Learning and Asymmetric Generalization in Intraday Electricity Markets",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.12685v1_Orderbook_Feature_Learning_and_Asymmetric_Generalization_in_Intraday_Electricity_Markets.pdf",
    "url": "http://arxiv.org/abs/2510.12685v1_Orderbook_Feature_Learning_and_Asymmetric_Generalization_in_Intraday_Electricity_Markets",
    "pdf_url": "https://arxiv.org/pdf/2510.12685v1_Orderbook_Feature_Learning_and_Asymmetric_Generalization_in_Intraday_Electricity_Markets",
    "file_size_mb": 0.8,
    "abstract": "—Accurate probabilistic forecasting of intraday elec- tricity prices is critical for market participants to inform trading decisions. Existing studies rely on specific domain features, such as Volume-Weighted Average Price (VWAP) and the last price. However, the rich information in the orderbook remains un- derexplored. Furthermore, these approaches are often developed within a single country and product type, making it unclear whether the approaches are generalizable. In this paper, we extract 384 features from the orderbook and identify a set of powerful features via feature selection. Based on selected features, we present a comprehensive benchmark using classical statistical models, tree-based ensembles, and deep learning models across two countries (Germany and Austria) and two product types (60- min and 15-min). We further perform a systematic generalization study across countries and product types, from which we reveal an asymmetric generalization phenomenon. The project page is at https://runyao-yu.github.io/AsymGen/.",
    "keywords": [
      "Intraday Electricity Market",
      "Feature Selection"
    ]
  },
  {
    "article_id": "2510.12725v1_Non-Parametric_Bootstrap_Robust_Optimization_for_Portfolios_and_Trading_Strategies",
    "title": "2510.12725v1 Non-Parametric Bootstrap Robust Optimization for Portfolios and Trading Strategies",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.12725v1_Non-Parametric_Bootstrap_Robust_Optimization_for_Portfolios_and_Trading_Strategies.pdf",
    "url": "http://arxiv.org/abs/2510.12725v1_Non-Parametric_Bootstrap_Robust_Optimization_for_Portfolios_and_Trading_Strategies",
    "pdf_url": "https://arxiv.org/pdf/2510.12725v1_Non-Parametric_Bootstrap_Robust_Optimization_for_Portfolios_and_Trading_Strategies",
    "file_size_mb": 1.48,
    "abstract": null,
    "keywords": [
      "Robust Optimization",
      "Nonparametric Bootstrap",
      "Portfolio Selection",
      "Overﬁtting"
    ]
  },
  {
    "article_id": "2510.12939v1_Pruning_Cannot_Hurt_Robustness_Certified_Trade-offs_in_Reinforcement_Learning",
    "title": "2510.12939v1 Pruning Cannot Hurt Robustness Certified Trade-offs in Reinforcement Learning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.12939v1_Pruning_Cannot_Hurt_Robustness_Certified_Trade-offs_in_Reinforcement_Learning.pdf",
    "url": "http://arxiv.org/abs/2510.12939v1_Pruning_Cannot_Hurt_Robustness_Certified_Trade-offs_in_Reinforcement_Learning",
    "pdf_url": "https://arxiv.org/pdf/2510.12939v1_Pruning_Cannot_Hurt_Robustness_Certified_Trade-offs_in_Reinforcement_Learning",
    "file_size_mb": 2.77,
    "abstract": "Reinforcement learning (RL) policies deployed in real-world environments must remain reliable under adversarial perturbations. At the same time, modern deep RL agents are heavily overparameterized, raising costs and fragility concerns. While pruning has been shown to improve robustness in supervised learning, its role in adversarial RL remains poorly understood. We develop the first theoretical framework for certified robustness under pruning in state-adversarial Markov decision processes (SA-MDPs). For Gaussian and categorical policies with Lipschitz networks, we prove that elementwise pruning can only tighten certified robustness bounds; pruning never makes the policy less robust. Building on this, we derive a novel three-term regret decomposition that disentangles clean-task performance, pruning-induced performance loss, and robustness gains, exposing a fundamental performance–robustness frontier. Empirically, we evaluate magnitude and micro-pruning schedules on continuous-control benchmarks with strong policy-aware adversaries. Across tasks, pruning consistently uncovers reproducible “sweet spots” at moderate sparsity levels, where robustness improves substantially without harming—and sometimes even enhancing—clean performance. These results position pruning not merely as a compression tool but as a structural intervention for robust RL.",
    "keywords": []
  },
  {
    "article_id": "2510.13158v1_Behavioral_Embeddings_of_Programs_A_Quasi-Dynamic_Approach_for_Optimization_Prediction",
    "title": "2510.13158v1 Behavioral Embeddings of Programs A Quasi-Dynamic Approach for Optimization Prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.13158v1_Behavioral_Embeddings_of_Programs_A_Quasi-Dynamic_Approach_for_Optimization_Prediction.pdf",
    "url": "http://arxiv.org/abs/2510.13158v1_Behavioral_Embeddings_of_Programs_A_Quasi-Dynamic_Approach_for_Optimization_Prediction",
    "pdf_url": "https://arxiv.org/pdf/2510.13158v1_Behavioral_Embeddings_of_Programs_A_Quasi-Dynamic_Approach_for_Optimization_Prediction",
    "file_size_mb": 8.32,
    "abstract": "Learning effective numerical representations, or embeddings, of programs is a fundamental prerequisite for applying machine learning to automate and enhance compiler optimization. Prevailing paradigms, however, present a dilemma. Static representations, derived from source code or intermediate representation (IR), are efficient and deterministic but offer limited insight into how a program will be- have or evolve under complex code transformations. Conversely, dynamic repre- sentations, which rely on runtime profiling, provide profound insights into perfor- mance bottlenecks but are often impractical for large-scale tasks due to prohibitive overhead and inherent non-determinism. This paper transcends this trade-off by proposing a novel quasi-dynamic framework for program representation. The core insight is to model a program’s optimization sensitivity. We introduce the Program Behavior Spectrum, a new representation generated by probing a program’s IR with a diverse set of optimization sequences and quantifying the resulting changes in its static features. To effectively encode this high-dimensional, continuous spec- trum, we pioneer a compositional learning approach. Product Quantization is em- ployed to discretize the continuous reaction vectors into structured, compositional sub-words. Subsequently, a multi-task Transformer model, termed PQ-BERT, is pre-trained to learn the deep contextual grammar of these behavioral codes. Com- prehensive experiments on two representative compiler optimization tasks—Best Pass Prediction and -Oz Benefit Prediction—demonstrate that our method outper- forms state-of-the-art static baselines. Our code is publicly available at 1.",
    "keywords": []
  },
  {
    "article_id": "2510.13437v1_Hybrid_Interval_Type-2_Mamdani-TSK_Fuzzy_System_for_Regression_Analysis",
    "title": "2510.13437v1 Hybrid Interval Type-2 Mamdani-TSK Fuzzy System for Regression Analysis",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.13437v1_Hybrid_Interval_Type-2_Mamdani-TSK_Fuzzy_System_for_Regression_Analysis.pdf",
    "url": "http://arxiv.org/abs/2510.13437v1_Hybrid_Interval_Type-2_Mamdani-TSK_Fuzzy_System_for_Regression_Analysis",
    "pdf_url": "https://arxiv.org/pdf/2510.13437v1_Hybrid_Interval_Type-2_Mamdani-TSK_Fuzzy_System_for_Regression_Analysis",
    "file_size_mb": 0.66,
    "abstract": "Regression analysis is employed to examine and quantify the relation- ships between input variables and a dependent and continuous output variable. It is widely used for predictive modelling in fields such as fi- nance, healthcare, and engineering. However, traditional methods of- ten struggle with real-world data complexities, including uncertainty and ambiguity. While deep learning approaches excel at capturing complex non-linear relationships, they lack interpretability and risk over-fitting on small datasets. Fuzzy systems provide an alternative framework for handling uncertainty and imprecision, with Mamdani and Takagi-Sugeno- Kang (TSK) systems offering complementary strengths: interpretability versus accuracy. This paper presents a novel fuzzy regression method that combines the interpretability of Mamdani systems with the preci- sion of TSK models. The proposed approach introduces a hybrid rule structure with fuzzy and crisp components and dual dominance types, enhancing both accuracy and explainability. Evaluations on benchmark datasets demonstrate state-of-the-art performance in several cases, with rules maintaining a component similar to traditional Mamdani systems while improving precision through improved rule outputs. This hybrid methodology offers a balanced and versatile tool for predictive modelling, addressing the trade-off between interpretability and accuracy inherent in fuzzy systems. In the 6 datasets tested, the proposed approach gave the best fuzzy methodology score in 4 datasets, out-performed the opaque models in 2 datasets and produced the best overall score in 1 dataset with the improvements in RMSE ranging from 0.4% to 19%.",
    "keywords": []
  },
  {
    "article_id": "2510.14097v1_Near-Optimal_Regret-Queue_Length_Tradeoff_in_Online_Learning_for_Two-Sided_Markets",
    "title": "2510.14097v1 Near-Optimal Regret-Queue Length Tradeoff in Online Learning for Two-Sided Markets",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.14097v1_Near-Optimal_Regret-Queue_Length_Tradeoff_in_Online_Learning_for_Two-Sided_Markets.pdf",
    "url": "http://arxiv.org/abs/2510.14097v1_Near-Optimal_Regret-Queue_Length_Tradeoff_in_Online_Learning_for_Two-Sided_Markets",
    "pdf_url": "https://arxiv.org/pdf/2510.14097v1_Near-Optimal_Regret-Queue_Length_Tradeoff_in_Online_Learning_for_Two-Sided_Markets",
    "file_size_mb": 1.54,
    "abstract": "We study a two-sided market, wherein, price-sensitive heterogeneous customers and servers arrive and join their respective queues. A compatible customer-server pair can then be matched by the platform, at which point, they leave the system. Our objective is to design pricing and matching algorithms that maximize the platform’s profit, while maintaining reasonable queue lengths. As the demand and supply curves governing the price-dependent arrival rates may not be known in practice, we design a novel online-learning-based pricing policy and establish its near- optimality. In particular, we prove a tradeoff among three performance metrics: ˜OpT 1´γq regret, ˜OpT γ{2q average queue length, and ˜OpT γq maximum queue length for γ P p0, 1{6s, significantly improving over existing results [1]. Moreover, barring the permissible range of γ, we show that this trade-off between regret and average queue length is optimal up to logarithmic factors under a class of policies, matching the optimal one as in [2] which assumes the demand and supply curves to be known. Our proposed policy has two noteworthy features: a dynamic component that optimizes the tradeoff between low regret and small queue lengths; and a probabilistic component that resolves the tension between obtaining useful samples for fast learning and maintaining small queue lengths.",
    "keywords": []
  },
  {
    "article_id": "2510.14985v1_DeepAries_Adaptive_Rebalancing_Interval_Selection_for_Enhanced_Portfolio_Selection",
    "title": "2510.14985v1 DeepAries Adaptive Rebalancing Interval Selection for Enhanced Portfolio Selection",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.14985v1_DeepAries_Adaptive_Rebalancing_Interval_Selection_for_Enhanced_Portfolio_Selection.pdf",
    "url": "http://arxiv.org/abs/2510.14985v1_DeepAries_Adaptive_Rebalancing_Interval_Selection_for_Enhanced_Portfolio_Selection",
    "pdf_url": "https://arxiv.org/pdf/2510.14985v1_DeepAries_Adaptive_Rebalancing_Interval_Selection_for_Enhanced_Portfolio_Selection",
    "file_size_mb": 1.98,
    "abstract": "We propose DeepAries, a novel deep reinforcement learning frame- work for dynamic portfolio management that jointly optimizes the timing and allocation of rebalancing decisions. Unlike prior reinforcement learning methods that employ fixed rebalancing intervals regardless of market conditions, DeepAries adaptively se- lects optimal rebalancing intervals along with portfolio weights to reduce unnecessary transaction costs and maximize risk-adjusted returns. Our framework integrates a Transformer-based state en- coder, which effectively captures complex long-term market de- pendencies, with Proximal Policy Optimization (PPO) to generate simultaneous discrete (rebalancing intervals) and continuous (asset allocations) actions. Extensive experiments on multiple real-world financial markets demonstrate that DeepAries significantly out- performs traditional fixed-frequency and full-rebalancing strate- gies in terms of risk-adjusted returns, transaction costs, and draw- downs. Additionally, we provide a live demo of DeepAries at https: //deep-aries.github.io/, along with the source code and dataset at https://github.com/dmis-lab/DeepAries, illustrating DeepAries’ ∗Corresponding authors. This work is licensed under a Creative Commons Attribution-NonCommercial- ShareAlike 4.0 International License. CIKM ’25, Seoul, Republic of Korea © 2025 Copyright held by the owner/author(s). ACM ISBN 979-8-4007-2040-6/2025/11 https://doi.org/10.1145/3746252.3761572 capability to produce interpretable rebalancing and allocation deci- sions aligned with shifting market regimes. Overall, DeepAries in- troduces an innovative paradigm for adaptive and practical portfo- lio management by integrating both timing and allocation into a unified decision-making process. CCS Concepts • Information systems →Expert systems; Data mining; • Computing methodologies →Artificial intelligence; Learn- ing paradigms.",
    "keywords": [
      "Portfolio Management",
      "Adaptive Rebalancing Interval Selection"
    ]
  },
  {
    "article_id": "2510.15076v1_Online_Correlation_Clustering_Simultaneously_Optimizing_All_ell_p-norms",
    "title": "2510.15076v1 Online Correlation Clustering Simultaneously Optimizing All ell p-norms",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.15076v1_Online_Correlation_Clustering_Simultaneously_Optimizing_All_ell_p-norms.pdf",
    "url": "http://arxiv.org/abs/2510.15076v1_Online_Correlation_Clustering_Simultaneously_Optimizing_All_ell_p-norms",
    "pdf_url": "https://arxiv.org/pdf/2510.15076v1_Online_Correlation_Clustering_Simultaneously_Optimizing_All_ell_p-norms",
    "file_size_mb": 1.4,
    "abstract": "The ℓp-norm objectives for correlation clustering present a fundamental trade-off between minimiz- ing total disagreements (the ℓ1-norm) and ensuring fairness to individual nodes (the ℓ8-norm). Sur- prisingly, in the offline setting it is possible to simultaneously approximate all ℓp-norms with a sin- gle clustering. Can this powerful guarantee be achieved in an online setting? This paper provides the first affirmative answer. We present a single algorithm for the online-with-a-sample (AOS) model that, given a small constant fraction of the input as a sample, produces one clustering that is simultaneously Oplog4 nq-competitive for all ℓp-norms with high probability, Oplog nq-competitive for the ℓ8-norm with high probability, and Op1q-competitive for the ℓ1-norm in expectation. This work successfully translates the offline “all-norms” guarantee to the online world. Our setting is motivated by a new hardness result that demonstrates a fundamental separation between these objectives in the standard random-order (RO) online model. Namely, while the ℓ1-norm is trivially Op1q-approximable in the RO model, we prove that any algorithm in the RO model for the fairness- promoting ℓ8-norm must have a competitive ratio of at least Ωpn1{3q. This highlights the necessity of a different beyond-worst-case model. We complement our algorithm with lower bounds, showing our competitive ratios for the ℓ1- and ℓ8- norms are nearly tight in the AOS model.",
    "keywords": []
  },
  {
    "article_id": "2510.15404v1_Online_Kernel_Dynamic_Mode_Decomposition_for_Streaming_Time_Series_Forecasting_with_Adaptive_Windowi",
    "title": "2510.15404v1 Online Kernel Dynamic Mode Decomposition for Streaming Time Series Forecasting with Adaptive Windowi",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.15404v1_Online_Kernel_Dynamic_Mode_Decomposition_for_Streaming_Time_Series_Forecasting_with_Adaptive_Windowi.pdf",
    "url": "http://arxiv.org/abs/2510.15404v1_Online_Kernel_Dynamic_Mode_Decomposition_for_Streaming_Time_Series_Forecasting_with_Adaptive_Windowi",
    "pdf_url": "https://arxiv.org/pdf/2510.15404v1_Online_Kernel_Dynamic_Mode_Decomposition_for_Streaming_Time_Series_Forecasting_with_Adaptive_Windowi",
    "file_size_mb": 1.44,
    "abstract": "Real-time forecasting from streaming data poses critical challenges: handling non-stationary dynamics, operating under strict computational limits, and adapting rapidly without catastrophic forgetting. However, many existing approaches face trade-offs between accuracy, adaptability, and efficiency, particularly when deployed in constrained computing environments. We introduce WORK-DMD (Windowed Online Random Kernel Dynamic Mode Decomposition), a method that combines Random Fourier Features with online Dynamic Mode Decomposition to capture nonlinear dynamics through explicit feature mapping, while preserving fixed computational cost and competitive predictive accuracy across evolving data. WORK-DMD employs Sherman–Morrison updates within rolling windows, enabling continuous adaptation to evolving dynamics from only current data, eliminating the need for lengthy training or large storage requirements for historical data. Experiments on benchmark datasets across several domains show that WORK-DMD achieves higher accuracy than several state-of-the-art online forecasting methods, while requiring only a single pass through the data and demonstrating particularly strong performance in short-term forecasting. Our results show that combining kernel evaluations with adaptive matrix updates achieves strong predictive performance with minimal data requirements. This sample efficiency offers a practical alternative to deep learning for streaming forecasting applications.",
    "keywords": []
  },
  {
    "article_id": "2510.15429v1_Safe_Efficient_and_Robust_Reinforcement_Learning_for_Ranking_and_Diffusion_Models",
    "title": "2510.15429v1 Safe Efficient and Robust Reinforcement Learning for Ranking and Diffusion Models",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.15429v1_Safe_Efficient_and_Robust_Reinforcement_Learning_for_Ranking_and_Diffusion_Models.pdf",
    "url": "http://arxiv.org/abs/2510.15429v1_Safe_Efficient_and_Robust_Reinforcement_Learning_for_Ranking_and_Diffusion_Models",
    "pdf_url": "https://arxiv.org/pdf/2510.15429v1_Safe_Efficient_and_Robust_Reinforcement_Learning_for_Ranking_and_Diffusion_Models",
    "file_size_mb": 22.17,
    "abstract": null,
    "keywords": []
  },
  {
    "article_id": "2510.15995v1_The_Invisible_Handshake_Tacit_Collusion_between_Adaptive_Market_Agents",
    "title": "2510.15995v1 The Invisible Handshake Tacit Collusion between Adaptive Market Agents",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.15995v1_The_Invisible_Handshake_Tacit_Collusion_between_Adaptive_Market_Agents.pdf",
    "url": "http://arxiv.org/abs/2510.15995v1_The_Invisible_Handshake_Tacit_Collusion_between_Adaptive_Market_Agents",
    "pdf_url": "https://arxiv.org/pdf/2510.15995v1_The_Invisible_Handshake_Tacit_Collusion_between_Adaptive_Market_Agents",
    "file_size_mb": 2.58,
    "abstract": "We study the emergence of tacit collusion between adaptive trading agents in a stochastic market with endogenous price formation. Using a two-player repeated game between a market maker and a market taker, we characterize feasible and collusive strategy profiles that raise prices beyond competitive levels. We show that, when agents follow simple learning algorithms (e.g., gradient ascent) to maximize their own wealth, the resulting dynamics converge to collusive strategy profiles, even in highly liquid markets with small trade sizes. By highlighting how simple learning strategies naturally lead to tacit collusion, our results offer new insights into the dynamics of AI-driven markets.",
    "keywords": [
      "Trading",
      "Algorithmic collusion",
      "Game theory",
      "Gradient ascent",
      "Fi-"
    ]
  },
  {
    "article_id": "2510.16008v1_Convolutional_Attention_in_Betting_Exchange_Markets",
    "title": "2510.16008v1 Convolutional Attention in Betting Exchange Markets",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.16008v1_Convolutional_Attention_in_Betting_Exchange_Markets.pdf",
    "url": "http://arxiv.org/abs/2510.16008v1_Convolutional_Attention_in_Betting_Exchange_Markets",
    "pdf_url": "https://arxiv.org/pdf/2510.16008v1_Convolutional_Attention_in_Betting_Exchange_Markets",
    "file_size_mb": 2.01,
    "abstract": "This study presents the implementation of a short-term forecasting system for price movements in exchange markets, using market depth data and a systematic procedure to enable a fully automated trading system. The case study focuses on the UK to Win Horse Racing market during the pre-live stage on the world’s leading betting exchange, Betfair. Innovative convolutional attention mecha- nisms are introduced and applied to multiple recurrent neural networks and bi-dimensional convolu- tional recurrent neural network layers. Additionally, a novel padding method for convolutional layers is proposed, specifically designed for multivariate time series processing. These innovations are thor- oughly detailed, along with their execution process. The proposed architectures follow a standard supervised learning approach, involving model training and subsequent testing on new data, which requires extensive pre-processing and data analysis. The study also presents a complete end-to-end framework for automated feature engineering and market interactions using the developed models in production. The key finding of this research is that all proposed innovations positively impact the performance metrics of the classification task under examination, thereby advancing the current state-of-the-art in convolutional attention mechanisms and padding methods applied to multivariate time series problems.",
    "keywords": [
      "Deep Learning",
      "Betting Exchange",
      "L3 Market Data",
      "Classification"
    ]
  },
  {
    "article_id": "2510.16620v2_Feedback_Lunch_Deep_Feedback_Codes_for_Wiretap_Channels",
    "title": "2510.16620v2 Feedback Lunch Deep Feedback Codes for Wiretap Channels",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.16620v2_Feedback_Lunch_Deep_Feedback_Codes_for_Wiretap_Channels.pdf",
    "url": "http://arxiv.org/abs/2510.16620v2_Feedback_Lunch_Deep_Feedback_Codes_for_Wiretap_Channels",
    "pdf_url": "https://arxiv.org/pdf/2510.16620v2_Feedback_Lunch_Deep_Feedback_Codes_for_Wiretap_Channels",
    "file_size_mb": 0.49,
    "abstract": "—We consider reversely-degraded wiretap channels, for which the secrecy capacity is zero if there is no chan- nel feedback. This work focuses on a seeded modular code design for the Gaussian wiretap channel with channel output feedback, combining universal hash functions for security and learned feedback-based codes for reliability to achieve positive secrecy rates. We study the trade-off between communication reliability and information leakage, illustrating that feedback enables agreeing on a secret key shared between legitimate parties, overcoming the security advantage of the wiretapper. Our findings also motivate code designs for sensing-assisted secure communication, to be used in next-generation integrated sensing and communication methods.",
    "keywords": [
      "Wiretap channel with feedback",
      "modular coding"
    ]
  },
  {
    "article_id": "2510.16663v1_Robust_Dynamic_Staffing_with_Predictions",
    "title": "2510.16663v1 Robust Dynamic Staffing with Predictions",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.16663v1_Robust_Dynamic_Staffing_with_Predictions.pdf",
    "url": "http://arxiv.org/abs/2510.16663v1_Robust_Dynamic_Staffing_with_Predictions",
    "pdf_url": "https://arxiv.org/pdf/2510.16663v1_Robust_Dynamic_Staffing_with_Predictions",
    "file_size_mb": 0.88,
    "abstract": ". We consider a natural dynamic staffing problem in which a decision-maker sequentially hires workers over a finite horizon to meet an unknown demand revealed at the end. Predictions about demand arrive over time and become increasingly accurate, while worker availability decreases. This creates a fundamental trade-off between hiring early to avoid understaffing (when workers are more available but forecasts are less reliable) and hiring late to avoid overstaffing (when forecasts are more accurate but availability is lower). This problem is motivated by last-mile delivery operations, where companies such as Amazon rely on gig-economy workers whose availability declines closer to the operating day. To address practical limitations of Bayesian models (in particular, to remain agnostic to the underlying forecasting method), we study this problem under adversarial predictions. In this model, sequential predictions are adversarially chosen uncertainty intervals that (approximately) contain the true demand. The objective is to minimize worst-case staffing imbalance cost. Our main result is a simple and computationally efficient online algorithm that is minimax optimal. We first characterize the minimax cost against a restricted adversary via a polynomial-size linear program, then show how to emulate this solution in the general case. While our base model focuses on a single demand, we extend the framework to multiple demands (with egalitarian or utilitarian objectives), to settings with costly reversals of hiring decisions, and to inconsistent prediction intervals. We also introduce a practical “re-solving” variant of our algorithm, which we prove is also minimax optimal. Finally, motivated by our collaboration with Amazon Last-Mile, we conduct numerical experiments showing that our algorithms outperform Bayesian heuristics in both cost and speed, and are competitive with (approximate or exact) Bayesian-optimal policies when those can be computed. Key words: Last-mile delivery, staffing, online algorithms, sequential predictions, inventory management. 1 arXiv:2510.16663v1 [cs.DS] 18 Oct 2025 Feng, Manshadi, Niazadeh, Neyshabouri: Robust Dynamic Staffing with Predictions 2",
    "keywords": [
      "Last-mile delivery",
      "staffing",
      "online algorithms",
      "sequential predictions",
      "inventory management"
    ]
  },
  {
    "article_id": "2510.16857v2_DrivAerStar_An_Industrial-Grade_CFD_Dataset_for_Vehicle_Aerodynamic_Optimization",
    "title": "2510.16857v2 DrivAerStar An Industrial-Grade CFD Dataset for Vehicle Aerodynamic Optimization",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.16857v2_DrivAerStar_An_Industrial-Grade_CFD_Dataset_for_Vehicle_Aerodynamic_Optimization.pdf",
    "url": "http://arxiv.org/abs/2510.16857v2_DrivAerStar_An_Industrial-Grade_CFD_Dataset_for_Vehicle_Aerodynamic_Optimization",
    "pdf_url": "https://arxiv.org/pdf/2510.16857v2_DrivAerStar_An_Industrial-Grade_CFD_Dataset_for_Vehicle_Aerodynamic_Optimization",
    "file_size_mb": 9.3,
    "abstract": "Vehicle aerodynamics optimization has become critical for automotive electrifica- tion, where drag reduction directly determines electric vehicle range and energy efficiency. Traditional approaches face an intractable trade-off: computationally expensive Computational Fluid Dynamics (CFD) simulations requiring weeks per design iteration, or simplified models that sacrifice production-grade accuracy. While machine learning offers transformative potential, existing datasets exhibit fundamental limitations—inadequate mesh resolution, missing vehicle compo- nents, and validation errors exceeding 5%—preventing deployment in industrial workflows. We present DrivAerStar, comprising 12,000 industrial-grade auto- motive CFD simulations generated using STAR-CCM+® software. The dataset systematically explores three vehicle configurations through 20 Computer Aided Design (CAD) parameters via Free Form Deformation (FFD) algorithms, includ- ing complete engine compartments and cooling systems with realistic internal air- flow. DrivAerStar achieves wind tunnel validation accuracy below 1.04%— a five-fold improvement over existing datasets—through refined mesh strategies with strict wall y` control. Benchmarks demonstrate that models trained on this data achieve production-ready accuracy while reducing computational costs from weeks to minutes. This represents the first dataset bridging academic machine learning research and industrial CFD practice, establishing a new standard for data-driven aerodynamic optimization in automotive development. Beyond auto- motive applications, DrivAerStar demonstrates a paradigm for integrating high- fidelity physics simulations with Artificial Intelligence (AI) across engineering disciplines where computational constraints currently limit innovation.",
    "keywords": []
  },
  {
    "article_id": "2510.18165v1_Saber_An_Efficient_Sampling_with_Adaptive_Acceleration_and_Backtracking_Enhanced_Remasking_for_Diffu",
    "title": "2510.18165v1 Saber An Efficient Sampling with Adaptive Acceleration and Backtracking Enhanced Remasking for Diffu",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.18165v1_Saber_An_Efficient_Sampling_with_Adaptive_Acceleration_and_Backtracking_Enhanced_Remasking_for_Diffu.pdf",
    "url": "http://arxiv.org/abs/2510.18165v1_Saber_An_Efficient_Sampling_with_Adaptive_Acceleration_and_Backtracking_Enhanced_Remasking_for_Diffu",
    "pdf_url": "https://arxiv.org/pdf/2510.18165v1_Saber_An_Efficient_Sampling_with_Adaptive_Acceleration_and_Backtracking_Enhanced_Remasking_for_Diffu",
    "file_size_mb": 0.57,
    "abstract": "Diffusion language models (DLMs) are emerging as a powerful and promising al- ternative to the dominant autoregressive paradigm, offering inherent advantages in parallel generation and bidirectional context modeling. However, the performance of DLMs on code generation tasks, which have stronger structural constraints, is significantly hampered by the critical trade-off between inference speed and output quality. We observed that accelerating the code generation process by re- ducing the number of sampling steps usually leads to a catastrophic collapse in performance. In this paper, we introduce efficient Sampling with Adaptive accel- eration and Backtracking Enhanced Remasking (i.e., Saber), a novel training-free sampling algorithm for DLMs to achieve better inference speed and output qual- ity in code generation. Specifically, Saber is motivated by two key insights in the DLM generation process: 1) it can be adaptively accelerated as more of the code context is established; 2) it requires a backtracking mechanism to reverse the generated tokens. Extensive experiments on multiple mainstream code generation benchmarks show that Saber boosts Pass@1 accuracy by an average improvement of 1.9% over mainstream DLM sampling methods, meanwhile achieving an aver- age 251.4% inference speedup. By leveraging the inherent advantages of DLMs, our work significantly narrows the performance gap with autoregressive models in code generation.1",
    "keywords": []
  },
  {
    "article_id": "2510.18225v1_Joint_Optimization_of_Cooperation_Efficiency_and_Communication_Covertness_for_Target_Detection_with_",
    "title": "2510.18225v1 Joint Optimization of Cooperation Efficiency and Communication Covertness for Target Detection with ",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.18225v1_Joint_Optimization_of_Cooperation_Efficiency_and_Communication_Covertness_for_Target_Detection_with_.pdf",
    "url": "http://arxiv.org/abs/2510.18225v1_Joint_Optimization_of_Cooperation_Efficiency_and_Communication_Covertness_for_Target_Detection_with_",
    "pdf_url": "https://arxiv.org/pdf/2510.18225v1_Joint_Optimization_of_Cooperation_Efficiency_and_Communication_Covertness_for_Target_Detection_with_",
    "file_size_mb": 1.4,
    "abstract": "—This paper investigates underwater cooperative tar- get detection using autonomous underwater vehicles (AUVs), with a focus on the critical trade-off between cooperation efficiency and communication covertness. To tackle this challenge, we first formulate a joint trajectory and power control optimization problem, and then present an innovative hierarchical action management framework to solve it. According to the hierarchical formulation, at the macro level, the master AUV models the agent selection process as a Markov decision process and deploys the proximal policy optimization algorithm for strategic task allocation. At the micro level, each selected agent’s decentralized decision-making is modeled as a partially observable Markov decision process, and a multi-agent proximal policy optimization algorithm is used to dynamically adjust its trajectory and transmission power based on its local observations. Under the centralized training and decentralized execution paradigm, our target detection framework enables adaptive covert cooperation while satisfying both energy and mobility constraints. By com- prehensively modeling the considered system, the involved signals and tasks, as well as energy consumption, theoretical insights and practical solutions for the efficient and secure operation of multiple AUVs are provided, offering significant implications for the execution of underwater covert communication tasks.",
    "keywords": [
      "Autonomous underwater vehicles",
      "target de-"
    ]
  },
  {
    "article_id": "2510.18904v1_DuoLens_A_Framework_for_Robust_Detection_of_Machine-Generated_Multilingual_Text_and_Code",
    "title": "2510.18904v1 DuoLens A Framework for Robust Detection of Machine-Generated Multilingual Text and Code",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.18904v1_DuoLens_A_Framework_for_Robust_Detection_of_Machine-Generated_Multilingual_Text_and_Code.pdf",
    "url": "http://arxiv.org/abs/2510.18904v1_DuoLens_A_Framework_for_Robust_Detection_of_Machine-Generated_Multilingual_Text_and_Code",
    "pdf_url": "https://arxiv.org/pdf/2510.18904v1_DuoLens_A_Framework_for_Robust_Detection_of_Machine-Generated_Multilingual_Text_and_Code",
    "file_size_mb": 0.62,
    "abstract": "The prevalence of Large Language Models (LLMs) for generating multilingual text and source code has only increased the imperative for machine-generated content detectors to be accurate and efficient across domains. Current detectors either incur high computational cost or lack sufficient accuracy, often with a trade-off between the two, leaving room for further improvement. To address these gaps, we propose the fine-tuning of encoder-only Small Language Models (SLMs), in particular, the pre-trained models of RoBERTA & CodeBERTa using specialized datasets on source code and other natural language to prove that for the task of binary classification, SLMs outperform LLMs by a huge margin whilst using a fraction of compute. Our encoders achieve AUROC = 0.97 to 0.99 and macro-F1 = 0.89 to 0.94 while reducing latency by 8-12× and peak VRAM by 3–5× at 512-token inputs. Under cross-generator shifts and adversarial transformations (paraphrase, back-translation; code formatting/renaming), performance retains ≥92% of clean AUROC. We release training and evaluation scripts with seeds and configs; a reproducibility checklist is also included.",
    "keywords": []
  },
  {
    "article_id": "2510.19173v1_News-Aware_Direct_Reinforcement_Trading_for_Financial_Markets",
    "title": "2510.19173v1 News-Aware Direct Reinforcement Trading for Financial Markets",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.19173v1_News-Aware_Direct_Reinforcement_Trading_for_Financial_Markets.pdf",
    "url": "http://arxiv.org/abs/2510.19173v1_News-Aware_Direct_Reinforcement_Trading_for_Financial_Markets",
    "pdf_url": "https://arxiv.org/pdf/2510.19173v1_News-Aware_Direct_Reinforcement_Trading_for_Financial_Markets",
    "file_size_mb": 2.34,
    "abstract": "The financial market is known to be highly sensitive to news. Therefore, effectively incorporating news data into quanti- tative trading remains an important challenge. Existing ap- proaches typically rely on manually designed rules and/or handcrafted features. In this work, we directly use the news sentiment scores derived from large language models, together with raw price and volume data, as observable inputs for rein- forcement learning. These inputs are processed by sequence models such as recurrent neural networks or Transformers to make end-to-end trading decisions. We conduct experiments using the cryptocurrency market as an example and evaluate two representative reinforcement learning algorithms, namely Double Deep Q-Network (DDQN) and Group Relative Pol- icy Optimization (GRPO). The results demonstrate that our news-aware approach, which does not depend on handcrafted features or manually designed rules, can achieve performance superior to market benchmarks. We further highlight the criti- cal role of time-series information in this process.",
    "keywords": []
  },
  {
    "article_id": "2510.19226v1_Controllable_Machine_Unlearning_via_Gradient_Pivoting",
    "title": "2510.19226v1 Controllable Machine Unlearning via Gradient Pivoting",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.19226v1_Controllable_Machine_Unlearning_via_Gradient_Pivoting.pdf",
    "url": "http://arxiv.org/abs/2510.19226v1_Controllable_Machine_Unlearning_via_Gradient_Pivoting",
    "pdf_url": "https://arxiv.org/pdf/2510.19226v1_Controllable_Machine_Unlearning_via_Gradient_Pivoting",
    "file_size_mb": 2.87,
    "abstract": "Machine unlearning (MU) aims to remove the influence of specific data from a trained model. However, approximate unlearning methods, often formulated as a single-objective optimization (SOO) problem, face a critical trade-off between unlearning efficacy and model fidelity. This leads to three primary challenges: the risk of over-forgetting, a lack of fine-grained control over the unlearning process, and the absence of metrics to holistically evaluate the trade-off. To address these issues, we reframe MU as a multi-objective optimization (MOO) problem. We then introduce a novel algorithm, Controllable Unlearning by Pivoting Gradient (CUP), which features a unique pivoting mechanism. Unlike traditional MOO methods that converge to a single solution, CUP’s mechanism is designed to controllably navigate the entire Pareto frontier. This navigation is governed by a single intuitive hyperparameter, the ‘unlearning intensity’, which allows for precise selection of a desired trade-off. To evaluate this capability, we adopt the hypervolume indicator, a metric that captures both the quality and diversity of the entire set of solutions an algorithm can generate. Our experimental results demonstrate that CUP produces a superior set of Pareto-optimal solutions, consistently outperforming existing methods across various vision tasks.",
    "keywords": [
      "Unlearning",
      "Data Privacy",
      "Trustworthy AI",
      "Selective Forgetting",
      "Multi-Objective"
    ]
  },
  {
    "article_id": "2510.19352v1_ConvXformer_Differentially_Private_Hybrid_ConvNeXt-Transformer_for_Inertial_Navigation",
    "title": "2510.19352v1 ConvXformer Differentially Private Hybrid ConvNeXt-Transformer for Inertial Navigation",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.19352v1_ConvXformer_Differentially_Private_Hybrid_ConvNeXt-Transformer_for_Inertial_Navigation.pdf",
    "url": "http://arxiv.org/abs/2510.19352v1_ConvXformer_Differentially_Private_Hybrid_ConvNeXt-Transformer_for_Inertial_Navigation",
    "pdf_url": "https://arxiv.org/pdf/2510.19352v1_ConvXformer_Differentially_Private_Hybrid_ConvNeXt-Transformer_for_Inertial_Navigation",
    "file_size_mb": 14.84,
    "abstract": "—Data-driven inertial sequence learning has revolu- tionized navigation in GPS-denied environments, offering su- perior odometric resolution compared to traditional Bayesian methods. However, deep learning-based inertial tracking systems remain vulnerable to privacy breaches that can expose sensi- tive training data. Existing differential privacy solutions often compromise model performance by introducing excessive noise, particularly in high-frequency inertial measurements. In this article, we propose ConvXformer, a hybrid architecture that fuses ConvNeXt blocks with Transformer encoders in a hierarchical structure for robust inertial navigation. We propose an efficient differential privacy mechanism incorporating adaptive gradient clipping and gradient-aligned noise injection (GANI) to protect sensitive information while ensuring model performance. Our framework leverages truncated singular value decomposition for gradient processing, enabling precise control over the privacy- utility trade-off. Comprehensive performance evaluations on benchmark datasets (OxIOD, RIDI, RoNIN) demonstrate that ConvXformer surpasses state-of-the-art methods, achieving more than 40% improvement in positioning accuracy while ensur- ing (ϵ, δ)-differential privacy guarantees. To validate real-world performance, we introduce the Mech-IO dataset, collected from the mechanical engineering building at KAIST, where intense magnetic fields from industrial equipment induce significant sensor perturbations. This demonstrated robustness under severe environmental distortions makes our framework well-suited for secure and intelligent navigation in cyber-physical systems.",
    "keywords": [
      "Neural Inertial Navigation",
      "Odometry",
      "Deep"
    ]
  },
  {
    "article_id": "2510.19934v1_Mitigating_Privacy-Utility_Trade-off_in_Decentralized_Federated_Learning_via_f-Differential_Privacy",
    "title": "2510.19934v1 Mitigating Privacy-Utility Trade-off in Decentralized Federated Learning via f-Differential Privacy",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.19934v1_Mitigating_Privacy-Utility_Trade-off_in_Decentralized_Federated_Learning_via_f-Differential_Privacy.pdf",
    "url": "http://arxiv.org/abs/2510.19934v1_Mitigating_Privacy-Utility_Trade-off_in_Decentralized_Federated_Learning_via_f-Differential_Privacy",
    "pdf_url": "https://arxiv.org/pdf/2510.19934v1_Mitigating_Privacy-Utility_Trade-off_in_Decentralized_Federated_Learning_via_f-Differential_Privacy",
    "file_size_mb": 1.86,
    "abstract": "Differentially private (DP) decentralized Federated Learning (FL) allows local users to collaborate without sharing their data with a central server. However, accurately quantifying the privacy budget of private FL algorithms is challenging due to the co-existence of complex algorithmic components such as decentralized communication and local updates. This paper addresses privacy accounting for two decentralized FL algorithms within the f-differential privacy (f-DP) framework. We develop two new f-DP–based accounting methods tailored to decentralized settings: Pairwise Network f-DP (PN-f-DP), which quantifies privacy leakage between user pairs under random-walk communication, and Secret-based f-Local DP (Sec-f-LDP), which supports structured noise injection via shared secrets. By combining tools from f-DP theory and Markov chain concentration, our accounting framework captures privacy amplification arising from sparse communication, local iterations, and correlated noise. Experiments on synthetic and real datasets demonstrate that our methods yield consistently tighter (ϵ, δ) bounds and improved utility compared to Rényi DP–based approaches, illustrating the benefits of f-DP in decentralized privacy accounting.",
    "keywords": []
  },
  {
    "article_id": "2510.20621v2_Towards_the_Formalization_of_a_Trustworthy_AI_for_Mining_Interpretable_Models_explOiting_Sophisticat",
    "title": "2510.20621v2 Towards the Formalization of a Trustworthy AI for Mining Interpretable Models explOiting Sophisticat",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.20621v2_Towards_the_Formalization_of_a_Trustworthy_AI_for_Mining_Interpretable_Models_explOiting_Sophisticat.pdf",
    "url": "http://arxiv.org/abs/2510.20621v2_Towards_the_Formalization_of_a_Trustworthy_AI_for_Mining_Interpretable_Models_explOiting_Sophisticat",
    "pdf_url": "https://arxiv.org/pdf/2510.20621v2_Towards_the_Formalization_of_a_Trustworthy_AI_for_Mining_Interpretable_Models_explOiting_Sophisticat",
    "file_size_mb": 2.37,
    "abstract": ". Interpretable-by-design models are crucial for fostering trust, accountability, and safe adoption of automated decision-making models in real-world applications. In this paper we formalize the ground for the MIMOSA (Mining Interpretable Models explOiting Sophisticated Algo- rithms) framework, a comprehensive methodology for generating predic- tive models that balance interpretability with performance while embed- ding key ethical properties. We formally define here the supervised learn- ing setting across diverse decision-making tasks and data types, includ- ing tabular data, time series, images, text, transactions, and trajectories. We characterize three major families of interpretable models: feature im- portance, rule, and instance based models. For each family, we analyze their interpretability dimensions, reasoning mechanisms, and complex- ity. Beyond interpretability, we formalize three critical ethical properties, namely causality, fairness, and privacy, providing formal definitions, eval- uation metrics, and verification procedures for each. We then examine the inherent trade-offs between these properties and discuss how privacy requirements, fairness constraints, and causal reasoning can be embed- ded within interpretable pipelines. By evaluating ethical measures during model generation, this framework establishes the theoretical foundations for developing AI systems that are not only accurate and interpretable but also fair, privacy-preserving, and causally aware, i.e., trustworthy.",
    "keywords": [
      "Interpretable Machine Learning",
      "Explainable Artificial In-"
    ]
  },
  {
    "article_id": "2510.21127v1_Enhanced_Evolutionary_Multi-Objective_Deep_Reinforcement_Learning_for_Reliable_and_Efficient_Wireles",
    "title": "2510.21127v1 Enhanced Evolutionary Multi-Objective Deep Reinforcement Learning for Reliable and Efficient Wireles",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.21127v1_Enhanced_Evolutionary_Multi-Objective_Deep_Reinforcement_Learning_for_Reliable_and_Efficient_Wireles.pdf",
    "url": "http://arxiv.org/abs/2510.21127v1_Enhanced_Evolutionary_Multi-Objective_Deep_Reinforcement_Learning_for_Reliable_and_Efficient_Wireles",
    "pdf_url": "https://arxiv.org/pdf/2510.21127v1_Enhanced_Evolutionary_Multi-Objective_Deep_Reinforcement_Learning_for_Reliable_and_Efficient_Wireles",
    "file_size_mb": 2.34,
    "abstract": "—Despite rapid advancements in sensor networks, conventional battery-powered sensor networks suffer from lim- ited operational lifespans and frequent maintenance requirements that severely constrain their deployment in remote and inaccessi- ble environments. As such, wireless rechargeable sensor networks (WRSNs) with mobile charging capabilities offer a promising solution to extend network lifetime. However, WRSNs face critical challenges from the inherent trade-off between maximizing the node survival rates and maximizing charging energy efficiency under dynamic operational conditions. In this paper, we investi- gate a typical scenario where mobile chargers move and charge the sensor, thereby maintaining the network connectivity while minimizing the energy waste. Specifically, we formulate a multi- objective optimization problem that simultaneously maximizes the network node survival rate and mobile charger energy usage efficiency across multiple time slots, which presents NP-hard computational complexity with long-term temporal dependencies that make traditional optimization approaches ineffective. To address these challenges, we propose an enhanced evolutionary multi-objective deep reinforcement learning algorithm, which integrates a long short-term memory (LSTM)-based policy net- work for temporal pattern recognition, a multilayer perceptron- based prospective increment model for future state prediction, and a time-varying Pareto policy evaluation method for dynamic preference adaptation. Extensive simulation results demonstrate that the proposed algorithm significantly outperforms existing approaches in balancing node survival rate and energy efficiency while generating diverse Pareto-optimal solutions. Moreover, we reveal that the LSTM-enhanced policy network achieves 25% faster convergence compared to conventional neural networks, and the time-varying evaluation method adapts effectively to changing network conditions with improved long-term perfor- mance stability.",
    "keywords": [
      "Wireless rechargeable sensor networks",
      "deep"
    ]
  },
  {
    "article_id": "2510.21147v1_Hierarchical_AI_Multi-Agent_Fundamental_Investing_Evidence_from_Chinas_A-Share_Market",
    "title": "2510.21147v1 Hierarchical AI Multi-Agent Fundamental Investing Evidence from Chinas A-Share Market",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.21147v1_Hierarchical_AI_Multi-Agent_Fundamental_Investing_Evidence_from_Chinas_A-Share_Market.pdf",
    "url": "http://arxiv.org/abs/2510.21147v1_Hierarchical_AI_Multi-Agent_Fundamental_Investing_Evidence_from_Chinas_A-Share_Market",
    "pdf_url": "https://arxiv.org/pdf/2510.21147v1_Hierarchical_AI_Multi-Agent_Fundamental_Investing_Evidence_from_Chinas_A-Share_Market",
    "file_size_mb": 0.94,
    "abstract": null,
    "keywords": [
      "Multi-agent system",
      "artificial intelligence",
      "large language models",
      "reinforcement learning"
    ]
  },
  {
    "article_id": "2510.21379v1_Cost-Sensitive_Freeze-thaw_Bayesian_Optimization_for_Efficient_Hyperparameter_Tuning",
    "title": "2510.21379v1 Cost-Sensitive Freeze-thaw Bayesian Optimization for Efficient Hyperparameter Tuning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.21379v1_Cost-Sensitive_Freeze-thaw_Bayesian_Optimization_for_Efficient_Hyperparameter_Tuning.pdf",
    "url": "http://arxiv.org/abs/2510.21379v1_Cost-Sensitive_Freeze-thaw_Bayesian_Optimization_for_Efficient_Hyperparameter_Tuning",
    "pdf_url": "https://arxiv.org/pdf/2510.21379v1_Cost-Sensitive_Freeze-thaw_Bayesian_Optimization_for_Efficient_Hyperparameter_Tuning",
    "file_size_mb": 3.45,
    "abstract": "In this paper, we address the problem of cost-sensitive hyperparameter optimiza- tion (HPO) built upon freeze-thaw Bayesian optimization (BO). Specifically, we assume a scenario where users want to early-stop the HPO process when the ex- pected performance improvement is not satisfactory with respect to the additional computational cost. Motivated by this scenario, we introduce utility in the freeze- thaw framework, a function describing the trade-off between the cost and perfor- mance that can be estimated from the user’s preference data. This utility function, combined with our novel acquisition function and stopping criterion, allows us to dynamically continue training the configuration that we expect to maximally im- prove the utility in the future, and also automatically stop the HPO process around the maximum utility. Further, we improve the sample efficiency of existing freeze- thaw methods with transfer learning to develop a specialized surrogate model for the cost-sensitive HPO problem. We validate our algorithm on established multi- fidelity HPO benchmarks and show that it outperforms all the previous freeze- thaw BO and transfer-BO baselines we consider, while achieving a significantly better trade-off between the cost and performance. Our code is publicly available at https://github.com/db-Lee/CFBO.",
    "keywords": []
  },
  {
    "article_id": "2510.22206v1_Right_Place_Right_Time_Market_Simulation-based_RL_for_Execution_Optimisation",
    "title": "2510.22206v1 Right Place Right Time Market Simulation-based RL for Execution Optimisation",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.22206v1_Right_Place_Right_Time_Market_Simulation-based_RL_for_Execution_Optimisation.pdf",
    "url": "http://arxiv.org/abs/2510.22206v1_Right_Place_Right_Time_Market_Simulation-based_RL_for_Execution_Optimisation",
    "pdf_url": "https://arxiv.org/pdf/2510.22206v1_Right_Place_Right_Time_Market_Simulation-based_RL_for_Execution_Optimisation",
    "file_size_mb": 1.7,
    "abstract": "Execution algorithms are vital to modern trading, they enable mar- ket participants to execute large orders while minimising market impact and transaction costs. As these algorithms grow more so- phisticated, optimising them becomes increasingly challenging. In this work, we present a reinforcement learning (RL) framework for discovering optimal execution strategies, evaluated within a reac- tive agent-based market simulator. This simulator creates reactive order flow and allows us to decompose slippage into its constituent components: market impact and execution risk. We assess the RL agent’s performance using the efficient frontier based on work by Almgren and Chriss, measuring its ability to balance risk and cost. Results show that the RL-derived strategies consistently outperform baselines and operate near the efficient frontier, demonstrating a strong ability to optimise for risk and impact. These findings high- light the potential of reinforcement learning as a powerful tool in the trader’s toolkit. CCS Concepts • Computing methodologies →Agent / discrete models; Rein- forcement learning.",
    "keywords": [
      "Reinforcement Learning",
      "Agent-Based Models",
      "Execution Algo-"
    ]
  },
  {
    "article_id": "2510.22209v1_Visual_Model_Selection_using_Feature_Importance_Clusters_in_Fairness-Performance_Similarity_Optimize",
    "title": "2510.22209v1 Visual Model Selection using Feature Importance Clusters in Fairness-Performance Similarity Optimize",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.22209v1_Visual_Model_Selection_using_Feature_Importance_Clusters_in_Fairness-Performance_Similarity_Optimize.pdf",
    "url": "http://arxiv.org/abs/2510.22209v1_Visual_Model_Selection_using_Feature_Importance_Clusters_in_Fairness-Performance_Similarity_Optimize",
    "pdf_url": "https://arxiv.org/pdf/2510.22209v1_Visual_Model_Selection_using_Feature_Importance_Clusters_in_Fairness-Performance_Similarity_Optimize",
    "file_size_mb": 1.29,
    "abstract": "In the context of algorithmic decision-making, fair machine learning methods often yield multiple models that balance predictive fairness and performance in varying degrees. This diversity introduces a challenge for stakeholders who must select a model that aligns with their specific requirements and values. To address this, we propose an interactive framework that assists in navigating and interpreting the trade-offs across a portfolio of models. Our approach leverages weakly supervised metric learning to learn a Mahalanobis distance that reflects similarity in fairness and performance outcomes, effectively structuring the feature importance space of the models according to stakeholder-relevant criteria. We then apply clustering technique (k-means) to group models based on their transformed representations of feature importances, allowing users to explore clusters of models with similar predictive behaviors and fairness characteristics. This facilitates informed decision-making by helping users understand how models differ not only in their fairness-performance balance but also in the features that drive their predictions.",
    "keywords": [
      "Fair Machine Learning",
      "Model Selection",
      "Fairness-Performance Trade-off",
      "Weakly Supervised Metric Learning"
    ]
  },
  {
    "article_id": "2510.22348v1_Causal_and_Predictive_Modeling_of_Short-Horizon_Market_Risk_and_Systematic_Alpha_Generation_Using_Hy",
    "title": "2510.22348v1 Causal and Predictive Modeling of Short-Horizon Market Risk and Systematic Alpha Generation Using Hy",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.22348v1_Causal_and_Predictive_Modeling_of_Short-Horizon_Market_Risk_and_Systematic_Alpha_Generation_Using_Hy.pdf",
    "url": "http://arxiv.org/abs/2510.22348v1_Causal_and_Predictive_Modeling_of_Short-Horizon_Market_Risk_and_Systematic_Alpha_Generation_Using_Hy",
    "pdf_url": "https://arxiv.org/pdf/2510.22348v1_Causal_and_Predictive_Modeling_of_Short-Horizon_Market_Risk_and_Systematic_Alpha_Generation_Using_Hy",
    "file_size_mb": 1.24,
    "abstract": "We present a systematic trading framework that forecasts short-horizon market risk, identifies its underlying drivers, and generates alpha using a hybrid machine learning ensemble built to trade on the resulting signal. The framework integrates neural networks with tree-based voting models to predict five-day drawdowns in the S&P 500 ETF (SPY), leveraging a cross-asset fea- ture set spanning equities, fixed income, foreign exchange, commodities, and volatility markets. Interpretable feature attribution methods reveal the key macroeconomic and microstructural factors that differentiate high-risk (crash) from benign (non-crash) weekly regimes. Empirical results show a Sharpe ratio of 2.51 and an annualized CAPM alpha of +0.28, with a mar- ket beta of 0.51, indicating that the model delivers substantial systematic alpha with limited directional exposure during the 2005˘2025 backtest period. Overall, the findings underscore the effectiveness of hybrid ensemble architectures in capturing nonlinear risk dynamics and identifying interpretable, potentially causal drivers, providing a robust blueprint for machine learning–driven alpha generation in systematic trading.",
    "keywords": [
      "systematic trading",
      "alpha generation",
      "short-horizon risk forecasting",
      "neural networks"
    ]
  },
  {
    "article_id": "2510.22654v1_UCB-type_Algorithm_for_Budget-Constrained_Expert_Learning",
    "title": "2510.22654v1 UCB-type Algorithm for Budget-Constrained Expert Learning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.22654v1_UCB-type_Algorithm_for_Budget-Constrained_Expert_Learning.pdf",
    "url": "http://arxiv.org/abs/2510.22654v1_UCB-type_Algorithm_for_Budget-Constrained_Expert_Learning",
    "pdf_url": "https://arxiv.org/pdf/2510.22654v1_UCB-type_Algorithm_for_Budget-Constrained_Expert_Learning",
    "file_size_mb": 1.72,
    "abstract": "In many modern applications, a system must dynamically choose between several adaptive learning algorithms that are trained online. Examples include model selection in streaming environments, switching between trading strategies in finance, and orchestrating multiple contextual bandit or reinforcement learning agents. At each round, a learner must select one predictor among K adaptive experts to make a prediction, while being able to update at most M ≤K of them under a fixed training budget. We address this problem in the stochastic setting and introduce M-LCB, a computationally efficient UCB-style meta-algorithm that provides anytime regret guarantees. Its confidence intervals are built directly from realized losses, require no additional optimization, and seamlessly reflect the convergence properties of the underlying experts. If each expert achieves internal regret ˜O(T α), then M-LCB ensures overall regret bounded by ˜O \u0010q KT M + (K/M)1−α T α\u0011 . To our knowledge, this is the first result establishing regret guarantees when multiple adaptive experts are trained simultaneously under per-round budget constraints. We illustrate the framework with two representative cases: (i) parametric models trained online with stochastic losses, and (ii) experts that are themselves multi-armed bandit algorithms. These examples highlight how M-LCB extends the classical bandit paradigm to the more realistic scenario of coordinating stateful, self-learning experts under limited resources.",
    "keywords": [
      "expert algorithms",
      "budget-constrained learning",
      "multi-armed bandits"
    ]
  },
  {
    "article_id": "2510.22685v1_TABL-ABM_A_Hybrid_Framework_for_Synthetic_LOB_Generation",
    "title": "2510.22685v1 TABL-ABM A Hybrid Framework for Synthetic LOB Generation",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.22685v1_TABL-ABM_A_Hybrid_Framework_for_Synthetic_LOB_Generation.pdf",
    "url": "http://arxiv.org/abs/2510.22685v1_TABL-ABM_A_Hybrid_Framework_for_Synthetic_LOB_Generation",
    "pdf_url": "https://arxiv.org/pdf/2510.22685v1_TABL-ABM_A_Hybrid_Framework_for_Synthetic_LOB_Generation",
    "file_size_mb": 2.64,
    "abstract": ". The recent application of deep learning models to finan- cial trading has heightened the need for high fidelity financial time series data. This synthetic data can be used to supplement historical data to train large trading models. The state-of-the-art models for the generative application often rely on huge amounts of historical data and large, complicated models. These models range from autoregres- sive and diffusion-based models through to architecturally simpler models such as the temporal-attention bilinear layer. Agent-based approaches to modelling limit order book dynamics can also recreate trading activity through mechanistic models of trader behaviours. In this work, we demonstrate how a popular agent-based framework for simulating intraday trading activity, the Chiarella model, can be com- bined with one of the most performant deep learning models for fore- casting multi-variate time series, the TABL model. This forecasting model is coupled to a simulation of a matching engine with a novel method for simulating deleted order flow. Our simulator gives us the ability to test the generative abilities of the forecasting model using stylised facts. Our results show that this methodology generates re- alistic price dynamics however, when analysing deeper, parts of the markets microstructure are not accurately recreated, highlighting the necessity for including more sophisticated agent behaviors into the modeling framework to help account for tail events.",
    "keywords": [
      "limit order book model",
      "hybrid model",
      "agent-based"
    ]
  },
  {
    "article_id": "2510.23039v1_Sublinear_Sketches_for_Approximate_Nearest_Neighbor_and_Kernel_Density_Estimation",
    "title": "2510.23039v1 Sublinear Sketches for Approximate Nearest Neighbor and Kernel Density Estimation",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.23039v1_Sublinear_Sketches_for_Approximate_Nearest_Neighbor_and_Kernel_Density_Estimation.pdf",
    "url": "http://arxiv.org/abs/2510.23039v1_Sublinear_Sketches_for_Approximate_Nearest_Neighbor_and_Kernel_Density_Estimation",
    "pdf_url": "https://arxiv.org/pdf/2510.23039v1_Sublinear_Sketches_for_Approximate_Nearest_Neighbor_and_Kernel_Density_Estimation",
    "file_size_mb": 1.13,
    "abstract": "Approximate Nearest Neighbor (ANN) search and Approximate Kernel Density Estimation (A-KDE) are fundamental problems at the core of modern machine learning, with broad applications in data analysis, information systems, and large-scale decision making. In massive and dynamic data streams, a central challenge is to design compact sketches that preserve essential structural properties of the data while enabling efficient queries. In this work, we develop new sketching algorithms that achieve sublinear space and query time guarantees for both ANN and A-KDE for a dynamic stream of data. For ANN in the streaming model, under natural assumptions, we design a sublinear sketch that requires only O(𝑛1+𝜌−𝜂) memory by storing only a sublinear (𝑛−𝜂) fraction of the total inputs, where 𝜌is a parameter of the LSH family, and 0 < 𝜂< 1. Our method supports sublinear query time, batch queries, and extends to the more general Turnstile model. While earlier works have focused on Exact NN, this is the first result on ANN that achieves near-optimal trade-offs between memory size and approximation error. Next, for A-KDE in the Sliding-Window model, we propose a sketch of size O \u0010 𝑅𝑊· 1 √ 1+𝜖−1 log2 𝑁 \u0011 , where 𝑅is the number of sketch rows, 𝑊is the LSH range, 𝑁is the window size, and 𝜖is the approximation error. This, to the best of our knowledge, is the first theoretical sublinear sketch guarantee for A-KDE in the Sliding-Window model. We complement our theoretical results with experiments on various real-world datasets, which show that the proposed sketches are lightweight and achieve consistently low error in practice. ∗Department of Computer Science & Engineering, Indian Institute of Technology Bombay, Mumbai, India. Email: veddanait@cse.iitb.ac.in †Department of Computer Science & Engineering, Indian Institute of Technology Bombay, Mumbai, India. Email: srijandas@cse.iitb.ac.in ‡Department of Computer Science & Engineering and Centre for Machine Intelligence & Data Science (CMINDS), Indian Institute of Technology Bombay, Mumbai, India. Email: sujoy@cse.iitb.ac.in 1 arXiv:2510.23039v1 [cs.LG] 27 Oct 2025 Contents",
    "keywords": []
  },
  {
    "article_id": "2510.23507v1_A_Deep_Latent_Factor_Graph_Clustering_with_Fairness-Utility_Trade-off_Perspective",
    "title": "2510.23507v1 A Deep Latent Factor Graph Clustering with Fairness-Utility Trade-off Perspective",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.23507v1_A_Deep_Latent_Factor_Graph_Clustering_with_Fairness-Utility_Trade-off_Perspective.pdf",
    "url": "http://arxiv.org/abs/2510.23507v1_A_Deep_Latent_Factor_Graph_Clustering_with_Fairness-Utility_Trade-off_Perspective",
    "pdf_url": "https://arxiv.org/pdf/2510.23507v1_A_Deep_Latent_Factor_Graph_Clustering_with_Fairness-Utility_Trade-off_Perspective",
    "file_size_mb": 2.3,
    "abstract": "—Fair graph clustering seeks partitions that respect network structure while maintaining proportional representation across sensitive groups, with applications spanning community detection, team formation, resource allocation, and social network analysis. Many existing approaches enforce rigid constraints or rely on multi-stage pipelines (e.g., spectral embedding followed by k-means), limiting trade-off control, interpretability, and scalability. We introduce DFNMF, an end-to-end deep nonnegative tri-factorization tailored to graphs that directly optimizes cluster assignments with a soft statistical-parity regularizer. A single parameter λ tunes the fairness–utility balance, while nonnegativity yields parts-based factors and transparent soft memberships. The optimization uses sparse-friendly alternating updates and scales near-linearly with the number of edges. Across synthetic and real networks, DFNMF achieves substantially higher group balance at comparable modularity, often dominating state-of- the-art baselines on the Pareto front. The code is available at https://github.com/SiamakGhodsi/DFNMF.git.",
    "keywords": [
      "Trustworthy ML",
      "Fair Graph Clustering",
      "Com-"
    ]
  },
  {
    "article_id": "2510.24699v1_AgentFold_Long-Horizon_Web_Agents_with_Proactive_Context_Management",
    "title": "2510.24699v1 AgentFold Long-Horizon Web Agents with Proactive Context Management",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.24699v1_AgentFold_Long-Horizon_Web_Agents_with_Proactive_Context_Management.pdf",
    "url": "http://arxiv.org/abs/2510.24699v1_AgentFold_Long-Horizon_Web_Agents_with_Proactive_Context_Management",
    "pdf_url": "https://arxiv.org/pdf/2510.24699v1_AgentFold_Long-Horizon_Web_Agents_with_Proactive_Context_Management",
    "file_size_mb": 1.97,
    "abstract": "LLM-based web agents show immense promise for information seeking, yet their effectiveness on long-horizon tasks is hindered by a fundamental trade-off in context management. Prevailing ReAct-based agents suffer from context saturation as they accumulate noisy, raw histories, while methods that fixedly summarize the full history at each step risk the irreversible loss of critical details. Addressing these, we introduce AgentFold, a novel agent paradigm centered on proactive context management, inspired by the human cognitive process of retrospective consolidation. AgentFold treats its context as a dynamic cognitive workspace to be actively sculpted, rather than a passive log to be filled. At each step, it learns to execute a ‘folding’ operation, which manages its historical trajectory at multiple scales: it can perform granular condensations to preserve vital, fine-grained details, or deep consolidations to abstract away entire multi- step sub-tasks. The results on prominent benchmarks are striking: with simple supervised fine-tuning (without continual pre-training or RL), our AgentFold- 30B-A3B agent achieves 36.2% on BrowseComp and 47.3% on BrowseComp- ZH. Notably, this performance not only surpasses or matches open-source models of a dramatically larger scale, such as the DeepSeek-V3.1-671B-A37B, but also surpasses leading proprietary agents like OpenAI’s o4-mini. AgentFold proactively folds its working context during complex task-solving Figure 1: Our AgentFold-30B-A3B agent demonstrates remarkable performance on challenging long- horizon benchmarks, matching or surpassing agents with significantly larger model sizes. This is enabled by its proactive context folding, which maintains a highly concise and focused context that reaches only 7k tokens after 100 turns of interaction and is capable of scaling to 500 turns. ∗Equal Core Contributors. \u0000Corresponding Authors. yr991129@sjtu.edu.cn {yinhuifeng.yhf, yongjiang.jy}@alibaba-inc.com 1 arXiv:2510.24699v1 [cs.CL] 28 Oct 2025",
    "keywords": []
  },
  {
    "article_id": "2510.25544v2_Error_Bounds_and_Optimal_Schedules_for_Masked_Diffusions_with_Factorized_Approximations",
    "title": "2510.25544v2 Error Bounds and Optimal Schedules for Masked Diffusions with Factorized Approximations",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.25544v2_Error_Bounds_and_Optimal_Schedules_for_Masked_Diffusions_with_Factorized_Approximations.pdf",
    "url": "http://arxiv.org/abs/2510.25544v2_Error_Bounds_and_Optimal_Schedules_for_Masked_Diffusions_with_Factorized_Approximations",
    "pdf_url": "https://arxiv.org/pdf/2510.25544v2_Error_Bounds_and_Optimal_Schedules_for_Masked_Diffusions_with_Factorized_Approximations",
    "file_size_mb": 0.45,
    "abstract": null,
    "keywords": []
  },
  {
    "article_id": "2510.25602v1_INT_vs_FP_A_Comprehensive_Study_of_Fine-Grained_Low-bit_Quantization_Formats",
    "title": "2510.25602v1 INT vs FP A Comprehensive Study of Fine-Grained Low-bit Quantization Formats",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.25602v1_INT_vs_FP_A_Comprehensive_Study_of_Fine-Grained_Low-bit_Quantization_Formats.pdf",
    "url": "http://arxiv.org/abs/2510.25602v1_INT_vs_FP_A_Comprehensive_Study_of_Fine-Grained_Low-bit_Quantization_Formats",
    "pdf_url": "https://arxiv.org/pdf/2510.25602v1_INT_vs_FP_A_Comprehensive_Study_of_Fine-Grained_Low-bit_Quantization_Formats",
    "file_size_mb": 1.45,
    "abstract": "Modern AI hardware, such as Nvidia’s Blackwell architecture, is increasingly embracing low- precision floating-point (FP) formats to handle the pervasive activation outliers in Large Language Models (LLMs). Despite this industry trend, a unified comparison of FP and integer (INT) quantization across varying granularities has been missing, leaving algorithm and hardware co- design without clear guidance. This paper fills that gap by systematically investigating the trade-offs between FP and INT formats. We reveal a critical performance crossover: while FP excels in coarse-grained quantization, the comparison at fine-grained (block-wise) levels is more nuanced. Our comprehensive comparison demonstrates that for popular 8-bit fine-grained formats (e.g., MX with block size 32), MXINT8 is superior to its FP counterpart in both algorithmic accuracy and hardware efficiency. However, for 4-bit formats, FP (e.g., MXFP4, NVFP4) often holds an accuracy advantage , though we show that NVINT4 can surpass NVFP4 when outlier- mitigation techniques like Hadamard rotation are applied. We also introduce a symmetric clipping method that resolves gradient bias in fine-grained low-bit INT training, enabling nearly lossless performance for MXINT8 training. These findings challenge the current hardware trajectory, demonstrating that a one-size-fits-all FP approach is suboptimal and advocating that fine-grained INT formats, particularly MXINT8, offer a better balance of accuracy, power, and efficiency for future AI accelerators. Date: October 30, 2025 Correspondence: binxingyan@bytedance.com, pluo@cs.hku.hk Code: https://github.com/ChenMnZ/INT_vs_FP",
    "keywords": []
  },
  {
    "article_id": "2510.25929v1_Multi-Agent_Reinforcement_Learning_for_Market_Making_Competition_without_Collusion",
    "title": "2510.25929v1 Multi-Agent Reinforcement Learning for Market Making Competition without Collusion",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.25929v1_Multi-Agent_Reinforcement_Learning_for_Market_Making_Competition_without_Collusion.pdf",
    "url": "http://arxiv.org/abs/2510.25929v1_Multi-Agent_Reinforcement_Learning_for_Market_Making_Competition_without_Collusion",
    "pdf_url": "https://arxiv.org/pdf/2510.25929v1_Multi-Agent_Reinforcement_Learning_for_Market_Making_Competition_without_Collusion",
    "file_size_mb": 0.65,
    "abstract": "Algorithmic collusion has emerged as a central question in AI: Will the interaction between different AI agents deployed in markets lead to collusion? More generally, understanding how emergent behavior, be it a cartel or market dominance from more advanced bots, affects the market overall is an important research question. We propose a hierarchical multi-agent reinforcement learning framework to study algorithmic collusion in market making. The framework includes a self-interested market maker (Agent A), which is trained in an uncertain environment shaped by an adversary, and three bottom-layer competitors: the self-interested Agent B1 (whose objective is to maximize its own PnL), the competitive Agent B2 (whose objective is to minimize the PnL of its opponent), and the hybrid Agent B★, which can modulate between the behavior of the other two. To analyze how these agents shape the behavior of each other and affect market outcomes, we propose interaction-level metrics that quantify behavioral asymmetry and system-level dy- namics, while providing signals potentially indicative of emergent interaction patterns. Experimental results show that Agent B2 secures dominant per- formance in a zero-sum setting against B1, aggressively captur- ing order flow while tightening average spreads, thus improving market execution efficiency. In contrast, Agent B★exhibits a self- interested inclination when co-existing with other profit-seeking agents, securing dominant market share through adaptive quoting, yet exerting a milder adverse impact on the rewards of Agents A and B1 compared to B2. These findings suggest that adaptive in- centive control supports more sustainable strategic co-existence in heterogeneous agent environments and offers a structured lens for evaluating behavioral design in algorithmic trading systems. CCS Concepts • Computing methodologies →Multi-agent systems.",
    "keywords": [
      "Multi-Agent Reinforcement Learning",
      "Agent-Based Modeling",
      "Mar-"
    ]
  },
  {
    "article_id": "2510.26165v1_Learning_to_Manage_Investment_Portfolios_beyond_Simple_Utility_Functions",
    "title": "2510.26165v1 Learning to Manage Investment Portfolios beyond Simple Utility Functions",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.26165v1_Learning_to_Manage_Investment_Portfolios_beyond_Simple_Utility_Functions.pdf",
    "url": "http://arxiv.org/abs/2510.26165v1_Learning_to_Manage_Investment_Portfolios_beyond_Simple_Utility_Functions",
    "pdf_url": "https://arxiv.org/pdf/2510.26165v1_Learning_to_Manage_Investment_Portfolios_beyond_Simple_Utility_Functions",
    "file_size_mb": 0.96,
    "abstract": "While investment funds publicly disclose their objectives in broad terms, their managers optimize for complex combinations of com- peting goals that go beyond simple risk-return trade-offs. Tradi- tional approaches attempt to model this through multi-objective utility functions, but face fundamental challenges in specification and parameterization. We propose a generative framework that learns latent representations of fund manager strategies without requiring explicit utility specification. Our approach directly models the conditional probability of a fund’s portfolio weights, given stock characteristics, historical returns, previous weights, and a latent variable representing the fund’s strategy. Unlike methods based on reinforcement learning or imitation learning, which require specified rewards or labeled expert objectives, our GAN-based architecture learns directly from the joint distribution of observed holdings and market data. We validate our framework on a dataset of 1436 U.S. equity mu- tual funds. The learned representations successfully capture known investment styles, such as \"growth\" and \"value,\" while also revealing implicit manager objectives. For instance, we find that while many funds exhibit characteristics of Markowitz-like optimization, they do so with heterogeneous realizations for turnover, concentration, and latent factors. To analyze and interpret the end-to-end model, we develop a series of tests that explain the model, and we show that the benchmark’s expert labeling are contained in our model’s encoding in a linear interpretable way. Our framework provides a data-driven approach for characterizing investment strategies for applications in market simulation, strategy attribution, and regulatory oversight. CCS Concepts • Computing methodologies →Neural networks; • Applied computing →Economics. ∗Corresponding Author This work is licensed under a Creative Commons Attribution 4.0 International License. ICAIF ’25, Singapore, Singapore © 2025 Copyright held by the owner/author(s). ACM ISBN 979-8-4007-2220-2/2025/11 https://doi.org/10.1145/3768292.3770426",
    "keywords": [
      "generative adversarial networks",
      "portfolio management",
      "investment"
    ]
  },
  {
    "article_id": "2510.26438v2_An_Impulse_Control_Approach_to_Market_Making_in_a_Hawkes_LOB_Market",
    "title": "2510.26438v2 An Impulse Control Approach to Market Making in a Hawkes LOB Market",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.26438v2_An_Impulse_Control_Approach_to_Market_Making_in_a_Hawkes_LOB_Market.pdf",
    "url": "http://arxiv.org/abs/2510.26438v2_An_Impulse_Control_Approach_to_Market_Making_in_a_Hawkes_LOB_Market",
    "pdf_url": "https://arxiv.org/pdf/2510.26438v2_An_Impulse_Control_Approach_to_Market_Making_in_a_Hawkes_LOB_Market",
    "file_size_mb": 1.16,
    "abstract": ". We study the optimal Market Making problem in a Limit Order Book (LOB) market simulated using a high-fidelity, mutually exciting Hawkes process. Departing from traditional Brownian-driven mid- price models, our setup captures key microstructural properties such as queue dynamics, inter-arrival clustering, and endogenous price impact. Recognizing the realistic constraint that market makers cannot update strategies at every LOB event, we formulate the control problem within an impulse control framework, where interventions occur discretely via limit, cancel, or market orders. This leads to a high-dimensional, non-local Hamilton-Jacobi-Bellman Quasi-Variational Inequality (HJB- QVI), whose solution is analytically intractable and computationally expensive due to the curse of dimensionality. To address this, we propose a novel Reinforcement Learning (RL) approximation inspired by auxiliary control formulations. Using a two-network PPO-based architecture with self- imitation learning, we demonstrate strong empirical performance with limited training, achieving Sharpe ratios above 30 in a realistic simulated LOB. In addition to that, we solve the HJB-QVI using a deep learning method inspired by Sirignano and Spiliopoulos 2018 [40] and compare the performance with the RL agent. Our findings highlight the promise of combining impulse control theory with modern deep RL to tackle optimal execution problems in jump-driven microstructural markets. Key words. Market Making; Limit Order Book; Hawkes Process; Impulse Control; Reinforcement Learning; Hamilton–Jacobi–Bellman Equation; Quasi-Variational Inequality; Deep Learning; Financial Mi- crostructure AMS subject classifications. Primary: 93E20; Secondary: 91G80, 60G55, 35Q93, 68T07, 49L25",
    "keywords": [
      "Market Making",
      "Limit Order Book",
      "Hawkes Process",
      "Impulse Control",
      "Reinforcement Learning"
    ]
  },
  {
    "article_id": "2510.26722v3_Non-Convex_Over-the-Air_Heterogeneous_Federated_Learning_A_Bias-Variance_Trade-off",
    "title": "2510.26722v3 Non-Convex Over-the-Air Heterogeneous Federated Learning A Bias-Variance Trade-off",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.26722v3_Non-Convex_Over-the-Air_Heterogeneous_Federated_Learning_A_Bias-Variance_Trade-off.pdf",
    "url": "http://arxiv.org/abs/2510.26722v3_Non-Convex_Over-the-Air_Heterogeneous_Federated_Learning_A_Bias-Variance_Trade-off",
    "pdf_url": "https://arxiv.org/pdf/2510.26722v3_Non-Convex_Over-the-Air_Heterogeneous_Federated_Learning_A_Bias-Variance_Trade-off",
    "file_size_mb": 1.44,
    "abstract": "—Over-the-air (OTA) federated learning (FL) has been well recognized as a scalable paradigm that exploits the waveform superposition of the wireless multiple-access channel to aggregate model updates simultaneously. Existing OTA-FL designs largely enforce zero-bias model updates by either assuming homogeneous wireless conditions (equal path loss across devices) or forcing zero bias updates to guarantee convergence. Under heterogeneous wireless scenarios, however, such designs are constrained by the weakest device and degrade the update variance. Moreover, prior analyses of biased OTA-FL largely address convex objectives, while most modern AI models are highly non-convex. Motivated by these gaps, we study OTA-FL with stochastic gradient descent (SGD) for smooth non-convex objectives under wireless hetero- geneity. We develop novel OTA-FL SGD updates that allow a structured, time-invariant model bias while facilitating reduced variance updates. We derive a finite-time stationarity bound (expected time average squared gradient norm) that explicitly reveals a bias–variance trade-off. To optimize this trade-off, we pose a non-convex joint OTA power-control design and develop an efficient successive convex approximation (SCA) algorithm that requires only statistical CSI at the base station. Experiments on a non-convex image classification task validate the approach: the SCA-based design accelerates convergence via an optimized bias and improves generalization over prior OTA-FL baselines.",
    "keywords": [
      "Federated Learning (FL)",
      "over-the-air computa-"
    ]
  },
  {
    "article_id": "2510.26788v1_Defeating_the_Training-Inference_Mismatch_via_FP16",
    "title": "2510.26788v1 Defeating the Training-Inference Mismatch via FP16",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.26788v1_Defeating_the_Training-Inference_Mismatch_via_FP16.pdf",
    "url": "http://arxiv.org/abs/2510.26788v1_Defeating_the_Training-Inference_Mismatch_via_FP16",
    "pdf_url": "https://arxiv.org/pdf/2510.26788v1_Defeating_the_Training-Inference_Mismatch_via_FP16",
    "file_size_mb": 0.91,
    "abstract": "Reinforcement learning (RL) fine-tuning of large language models (LLMs) often suffers from instability due to the numerical mismatch between the training and inference policies. While prior work has attempted to mitigate this issue through algorithmic corrections or engineering alignments, we show that its root cause lies in the floating point precision itself. The widely adopted BF16, despite its large dy- namic range, introduces large rounding errors that breaks the consistency between training and inference. In this work, we demonstrate that simply reverting to FP16 effectively eliminates this mismatch. The change is simple, fully supported by mod- ern frameworks with only a few lines of code change, and requires no modification to the model architecture or learning algorithm. Our results suggest that using FP16 uniformly yields more stable optimization, faster convergence, and stronger per- formance across diverse tasks, algorithms and frameworks. We hope these findings motivate a broader reconsideration of precision trade-offs in RL fine-tuning. 0 250 500 750 1000 1250 1500 1750 2000 Training Steps 0.5 0.6 0.7 0.8 0.9 1.0 (a) Sanity GRPO BF16 FP16 0 500 1000 1500 2000 2500 Training Steps 0.6 0.7 0.8 0.9 1.0 (b) Sanity GRPO-Token-TIS BF16 FP16 0 500 1000 1500 2000 2500 Training Steps 0.5 0.6 0.7 0.8 0.9 1.0 (c) Sanity GRPO-Seq-MIS BF16 FP16 0 500 1000 1500 2000 Training Steps 0.6 0.7 0.8 0.9 1.0 (d) Sanity GSPO BF16 FP16 0 500 1000 1500 2000 Training Steps 0.5 0.6 0.7 0.8 0.9 1.0 (e) Sanity PG-Seq-IS BF16 FP16 0 500 1000 1500 2000 2500 Training Steps 0.6 0.7 0.8 0.9 1.0 (f) Sanity PG-Seq-MIS BF16 FP16 0 200 400 600 800 1000 Training Steps 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 (g) OctoThinker GRPO BF16 FP16 0 200 400 600 800 1000 1200 1400 Training Steps 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 (h) Lora GRPO-Token-TIS BF16 FP16 0 20 40 60 80 100 120 140 160 Training Steps 0.1 0.2 0.3 0.4 0.5 0.6 0.7 (i) MoE GRPO-Seq-MIS BF16 FP16 0 50 100 150 200 Training Steps 0.1 0.2 0.3 0.4 0.5 0.6 0.7 (j) MoE GRPO-Token-TIS BF16 FP16 0 25 50 75 100 125 150 175 Training Steps 0.1 0.2 0.3 0.4 0.5 0.6 0.7 (k) MoE PG-Seq-TIS BF16 FP16 0 10 20 30 40 50 60 70 80 Training Steps 0.60 0.65 0.70 0.75 0.80 (l) Dense-14B DAPO BF16 FP16 Figure 1: Training reward comparison between BF16 and FP16. We evaluate across diverse settings: our Sanity test (Section 4) with various algorithms (GRPO, GSPO, TIS, MIS, PG); different model families (R1D, Qwen and OctoThinker); alternative fine-tuning methods (Lora); and larger scale models (Dense-14B, MoE). Results are validated on two independent frameworks (VeRL and Oat). ∗Core Contributors. †Project Lead. Preprint. Work in process. arXiv:2510.26788v1 [cs.LG] 30 Oct 2025",
    "keywords": []
  },
  {
    "article_id": "2510.26940v1_Mind_the_Gaps_Auditing_and_Reducing_Group_Inequity_in_Large-Scale_Mobility_Prediction",
    "title": "2510.26940v1 Mind the Gaps Auditing and Reducing Group Inequity in Large-Scale Mobility Prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.26940v1_Mind_the_Gaps_Auditing_and_Reducing_Group_Inequity_in_Large-Scale_Mobility_Prediction.pdf",
    "url": "http://arxiv.org/abs/2510.26940v1_Mind_the_Gaps_Auditing_and_Reducing_Group_Inequity_in_Large-Scale_Mobility_Prediction",
    "pdf_url": "https://arxiv.org/pdf/2510.26940v1_Mind_the_Gaps_Auditing_and_Reducing_Group_Inequity_in_Large-Scale_Mobility_Prediction",
    "file_size_mb": 3.78,
    "abstract": "Next location prediction underpins a growing number of mo- bility, retail, and public-health applications, yet its societal impacts remain largely unexplored. In this paper, we audit state-of-the-art mobility prediction models trained on a large- scale dataset, highlighting hidden disparities based on user demographics. Drawing from aggregate census data, we com- pute the difference in predictive performance on racial and ethnic user groups and show a systematic disparity resulting from the underlying dataset, resulting in large differences in accuracy based on location and user groups. To address this, we propose Fairness-Guided Incremental Sampling (FGIS), a group-aware sampling strategy designed for incremental data collection settings. Because individual- level demographic labels are unavailable, we introduce Size- Aware K-Means (SAKM)—a clustering method that partitions users in latent mobility space while enforcing census-derived group proportions. This yields proxy racial labels for the four largest groups in the state: Asian, Black, Hispanic, and White. Built on these labels, our sampling algorithm prioritizes users based on expected performance gains and current group rep- resentation. This method incrementally constructs training datasets that reduce demographic performance gaps while preserving overall accuracy. Our method reduces total dis- parity between groups by up to 40% with minimal accuracy trade-offs, as evaluated on a state-of-art MetaPath2Vec model and a transformer-encoder model. Improvements are most significant in early sampling stages, highlighting the poten- tial for fairness-aware strategies to deliver meaningful gains even in low-resource settings. Our findings expose structural inequities in mobility predic- tion pipelines and demonstrate how lightweight, data-centric interventions can improve fairness with little added complex- ity, especially for low-data applications.",
    "keywords": []
  },
  {
    "article_id": "2510.27334v1_When_AI_Trading_Agents_Compete_Adverse_Selection_of_Meta-Orders_by_Reinforcement_Learning-Based_Mark",
    "title": "2510.27334v1 When AI Trading Agents Compete Adverse Selection of Meta-Orders by Reinforcement Learning-Based Mark",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2510.27334v1_When_AI_Trading_Agents_Compete_Adverse_Selection_of_Meta-Orders_by_Reinforcement_Learning-Based_Mark.pdf",
    "url": "http://arxiv.org/abs/2510.27334v1_When_AI_Trading_Agents_Compete_Adverse_Selection_of_Meta-Orders_by_Reinforcement_Learning-Based_Mark",
    "pdf_url": "https://arxiv.org/pdf/2510.27334v1_When_AI_Trading_Agents_Compete_Adverse_Selection_of_Meta-Orders_by_Reinforcement_Learning-Based_Mark",
    "file_size_mb": 1.07,
    "abstract": "We investigate the mechanisms by which medium-frequency trading agents are adversely selected by opportunistic high- frequency traders. We use reinforcement learning (RL) within a Hawkes Limit Order Book (LOB) model in order to repli- cate the behaviours of high-frequency market makers. In con- trast to the classical models with exogenous price impact as- sumptions, the Hawkes model accounts for endogenous price impact and other key properties of the market (Jain et al. 2024a). Given the real-world impracticalities of the market maker updating strategies for every event in the LOB, we for- mulate the high-frequency market making agent via an im- pulse control reinforcement learning framework (Jain et al. 2025). The RL used in the simulation utilises Proximal Pol- icy Optimisation (PPO) and self-imitation learning. To repli- cate the adverse selection phenomenon, we test the RL agent trading against a medium frequency trader (MFT) execut- ing a meta-order and demonstrate that, with training against the MFT meta-order execution agent, the RL market mak- ing agent learns to capitalise on the price drift induced by the meta-order. Recent empirical studies have shown that medium-frequency traders are increasingly subject to ad- verse selection by high-frequency trading agents. As high- frequency trading continues to proliferate across financial markets, the slippage costs incurred by medium-frequency traders are likely to increase over time. However, we do not observe that increased profits for the market making RL agent necessarily cause significantly increased slippages for the MFT agent. Code — https://github.com/konqr/lobSimulations/tree/ master/HawkesRLTrading",
    "keywords": []
  },
  {
    "article_id": "2511.00039v1_Graph-Attentive_MAPPO_for_Dynamic_Retail_Pricing",
    "title": "2511.00039v1 Graph-Attentive MAPPO for Dynamic Retail Pricing",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.00039v1_Graph-Attentive_MAPPO_for_Dynamic_Retail_Pricing.pdf",
    "url": "http://arxiv.org/abs/2511.00039v1_Graph-Attentive_MAPPO_for_Dynamic_Retail_Pricing",
    "pdf_url": "https://arxiv.org/pdf/2511.00039v1_Graph-Attentive_MAPPO_for_Dynamic_Retail_Pricing",
    "file_size_mb": 0.48,
    "abstract": "Dynamic pricing in retail requires policies that adapt to shifting demand while coordinating decisions across related products. We present a systematic empirical study of multi-agent reinforcement learning for retail price optimization, comparing a strong MAPPO base- line with a graph-attention-augmented variant (MAPPO+GAT) that leverages learned interactions among products. Using a simulated pricing environment derived from real transaction data, we evaluate profit, stability across random seeds, fairness across prod- ucts, and training efficiency under a standardized evaluation protocol. The results indicate that MAPPO provides a robust and reproducible foundation for portfolio-level price con- trol, and that MAPPO+GAT further enhances performance by sharing information over the product graph without inducing excessive price volatility. These results indicate that graph-integrated MARL provides a more scalable and stable solution than independent learners for dynamic retail pricing, offering practical advantages in multi-product decision- making.",
    "keywords": [
      "Dynamic pricing",
      "retail",
      "multi-agent reinforcement learning (MARL)",
      "MAPPO"
    ]
  },
  {
    "article_id": "2511.00190v1_Deep_reinforcement_learning_for_optimal_trading_with_partial_information",
    "title": "2511.00190v1 Deep reinforcement learning for optimal trading with partial information",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.00190v1_Deep_reinforcement_learning_for_optimal_trading_with_partial_information.pdf",
    "url": "http://arxiv.org/abs/2511.00190v1_Deep_reinforcement_learning_for_optimal_trading_with_partial_information",
    "pdf_url": "https://arxiv.org/pdf/2511.00190v1_Deep_reinforcement_learning_for_optimal_trading_with_partial_information",
    "file_size_mb": 3.03,
    "abstract": "Reinforcement Learning (RL) applied to financial problems has been the subject of a lively area of research. The use of RL for optimal trading strategies that exploit latent information in the market is, to the best of our knowledge, not widely tackled. In this paper we study an optimal trading problem, where a trading signal follows an Ornstein–Uhlenbeck process with regime-switching dynamics. We employ a blend of RL and Recurrent Neural Networks (RNN) in order to make the most at extracting underlying information from the trading signal with latent parameters. The latent parameters driving mean reversion, speed, and volatility are filtered from observations of the signal, and trading strategies are derived via RL. To address this problem, we propose three Deep Deterministic Policy Gradient (DDPG)–based algorithms that integrate Gated Recurrent Unit (GRU) networks to capture temporal dependencies in the signal. The first, a one-step approach (hid- DDPG), directly encodes hidden states from the GRU into the RL trader. The second and third are two-step methods: one (prob-DDPG) makes use of posterior regime probability estimates, while the other (reg-DDPG) relies on forecasts of the next signal value. Through extensive simulations with increasingly complex Markovian regime dynamics for the trading signal’s parameters, as well as an empirical application to equity pair trading, we find that prob-DDPG achieves superior cumulative rewards and exhibits more interpretable strategies. By contrast, reg-DDPG provides limited benefits, while hid-DDPG offers intermediate performance with less interpretable strategies. Our results show that the quality and structure of the information supplied to the agent are crucial: embedding probabilistic insights into latent regimes substantially improves both profitability and robustness of reinforcement learning–based trading strategies.",
    "keywords": []
  },
  {
    "article_id": "2511.01570v1_Gated_Fusion_Enhanced_Multi-Scale_Hierarchical_Graph_Convolutional_Network_for_Stock_Movement_Predic",
    "title": "2511.01570v1 Gated Fusion Enhanced Multi-Scale Hierarchical Graph Convolutional Network for Stock Movement Predic",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.01570v1_Gated_Fusion_Enhanced_Multi-Scale_Hierarchical_Graph_Convolutional_Network_for_Stock_Movement_Predic.pdf",
    "url": "http://arxiv.org/abs/2511.01570v1_Gated_Fusion_Enhanced_Multi-Scale_Hierarchical_Graph_Convolutional_Network_for_Stock_Movement_Predic",
    "pdf_url": "https://arxiv.org/pdf/2511.01570v1_Gated_Fusion_Enhanced_Multi-Scale_Hierarchical_Graph_Convolutional_Network_for_Stock_Movement_Predic",
    "file_size_mb": 0.68,
    "abstract": ". Accurately predicting stock market movements remains a formidable challenge due to the inherent volatility and complex interde- pendencies among stocks. Although multi-scale Graph Neural Networks (GNNs) hold potential for modeling these relationships, they frequently neglect two key points: the subtle intra-attribute patterns within each stock affecting inter-stock correlation, and the biased attention to coarse- and fine-grained features during multi-scale sampling. To overcome these challenges, we introduce MS-HGFN (Multi-Scale Hierarchical Graph Fu- sion Network). The model features a hierarchical GNN module that forms dynamic graphs by learning patterns from intra-attributes and features from inter-attributes over different time scales, thus comprehen- sively capturing spatio-temporal dependencies. Additionally, a top-down gating approach facilitates the integration of multi-scale spatio-temporal features, preserving critical coarse- and fine-grained features without too much interference. Experiments utilizing real-world datasets from U.S. and Chinese stock markets demonstrate that MS-HGFN outperforms both traditional and advanced models, yielding up to a 1.4% improve- ment in prediction accuracy and enhanced stability in return simulations. The code is available at https://github.com/snowman0123/MS-HGFN.",
    "keywords": [
      "Trend prediction",
      "Graph Neural Networks",
      "Multi-scale"
    ]
  },
  {
    "article_id": "2511.01737v1_Edge_AI_in_Highly_Volatile_Environments_Is_Fairness_Worth_the_Accuracy_Trade-off",
    "title": "2511.01737v1 Edge AI in Highly Volatile Environments Is Fairness Worth the Accuracy Trade-off",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.01737v1_Edge_AI_in_Highly_Volatile_Environments_Is_Fairness_Worth_the_Accuracy_Trade-off.pdf",
    "url": "http://arxiv.org/abs/2511.01737v1_Edge_AI_in_Highly_Volatile_Environments_Is_Fairness_Worth_the_Accuracy_Trade-off",
    "pdf_url": "https://arxiv.org/pdf/2511.01737v1_Edge_AI_in_Highly_Volatile_Environments_Is_Fairness_Worth_the_Accuracy_Trade-off",
    "file_size_mb": 1.72,
    "abstract": "—Federated learning (FL) has emerged as a trans- formative paradigm for edge intelligence, enabling collaborative model training while preserving data privacy across distributed personal devices. However, the inherent volatility of edge envi- ronments, characterized by dynamic resource availability and heterogeneous client capabilities, poses significant challenges for achieving high accuracy and fairness in client participation. This paper investigates the fundamental trade-off between model accuracy and fairness in highly volatile edge environments. This paper provides an extensive empirical evaluation of fairness- based client selection algorithms such as RBFF and RBCSF against random and greedy client selection regarding fairness, model performance, and time, in three benchmarking datasets (CIFAR10, FashionMNIST, and EMNIST). This work aims to shed light on the fairness-performance and fairness-speed trade- offs in a volatile edge environment and explore potential future research opportunities to address existing pitfalls in fair client selection strategies in FL. Our results indicate that more equitable client selection algorithms, while providing a marginally better opportunity among clients, can result in slower global training in volatile environments1.",
    "keywords": [
      "Federated learning",
      "Edge Intelligence",
      "Fairness"
    ]
  },
  {
    "article_id": "2511.01923v1_When_Assurance_Undermines_Intelligence_The_Efficiency_Costs_of_Data_Governance_in_AI-Enabled_Labor_M",
    "title": "2511.01923v1 When Assurance Undermines Intelligence The Efficiency Costs of Data Governance in AI-Enabled Labor M",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.01923v1_When_Assurance_Undermines_Intelligence_The_Efficiency_Costs_of_Data_Governance_in_AI-Enabled_Labor_M.pdf",
    "url": "http://arxiv.org/abs/2511.01923v1_When_Assurance_Undermines_Intelligence_The_Efficiency_Costs_of_Data_Governance_in_AI-Enabled_Labor_M",
    "pdf_url": "https://arxiv.org/pdf/2511.01923v1_When_Assurance_Undermines_Intelligence_The_Efficiency_Costs_of_Data_Governance_in_AI-Enabled_Labor_M",
    "file_size_mb": 1.06,
    "abstract": "Generative artificial intelligence (GenAI) like Large Language Model (LLM) is increasingly integrated into digital platforms to enhance information access, deliver personalized experiences, and improve matching efficiency. However, these algorithmic advancements rely heavily on large-scale user data, creating a fundamental tension between information assurance—the protection, integrity, and responsible use of privacy data—and artificial intelligence—the learning capacity and predictive accuracy of models. We examine this assurance-intelligence trade-off in the context of LinkedIn, leveraging a regulatory intervention that suspended the use of user data for model training in Hong Kong. Using large-scale employment and job posting data from Revelio Labs and a Difference-in-Differences design, we show that restricting data use significantly reduced GenAI efficiency, leading to lower matching rates, higher employee turnover, and heightened labor market frictions. These effects were especially pronounced for small and fast-growing firms that rely heavily on AI for talent acquisition. Our findings reveal the unintended efficiency costs of well-intentioned data governance and highlight that information assurance, while essential for trust, can undermine intelligence-driven efficiency when misaligned with AI system design. This study contributes to emerging research on AI governance and digital platform by theorizing data assurance as an institutional complement— and potential constraint—to GenAI efficacy in data-intensive environments.",
    "keywords": [
      "Generative AI",
      "Assurance-intelligence Trade-off",
      "Platform Efficiency",
      "Labor Market"
    ]
  },
  {
    "article_id": "2511.02136v1_JaxMARL-HFT_GPU-Accelerated_Large-Scale_Multi-Agent_Reinforcement_Learning_for_High-Frequency_Tradin",
    "title": "2511.02136v1 JaxMARL-HFT GPU-Accelerated Large-Scale Multi-Agent Reinforcement Learning for High-Frequency Tradin",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.02136v1_JaxMARL-HFT_GPU-Accelerated_Large-Scale_Multi-Agent_Reinforcement_Learning_for_High-Frequency_Tradin.pdf",
    "url": "http://arxiv.org/abs/2511.02136v1_JaxMARL-HFT_GPU-Accelerated_Large-Scale_Multi-Agent_Reinforcement_Learning_for_High-Frequency_Tradin",
    "pdf_url": "https://arxiv.org/pdf/2511.02136v1_JaxMARL-HFT_GPU-Accelerated_Large-Scale_Multi-Agent_Reinforcement_Learning_for_High-Frequency_Tradin",
    "file_size_mb": 3.64,
    "abstract": "Agent-based modelling (ABM) approaches for high-frequency fi- nancial markets are difficult to calibrate and validate, partly due to the large parameter space created by defining fixed agent policies. Multi-agent reinforcement learning (MARL) enables more realistic agent behaviour and reduces the number of free parameters, but the heavy computational cost has so far limited research efforts. To address this, we introduce JaxMARL-HFT (JAX-based Multi-Agent Reinforcement Learning for High-Frequency Trading), the first GPU- accelerated open-source multi-agent reinforcement learning en- vironment for high-frequency trading (HFT) on market-by-order (MBO) data. Extending the JaxMARL framework and building on the JAX-LOB implementation, JaxMARL-HFT is designed to handle a heterogeneous set of agents, enabling diverse observation/action spaces and reward functions. It is designed flexibly, so it can also be used for single-agent RL, or extended to act as an ABM with fixed-policy agents. Leveraging JAX enables up to a 240x reduc- tion in end-to-end training time, compared with state-of-the-art reference implementations on the same hardware. This significant speed-up makes it feasible to exploit the large, granular datasets available in high-frequency trading, and to perform the extensive hyperparameter sweeps required for robust and efficient MARL research in trading. We demonstrate the use of JaxMARL-HFT with independent Proximal Policy Optimization (IPPO) for a two-player environment, with an order execution and a market making agent, using one year of LOB data (400 million orders), and show that these agents learn to outperform standard benchmarks. The code for the JaxMARL-HFT framework is available on GitHub1. ∗Authors contributed equally to this research. 1https://github.com/vmohl/JaxMARL-HFT",
    "keywords": [
      "limit order book",
      "high-frequency trading",
      "market making",
      "JAX"
    ]
  },
  {
    "article_id": "2511.02398v1_A_Spatially_Informed_Gaussian_Process_UCB_Method_for_Decentralized_Coverage_Control",
    "title": "2511.02398v1 A Spatially Informed Gaussian Process UCB Method for Decentralized Coverage Control",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.02398v1_A_Spatially_Informed_Gaussian_Process_UCB_Method_for_Decentralized_Coverage_Control.pdf",
    "url": "http://arxiv.org/abs/2511.02398v1_A_Spatially_Informed_Gaussian_Process_UCB_Method_for_Decentralized_Coverage_Control",
    "pdf_url": "https://arxiv.org/pdf/2511.02398v1_A_Spatially_Informed_Gaussian_Process_UCB_Method_for_Decentralized_Coverage_Control",
    "file_size_mb": 0.81,
    "abstract": "—We present a novel decentralized algorithm for coverage control in unknown spatial environments modeled by Gaussian Processes (GPs). To trade-off between exploration and exploitation, each agent autonomously determines its trajectory by minimizing a local cost function. Inspired by the GP-UCB (Upper Confidence Bound for GPs) acquisition function, the proposed cost combines the expected locational cost with a variance-based exploration term, guiding agents toward regions that are both high in predicted density and model uncertainty. Compared to previous work, our algorithm operates in a fully decentralized fashion, relying only on local observations and communication with neighboring agents. In particular, agents periodically update their inducing points using a greedy selection strategy, enabling scalable online GP updates. We demonstrate the effectiveness of our algorithm in simulation.",
    "keywords": []
  },
  {
    "article_id": "2511.02672v1_RL-Aided_Cognitive_ISAC_Robust_Detection_and_Sensing-Communication_Trade-offs",
    "title": "2511.02672v1 RL-Aided Cognitive ISAC Robust Detection and Sensing-Communication Trade-offs",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.02672v1_RL-Aided_Cognitive_ISAC_Robust_Detection_and_Sensing-Communication_Trade-offs.pdf",
    "url": "http://arxiv.org/abs/2511.02672v1_RL-Aided_Cognitive_ISAC_Robust_Detection_and_Sensing-Communication_Trade-offs",
    "pdf_url": "https://arxiv.org/pdf/2511.02672v1_RL-Aided_Cognitive_ISAC_Robust_Detection_and_Sensing-Communication_Trade-offs",
    "file_size_mb": 0.63,
    "abstract": "This paper proposes a reinforcement learning (RL)-aided cognitive framework for massive MIMO-based integrated sensing and communication (ISAC) sys- tems employing a uniform planar array (UPA). The focus is on enhancing radar sensing performance in environments with unknown and dynamic disturbance characteristics. A Wald-type detector is employed for robust target detection under non-Gaussian clutter, while a SARSA-based RL algorithm enables adap- tive estimation of target positions without prior environmental knowledge. Based on the RL-derived sensing information, a joint waveform optimization strategy is formulated to balance radar sensing accuracy and downlink communica- tion throughput. The resulting design provides an adaptive trade-off between detection performance and achievable sum rate through an analytically derived closed-form solution. Monte Carlo simulations demonstrate that the proposed cognitive ISAC framework achieves significantly improved detection probability compared to orthogonal and non-learning adaptive baselines, while maintaining competitive communication performance. These results underline the potential of RL-assisted sensing for robust and spectrum-efficient ISAC in next-generation wireless networks.",
    "keywords": [
      "ISAC",
      "Cognitive Radio",
      "Reinforcement Learning",
      "MIMO",
      "Robust Detection"
    ]
  },
  {
    "article_id": "2511.03554v1_The_Structure_of_Cross-Validation_Error_Stability_Covariance_and_Minimax_Limits",
    "title": "2511.03554v1 The Structure of Cross-Validation Error Stability Covariance and Minimax Limits",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.03554v1_The_Structure_of_Cross-Validation_Error_Stability_Covariance_and_Minimax_Limits.pdf",
    "url": "http://arxiv.org/abs/2511.03554v1_The_Structure_of_Cross-Validation_Error_Stability_Covariance_and_Minimax_Limits",
    "pdf_url": "https://arxiv.org/pdf/2511.03554v1_The_Structure_of_Cross-Validation_Error_Stability_Covariance_and_Minimax_Limits",
    "file_size_mb": 0.78,
    "abstract": ". Despite ongoing theoretical research on cross-validation (CV), many theoretical questions about CV remain widely open. This motivates our investigation into how properties of algorithm- distribution pairs can affect the choice for the number of folds in 𝑘-fold cross-validation. Our results consist of a novel decomposition of the mean-squared error of cross-validation for risk estimation, which explicitly captures the correlations of error estimates across overlapping folds and includes a novel algorithmic stability notion, squared loss stability, that is considerably weaker than the typically required hypothesis stability in other comparable works. Furthermore, we prove: 1. For every learning algorithm that minimizes empirical error, a minimax lower bound on the mean-squared error of 𝑘-fold CV estimating the population risk 𝐿D: min 𝑘|𝑛max D 𝔼 h\u0000b𝐿(𝑘) CV −𝐿D \u00012i = Ω\u0000√ 𝑘/𝑛\u0001, where 𝑛is the sample size and 𝑘the number of folds. This shows that even under idealized conditions, for large values of 𝑘, CV cannot attain the optimum of order 1/𝑛achievable by a validation set of size 𝑛, reflecting an inherent penalty caused by dependence between folds. 2. Complementing this, we exhibit learning rules for which max D 𝔼 h\u0000b𝐿(𝑘) CV −𝐿D \u00012i = Ω(𝑘/𝑛), matching (up to constants) the accuracy of a hold-out estimator of a single fold of size 𝑛/𝑘. Together these results delineate the fundamental trade-off in resampling-based risk estimation: CV cannot fully exploit all 𝑛samples for unbiased risk evaluation, and its minimax performance is pinned between the 𝑘/𝑛and √ 𝑘/𝑛regimes.",
    "keywords": [
      "and phrases. cross-validation",
      "learning theory",
      "algorithmic stability"
    ]
  },
  {
    "article_id": "2511.03670v1_DQN_Performance_with_Epsilon_Greedy_Policies_and_Prioritized_Experience_Replay",
    "title": "2511.03670v1 DQN Performance with Epsilon Greedy Policies and Prioritized Experience Replay",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.03670v1_DQN_Performance_with_Epsilon_Greedy_Policies_and_Prioritized_Experience_Replay.pdf",
    "url": "http://arxiv.org/abs/2511.03670v1_DQN_Performance_with_Epsilon_Greedy_Policies_and_Prioritized_Experience_Replay",
    "pdf_url": "https://arxiv.org/pdf/2511.03670v1_DQN_Performance_with_Epsilon_Greedy_Policies_and_Prioritized_Experience_Replay",
    "file_size_mb": 2.23,
    "abstract": null,
    "keywords": []
  },
  {
    "article_id": "2511.03806v1_FusionDP_Foundation_Model-Assisted_Differentially_Private_Learning_for_Partially_Sensitive_Features",
    "title": "2511.03806v1 FusionDP Foundation Model-Assisted Differentially Private Learning for Partially Sensitive Features",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.03806v1_FusionDP_Foundation_Model-Assisted_Differentially_Private_Learning_for_Partially_Sensitive_Features.pdf",
    "url": "http://arxiv.org/abs/2511.03806v1_FusionDP_Foundation_Model-Assisted_Differentially_Private_Learning_for_Partially_Sensitive_Features",
    "pdf_url": "https://arxiv.org/pdf/2511.03806v1_FusionDP_Foundation_Model-Assisted_Differentially_Private_Learning_for_Partially_Sensitive_Features",
    "file_size_mb": 1.26,
    "abstract": "Ensuring the privacy of sensitive training data is crucial in privacy-preserving machine learning. However, in practical scenarios, privacy protection may be required for only a sub- set of features. For instance, in ICU data, demographic at- tributes like age and gender pose higher privacy risks due to their re-identification potential, whereas raw lab results are generally less sensitive. Traditional DP-SGD enforces privacy protection on all features in one sample, leading to excessive noise injection and significant utility degradation. We propose FUSIONDP, a two-step framework that enhances model utility under feature-level differential privacy. First, FUSIONDP leverages large foundation models to impute sen- sitive features given non-sensitive features, treating them as external priors that provide high-quality estimates of sensi- tive attributes without accessing the true values during model training. Second, we introduce a modified DP-SGD algorithm that trains models on both original and imputed features while formally preserving the privacy of the original sensitive fea- tures. We evaluate FUSIONDP on two modalities: a sepsis prediction task on tabular data from PhysioNet and a clini- cal note classification task from MIMIC-III. By comparing against privacy-preserving baselines, our results show that FUSIONDP significantly improves model performance while maintaining rigorous feature-level privacy, demonstrating the potential of foundation model-driven imputation to enhance the privacy-utility trade-off for various modalities.",
    "keywords": []
  },
  {
    "article_id": "2511.03825v1_How_Different_Tokenization_Algorithms_Impact_LLMs_and_Transformer_Models_for_Binary_Code_Analysis",
    "title": "2511.03825v1 How Different Tokenization Algorithms Impact LLMs and Transformer Models for Binary Code Analysis",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.03825v1_How_Different_Tokenization_Algorithms_Impact_LLMs_and_Transformer_Models_for_Binary_Code_Analysis.pdf",
    "url": "http://arxiv.org/abs/2511.03825v1_How_Different_Tokenization_Algorithms_Impact_LLMs_and_Transformer_Models_for_Binary_Code_Analysis",
    "pdf_url": "https://arxiv.org/pdf/2511.03825v1_How_Different_Tokenization_Algorithms_Impact_LLMs_and_Transformer_Models_for_Binary_Code_Analysis",
    "file_size_mb": 0.97,
    "abstract": "—Tokenization is fundamental in assembly code anal- ysis, impacting intrinsic characteristics like vocabulary size, semantic coverage, and extrinsic performance in downstream tasks. Despite its significance, tokenization in the context of assembly code remains an underexplored area. This study aims to address this gap by evaluating the intrinsic properties of Natural Language Processing (NLP) tokenization models and parameter choices, such as vocabulary size. We explore prepro- cessing customization options and pre-tokenization rules tailored to the unique characteristics of assembly code. Additionally, we assess their impact on downstream tasks like function signature prediction—a critical problem in binary code analysis. To this end, we conduct a thorough study on various tokeniza- tion models, systematically analyzing their efficiency in encoding assembly instructions and capturing semantic nuances. Through intrinsic evaluations, we compare tokenizers based on tokeniza- tion efficiency, vocabulary compression, and representational fidelity for assembly code. Using state-of-the-art pre-trained models such as the decoder-only Large Language Model (LLM) Llama 3.2, the encoder-only transformer BERT, and the encoder- decoder model BART, we evaluate the effectiveness of these tokenizers across multiple performance metrics. Preliminary find- ings indicate that tokenizer choice significantly influences down- stream performance, with intrinsic metrics providing partial but incomplete predictability of extrinsic evaluation outcomes. These results reveal complex trade-offs between intrinsic tokenizer properties and their utility in practical assembly code tasks. Ultimately, this study provides valuable insights into optimizing tokenization models for low-level code analysis, contributing to the robustness and scalability of Natural Language Model (NLM)-based binary analysis workflows.",
    "keywords": []
  },
  {
    "article_id": "2511.05295v1_Language_Generation_and_Identification_From_Partial_Enumeration_Tight_Density_Bounds_and_Topological",
    "title": "2511.05295v1 Language Generation and Identification From Partial Enumeration Tight Density Bounds and Topological",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.05295v1_Language_Generation_and_Identification_From_Partial_Enumeration_Tight_Density_Bounds_and_Topological.pdf",
    "url": "http://arxiv.org/abs/2511.05295v1_Language_Generation_and_Identification_From_Partial_Enumeration_Tight_Density_Bounds_and_Topological",
    "pdf_url": "https://arxiv.org/pdf/2511.05295v1_Language_Generation_and_Identification_From_Partial_Enumeration_Tight_Density_Bounds_and_Topological",
    "file_size_mb": 0.48,
    "abstract": "The recent successes of large language models (LLMs) have led to active lines of work in formal theories of language generation and learning. We build on one such theory, language generation in the limit, in which an adversary enumerates the strings of an unknown language K drawn from a countable list of candidate languages, and an algorithm tries to generate unseen strings from the language. Initial work on this model showed there is an algorithm that can always succeed at this task, and more recent work has shown there is in fact an algorithm that can produce a positive-density subset of the language. These results on density reflect the validity–breadth tension in language generation: the trade-off between generating only valid strings while also achieving wide coverage of the true language. Here we begin by resolving one of the main open questions from this work on density, establishing a tight bound of 1/2 on the best achievable lower density of any algorithm. We then consider a more powerful adversary, capturing the fact that generation algorithms may typically be faced with an environment in which only a subset of the language is being produced. This is a model with only partial enumeration of K: We show that there is an algorithm with the property that if an adversary only outputs an infinite subset C of the true language K, it can still achieve language generation in the limit; and moreover, if the subset C has lower density α in K, then the algorithm produces a subset of lower density at least α/2, which matches the upper bound. This generalizes the tight density bound of 1/2 to the case where the algorithm must come within 1/2 of the density of whichever subset of K the adversary reveals. We also revisit the classical Gold-Angluin model of language identification (rather than gen- eration) when the adversary need only partially enumerate an infinite subset C of the true language K. We characterize when it is possible for an algorithm to achieve the natural ana- logue of identification in the limit in this partial setting, producing languages Mt (and finite representations of them) such that eventually C ⊆M ⊆K. Our characterization builds on our earlier topological approach on density in language generation [15], and in the process we give a new topological formulation of Angluin’s characterization for language identification in the ∗Department of Computer Science and Information Science, Cornell University, Ithaca NY 14853 USA. Supported in part by a Vannevar Bush Faculty Fellowship, AFOSR grant FA9550-23-1-0410, a Simons Collaboration grant, and a grant from the MacArthur Foundation. †Department of Mathemaics, Duke University, 120 Science Drive, Durham, NC 27710, USA. Research supported by NSF grants DMS-2404167 and DMS-2401414. arXiv:2511.05295v1 [cs.DS] 7 Nov 2025 limit, showing that her condition is precisely equivalent to some appropriate topological space having the TD separation property. Contents",
    "keywords": []
  },
  {
    "article_id": "2511.05529v2_Selective_Diabetic_Retinopathy_Screening_with_Accuracy-Weighted_Deep_Ensembles_and_Entropy-Guided_Ab",
    "title": "2511.05529v2 Selective Diabetic Retinopathy Screening with Accuracy-Weighted Deep Ensembles and Entropy-Guided Ab",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.05529v2_Selective_Diabetic_Retinopathy_Screening_with_Accuracy-Weighted_Deep_Ensembles_and_Entropy-Guided_Ab.pdf",
    "url": "http://arxiv.org/abs/2511.05529v2_Selective_Diabetic_Retinopathy_Screening_with_Accuracy-Weighted_Deep_Ensembles_and_Entropy-Guided_Ab",
    "pdf_url": "https://arxiv.org/pdf/2511.05529v2_Selective_Diabetic_Retinopathy_Screening_with_Accuracy-Weighted_Deep_Ensembles_and_Entropy-Guided_Ab",
    "file_size_mb": 1.17,
    "abstract": "—Diabetic retinopathy (DR), a microvascular compli- cation of diabetes and a leading cause of preventable blindness, is projected to affect more than 130 million individuals worldwide by 2030. Early identification is essential to reduce irreversible vision loss, yet current diagnostic workflows rely on methods such as fundus photography and expert review, which remain costly and resource-intensive. This, combined with DR’s asymptomatic nature, results in its underdiagnosis rate of approximately 25%. Although convolutional neural networks (CNNs) have demon- strated strong performance in medical imaging tasks, limited interpretability and the absence of uncertainty quantification restrict clinical reliability. Therefore, in this study, a deep ensem- ble learning framework integrated with uncertainty estimation is introduced to improve robustness, transparency, and scala- bility in DR detection. The ensemble incorporates seven CNN architectures—ResNet-50, DenseNet-121, MobileNetV3 (Small and Large), and EfficientNet (B0, B2, B3)— whose outputs are fused through an accuracy-weighted majority voting strategy. A probability-weighted entropy metric quantifies prediction uncer- tainty, enabling low-confidence samples to be excluded or flagged for additional review. Training and validation on 35,000 EyePACS retinal fundus images produced an unfiltered accuracy of 93.70% (F1 = 0.9376). Uncertainty-filtering later was conducted to remove unconfident samples, resulting in maximum-accuracy of 99.44% (F1 = 0.9932). The framework shows that uncertainty-aware, accuracy-weighted ensembling improves reliability without hin- dering performance. With confidence-calibrated outputs and a tunable accuracy–coverage trade-off, it offers a generalizable paradigm for deploying trustworthy AI diagnostics in high-risk care.",
    "keywords": []
  },
  {
    "article_id": "2511.05568v1_Adaptive_Sample-Level_Framework_Motivated_by_Distributionally_Robust_Optimization_with_Variance-Base",
    "title": "2511.05568v1 Adaptive Sample-Level Framework Motivated by Distributionally Robust Optimization with Variance-Base",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.05568v1_Adaptive_Sample-Level_Framework_Motivated_by_Distributionally_Robust_Optimization_with_Variance-Base.pdf",
    "url": "http://arxiv.org/abs/2511.05568v1_Adaptive_Sample-Level_Framework_Motivated_by_Distributionally_Robust_Optimization_with_Variance-Base",
    "pdf_url": "https://arxiv.org/pdf/2511.05568v1_Adaptive_Sample-Level_Framework_Motivated_by_Distributionally_Robust_Optimization_with_Variance-Base",
    "file_size_mb": 0.8,
    "abstract": "Distribution shifts and minority subpopulations frequently undermine the reliability of deep neural networks trained using Empirical Risk Minimization (ERM). Distributionally Robust Optimization (DRO) addresses this by optimizing for the worst-case risk within a neighborhood of the training distribution. However, conventional methods depend on a single, global robustness budget, which can lead to overly conservative models or a misallocation of robustness. We propose a variance-driven, adaptive, sample-level DRO (Var-DRO) framework that automatically identifies high-risk training samples and assigns a personalized robustness budget to each based on its online loss variance. Our formulation employs two-sided, KL-divergence-style bounds to constrain the ratio between adversarial and empirical weights for every sample. This results in a linear inner maximization problem over a convex polytope, which admits an efficient water-filling solution. To stabilize training, we introduce a warmup phase and a linear ramp schedule for the global cap on per-sample budgets, complemented by label smoothing for numerical robustness. Evaluated on CIFAR-10-C (corruptions), our method achieves the highest overall mean accuracy compared to ERM and KL-DRO. On Waterbirds, Var-DRO improves overall performance while matching or surpassing KL-DRO. On the original CIFAR-10 dataset, Var-DRO remains competitive, exhibiting the modest trade-off anticipated when prioritizing robustness. The proposed framework is unsupervised (requiring no group labels), straightforward to implement, theoretically sound, and computationally efficient.",
    "keywords": [
      "Distributionally Robust Optimization",
      "Out-of-Distribution Generalization",
      "Neural Net- works",
      "Variance-Based"
    ]
  },
  {
    "article_id": "2511.05569v1_Data-driven_jet_fuel_demand_forecasting_A_case_study_of_Copenhagen_Airport",
    "title": "2511.05569v1 Data-driven jet fuel demand forecasting A case study of Copenhagen Airport",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.05569v1_Data-driven_jet_fuel_demand_forecasting_A_case_study_of_Copenhagen_Airport.pdf",
    "url": "http://arxiv.org/abs/2511.05569v1_Data-driven_jet_fuel_demand_forecasting_A_case_study_of_Copenhagen_Airport",
    "pdf_url": "https://arxiv.org/pdf/2511.05569v1_Data-driven_jet_fuel_demand_forecasting_A_case_study_of_Copenhagen_Airport",
    "file_size_mb": 3.25,
    "abstract": "Accurate forecasting of jet fuel demand is crucial for optimizing supply chain operations in the aviation market. Fuel distributors specifically require precise estimates to avoid inventory shortages or excesses. However, there is a lack of studies that analyze the jet fuel demand forecasting problem using machine learning models. Instead, many industry practitioners rely on deterministic or expertise-based models. In this research, we evaluate the performance of data- driven approaches using a substantial amount of data obtained from a major aviation fuel distributor in the Danish market. Our analysis compares the predictive capabilities of traditional time series models, Prophet, LSTM sequence- to-sequence neural networks, and hybrid models. A key challenge in developing these models is the required forecasting horizon, as fuel demand needs to be predicted for the next 30 days to optimize sourcing strategies. To ensure the reliability of the data-driven approaches and provide valuable insights to practi- tioners, we analyze three different datasets. The primary objective of this study is to present a comprehensive case study on jet fuel demand forecasting, demon- strating the advantages of employing data-driven models and highlighting the impact of incorporating additional variables in the predictive models.",
    "keywords": [
      "Supply chain management",
      "demand forecasting",
      "jet fuel",
      "time series"
    ]
  },
  {
    "article_id": "2511.05694v2_Distributionally_Robust_Self_Paced_Curriculum_Reinforcement_Learning",
    "title": "2511.05694v2 Distributionally Robust Self Paced Curriculum Reinforcement Learning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.05694v2_Distributionally_Robust_Self_Paced_Curriculum_Reinforcement_Learning.pdf",
    "url": "http://arxiv.org/abs/2511.05694v2_Distributionally_Robust_Self_Paced_Curriculum_Reinforcement_Learning",
    "pdf_url": "https://arxiv.org/pdf/2511.05694v2_Distributionally_Robust_Self_Paced_Curriculum_Reinforcement_Learning",
    "file_size_mb": 8.07,
    "abstract": "A central challenge in reinforcement learning is that policies trained in controlled environments often fail under distribution shifts at deployment into real-world environments. Distributionally Robust Reinforcement Learning (DRRL) addresses this by optimizing for worst-case performance within an uncertainty set defined by a robustness budget ϵ. However, fixing ϵ results in a tradeoff between performance and robustness: small values yield high nominal performance but weak robustness, while large values can result in instability and overly conservative policies. We propose Distributionally Robust Self-Paced Curriculum Reinforcement Learning (DR-SPCRL), a method that overcomes this limitation by treating ϵ as a continuous curriculum. DR-SPCRL adaptively schedules the robustness budget according to the agent’s progress, enabling a balance between nominal and robust performance. Empirical results across multiple environments demonstrate that DR-SPCRL not only stabilizes training but also achieves a superior robustness–performance trade-off, yielding an average 11.8% increase in episodic return under varying perturbations compared to fixed or heuristic scheduling strategies, and achieving approximately 1.9× the performance of the corresponding nominal RL algorithms.",
    "keywords": []
  },
  {
    "article_id": "2511.05861v2_Equilibrium_Portfolio_Selection_under_Utility-Variance_Analysis_of_Log_Returns_in_Incomplete_Markets",
    "title": "2511.05861v2 Equilibrium Portfolio Selection under Utility-Variance Analysis of Log Returns in Incomplete Markets",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.05861v2_Equilibrium_Portfolio_Selection_under_Utility-Variance_Analysis_of_Log_Returns_in_Incomplete_Markets.pdf",
    "url": "http://arxiv.org/abs/2511.05861v2_Equilibrium_Portfolio_Selection_under_Utility-Variance_Analysis_of_Log_Returns_in_Incomplete_Markets",
    "pdf_url": "https://arxiv.org/pdf/2511.05861v2_Equilibrium_Portfolio_Selection_under_Utility-Variance_Analysis_of_Log_Returns_in_Incomplete_Markets",
    "file_size_mb": 1.21,
    "abstract": "This paper investigates a time-inconsistent portfolio selection problem in the incomplete market model, integrating expected utility maximization with risk control. The objective func- tional balances the expected utility and variance on log returns, giving rise to time inconsistency and motivating the search for a time-consistent equilibrium strategy. We characterize the equi- librium via a coupled quadratic backward stochastic differential equation (BSDE) system and establish the existence results in two special cases: (i) the two Brownian motions driving the price dynamics and the factor process are independent (ρ = 0); (ii) the trading strategy is con- strained to be bounded. For the general case with correlation coefficient ρ ̸= 0, we introduce the notion of an approximate time-consistent equilibrium. Employing the solution structure from the equilibrium in the case ρ = 0, we can construct an approximate time-consistent equilibrium in the general case with an error of order O(ρ2). Numerical examples and financial insights are also presented based on deep learning algorithms.",
    "keywords": [
      "Time inconsistent control",
      "time-consistent equilibrium",
      "quadratic BSDE system"
    ]
  },
  {
    "article_id": "2511.06273v1_COTN_A_Chaotic_Oscillatory_Transformer_Network_for_Complex_Volatile_Systems_under_Extreme_Conditions",
    "title": "2511.06273v1 COTN A Chaotic Oscillatory Transformer Network for Complex Volatile Systems under Extreme Conditions",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.06273v1_COTN_A_Chaotic_Oscillatory_Transformer_Network_for_Complex_Volatile_Systems_under_Extreme_Conditions.pdf",
    "url": "http://arxiv.org/abs/2511.06273v1_COTN_A_Chaotic_Oscillatory_Transformer_Network_for_Complex_Volatile_Systems_under_Extreme_Conditions",
    "pdf_url": "https://arxiv.org/pdf/2511.06273v1_COTN_A_Chaotic_Oscillatory_Transformer_Network_for_Complex_Volatile_Systems_under_Extreme_Conditions",
    "file_size_mb": 1.75,
    "abstract": "—Accurate prediction of financial and electricity markets, especially under extreme conditions, remains a significant challenge due to their intrinsic nonlinearity, rapid fluctuations, and chaotic patterns. To address these limitations, we propose the Chaotic Oscillatory Transformer Network (COTN). COTN innovatively combines a Transformer architecture with a novel Lee Oscillator activation function, processed through Max-over-Time pooling and a λ-gating mechanism. This design is specifically tailored to effectively capture chaotic dynamics and improve responsiveness during periods of heightened volatility, where conventional activation functions (e.g., ReLU, GELU) tend to saturate. Furthermore, COTN incorporates an Autoencoder Self-Regressive (ASR) module to detect and isolate abnormal market patterns, such as sudden price spikes or crashes, thereby preventing corruption of the core prediction process and enhancing robustness. Extensive experiments across electricity spot markets and financial markets demonstrate the practical applicability and resilience of COTN. Our approach outperforms state-of-the-art deep learning models like Informer by up to 17% and traditional statistical methods like GARCH by as much as 40%. These results underscore COTN’s effectiveness in navigating real-world market uncertainty and complexity, offering a powerful tool for forecasting highly volatile systems under duress. Index Terms—Lee Oscillator, Transformer Model, Time Series Forecasting, Complex Volatile Systems, Extreme Conditions, Anomaly Detection, Deep Learning",
    "keywords": []
  },
  {
    "article_id": "2511.07118v1_On_the_Joint_Minimization_of_Regularization_Loss_Functions_in_Deep_Variational_Bayesian_Methods_for_",
    "title": "2511.07118v1 On the Joint Minimization of Regularization Loss Functions in Deep Variational Bayesian Methods for ",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.07118v1_On_the_Joint_Minimization_of_Regularization_Loss_Functions_in_Deep_Variational_Bayesian_Methods_for_.pdf",
    "url": "http://arxiv.org/abs/2511.07118v1_On_the_Joint_Minimization_of_Regularization_Loss_Functions_in_Deep_Variational_Bayesian_Methods_for_",
    "pdf_url": "https://arxiv.org/pdf/2511.07118v1_On_the_Joint_Minimization_of_Regularization_Loss_Functions_in_Deep_Variational_Bayesian_Methods_for_",
    "file_size_mb": 3.32,
    "abstract": "—Explicit latent variable models provide a flexible yet powerful framework for data synthesis, enabling controlled manipulation of generative factors. With latent variables drawn from a tractable probability density function that can be further constrained, these models enable continuous and semantically rich exploration of the output space by navigating their latent spaces. Structured latent representations are typically obtained through the joint minimization of regularization loss functions. In variational information bottleneck models, reconstruction loss and Kullback-Leibler Divergence (KLD) are often linearly combined with an auxiliary Attribute-Regularization (AR) loss. However, balancing KLD and AR turns out to be a very delicate matter. When KLD dominates over AR, generative models tend to lack controllability; when AR dominates over KLD, the stochastic encoder is encouraged to violate the standard normal prior. We explore this trade-off in the context of symbolic music generation with explicit control over continuous musical attributes. We show that existing approaches struggle to jointly minimize both regu- larization objectives, whereas suitable attribute transformations can help achieve both controllability and regularization of the target latent dimensions.",
    "keywords": [
      "symbolic music generation",
      "attribute-controlled"
    ]
  },
  {
    "article_id": "2511.07210v2_Breaking_the_Stealth-Potency_Trade-off_in_Clean-Image_Backdoors_with_Generative_Trigger_Optimization",
    "title": "2511.07210v2 Breaking the Stealth-Potency Trade-off in Clean-Image Backdoors with Generative Trigger Optimization",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.07210v2_Breaking_the_Stealth-Potency_Trade-off_in_Clean-Image_Backdoors_with_Generative_Trigger_Optimization.pdf",
    "url": "http://arxiv.org/abs/2511.07210v2_Breaking_the_Stealth-Potency_Trade-off_in_Clean-Image_Backdoors_with_Generative_Trigger_Optimization",
    "pdf_url": "https://arxiv.org/pdf/2511.07210v2_Breaking_the_Stealth-Potency_Trade-off_in_Clean-Image_Backdoors_with_Generative_Trigger_Optimization",
    "file_size_mb": 6.58,
    "abstract": "Clean-image backdoor attacks, which use only label manipula- tion in training datasets to compromise deep neural networks, pose a significant threat to security-critical applications. A critical flaw in existing methods is that the poison rate re- quired for a successful attack induces a proportional, and thus noticeable, drop in Clean Accuracy (CA), undermining their stealthiness. This paper presents a new paradigm for clean- image attacks that minimizes this accuracy degradation by optimizing the trigger itself. We introduce Generative Clean- Image Backdoors (GCB), a framework that uses a conditional InfoGAN to identify naturally occurring image features that can serve as potent and stealthy triggers. By ensuring these triggers are easily separable from benign task-related features, GCB enables a victim model to learn the backdoor from an extremely small set of poisoned examples, resulting in a CA drop of less than 1%. Our experiments demonstrate GCB’s remarkable versatility, successfully adapting to six datasets, five architectures, and four tasks, including the first demonstra- tion of clean-image backdoors in regression and segmentation. GCB also exhibits resilience against most of the existing back- door defenses. Code — https://github.com/binyxu/GCB",
    "keywords": []
  },
  {
    "article_id": "2511.07560v1_EvoPS_Evolutionary_Patch_Selection_for_Whole_Slide_Image_Analysis_in_Computational_Pathology",
    "title": "2511.07560v1 EvoPS Evolutionary Patch Selection for Whole Slide Image Analysis in Computational Pathology",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.07560v1_EvoPS_Evolutionary_Patch_Selection_for_Whole_Slide_Image_Analysis_in_Computational_Pathology.pdf",
    "url": "http://arxiv.org/abs/2511.07560v1_EvoPS_Evolutionary_Patch_Selection_for_Whole_Slide_Image_Analysis_in_Computational_Pathology",
    "pdf_url": "https://arxiv.org/pdf/2511.07560v1_EvoPS_Evolutionary_Patch_Selection_for_Whole_Slide_Image_Analysis_in_Computational_Pathology",
    "file_size_mb": 15.7,
    "abstract": "In computational pathology, the gigapixel scale of Whole-Slide Images (WSIs) necessitates their division into thousands of smaller patches. Analyz- ing these high-dimensional patch embeddings is computationally expensive and risks diluting key diagnostic signals with many uninformative patches. Existing patch selection methods often rely on random sampling or simple clustering heuristics and typically fail to explicitly manage the crucial trade- off between the number of selected patches and the accuracy of the resulting slide representation. To address this gap, we propose EvoPS (Evolution- ary Patch Selection), a novel framework that formulates patch selection as a multi-objective optimization problem and leverages an evolutionary search to simultaneously minimize the number of selected patch embeddings and maximize the performance of a downstream similarity search task, generat- ing a Pareto front of optimal trade-off solutions. We validated our framework across four major cancer cohorts from The Cancer Genome Atlas (TCGA) using five pretrained deep learning models to generate patch embeddings, including both supervised CNNs and large self-supervised foundation mod- els. The results demonstrate that EvoPS can reduce the required number of training patch embeddings by over 90% while consistently maintaining or even improving the final classification F1-score compared to a baseline that uses all available patches’ embeddings selected through a standard extraction pipeline. The EvoPS framework provides a robust and principled method for creating efficient, accurate, and interpretable WSI representations, empow- ering users to select an optimal balance between computational cost and diagnostic performance.",
    "keywords": [
      "Computational Pathology",
      "Evolutionary Computation",
      "Patch"
    ]
  },
  {
    "article_id": "2511.08658v1_It_Looks_All_the_Same_to_Me_Cross-index_Training_for_Long-term_Financial_Series_Prediction",
    "title": "2511.08658v1 It Looks All the Same to Me Cross-index Training for Long-term Financial Series Prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.08658v1_It_Looks_All_the_Same_to_Me_Cross-index_Training_for_Long-term_Financial_Series_Prediction.pdf",
    "url": "http://arxiv.org/abs/2511.08658v1_It_Looks_All_the_Same_to_Me_Cross-index_Training_for_Long-term_Financial_Series_Prediction",
    "pdf_url": "https://arxiv.org/pdf/2511.08658v1_It_Looks_All_the_Same_to_Me_Cross-index_Training_for_Long-term_Financial_Series_Prediction",
    "file_size_mb": 0.51,
    "abstract": ". We investigate a number of Artificial Neural Network archi- tectures (well-known and more “exotic”) in application to the long-term financial time-series forecasts of indexes on different global markets. The particular area of interest of this research is to examine the correlation of these indexes’ behaviour in terms of Machine Learning algorithms cross- training. Would training an algorithm on an index from one global mar- ket produce similar or even better accuracy when such a model is applied for predicting another index from a different market? The demonstrated predominately positive answer to this question is another argument in favour of the long-debated Efficient Market Hypothesis of Eugene Fama.",
    "keywords": [
      "Efficient Market Hypothesis",
      "neural networks",
      "cross-training"
    ]
  },
  {
    "article_id": "2511.09962v1_AI-Integrated_Decision_Support_System_for_Real-Time_Market_Growth_Forecasting_and_Multi-Source_Conte",
    "title": "2511.09962v1 AI-Integrated Decision Support System for Real-Time Market Growth Forecasting and Multi-Source Conte",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.09962v1_AI-Integrated_Decision_Support_System_for_Real-Time_Market_Growth_Forecasting_and_Multi-Source_Conte.pdf",
    "url": "http://arxiv.org/abs/2511.09962v1_AI-Integrated_Decision_Support_System_for_Real-Time_Market_Growth_Forecasting_and_Multi-Source_Conte",
    "pdf_url": "https://arxiv.org/pdf/2511.09962v1_AI-Integrated_Decision_Support_System_for_Real-Time_Market_Growth_Forecasting_and_Multi-Source_Conte",
    "file_size_mb": 1.37,
    "abstract": ". The rapid proliferation of AI-generated content (AIGC) has reshaped the dynamics of digital marketing and online consumer behavior. However, predicting the diffusion trajectory and market impact of such content remains challenging due to data heterogeneity, non-linear propagation mechanisms, and evolving consumer interactions. This study proposes an AI-driven Decision Support System (DSS) that integrates multi-source data—including social media streams, marketing expenditure records, consumer engagement logs, and sentiment dynamics—using a hybrid Graph Neural Network (GNN) and Temporal Transformer framework. The model jointly learns the content diffusion structure and temporal influence evolution through a dual-channel architecture, while causal inference modules disentangle the effects of marketing stimuli on return on investment (ROI) and market visibility. Experiments on large-scale real-world datasets collected from multiple online platforms such as Twitter, TikTok, and YouTube advertising show that our system outperforms existing baselines in all six metrics. The proposed DSS enhances marketing decisions by providing interpretable real-time insights into AIGC driven content dissemination and market growth patterns.",
    "keywords": [
      "AI-generated content (AIGC)",
      "Decision Support System (DSS)",
      "Graph"
    ]
  },
  {
    "article_id": "2511.10435v1_Neuronal_Fluctuations_Learning_Rates_vs_Participating_Neurons",
    "title": "2511.10435v1 Neuronal Fluctuations Learning Rates vs Participating Neurons",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.10435v1_Neuronal_Fluctuations_Learning_Rates_vs_Participating_Neurons.pdf",
    "url": "http://arxiv.org/abs/2511.10435v1_Neuronal_Fluctuations_Learning_Rates_vs_Participating_Neurons",
    "pdf_url": "https://arxiv.org/pdf/2511.10435v1_Neuronal_Fluctuations_Learning_Rates_vs_Participating_Neurons",
    "file_size_mb": 3.0,
    "abstract": "Deep Neural Networks (DNNs) rely on inherent fluctuations in their internal parameters—weights and biases—to effectively navigate the com- plex optimization landscape and achieve robust performance. While these fluctuations are recognized as crucial for escaping local minima and im- proving generalization, their precise relationship with fundamental hy- perparameters remains underexplored. A significant knowledge gap exists concerning how the learning rate, a critical parameter governing the train- ing process, directly influences the dynamics of these neural fluctuations. This study systematically investigates the impact of varying learning rates on the magnitude and character of weight and bias fluctuations within a neural network. We trained a model using distinct learning rates (0.01, 0.001, and 0.0001) and analyzed the corresponding parameter fluctua- tions in conjunction with the network’s final accuracy. Our findings aim to establish a clear link between the learning rate’s value, the resulting fluctuation patterns, and overall model performance. By doing so, we pro- vide deeper insights into the optimization process, shedding light on how the learning rate mediates the crucial exploration-exploitation trade-off during training. This work contributes to a more nuanced understanding of hyperparameter tuning and the underlying mechanics of deep learning. 1 arXiv:2511.10435v1 [cs.LG] 13 Nov 2025",
    "keywords": []
  },
  {
    "article_id": "2511.10494v1_Weak_Relation_Enforcement_for_Kinematic-Informed_Long-Term_Stock_Prediction_with_Artificial_Neural_N",
    "title": "2511.10494v1 Weak Relation Enforcement for Kinematic-Informed Long-Term Stock Prediction with Artificial Neural N",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.10494v1_Weak_Relation_Enforcement_for_Kinematic-Informed_Long-Term_Stock_Prediction_with_Artificial_Neural_N.pdf",
    "url": "http://arxiv.org/abs/2511.10494v1_Weak_Relation_Enforcement_for_Kinematic-Informed_Long-Term_Stock_Prediction_with_Artificial_Neural_N",
    "pdf_url": "https://arxiv.org/pdf/2511.10494v1_Weak_Relation_Enforcement_for_Kinematic-Informed_Long-Term_Stock_Prediction_with_Artificial_Neural_N",
    "file_size_mb": 0.38,
    "abstract": ". We propose loss function week enforcement of the velocity relations between time-series points in the Kinematic-Informed artificial Neural Networks (KINN) for long-term stock prediction. Problems of the series volatility, Out-of-Distribution (OOD) test data, and outliers in training data are addressed by (Artificial Neural Networks) ANN’s learning not only future points prediction but also by learning velocity relations between the points, such a way as avoiding unrealistic spurious predictions. The presented loss function penalizes not only errors be- tween predictions and supervised label data, but also errors between the next point prediction and the previous point plus velocity prediction. The loss function is tested on the multiple popular and exotic AR ANN archi- tectures, and around fifteen years of Dow Jones function demonstrated statistically meaningful improvement across the normalization-sensitive activation functions prone to spurious behaviour in the OOD data con- ditions. Results show that such architecture addresses the issue of the normalization in the auto-regressive models that break the data topol- ogy by weakly enforcing the data neighbourhood proximity (relation) preservation during the ANN transformation.",
    "keywords": [
      "financial series",
      "temporal graph neural networks",
      "physics-"
    ]
  },
  {
    "article_id": "2511.10964v1_How_Data_Quality_Affects_Machine_Learning_Models_for_Credit_Risk_Assessment",
    "title": "2511.10964v1 How Data Quality Affects Machine Learning Models for Credit Risk Assessment",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.10964v1_How_Data_Quality_Affects_Machine_Learning_Models_for_Credit_Risk_Assessment.pdf",
    "url": "http://arxiv.org/abs/2511.10964v1_How_Data_Quality_Affects_Machine_Learning_Models_for_Credit_Risk_Assessment",
    "pdf_url": "https://arxiv.org/pdf/2511.10964v1_How_Data_Quality_Affects_Machine_Learning_Models_for_Credit_Risk_Assessment",
    "file_size_mb": 0.85,
    "abstract": "Machine Learning (ML) models are being increasingly employed for credit risk evaluation, with their effectiveness largely hinging on the quality of the input data. In this paper we investigate the impact of several data quality issues, including missing values, noisy attributes, outliers, and label errors, on the predictive accuracy of the machine learning model used in credit risk assessment. Utilizing an open-source dataset, we introduce controlled data corruption using the Pucktrick library to assess the robustness of 10 frequently used models like Random Forest, SVM, and Logistic Regression and so on. Our experiments show significant differences in model robustness based on the nature and severity of the data degradation. Moreover, the proposed methodology and accompanying tools offer practical support for practitioners seeking to enhance data pipeline robustness, and provide researchers with a flexible framework for further experimentation in data-centric AI contexts. CCS Concepts • Theory of computation →Models of learning; Data model- ing; • Computing methodologies →Machine learning algo- rithms; • Information systems →Inconsistent data; Incom- plete data; Data cleaning.",
    "keywords": [
      "Credit risk",
      "Data quality",
      "Machine learning",
      "Robustness",
      "Data cor-"
    ]
  },
  {
    "article_id": "2511.11481v1_Risk-Aware_Deep_Reinforcement_Learning_for_Dynamic_Portfolio_Optimization",
    "title": "2511.11481v1 Risk-Aware Deep Reinforcement Learning for Dynamic Portfolio Optimization",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.11481v1_Risk-Aware_Deep_Reinforcement_Learning_for_Dynamic_Portfolio_Optimization.pdf",
    "url": "http://arxiv.org/abs/2511.11481v1_Risk-Aware_Deep_Reinforcement_Learning_for_Dynamic_Portfolio_Optimization",
    "pdf_url": "https://arxiv.org/pdf/2511.11481v1_Risk-Aware_Deep_Reinforcement_Learning_for_Dynamic_Portfolio_Optimization",
    "file_size_mb": 0.74,
    "abstract": "This paper presents a deep reinforcement learning (DRL) framework for dynamic portfolio optimiza- tion in the presence of market uncertainty and risk. Traditional portfolio allocation methods often fall short in adapting to evolving market conditions while managing risk effectively. We introduce a risk-aware DRL model that integrates advanced reinforcement learning algorithms, a novel reward function based on the Sharpe ratio, and direct risk control strategies including maximum drawdown and portfolio volatility constraints. The model is trained and validated on historical financial data using Proximal Policy Optimization (PPO), and compared against mean-variance and equal-weighted benchmarks. Our empirical results show the DRL-based approach offers adaptive asset allocation and competitive performance under realistic constraints. This research contributes to the development of intelligent and risk-sensitive financial decision-making tools.",
    "keywords": [
      "Deep Reinforcement Learning",
      "Dynamic Portfolio Allocation",
      "Risk-Aware Optimization",
      "Sharpe Ratio"
    ]
  },
  {
    "article_id": "2511.11701v1_Bayesian_Neural_Networks_with_Monte_Carlo_Dropout_for_Probabilistic_Electricity_Price_Forecasting",
    "title": "2511.11701v1 Bayesian Neural Networks with Monte Carlo Dropout for Probabilistic Electricity Price Forecasting",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.11701v1_Bayesian_Neural_Networks_with_Monte_Carlo_Dropout_for_Probabilistic_Electricity_Price_Forecasting.pdf",
    "url": "http://arxiv.org/abs/2511.11701v1_Bayesian_Neural_Networks_with_Monte_Carlo_Dropout_for_Probabilistic_Electricity_Price_Forecasting",
    "pdf_url": "https://arxiv.org/pdf/2511.11701v1_Bayesian_Neural_Networks_with_Monte_Carlo_Dropout_for_Probabilistic_Electricity_Price_Forecasting",
    "file_size_mb": 0.25,
    "abstract": "—Accurate electricity price forecasting is critical for strategic decision-making in deregulated electricity markets, where volatility stems from complex supply-demand dynamics and external factors. Traditional point forecasts often fail to capture inherent uncertainties, limiting their utility for risk management. This work presents a framework for probabilistic electricity price forecasting using Bayesian neural networks (BNNs) with Monte Carlo (MC) dropout, training separate models for each hour of the day to capture diurnal patterns. A critical assessment and comparison with the benchmark model, namely: generalized autoregressive conditional heteroskedasticity with exogenous variable (GARCHX) model and the LASSO estimated auto-regressive model (LEAR), highlights that the proposed model outperforms the benchmark models in terms of point prediction and intervals. This work serves as a reference for leveraging probabilistic neural models in energy market predictions.",
    "keywords": [
      "Electricity Price Forecasting",
      "Bayesian Neural"
    ]
  },
  {
    "article_id": "2511.11880v1_Transformers_vs_Recurrent_Models_for_Estimating_Forest_Gross_Primary_Production",
    "title": "2511.11880v1 Transformers vs Recurrent Models for Estimating Forest Gross Primary Production",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.11880v1_Transformers_vs_Recurrent_Models_for_Estimating_Forest_Gross_Primary_Production.pdf",
    "url": "http://arxiv.org/abs/2511.11880v1_Transformers_vs_Recurrent_Models_for_Estimating_Forest_Gross_Primary_Production",
    "pdf_url": "https://arxiv.org/pdf/2511.11880v1_Transformers_vs_Recurrent_Models_for_Estimating_Forest_Gross_Primary_Production",
    "file_size_mb": 0.49,
    "abstract": "Monitoring the spatiotemporal dynamics of forest CO2 uptake (Gross Primary Production, GPP), remains a central challenge in terrestrial ecosystem research. While Eddy Covariance (EC) towers provide high-frequency estimates, their limited spatial coverage constrains large- scale assessments. Remote sensing offers a scalable alternative, yet most approaches rely on single-sensor spectral indices and statistical models that are often unable to capture the complex temporal dynamics of GPP. Recent advances in deep learning (DL) and data fusion offer new opportunities to better represent the temporal dynamics of vegetation processes, but comparative evaluations of state-of-the-art DL models for multimodal GPP prediction re- main scarce. Here, we explore the performance of two representative models for predicting GPP: 1) GPT-2, a transformer architecture, and 2) Long Short-Term Memory (LSTM), a re- current neural network, using multivariate inputs. Overall, both achieve similar accuracy. But, while LSTM performs better overall, GPT-2 excels during extreme events. Analysis of temporal context length further reveals that LSTM attains similar accuracy using substantially shorter input windows than GPT-2, highlighting an accuracy-efficiency trade-off between the two architectures. Feature importance analysis reveals radiation as the dominant predictor, followed by Sentinel-2, MODIS land surface temperature, and Sentinel-1 contributions. Our results demonstrate how model architecture, context length, and multimodal inputs jointly determine performance in GPP prediction, guiding future developments of DL frameworks for monitoring terrestrial carbon dynamics.",
    "keywords": []
  },
  {
    "article_id": "2511.12120v1_Deep_Reinforcement_Learning_for_Automated_Stock_Trading_An_Ensemble_Strategy",
    "title": "2511.12120v1 Deep Reinforcement Learning for Automated Stock Trading An Ensemble Strategy",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.12120v1_Deep_Reinforcement_Learning_for_Automated_Stock_Trading_An_Ensemble_Strategy.pdf",
    "url": "http://arxiv.org/abs/2511.12120v1_Deep_Reinforcement_Learning_for_Automated_Stock_Trading_An_Ensemble_Strategy",
    "pdf_url": "https://arxiv.org/pdf/2511.12120v1_Deep_Reinforcement_Learning_for_Automated_Stock_Trading_An_Ensemble_Strategy",
    "file_size_mb": 0.76,
    "abstract": "—Stock trading strategies play a critical role in investment. However, it is challenging to design a profitable strategy in a complex and dynamic stock market. In this paper, we propose an ensemble strategy that employs deep reinforcement schemes to learn a stock trading strategy by maximizing investment return. We train a deep reinforcement learning agent and obtain an ensemble trading strategy using three actor-critic based algorithms: Proximal Policy Optimization (PPO), Advantage Actor Critic (A2C), and Deep Deterministic Policy Gradient (DDPG). The ensemble strategy inherits and integrates the best features of the three algorithms, thereby robustly adjusting to different market situations. In order to avoid the large memory consumption in training networks with continuous action space, we employ a load-on-demand technique for processing very large data. We test our algorithms on the 30 Dow Jones stocks that have adequate liquidity. The performance of the trading agent with different reinforcement learning algorithms is evaluated and compared with both the Dow Jones Industrial Average index and the traditional min-variance portfolio allocation strategy. The proposed deep ensemble strategy is shown to outperform the three individual algorithms and two baselines in terms of the risk-adjusted return measured by the Sharpe ratio. This work is fully open-sourced at GitHub.",
    "keywords": [
      "Deep reinforcement learning",
      "Markov De-"
    ]
  },
  {
    "article_id": "2511.12122v1_Dynamic_Anomaly_Identification_in_Accounting_Transactions_via_Multi-Head_Self-Attention_Networks",
    "title": "2511.12122v1 Dynamic Anomaly Identification in Accounting Transactions via Multi-Head Self-Attention Networks",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.12122v1_Dynamic_Anomaly_Identification_in_Accounting_Transactions_via_Multi-Head_Self-Attention_Networks.pdf",
    "url": "http://arxiv.org/abs/2511.12122v1_Dynamic_Anomaly_Identification_in_Accounting_Transactions_via_Multi-Head_Self-Attention_Networks",
    "pdf_url": "https://arxiv.org/pdf/2511.12122v1_Dynamic_Anomaly_Identification_in_Accounting_Transactions_via_Multi-Head_Self-Attention_Networks",
    "file_size_mb": 0.29,
    "abstract": "-This study addresses the problem of dynamic anomaly detection in accounting transactions and proposes a real-time detection method based on a Transformer to tackle the challenges of hidden abnormal behaviors and high timeliness requirements in complex trading environments. The approach first models accounting transaction data by representing multi-dimensional records as time-series matrices and uses embedding layers and positional encoding to achieve low-dimensional mapping of inputs. A sequence modeling structure with multi-head self-attention is then constructed to capture global dependencies and aggregate features from multiple perspectives, thereby enhancing the ability to detect abnormal patterns. The network further integrates feed- forward layers and regularization strategies to achieve deep feature representation and accurate anomaly probability estimation. To validate the effectiveness of the method, extensive experiments were conducted on a public dataset, including comparative analysis, hyperparameter sensitivity tests, environmental sensitivity tests, and data sensitivity tests. Results show that the proposed method outperforms baseline models in AUC, F1-Score, Precision, and Recall, and maintains stable performance under different environmental conditions and data perturbations. These findings confirm the applicability and advantages of the Transformer-based framework for dynamic anomaly detection in accounting transactions and provide methodological support for intelligent financial risk control and auditing. CCS CONCEPTS: Computing methodologies~Machine learning~Machine learning approaches",
    "keywords": [
      "Accounting flow",
      "anomaly detection",
      "self-attention"
    ]
  },
  {
    "article_id": "2511.12129v1_A_Practical_Machine_Learning_Approach_for_Dynamic_Stock_Recommendation",
    "title": "2511.12129v1 A Practical Machine Learning Approach for Dynamic Stock Recommendation",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.12129v1_A_Practical_Machine_Learning_Approach_for_Dynamic_Stock_Recommendation.pdf",
    "url": "http://arxiv.org/abs/2511.12129v1_A_Practical_Machine_Learning_Approach_for_Dynamic_Stock_Recommendation",
    "pdf_url": "https://arxiv.org/pdf/2511.12129v1_A_Practical_Machine_Learning_Approach_for_Dynamic_Stock_Recommendation",
    "file_size_mb": 0.79,
    "abstract": "—Stock recommendation is vital to investment companies and investors. However, no single stock selection strategy will always win while analysts may not have enough time to check all S&P 500 stocks (the Standard & Poor’s 500). In this paper, we propose a practical scheme that recommends stocks from S&P 500 using machine learning. Our basic idea is to buy and hold the top 20% stocks dynamically. First, we select representative stock indicators with good explanatory power. Secondly, we take five frequently used machine learning methods, including linear regression, ridge regression, stepwise regression, random forest and generalized boosted regression, to model stock indicators and quarterly log-return in a rolling window. Thirdly, we choose the model with the lowest Mean Square Error in each period to rank stocks. Finally, we test the selected stocks by conducting portfolio allocation methods such as equally weighted, mean- variance, and minimum-variance. Our empirical results show that the proposed scheme outperforms the long-only strategy on the S&P 500 index in terms of Sharpe ratio and cumulative returns. This work is fully open-sourced at GitHub.",
    "keywords": [
      "Stock recommendation",
      "fundamental value"
    ]
  },
  {
    "article_id": "2511.12236v1_Consistency_Is_the_Key_Detecting_Hallucinations_in_LLM_Generated_Text_By_Checking_Inconsistencies_Ab",
    "title": "2511.12236v1 Consistency Is the Key Detecting Hallucinations in LLM Generated Text By Checking Inconsistencies Ab",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.12236v1_Consistency_Is_the_Key_Detecting_Hallucinations_in_LLM_Generated_Text_By_Checking_Inconsistencies_Ab.pdf",
    "url": "http://arxiv.org/abs/2511.12236v1_Consistency_Is_the_Key_Detecting_Hallucinations_in_LLM_Generated_Text_By_Checking_Inconsistencies_Ab",
    "pdf_url": "https://arxiv.org/pdf/2511.12236v1_Consistency_Is_the_Key_Detecting_Hallucinations_in_LLM_Generated_Text_By_Checking_Inconsistencies_Ab",
    "file_size_mb": 0.81,
    "abstract": "Large language models (LLMs), despite their remarkable text generation capabilities, often hallucinate and generate text that is factually incorrect and not grounded in real-world knowl- edge. This poses serious risks in domains like healthcare, finance, and customer support. A typical way to use LLMs is via the APIs pro- vided by LLM vendors where there is no ac- cess to model weights or options to fine-tune the model. Existing methods to detect hallu- cinations in such settings where the model ac- cess is restricted or constrained by resources typically require making multiple LLM API calls, increasing latency and API cost. We in- troduce CONFACTCHECK, an efficient halluci- nation detection approach that does not lever- age any external knowledge base and works on the simple intuition that responses to factual probes within the generated text should be con- sistent within a single LLM and across different LLMs. Rigorous empirical evaluation on mul- tiple datasets that cover both the generation of factual texts and the open generation shows that CONFACTCHECK can detect hallucinated facts efficiently using fewer resources and achieves higher accuracy scores compared to existing baselines that operate under similar conditions. Our code is available here.",
    "keywords": []
  },
  {
    "article_id": "2511.13365v1_InfoDecom_Decomposing_Information_for_Defending_against_Privacy_Leakage_in_Split_Inference",
    "title": "2511.13365v1 InfoDecom Decomposing Information for Defending against Privacy Leakage in Split Inference",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.13365v1_InfoDecom_Decomposing_Information_for_Defending_against_Privacy_Leakage_in_Split_Inference.pdf",
    "url": "http://arxiv.org/abs/2511.13365v1_InfoDecom_Decomposing_Information_for_Defending_against_Privacy_Leakage_in_Split_Inference",
    "pdf_url": "https://arxiv.org/pdf/2511.13365v1_InfoDecom_Decomposing_Information_for_Defending_against_Privacy_Leakage_in_Split_Inference",
    "file_size_mb": 1.1,
    "abstract": "Split inference (SI) enables users to access deep learning (DL) services without directly transmitting raw data. How- ever, recent studies reveal that data reconstruction attacks (DRAs) can recover the original inputs from the smashed data sent from the client to the server, leading to significant privacy leakage. While various defenses have been proposed, they of- ten result in substantial utility degradation, particularly when the client-side model is shallow. We identify a key cause of this trade-off: existing defenses apply excessive perturbation to redundant information in the smashed data. To address this issue in computer vision tasks, we propose InfoDecom, a de- fense framework that first decomposes and removes redun- dant information and then injects noise calibrated to provide theoretically guaranteed privacy. Experiments demonstrate that InfoDecom achieves a superior utility-privacy trade-off compared to existing baselines. The code and the appendix are available at https://github.com/SASA-cloud/InfoDecom.",
    "keywords": []
  },
  {
    "article_id": "2511.13384v4_CBDC_Stress_Test_in_a_Dual-Currency_Setting",
    "title": "2511.13384v4 CBDC Stress Test in a Dual-Currency Setting",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.13384v4_CBDC_Stress_Test_in_a_Dual-Currency_Setting.pdf",
    "url": "http://arxiv.org/abs/2511.13384v4_CBDC_Stress_Test_in_a_Dual-Currency_Setting",
    "pdf_url": "https://arxiv.org/pdf/2511.13384v4_CBDC_Stress_Test_in_a_Dual-Currency_Setting",
    "file_size_mb": 23.54,
    "abstract": "....................................................................................................................................................................................................12 Executive Summary...........................................................................................................................................................................13",
    "keywords": []
  },
  {
    "article_id": "2511.13761v1_What_happens_when_nanochat_meets_DiLoCo",
    "title": "2511.13761v1 What happens when nanochat meets DiLoCo",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.13761v1_What_happens_when_nanochat_meets_DiLoCo.pdf",
    "url": "http://arxiv.org/abs/2511.13761v1_What_happens_when_nanochat_meets_DiLoCo",
    "pdf_url": "https://arxiv.org/pdf/2511.13761v1_What_happens_when_nanochat_meets_DiLoCo",
    "file_size_mb": 1.16,
    "abstract": "Although LLM training is typically centralized with high-bandwidth interconnects and large compute budgets, emerging methods target communication-constrained training in dis- tributed environments. The model trade-offs introduced by this shift remain underexplored, and our goal is to study them. We use the open-source nanochat project [1], a compact 8K-line full-stack ChatGPT-like implementation containing tokenization, pretraining, fine-tuning, and serving, as a controlled baseline. We implement the DiLoCo algorithm [2] as a lightweight wrapper over nanochat’s training loop, performing multiple local steps per worker before synchronization with an outer optimizer, effectively reducing communication by orders of magnitude. This inner-outer training is compared against a standard data-parallel (DDP) setup. Because nanochat is small and inspectable, it enables controlled pipeline adaptations and allows direct comparison with the conventional centralized baseline. DiLoCo achieves stable convergence and competitive loss in pretraining but yields worse MMLU, GSM8K, and HumanEval scores after mid-training and SFT. We discover that using DiLoCo-pretrained weights and running mid- and post-training with DDP fails to recover per- formance, revealing irreversible representation drift from asynchronous updates that impairs downstream alignment. We provide this implementation as an official fork of nanochat on GitHub 1.",
    "keywords": []
  },
  {
    "article_id": "2511.14214v2_Do_Large_Language_Models_LLMs_Understand_Chronology",
    "title": "2511.14214v2 Do Large Language Models LLMs Understand Chronology",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.14214v2_Do_Large_Language_Models_LLMs_Understand_Chronology.pdf",
    "url": "http://arxiv.org/abs/2511.14214v2_Do_Large_Language_Models_LLMs_Understand_Chronology",
    "pdf_url": "https://arxiv.org/pdf/2511.14214v2_Do_Large_Language_Models_LLMs_Understand_Chronology",
    "file_size_mb": 3.79,
    "abstract": "Large language models (LLMs) are increasingly used in finance and economics, where prompt-based attempts against look-ahead bias implicitly assume that mod- els understand chronology. We test this fundamental question with a series of chronological ordering tasks with increasing complexities over facts the model already knows from pre-training. Our tasks cover (1) chronological ordering, (2) conditional sorting (filter, then order), and (3) anachronism detection. We evaluate GPT-4.1 and Claude-3.7 Sonnet, with and without Extended Thinking (ET), and the newly released GPT-5 across multiple reasoning-effort settings. Across models, Exact match rate drops sharply as sequences lengthen even while rank correlations stay high as LLMs largely preserve local order but struggle to maintain a single globally consistent timeline. In conditional sorting, most failures stem from the fil- tering step rather than the ordering step, but GPT-5 and Claude-3.7 with Extended Thinking outshine normal models significantly. Lastly, anachronism detection is found to be the easiest task for the LLMs but performance still declines with increasingly overlapping timelines or entities. Overall, our main significant contri- bution is showing that allocating explicit reasoning budget helps with chronological ordering with GPT-5 at medium/high reasoning effort achieving flawless ordering at all lengths and perfect conditional sorting (both self-filtered and given-subset), whereas low/minimal effort degrades with longer lists, mirroring earlier models. We release all code and evaluation templates to support full reproducibility.1”",
    "keywords": []
  },
  {
    "article_id": "2511.14980v1_Selective_Forgetting_in_Option_Calibration_An_Operator-Theoretic_Gauss-Newton_Framework",
    "title": "2511.14980v1 Selective Forgetting in Option Calibration An Operator-Theoretic Gauss-Newton Framework",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.14980v1_Selective_Forgetting_in_Option_Calibration_An_Operator-Theoretic_Gauss-Newton_Framework.pdf",
    "url": "http://arxiv.org/abs/2511.14980v1_Selective_Forgetting_in_Option_Calibration_An_Operator-Theoretic_Gauss-Newton_Framework",
    "pdf_url": "https://arxiv.org/pdf/2511.14980v1_Selective_Forgetting_in_Option_Calibration_An_Operator-Theoretic_Gauss-Newton_Framework",
    "file_size_mb": 0.61,
    "abstract": "Calibration of option pricing models is routinely repeated as markets evolve, yet modern systems lack an operator for removing data from a calibrated model without full retraining. When quotes become stale, corrupted, or subject to deletion requirements, existing calibration pipelines must rebuild the entire nonlinear least-squares problem, even if only a small subset of data must be excluded. In this work, we introduce a principled framework for selective forget- ting (machine unlearning) in parametric option calibration. We provide stability guarantees, perturbation bounds, and show that the proposed operators satisfy local exactness under standard regularity assumptions.",
    "keywords": [
      "selective forgetting",
      "option calibration",
      "Gauss–Newton methods",
      "sufficient"
    ]
  },
  {
    "article_id": "2511.15262v1_Reinforcement_Learning_in_Queue-Reactive_Models_Application_to_Optimal_Execution",
    "title": "2511.15262v1 Reinforcement Learning in Queue-Reactive Models Application to Optimal Execution",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.15262v1_Reinforcement_Learning_in_Queue-Reactive_Models_Application_to_Optimal_Execution.pdf",
    "url": "http://arxiv.org/abs/2511.15262v1_Reinforcement_Learning_in_Queue-Reactive_Models_Application_to_Optimal_Execution",
    "pdf_url": "https://arxiv.org/pdf/2511.15262v1_Reinforcement_Learning_in_Queue-Reactive_Models_Application_to_Optimal_Execution",
    "file_size_mb": 2.34,
    "abstract": "We investigate the use of Reinforcement Learning for the optimal execution of meta- orders, where the objective is to execute incrementally large orders while minimizing implementation shortfall and market impact over an extended period of time. Depart- ing from traditional parametric approaches to price dynamics and impact modeling, we adopt a model-free, data-driven framework. Since policy optimization requires coun- terfactual feedback that historical data cannot provide, we employ the Queue-Reactive Model to generate realistic and tractable limit order book simulations that encompass transient price impact, and nonlinear and dynamic order flow responses. Methodolog- ically, we train a Double Deep Q-Network agent on a state space comprising time, inventory, price, and depth variables, and evaluate its performance against established benchmarks. Numerical simulation results show that the agent learns a policy that is both strategic and tactical, adapting effectively to order book conditions and out- performing standard approaches across multiple training configurations. These findings provide strong evidence that model-free Reinforcement Learning can yield adaptive and robust solutions to the optimal execution problem.",
    "keywords": [
      "Optimal Execution",
      "Reinforcement Learning",
      "Queue-Reactive Model",
      "Limit"
    ]
  },
  {
    "article_id": "2511.15332v1_Exponential_Lasso_robust_sparse_penalization_under_heavy-tailed_noise_and_outliers_with_exponential-",
    "title": "2511.15332v1 Exponential Lasso robust sparse penalization under heavy-tailed noise and outliers with exponential-",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.15332v1_Exponential_Lasso_robust_sparse_penalization_under_heavy-tailed_noise_and_outliers_with_exponential-.pdf",
    "url": "http://arxiv.org/abs/2511.15332v1_Exponential_Lasso_robust_sparse_penalization_under_heavy-tailed_noise_and_outliers_with_exponential-",
    "pdf_url": "https://arxiv.org/pdf/2511.15332v1_Exponential_Lasso_robust_sparse_penalization_under_heavy-tailed_noise_and_outliers_with_exponential-",
    "file_size_mb": 0.33,
    "abstract": "In high-dimensional statistics, the Lasso is a cornerstone method for simultaneous variable selection and parameter estimation. However, its reliance on the squared loss function renders it highly sensitive to outliers and heavy-tailed noise, potentially leading to unreliable model se- lection and biased estimates. To address this limitation, we introduce the Exponential Lasso, a novel robust method that integrates an exponential-type loss function within the Lasso frame- work. This loss function is designed to achieve a smooth trade-oﬀbetween statistical eﬃciency under Gaussian noise and robustness against data contamination. Unlike other methods that cap the inﬂuence of large residuals, the exponential loss smoothly redescends, eﬀectively down- weighting the impact of extreme outliers while preserving near-quadratic behavior for small errors. We establish theoretical guarantees showing that the Exponential Lasso achieves strong statistical convergence rates, matching the classical Lasso under ideal conditions while main- taining its robustness in the presence of heavy-tailed contamination. Computationally, the estimator is optimized eﬃciently via a Majorization-Minimization (MM) algorithm that itera- tively solves a series of weighted Lasso subproblems. Numerical experiments demonstrate that the proposed method is highly competitive, outperforming the classical Lasso in contaminated settings and maintaining strong performance even under Gaussian noise. Our method is implemented in the R package heavylasso available on Github: https://github.com/tienmt/heavylasso.",
    "keywords": [
      "heavy-tailed noise",
      "Lasso",
      "robust regression",
      "sparsity",
      "soft-thresholding",
      "non-asymptotic"
    ]
  },
  {
    "article_id": "2511.15456v1_Know_Your_Intent_An_Autonomous_Multi-Perspective_LLM_Agent_Framework_for_DeFi_User_Transaction_Inten",
    "title": "2511.15456v1 Know Your Intent An Autonomous Multi-Perspective LLM Agent Framework for DeFi User Transaction Inten",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.15456v1_Know_Your_Intent_An_Autonomous_Multi-Perspective_LLM_Agent_Framework_for_DeFi_User_Transaction_Inten.pdf",
    "url": "http://arxiv.org/abs/2511.15456v1_Know_Your_Intent_An_Autonomous_Multi-Perspective_LLM_Agent_Framework_for_DeFi_User_Transaction_Inten",
    "pdf_url": "https://arxiv.org/pdf/2511.15456v1_Know_Your_Intent_An_Autonomous_Multi-Perspective_LLM_Agent_Framework_for_DeFi_User_Transaction_Inten",
    "file_size_mb": 5.08,
    "abstract": "As Decentralized Finance (DeFi) develops, understanding user in- tent behind DeFi transactions is crucial yet challenging due to complex smart contract interactions, multifaceted on-/off-chain factors, and opaque hex logs. Existing methods lack deep seman- tic insight. To address this, we propose the Transaction Intent Mining (TIM) framework. TIM leverages a DeFi intent taxonomy built on grounded theory and a multi-agent Large Language Model (LLM) system to robustly infer user intents. A Meta-Level Planner dynamically coordinates domain experts to decompose multiple perspective-specific intent analyses into solvable subtasks. Question Solvers handle the tasks with multi-modal on/off-chain data. While a Cognitive Evaluator mitigates LLM hallucinations and ensures verifiability. Experiments show that TIM significantly outperforms machine learning models, single LLMs, and single Agent baselines. We also analyze core challenges in intent inference. This work helps provide a more reliable understanding of user motivations in DeFi, offering context-aware explanations for complex blockchain activity. CCS Concepts • Security and privacy →Economics of security and privacy; Cryptography; • Information systems →Data analytics; • Com- puting methodologies →Multi-agent systems; Natural language processing.",
    "keywords": [
      "Multi-agent System",
      "Intent Mining",
      "Decentralized Finance",
      "On-"
    ]
  },
  {
    "article_id": "2511.15960v1_Machine_Learning_vs_Randomness_Challenges_in_Predicting_Binary_Options_Movements",
    "title": "2511.15960v1 Machine Learning vs Randomness Challenges in Predicting Binary Options Movements",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.15960v1_Machine_Learning_vs_Randomness_Challenges_in_Predicting_Binary_Options_Movements.pdf",
    "url": "http://arxiv.org/abs/2511.15960v1_Machine_Learning_vs_Randomness_Challenges_in_Predicting_Binary_Options_Movements",
    "pdf_url": "https://arxiv.org/pdf/2511.15960v1_Machine_Learning_vs_Randomness_Challenges_in_Predicting_Binary_Options_Movements",
    "file_size_mb": 0.51,
    "abstract": ". Binary options trading is often marketed as a field where predictive models can generate consistent profits. However, the inherent randomness and stochastic nature of binary options make price move- ments highly unpredictable, posing significant challenges for any fore- casting approach. This study demonstrates that machine learning al- gorithms struggle to outperform a simple baseline in predicting binary options movements. Using a dataset of EUR/USD currency pairs from 2021 to 2023, we tested multiple models, including Random Forest, Logis- tic Regression, Gradient Boosting, and k-Nearest Neighbors (kNN), both before and after hyperparameter optimization. Furthermore, several neu- ral network architectures, including Multi-Layer Perceptrons (MLP) and a Long Short-Term Memory (LSTM) network, were evaluated under dif- ferent training conditions. Despite these exhaustive efforts, none of the models surpassed the ZeroR baseline accuracy, highlighting the inher- ent randomness of binary options. These findings reinforce the notion that binary options lack predictable patterns, making them unsuitable for machine learning-based forecasting.",
    "keywords": [
      "Binary Options",
      "Machine Learning",
      "Neural Networks"
    ]
  },
  {
    "article_id": "2511.16375v1_Are_Foundation_Models_Useful_for_Bankruptcy_Prediction",
    "title": "2511.16375v1 Are Foundation Models Useful for Bankruptcy Prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.16375v1_Are_Foundation_Models_Useful_for_Bankruptcy_Prediction.pdf",
    "url": "http://arxiv.org/abs/2511.16375v1_Are_Foundation_Models_Useful_for_Bankruptcy_Prediction",
    "pdf_url": "https://arxiv.org/pdf/2511.16375v1_Are_Foundation_Models_Useful_for_Bankruptcy_Prediction",
    "file_size_mb": 0.36,
    "abstract": "Foundation models have shown promise across various financial applications, yet their effectiveness for corporate bankruptcy prediction remains systematically unevaluated against established methods. We study bankruptcy forecasting us- ing Llama-3.3-70B-Instruct and TabPFN, evaluated on large, highly imbalanced datasets of over one million company records from the Visegrád Group. We provide the first systematic comparison of foundation models against classical machine learning baselines for this task. Our results show that models such as XGBoost and CatBoost consistently outperform foundation models across all prediction horizons. LLM-based approaches suffer from unreliable probability estimates, undermin- ing their use in risk-sensitive financial settings. TabPFN shows mixed results — underperforming on ROC-AUC but competitive on F1-score — while requiring substantial computational resources that cannot be justified by its performance. These findings suggest that, despite their generality, current foundation models remain less effective than specialized methods for bankruptcy forecasting.",
    "keywords": []
  },
  {
    "article_id": "2511.16657v1_Enhancing_Forex_Forecasting_Accuracy_The_Impact_of_Hybrid_Variable_Sets_in_Cognitive_Algorithmic_Tra",
    "title": "2511.16657v1 Enhancing Forex Forecasting Accuracy The Impact of Hybrid Variable Sets in Cognitive Algorithmic Tra",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.16657v1_Enhancing_Forex_Forecasting_Accuracy_The_Impact_of_Hybrid_Variable_Sets_in_Cognitive_Algorithmic_Tra.pdf",
    "url": "http://arxiv.org/abs/2511.16657v1_Enhancing_Forex_Forecasting_Accuracy_The_Impact_of_Hybrid_Variable_Sets_in_Cognitive_Algorithmic_Tra",
    "pdf_url": "https://arxiv.org/pdf/2511.16657v1_Enhancing_Forex_Forecasting_Accuracy_The_Impact_of_Hybrid_Variable_Sets_in_Cognitive_Algorithmic_Tra",
    "file_size_mb": 0.4,
    "abstract": "This paper presents the implementation of an advanced artificial intelligence-based al- gorithmic trading system specifically designed for the EUR-USD pair within the complex and high-frequency environment of the Forex market. The methodological approach centers on integrating a holistic set of input features: key fundamental macroeconomic variables (e.g., Gross Domestic Product, Unemployment Rate) collected from both the Euro Zone and the American Zone, alongside a comprehensive suite of technical variables (including various indicators, oscillators, Fibonacci levels, and price divergences). The performance of the resulting algorithm is subjected to a rigorous evaluation process. This assessment uti- lizes both standard Machine Learning metrics to quantify model accuracy and backtesting simulations across historical data to evaluate trading profitability and risk. Crucially, the study concludes with a detailed comparative analysis designed to determine which class of input features—fundamental or technical—provides the system with the greater and more reliable predictive capacity for generating profitable trading signals.",
    "keywords": []
  },
  {
    "article_id": "2511.16854v3_MRI_Super-Resolution_with_Deep_Learning_A_Comprehensive_Survey",
    "title": "2511.16854v3 MRI Super-Resolution with Deep Learning A Comprehensive Survey",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.16854v3_MRI_Super-Resolution_with_Deep_Learning_A_Comprehensive_Survey.pdf",
    "url": "http://arxiv.org/abs/2511.16854v3_MRI_Super-Resolution_with_Deep_Learning_A_Comprehensive_Survey",
    "pdf_url": "https://arxiv.org/pdf/2511.16854v3_MRI_Super-Resolution_with_Deep_Learning_A_Comprehensive_Survey",
    "file_size_mb": 1.76,
    "abstract": "— High-resolution (HR) magnetic resonance imaging (MRI) is crucial for many clinical and research applications. However, achieving it remains costly and con- strained by technical trade-offs and experimental limita- tions. Super-resolution (SR) presents a promising compu- tational approach to overcome these challenges by gener- ating HR images from more affordable low-resolution (LR) scans, potentially improving diagnostic accuracy and effi- ciency without requiring additional hardware. This survey reviews recent advances in MRI SR techniques, with a focus on deep learning (DL) approaches. It examines DL- based MRI SR methods from the perspectives of computer vision, computational imaging, inverse problems, and MR physics, covering theoretical foundations, architectural de- signs, learning strategies, benchmark datasets, and per- formance metrics. We propose a systematic taxonomy to categorize these methods and present an in-depth study of both established and emerging SR techniques applica- ble to MRI, considering unique challenges in clinical and research contexts. We also highlight open challenges and directions that the community needs to address. Addi- tionally, we provide a collection of essential open-access resources, tools, and tutorials, available on our GitHub: https://github.com/mkhateri/Awesome-MRI-Super-Resolution.",
    "keywords": [
      "MRI",
      "Super-Resolution",
      "Deep Learning"
    ]
  },
  {
    "article_id": "2511.17600v1_SALPA_Spaceborne_LiDAR_Point_Adjustment_for_Enhanced_GEDI_Footprint_Geolocation",
    "title": "2511.17600v1 SALPA Spaceborne LiDAR Point Adjustment for Enhanced GEDI Footprint Geolocation",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.17600v1_SALPA_Spaceborne_LiDAR_Point_Adjustment_for_Enhanced_GEDI_Footprint_Geolocation.pdf",
    "url": "http://arxiv.org/abs/2511.17600v1_SALPA_Spaceborne_LiDAR_Point_Adjustment_for_Enhanced_GEDI_Footprint_Geolocation",
    "pdf_url": "https://arxiv.org/pdf/2511.17600v1_SALPA_Spaceborne_LiDAR_Point_Adjustment_for_Enhanced_GEDI_Footprint_Geolocation",
    "file_size_mb": 11.72,
    "abstract": "Spaceborne Light Detection and Ranging (LiDAR) systems, such as NASA’s Global Ecosystem Dynamics Investigation (GEDI), provide forest structure for global carbon as- sessments. However, geolocation uncertainties (typically 5–15 m) propagate systematically through derived products, undermining forest profile estimates, including carbon stock as- sessments. Existing correction methods face critical limitations: waveform simulation ap- proaches achieve meter-level accuracy but require high-resolution LiDAR data unavailable in most regions, while terrain-based methods employ deterministic grid searches that may overlook optimal solutions in continuous solution spaces. We present SALPA (Spaceborne LiDAR Point Adjustment), a multi-algorithm optimization framework integrating three op- timization paradigms with five distance metrics. Operating exclusively with globally avail- able digital elevation models and geoid data, SALPA explores continuous solution spaces through gradient-based, evolutionary, and swarm intelligence approaches. Validation across contrasting sites: topographically complex Nikko, Japan, and flat Landes, France, demon- strates 15–16% improvements over original GEDI positions and 0.5–2% improvements over the state-of-the-art GeoGEDI algorithm. L-BFGS-B with Area-based metrics achieves op- timal accuracy-efficiency trade-offs, while population-based algorithms (genetic algorithms, particle swarm optimization) excel in complex terrain. The platform-agnostic framework facilitates straightforward adaptation to emerging spaceborne LiDAR missions, providing a generalizable foundation for universal geolocation correction essential for reliable global forest monitoring and climate policy decisions.",
    "keywords": []
  },
  {
    "article_id": "2511.17892v1_Arbitrage-Free_Bond_and_Yield_Curve_Forecasting_with_Neural_Filters_under_HJM_Constraints",
    "title": "2511.17892v1 Arbitrage-Free Bond and Yield Curve Forecasting with Neural Filters under HJM Constraints",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.17892v1_Arbitrage-Free_Bond_and_Yield_Curve_Forecasting_with_Neural_Filters_under_HJM_Constraints.pdf",
    "url": "http://arxiv.org/abs/2511.17892v1_Arbitrage-Free_Bond_and_Yield_Curve_Forecasting_with_Neural_Filters_under_HJM_Constraints",
    "pdf_url": "https://arxiv.org/pdf/2511.17892v1_Arbitrage-Free_Bond_and_Yield_Curve_Forecasting_with_Neural_Filters_under_HJM_Constraints",
    "file_size_mb": 5.39,
    "abstract": "We develop an arbitrage-free deep learning framework for yield curve and bond price forecasting based on the Heath- Jarrow-Morton (HJM) term-structure model and a dynamic Nelson-Siegel parameterization of forward rates. Our approach embeds a no-arbitrage drift restriction into a neural state-space architecture by combining Kalman, extended Kalman, and particle ﬁlters with recurrent neural networks (LSTM/CLSTM), and introduces an explicit arbitrage error regularization (AER) term during training. The model is applied to U.S. Treasury and corporate bond data, and its performance is evaluated for both yield-space and price-space predictions at 1-day and 5-day horizons. Empirically, arbitrage regularization leads to its strongest improvements at short maturities, particularly in 5-day-ahead forecasts, increasing market-consistency as measured by bid-ask hit rates and reducing dollar-denominated prediction errors.",
    "keywords": [
      "arbitrage-free modeling",
      "yield curve forecasting",
      "HJM framework",
      "dynamic Nelson–Siegel",
      "Kalman ﬁlter",
      "particle"
    ]
  },
  {
    "article_id": "2511.17954v1_A_multi-view_contrastive_learning_framework_for_spatial_embeddings_in_risk_modelling",
    "title": "2511.17954v1 A multi-view contrastive learning framework for spatial embeddings in risk modelling",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.17954v1_A_multi-view_contrastive_learning_framework_for_spatial_embeddings_in_risk_modelling.pdf",
    "url": "http://arxiv.org/abs/2511.17954v1_A_multi-view_contrastive_learning_framework_for_spatial_embeddings_in_risk_modelling",
    "pdf_url": "https://arxiv.org/pdf/2511.17954v1_A_multi-view_contrastive_learning_framework_for_spatial_embeddings_in_risk_modelling",
    "file_size_mb": 15.64,
    "abstract": "Incorporating spatial information, particularly those influenced by climate, weather, and demo- graphic factors, is crucial for improving underwriting precision and enhancing risk management in insurance. However, spatial data are often unstructured, high-dimensional, and difficult to integrate into predictive models. Embedding methods are needed to convert spatial data into meaningful representations for modelling tasks. We propose a novel multi-view contrastive learning framework for generating spatial embeddings that combine information from multiple spatial data sources. To train the model, we construct a spatial dataset that merges satellite imagery and OpenStreetMap features across Europe. The framework aligns these spatial views with coordinate-based encodings, producing low-dimensional embeddings that capture both spa- tial structure and contextual similarity. Once trained, the model generates embeddings directly from latitude–longitude pairs, enabling any dataset with coordinates to be enriched with mean- ingful spatial features without requiring access to the original spatial inputs. In a case study on French real estate prices, we compare models trained on raw coordinates against those using our spatial embeddings as inputs. The embeddings consistently improve predictive accuracy across generalised linear, additive, and boosting models, while providing interpretable spatial effects and demonstrating transferability to unseen regions.",
    "keywords": [
      "spatial embedding",
      "multi-view learning",
      "GeoAI",
      "spatial representation learning"
    ]
  },
  {
    "article_id": "2511.17963v1_Hybrid_LSTM_and_PPO_Networks_for_Dynamic_Portfolio_Optimization",
    "title": "2511.17963v1 Hybrid LSTM and PPO Networks for Dynamic Portfolio Optimization",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.17963v1_Hybrid_LSTM_and_PPO_Networks_for_Dynamic_Portfolio_Optimization.pdf",
    "url": "http://arxiv.org/abs/2511.17963v1_Hybrid_LSTM_and_PPO_Networks_for_Dynamic_Portfolio_Optimization",
    "pdf_url": "https://arxiv.org/pdf/2511.17963v1_Hybrid_LSTM_and_PPO_Networks_for_Dynamic_Portfolio_Optimization",
    "file_size_mb": 2.16,
    "abstract": "This paper introduces a hybrid framework for portfolio optimization that fuses Long Short-Term Memory (LSTM) forecasting with a Proximal Policy Optimization (PPO) reinforcement learning strategy. The proposed system leverages the predictive power of deep recurrent networks to capture temporal dependencies, while the PPO agent adaptively refines portfolio allocations in continuous action spaces, allowing the system to anticipate trends while adjusting dynamically to market shifts. Using multi-asset datasets covering U.S. and Indonesian equities, U.S. Treasuries, and major cryptocurrencies from January 2018 to December 2024, the model is evaluated against several baselines, including equal-weight, index-style, and single-model variants (LSTM-only and PPO- only). The framework’s performance is benchmarked against equal-weighted, index-based, and single-model approaches (LSTM-only and PPO-only) using annualized return, volatility, Sharpe ratio, and maximum drawdown metrics, each adjusted for transaction costs. The results indicate that the hybrid architecture delivers higher returns and stronger resilience under non-stationary market regimes, suggesting its promise as a robust, AI-driven framework for dynamic portfolio optimization.",
    "keywords": [
      "portfolio optimization",
      "deep reinforcement learning",
      "long short-term memory",
      "proximal policy"
    ]
  },
  {
    "article_id": "2511.18025v1_Correlated-Sequence_Differential_Privacy",
    "title": "2511.18025v1 Correlated-Sequence Differential Privacy",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.18025v1_Correlated-Sequence_Differential_Privacy.pdf",
    "url": "http://arxiv.org/abs/2511.18025v1_Correlated-Sequence_Differential_Privacy",
    "pdf_url": "https://arxiv.org/pdf/2511.18025v1_Correlated-Sequence_Differential_Privacy",
    "file_size_mb": 0.9,
    "abstract": "—Data streams collected from multiple sources are rarely independent. Values evolve over time and influence one another across sequences. These correlations improve prediction in healthcare, finance, and smart-city control yet violate the record-independence assumption built into most Differential Privacy (DP) mechanisms. To restore rigorous privacy guarantees without sacrificing utility, we introduce Correlated-Sequence Dif- ferential Privacy (CSDP), a framework specifically designed for preserving privacy in correlated sequential data. CSDP addresses two linked challenges: quantifying the extra information an attacker gains from joint temporal and cross-sequence links, and adding just enough noise to hide that information while keeping the data useful. We model multivariate streams as a Coupling Markov Chain, yielding the derived loose leakage bound expressed with a few spectral terms and revealing a counterintuitive result: stronger coupling can actually decrease worst-case leakage by dispersing perturbations across sequences. Guided by these bounds, we build the Freshness-Regulated Adaptive Noise (FRAN) mechanism—combining data aging, correlation-aware sensitivity scaling, and Laplace noise—that runs in linear time. Tests on two-sequence datasets show that CSDP improves the privacy-utility trade-off by approximately 50% over existing correlated-DP methods and by two orders of magnitude compared to the standard DP approach.",
    "keywords": [
      "Correlated data privacy",
      "sequential data",
      "differ-"
    ]
  },
  {
    "article_id": "2511.18076v1_Reinforcement_Learning_for_Portfolio_Optimization_with_a_Financial_Goal_and_Defined_Time_Horizons",
    "title": "2511.18076v1 Reinforcement Learning for Portfolio Optimization with a Financial Goal and Defined Time Horizons",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.18076v1_Reinforcement_Learning_for_Portfolio_Optimization_with_a_Financial_Goal_and_Defined_Time_Horizons.pdf",
    "url": "http://arxiv.org/abs/2511.18076v1_Reinforcement_Learning_for_Portfolio_Optimization_with_a_Financial_Goal_and_Defined_Time_Horizons",
    "pdf_url": "https://arxiv.org/pdf/2511.18076v1_Reinforcement_Learning_for_Portfolio_Optimization_with_a_Financial_Goal_and_Defined_Time_Horizons",
    "file_size_mb": 1.15,
    "abstract": "This research proposes an enhancement to the innovative portfolio optimization approach using the G- Learning algorithm, combined with parametric optimization via the GIRL algorithm (G-learning approach to the setting of Inverse Reinforcement Learning) as presented by [1]. The goal is to maximize portfolio value by a target date while minimizing the investor’s periodic contributions. Our model operates in a highly volatile market with a well-diversified portfolio, ensuring a low-risk level for the investor, and leverages reinforcement learning to dynamically adjust portfolio positions over time. Results show that we improved the Sharpe Ratio from 0.42, as suggested by recent studies using the same approach, to a value of 0.483 a notable achievement in highly volatile markets with diversified portfolios. The comparison between G-Learning and GIRL reveals that while GIRL optimizes the reward function parameters (e.g., λ = 0.0012 compared to 0.002), its impact on portfo- lio performance remains marginal. This suggests that reinforcement learning methods, like G-Learning, already enable robust optimization. This research contributes to the growing development of reinforcement learning applications in financial decision-making, demonstrating that probabilistic learning algorithms can effectively align portfolio management strategies with investor needs.",
    "keywords": [
      "Portfolio optimization",
      "Goal-based wealth management",
      "Q-learning",
      "G-Learning",
      "GIRL",
      "G-learner"
    ]
  },
  {
    "article_id": "2511.18422v1_NeuroVascU-Net_A_Unified_Multi-Scale_and_Cross-Domain_Adaptive_Feature_Fusion_U-Net_for_Precise_3D_S",
    "title": "2511.18422v1 NeuroVascU-Net A Unified Multi-Scale and Cross-Domain Adaptive Feature Fusion U-Net for Precise 3D S",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.18422v1_NeuroVascU-Net_A_Unified_Multi-Scale_and_Cross-Domain_Adaptive_Feature_Fusion_U-Net_for_Precise_3D_S.pdf",
    "url": "http://arxiv.org/abs/2511.18422v1_NeuroVascU-Net_A_Unified_Multi-Scale_and_Cross-Domain_Adaptive_Feature_Fusion_U-Net_for_Precise_3D_S",
    "pdf_url": "https://arxiv.org/pdf/2511.18422v1_NeuroVascU-Net_A_Unified_Multi-Scale_and_Cross-Domain_Adaptive_Feature_Fusion_U-Net_for_Precise_3D_S",
    "file_size_mb": 1.66,
    "abstract": "Precise 3D segmentation of cerebral vasculature from T1-weighted contrast- enhanced (T1CE) Magnetic Resonance Imaging (MRI) is critical for safe and effective neurosurgical planning. However, manual delineation is labor- intensive and prone to inter-observer variability, while existing automated methods often face a trade-off between segmentation accuracy and compu- tational efficiency, hindering clinical adoption. To the best of our knowl- edge, this study presents NeuroVascU-Net, the first deep learning archi- tecture specifically designed to segment cerebrovascular structures directly from clinically standard T1CE MRI in neuro-oncology patients, addressing a significant gap in the literature that predominantly focuses on Time-of- Flight Magnetic Resonance Angiography (TOF-MRA). NeuroVascU-Net is ∗Behzad Moshiri, Mansour Parvaresh Rizi Email addresses: Mhmmd.jafari@ut.ac.ir (Mohammad Jafari Vayeghan), ndelfan@yorku.ca (Niloufar Delfan), m.t.masouleh@ut.ac.ir (Mehdi Tale Masouleh), parvareshrizi.m@iums.ac.ir (Mansour Parvaresh Rizi), moshiri@ut.ac.ir (Behzad Moshiri) arXiv:2511.18422v1 [cs.CV] 23 Nov 2025 built upon a dilated U-Net backbone and uniquely integrates two specialized modules: a Multi-Scale Contextual Feature Fusion (MSC2F) module at the bottleneck and a Cross-Domain Adaptive Feature Fusion (CDA2F) module at deeper hierarchical levels. The MSC2F module captures local and global contextual information through multi-scale dilated convolutions, while the CDA2F module dynamically integrates domain-specific features, collectively enhancing feature representation while minimizing computational overhead. The model was trained and validated on a uniquely curated dataset of T1CE MRI scans from 137 patients undergoing brain tumor biopsy, with expert annotations by a board-certified functional neurosurgeon. NeuroVascU-Net achieved state-of-the-art performance, demonstrating a Dice Similarity Co- efficient (DSC) of 0.8609 and precision of 0.8841, accurately delineating both large and fine vascular structures. Notably, it operates with only 12.4 mil- lion parameters, significantly fewer than transformer-based models like Swin U-NetR (15.7 million), ensuring reduced computational load without compro- mising accuracy. This combination of high precision and efficiency positions NeuroVascU-Net as a powerful, practical solution for computer-assisted neu- rosurgical planning, with considerable potential to enhance procedural safety and improve patient outcomes.",
    "keywords": [
      "Deep Learning",
      "Contrast Enhanced Magnetic Resonance"
    ]
  },
  {
    "article_id": "2511.18567v1_In_Search_of_Goodness_Large_Scale_Benchmarking_of_Goodness_Functions_for_the_Forward-Forward_Algorit",
    "title": "2511.18567v1 In Search of Goodness Large Scale Benchmarking of Goodness Functions for the Forward-Forward Algorit",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.18567v1_In_Search_of_Goodness_Large_Scale_Benchmarking_of_Goodness_Functions_for_the_Forward-Forward_Algorit.pdf",
    "url": "http://arxiv.org/abs/2511.18567v1_In_Search_of_Goodness_Large_Scale_Benchmarking_of_Goodness_Functions_for_the_Forward-Forward_Algorit",
    "pdf_url": "https://arxiv.org/pdf/2511.18567v1_In_Search_of_Goodness_Large_Scale_Benchmarking_of_Goodness_Functions_for_the_Forward-Forward_Algorit",
    "file_size_mb": 2.19,
    "abstract": "The Forward-Forward (FF) algorithm offers a biologically plausible alternative to backpropagation, enabling neural networks to learn through local updates. However, FF’s efficacy relies heavily on the definition of \"goodness\", which is a scalar measure of neural activity. While current implementations predominantly utilize a simple sum-of-squares metric, it remains unclear if this default choice is optimal. To address this, we benchmarked 21 distinct goodness functions across four standard image datasets (MNIST, FashionMNIST, CIFAR-10, STL-10), evaluating classification accuracy, energy con- sumption, and carbon footprint. We found that certain alternative goodness functions inspired from var- ious domains significantly outperform the standard baseline. Specifically, game_theoretic_local achieved 97.15% accuracy on MNIST, softmax_energy_margin_local reached 82.84% on Fash- ionMNIST, and triplet_margin_local attained 37.69% on STL-10. Furthermore, we observed substantial variability in computational efficiency, highlighting a critical trade-off between predictive performance and environmental cost. These findings demonstrate that the goodness function is a pivotal hyperparameter in FF design. We release our code on Github for reference and reproducibility.",
    "keywords": [
      "Forward-Forward Algorithm",
      "Biologically Plausible Learning",
      "Goodness Functions",
      "Green AI"
    ]
  },
  {
    "article_id": "2511.18578v1_ReVisiting_Time_Series_Foundation_Models_in_Finance",
    "title": "2511.18578v1 ReVisiting Time Series Foundation Models in Finance",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.18578v1_ReVisiting_Time_Series_Foundation_Models_in_Finance.pdf",
    "url": "http://arxiv.org/abs/2511.18578v1_ReVisiting_Time_Series_Foundation_Models_in_Finance",
    "pdf_url": "https://arxiv.org/pdf/2511.18578v1_ReVisiting_Time_Series_Foundation_Models_in_Finance",
    "file_size_mb": 3.5,
    "abstract": "Financial time series forecasting is vital for trading, portfolio optimization, and risk man- agement but is difficult due to noisy, non-stationary, and heterogeneous data. Recent time series foundation models (TSFMs), inspired by large language models, offer a new ap- proach for learning generalizable temporal representations. This paper provides the first comprehensive empirical evaluation of TSFMs in global financial markets using large-scale daily excess-return data. We assess zero-shot inference, fine-tuning, and pre-training from scratch against strong benchmarks. Off-the-shelf TSFMs perform poorly, while models pre-trained on financial data deliver substantial forecasting and economic gains. Larger datasets, synthetic data augmentation, and hyperparameter tuning further improve results.",
    "keywords": [
      "Time Series Foundation Models",
      "Transformer Models",
      "Asset Return Predictability",
      "Cross-"
    ]
  },
  {
    "article_id": "2511.19150v1_Feature_Ranking_in_Credit-Risk_with_Qudit-Based_Networks",
    "title": "2511.19150v1 Feature Ranking in Credit-Risk with Qudit-Based Networks",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.19150v1_Feature_Ranking_in_Credit-Risk_with_Qudit-Based_Networks.pdf",
    "url": "http://arxiv.org/abs/2511.19150v1_Feature_Ranking_in_Credit-Risk_with_Qudit-Based_Networks",
    "pdf_url": "https://arxiv.org/pdf/2511.19150v1_Feature_Ranking_in_Credit-Risk_with_Qudit-Based_Networks",
    "file_size_mb": 1.19,
    "abstract": null,
    "keywords": []
  },
  {
    "article_id": "2511.19701v1_Optimal_dividend_and_capital_injection_under_self-exciting_claims",
    "title": "2511.19701v1 Optimal dividend and capital injection under self-exciting claims",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.19701v1_Optimal_dividend_and_capital_injection_under_self-exciting_claims.pdf",
    "url": "http://arxiv.org/abs/2511.19701v1_Optimal_dividend_and_capital_injection_under_self-exciting_claims",
    "pdf_url": "https://arxiv.org/pdf/2511.19701v1_Optimal_dividend_and_capital_injection_under_self-exciting_claims",
    "file_size_mb": 2.96,
    "abstract": "In this paper, we study an optimal dividend and capital-injection problem in a Cramér-Lundberg model where claim arrivals follow a Hawkes process, capturing clustering effects often observed in insurance portfolios. We establish key analytical properties of the value function and characterise the optimal capital-injection strategy through an explicit threshold. We also show that the value function is the unique viscosity solution of the associated HJB variational inequality. For numerical purposes, we first compute a benchmark solution via a monotone finite-difference scheme with Howard’s policy iteration. We then develop a reinforcement learning approach based on policy-gradient and actor-critic methods. The learned strategies closely match the PDE benchmark and remain stable across initial conditions. The results highlight the relevance of policy-gradient techniques for dividend optimisation under self-exciting claim dynamics and point toward scalable methods for higher-dimensional extensions.",
    "keywords": [
      "Optimal dividend",
      "Singular stochastic control",
      "Hawkes processes",
      "Viscosity solutions",
      "Reinforce-"
    ]
  },
  {
    "article_id": "2511.19761v1_Order_Selection_in_Vector_Autoregression_by_Mean_Square_Information_Criterion",
    "title": "2511.19761v1 Order Selection in Vector Autoregression by Mean Square Information Criterion",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.19761v1_Order_Selection_in_Vector_Autoregression_by_Mean_Square_Information_Criterion.pdf",
    "url": "http://arxiv.org/abs/2511.19761v1_Order_Selection_in_Vector_Autoregression_by_Mean_Square_Information_Criterion",
    "pdf_url": "https://arxiv.org/pdf/2511.19761v1_Order_Selection_in_Vector_Autoregression_by_Mean_Square_Information_Criterion",
    "file_size_mb": 0.58,
    "abstract": "Vector autoregressive (VAR) processes are ubiquitously used in economics, finance, and biology. Order selection is an essential step in fitting VAR models. While many order selection methods exist, all come with weaknesses. Order selection by minimizing AIC is a popular approach but is known to consistently overestimate the true order for processes of small dimension. On the other hand, methods based on BIC or the Hannan-Quinn (HQ) criteria are shown to require large sample sizes in order to accurately estimate the order for larger-dimensional processes. We propose the mean square information criterion (MIC) based on the observation that the expected squared error loss is flat once the fitted order reaches or exceeds the true order. MIC is shown to consistently estimate the order of the process under relatively mild conditions. Our simulation results show that MIC offers better performance relative to AIC, BIC, and HQ under misspecification. This advantage is corroborated when forecasting COVID-19 outcomes in New York City. Order selection by MIC is implemented in the micvar R package available on CRAN.",
    "keywords": []
  },
  {
    "article_id": "2511.19849v1_Reinforcement_Learning_with_ω-Regular_Objectives_and_Constraints",
    "title": "2511.19849v1 Reinforcement Learning with ω-Regular Objectives and Constraints",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.19849v1_Reinforcement_Learning_with_ω-Regular_Objectives_and_Constraints.pdf",
    "url": "http://arxiv.org/abs/2511.19849v1_Reinforcement_Learning_with_ω-Regular_Objectives_and_Constraints",
    "pdf_url": "https://arxiv.org/pdf/2511.19849v1_Reinforcement_Learning_with_ω-Regular_Objectives_and_Constraints",
    "file_size_mb": 0.21,
    "abstract": "Reinforcement learning (RL) commonly relies on scalar rewards with lim- ited ability to express temporal, conditional, or safety-critical goals, and can lead to reward hacking. Temporal logic expressible via the more gen- eral class of ω-regular objectives addresses this by precisely specifying rich behavioural properties. Even still, measuring performance by a single scalar (be it reward or satisfaction probability) masks safety–performance trade-offs that arise in settings with a tolerable level of risk. We address both limitations simulatenously by combining ω-regular ob- jectives with explicit constraints, allowing safety requirements and opti- misation targets to be treated separately. We develop a model-based RL algorithm based on linear programming, which in the limit produces a pol- icy maximizing the probability of satisfying an ω-regular objective while also adhering to ω-regular constraints within specified thresholds. Fur- thermore, we establish a translation to constrained limit-average problems with optimality-preserving guarantees.",
    "keywords": []
  },
  {
    "article_id": "2511.19935v1_EfficientXpert_Efficient_Domain_Adaptation_for_Large_Language_Models_via_Propagation-Aware_Pruning",
    "title": "2511.19935v1 EfficientXpert Efficient Domain Adaptation for Large Language Models via Propagation-Aware Pruning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.19935v1_EfficientXpert_Efficient_Domain_Adaptation_for_Large_Language_Models_via_Propagation-Aware_Pruning.pdf",
    "url": "http://arxiv.org/abs/2511.19935v1_EfficientXpert_Efficient_Domain_Adaptation_for_Large_Language_Models_via_Propagation-Aware_Pruning",
    "pdf_url": "https://arxiv.org/pdf/2511.19935v1_EfficientXpert_Efficient_Domain_Adaptation_for_Large_Language_Models_via_Propagation-Aware_Pruning",
    "file_size_mb": 0.71,
    "abstract": "The rapid advancement of large language models (LLMs) has created an increasing demand for domain-specialized vari- ants in areas such as law, healthcare, and finance. However, their large size remains a barrier to deployment in resource- constrained environments, and existing compression meth- ods either fail to generalize across domains or introduce high overhead. In this work, we propose EfficientXpert, a lightweight domain pruning framework that combines a propagation-aware pruning criterion (Foresight Mask) with an efficient adapter update algorithm (Partial Brain Surgeon). Embedded within the LoRA fine-tuning process, EfficientX- pert enables a one-step transformation of general pretrained models into sparse, domain-adapted experts. It achieves up to 98% of original dense model performance at 40% spar- sity on tasks in the health and legal domains, outperforming state-of-the-art approaches. Further analysis reveals signifi- cant domain-dependent structural shifts that undermine gen- eral pruning masks, highlighting the necessity of adaptive, domain-aware pruning strategies tailored to each domain’s unique model changes.",
    "keywords": []
  },
  {
    "article_id": "2511.20678v1_Cryptocurrency_Portfolio_Management_with_Reinforcement_Learning_Soft_Actor--Critic_and_Deep_Determin",
    "title": "2511.20678v1 Cryptocurrency Portfolio Management with Reinforcement Learning Soft Actor--Critic and Deep Determin",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.20678v1_Cryptocurrency_Portfolio_Management_with_Reinforcement_Learning_Soft_Actor--Critic_and_Deep_Determin.pdf",
    "url": "http://arxiv.org/abs/2511.20678v1_Cryptocurrency_Portfolio_Management_with_Reinforcement_Learning_Soft_Actor--Critic_and_Deep_Determin",
    "pdf_url": "https://arxiv.org/pdf/2511.20678v1_Cryptocurrency_Portfolio_Management_with_Reinforcement_Learning_Soft_Actor--Critic_and_Deep_Determin",
    "file_size_mb": 4.78,
    "abstract": ". This study proposes a deep reinforcement learning (DRL) frame- work for dynamic cryptocurrency portfolio management across four major as- sets: Bitcoin, Ethereum, Litecoin, and Dogecoin. The trading environment is formulated as a discrete-time stochastic system in which an intelligent agent optimizes portfolio allocation through interaction with market data. Oper- ating under partial observability, the agent utilizes daily open, high, low, and close prices together with trading volume to determine optimal asset weights for the next trading period. The framework integrates actor–critic algorithms—specifically Deep Deterministic Policy Gradient and Soft Actor– Critic—enhanced with Long Short-Term Memory networks to capture tempo- ral dependencies within the policy and value functions. For benchmarking, the classical Markowitz mean–variance model is employed. Empirical evaluations demonstrate that the proposed DRL-based agents learn adaptive strategies that consistently outperform the Markowitz benchmark in both absolute re- turn and risk-adjusted performance. These findings highlight the potential of reinforcement learning as a robust methodology for managing cryptocurrency portfolios in volatile and nonstationary markets.",
    "keywords": [
      "and phrases"
    ]
  },
  {
    "article_id": "2511.20702v1_Post-Pruning_Accuracy_Recovery_via_Data-Free_Knowledge_Distillation",
    "title": "2511.20702v1 Post-Pruning Accuracy Recovery via Data-Free Knowledge Distillation",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.20702v1_Post-Pruning_Accuracy_Recovery_via_Data-Free_Knowledge_Distillation.pdf",
    "url": "http://arxiv.org/abs/2511.20702v1_Post-Pruning_Accuracy_Recovery_via_Data-Free_Knowledge_Distillation",
    "pdf_url": "https://arxiv.org/pdf/2511.20702v1_Post-Pruning_Accuracy_Recovery_via_Data-Free_Knowledge_Distillation",
    "file_size_mb": 6.7,
    "abstract": "—Model pruning is a widely adopted technique to re- duce the computational complexity and memory footprint of Deep Neural Networks (DNNs). However, global unstructured pruning often leads to significant degradation in accuracy, typically ne- cessitating fine-tuning on the original training dataset to recover performance. In privacy-sensitive domains such as healthcare or finance, access to the original training data is often restricted post-deployment due to regulations (e.g., GDPR, HIPAA). This paper proposes a Data-Free Knowledge Distillation framework to bridge the gap between model compression and data privacy. We utilize DeepInversion to synthesize privacy-preserving “dream” images from the pre-trained teacher model by inverting Batch Normalization (BN) statistics. These synthetic images serve as a transfer set to distill knowledge from the original teacher to the pruned student network. Experimental results on CIFAR-10 across various architectures (ResNet, MobileNet, VGG) demon- strate that our method significantly recovers accuracy lost during pruning without accessing a single real data point. The code is available at: https://github.com/chinoscode1708/DF- Prune-Recover",
    "keywords": [
      "Model Compression",
      "Neural Network Pruning"
    ]
  },
  {
    "article_id": "2511.20837v1_Constrained_deep_learning_for_pricing_and_hedging_european_options_in_incomplete_markets",
    "title": "2511.20837v1 Constrained deep learning for pricing and hedging european options in incomplete markets",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.20837v1_Constrained_deep_learning_for_pricing_and_hedging_european_options_in_incomplete_markets.pdf",
    "url": "http://arxiv.org/abs/2511.20837v1_Constrained_deep_learning_for_pricing_and_hedging_european_options_in_incomplete_markets",
    "pdf_url": "https://arxiv.org/pdf/2511.20837v1_Constrained_deep_learning_for_pricing_and_hedging_european_options_in_incomplete_markets",
    "file_size_mb": 1.3,
    "abstract": "In incomplete financial markets, pricing and hedging European options lack a unique no-arbitrage solution due to unhedgeable risks. This paper introduces a constrained deep learning approach to determine option prices and hedging strategies that minimize the Profit and Loss (P&L) distribution around zero. We employ a single neural network to represent the option price function, with its gradient serving as the hedging strategy, optimized via a loss function en- forcing the self-financing portfolio condition. A key challenge arises from the non-smooth nature of option payoffs (e.g., vanilla calls are non-differentiable at- the-money, while digital options are discontinuous), which conflicts with the in- herent smoothness of standard neural networks. To address this, we compare unconstrained networks against constrained architectures that explicitly embed the terminal payoff condition, drawing inspiration from PDE-solving techniques. Our framework assumes two tradable assets: the underlying and a liquid call op- tion capturing volatility dynamics. Numerical experiments evaluate the method on simple options with varying non-smoothness, the exotic Equinox option, and scenarios with market jumps for robustness. Results demonstrate superior P&L distributions, highlighting the efficacy of constrained networks in handling real- istic payoffs. This work advances machine learning applications in quantitative finance by integrating boundary constraints, offering a practical tool for pricing and hedging in incomplete markets.",
    "keywords": []
  },
  {
    "article_id": "2511.21050v1_Breaking_the_Safety-Capability_Tradeoff_Reinforcement_Learning_with_Verifiable_Rewards_Maintains_Saf",
    "title": "2511.21050v1 Breaking the Safety-Capability Tradeoff Reinforcement Learning with Verifiable Rewards Maintains Saf",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.21050v1_Breaking_the_Safety-Capability_Tradeoff_Reinforcement_Learning_with_Verifiable_Rewards_Maintains_Saf.pdf",
    "url": "http://arxiv.org/abs/2511.21050v1_Breaking_the_Safety-Capability_Tradeoff_Reinforcement_Learning_with_Verifiable_Rewards_Maintains_Saf",
    "pdf_url": "https://arxiv.org/pdf/2511.21050v1_Breaking_the_Safety-Capability_Tradeoff_Reinforcement_Learning_with_Verifiable_Rewards_Maintains_Saf",
    "file_size_mb": 1.22,
    "abstract": "Fine-tuning large language models (LLMs) for downstream tasks typically exhibit a fundamental safety-capability trade- off, where improving task performance degrades safety alignment even on benign datasets. This degradation per- sists across standard approaches including supervised fine- tuning (SFT) and reinforcement learning from human feed- back (RLHF). While reinforcement learning with verifiable rewards (RLVR) has emerged as a promising alternative that optimizes models on objectively measurable tasks, its safety implications remain unexplored. We present the first com- prehensive theoretical and empirical analysis of safety prop- erties in RLVR. Theoretically, we derive upper bounds on safety drift under KL-constrained optimization and prove conditions under which safety degradation is eliminated. Empirically, we conduct extensive experiments across five adversarial safety benchmarks, demonstrating that RLVR can simultaneously enhance reasoning capabilities while maintaining or improving safety guardrails. Our compre- hensive ablation studies examine the effects of optimiza- tion algorithms, model scale, and task domains. Our findings challenge the prevailing assumption of an inevitable safety- capability trade-off, and establish that a specific training methodology can achieve both objectives simultaneously, providing insights for the safe deployment of reasoning- capable LLMs.",
    "keywords": []
  },
  {
    "article_id": "2511.21101v2_Mortgage_Language_Model_Domain-Adaptive_Pretraining_with_Residual_Instruction_Alignment_Tuning_and_T",
    "title": "2511.21101v2 Mortgage Language Model Domain-Adaptive Pretraining with Residual Instruction Alignment Tuning and T",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.21101v2_Mortgage_Language_Model_Domain-Adaptive_Pretraining_with_Residual_Instruction_Alignment_Tuning_and_T.pdf",
    "url": "http://arxiv.org/abs/2511.21101v2_Mortgage_Language_Model_Domain-Adaptive_Pretraining_with_Residual_Instruction_Alignment_Tuning_and_T",
    "pdf_url": "https://arxiv.org/pdf/2511.21101v2_Mortgage_Language_Model_Domain-Adaptive_Pretraining_with_Residual_Instruction_Alignment_Tuning_and_T",
    "file_size_mb": 0.75,
    "abstract": "Large Language Models (LLMs) demonstrate exceptional capabilities across general domains, yet their application to specialized sectors such as mortgage finance requires domain-specific knowledge augmentation while preserving instruction-following fidelity. We present Mortgage Language Model, a novel domain-specific large language model that addresses this dual challenge. It is developed using a dual-track specialization framework from a single base model (Meta-LLaMA-3.1-8B). We opted for this dual-expert approach as a single multi-task model suffers from performance trade-offs, where optimizing for structured tasks (like classification via SFT) degrades conversational fidelity (achieved via DPO). Our dual-track method solves this by creating two specialists, allowing each to be optimally trained for its distinct capability. Our approach applies the instruction residual technique to restore instruction-following capabilities post-domain adaptation without supervised fine-tuning. We contribute: (1) application of this residual technique to the highly specialized mortgage finance domain; (2) a dual-expert architecture combining a conversational Q&A model and a structured task model for classification and summarization; and (3) an intelligent task routing mechanism using few-shot classification performed by one of the expert models itself. We validate our approach on domain-specific benchmarks, where our final model (MLM v2) significantly outperforms the base LLaMA 3.1 8B Instruct model, achieving an LLM-as-a-Judge summarization score of 4.58 (vs. 3.99), a Q&A score of 4.09 (vs. 4.0), and a classification score of 2.6 (vs. 1.2). On semantic similarity, our model achieved a BERTScore of 0.77 for summarization (vs. 0.74), 0.68 for Q&A (vs. 0.58), and 0.75 for classification (vs. 0.73), substantially outperforming baseline approaches. Our framework demonstrates that specialized domain knowledge and general instruction-following abilities can be effectively balanced through the instruction residual methodology in highly technical domains.",
    "keywords": []
  },
  {
    "article_id": "2511.21465v1_Ensemble_Performance_Through_the_Lens_of_Linear_Independence_of_Classifier_Votes_in_Data_Streams",
    "title": "2511.21465v1 Ensemble Performance Through the Lens of Linear Independence of Classifier Votes in Data Streams",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.21465v1_Ensemble_Performance_Through_the_Lens_of_Linear_Independence_of_Classifier_Votes_in_Data_Streams.pdf",
    "url": "http://arxiv.org/abs/2511.21465v1_Ensemble_Performance_Through_the_Lens_of_Linear_Independence_of_Classifier_Votes_in_Data_Streams",
    "pdf_url": "https://arxiv.org/pdf/2511.21465v1_Ensemble_Performance_Through_the_Lens_of_Linear_Independence_of_Classifier_Votes_in_Data_Streams",
    "file_size_mb": 7.58,
    "abstract": "—Ensemble learning improves classification perfor- mance by combining multiple base classifiers. While increasing the number of classifiers generally enhances accuracy, excessively large ensembles can lead to computational inefficiency and diminishing returns. This paper investigates the relationship between ensemble size and performance through the lens of linear independence among classifier votes in data streams. We propose that ensembles composed of linearly independent classifiers maximize representational capacity, particularly under a geometric model. We then generalize the importance of linear independence to the weighted majority voting problem. By modeling the probability of achieving linear independence among classifier outputs, we derive a theoretical framework that explains the trade-off between ensemble size and accuracy. Our analysis leads to a theoretical estimate of the ensemble size required to achieve a user-specified probability of linear independence. We validate our theory through experiments on both real-world and synthetic datasets using two ensemble methods, OzaBagging and GOOWE. Our results confirm that this theoretical estimate effectively identifies the point of performance saturation for robust ensembles like OzaBagging. Conversely, for complex weighting schemes like GOOWE, our framework reveals that high theoretical diversity can trigger algorithmic instability. Our implementation is publicly available to support reproducibility and future research1.",
    "keywords": [
      "Data stream classification",
      "ensemble size",
      "en-"
    ]
  },
  {
    "article_id": "2511.21600v1_TAB-DRW_A_DFT-based_Robust_Watermark_for_Generative_Tabular_Data",
    "title": "2511.21600v1 TAB-DRW A DFT-based Robust Watermark for Generative Tabular Data",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.21600v1_TAB-DRW_A_DFT-based_Robust_Watermark_for_Generative_Tabular_Data.pdf",
    "url": "http://arxiv.org/abs/2511.21600v1_TAB-DRW_A_DFT-based_Robust_Watermark_for_Generative_Tabular_Data",
    "pdf_url": "https://arxiv.org/pdf/2511.21600v1_TAB-DRW_A_DFT-based_Robust_Watermark_for_Generative_Tabular_Data",
    "file_size_mb": 1.62,
    "abstract": "The rise of generative AI has enabled the production of high-fidelity synthetic tabular data across fields such as healthcare, finance, and public policy, raising growing concerns about data provenance and misuse. Watermarking offers a promising solution to address these concerns by ensuring the traceability of synthetic data, but existing methods face many limitations: they are computationally expensive due to reliance on large diffusion models, struggle with mixed discrete-continuous data, or lack robustness to post-modifications. To address them, we propose TAB-DRW, an efficient and robust post-editing watermarking scheme for generative tabular data. TAB-DRW embeds watermark signals in the frequency domain: it normalizes heterogeneous features via the Yeo-Johnson transformation and standardization, applies the discrete Fourier transform (DFT), and adjusts the imaginary parts of adaptively selected entries according to precomputed pseudorandom bits. To further enhance robustness and efficiency, we introduce a novel rank-based pseudorandom bit generation method that enables row-wise retrieval without incurring storage overhead. Experiments on five benchmark tabular datasets show that TAB-DRW achieves strong detectability and robustness against common post-processing attacks, while preserving high data fidelity and fully supporting mixed-type features.",
    "keywords": []
  },
  {
    "article_id": "2511.21631v2_Qwen3-VL_Technical_Report",
    "title": "2511.21631v2 Qwen3-VL Technical Report",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.21631v2_Qwen3-VL_Technical_Report.pdf",
    "url": "http://arxiv.org/abs/2511.21631v2_Qwen3-VL_Technical_Report",
    "pdf_url": "https://arxiv.org/pdf/2511.21631v2_Qwen3-VL_Technical_Report",
    "file_size_mb": 4.18,
    "abstract": "We introduce Qwen3-VL, the most capable vision–language model in the Qwen series to date, achieving superior performance across a broad range of multimodal benchmarks. It natively supports interleaved contexts of up to 256K tokens, seamlessly integrat- ing text, images, and video. The model family includes both dense (2B/4B/8B/32B) and mixture-of-experts (30B-A3B/235B-A22B) variants to accommodate diverse la- tency–quality trade-offs. Qwen3-VL delivers three core pillars: (i) markedly stronger pure-text understanding, surpassing comparable text-only backbones in several cases; (ii) robust long-context comprehension with a native 256K-token window for both text and interleaved multimodal inputs, enabling faithful retention, retrieval, and cross- referencing across long documents and videos; and (iii) advanced multimodal reasoning across single-image, multi-image, and video tasks, demonstrating leading performance on comprehensive evaluations such as MMMU and visual-math benchmarks (e.g., Math- Vista and MathVision). Architecturally, we introduce three key upgrades: (i) an enhanced interleaved-MRoPE for stronger spatial–temporal modeling across images and video; (ii) DeepStack integration, which effectively leverages multi-level ViT features to tighten vision–language alignment; and (iii) text-based time alignment for video, evolving from T-RoPE to explicit textual timestamp alignment for more precise temporal grounding. To balance text-only and multimodal learning objectives, we apply square-root reweight- ing, which boosts multimodal performance without compromising text capabilities. We extend pretraining to a context length of 256K tokens and bifurcate post-training into non-thinking and thinking variants to address distinct application requirements. Furthermore, we allocate additional compute resources to the post-training phase to further enhance model performance. Under comparable token budgets and latency constraints, Qwen3-VL achieves superior performance in both dense and Mixture-of- Experts (MoE) architectures. We envision Qwen3-VL serving as a foundational engine for image-grounded reasoning, agentic decision-making, and multimodal code intelligence in real-world workflows. 1 arXiv:2511.21631v2 [cs.CV] 27 Nov 2025",
    "keywords": []
  },
  {
    "article_id": "2511.22153v2_Simplex-Optimized_Hybrid_Ensemble_for_Large_Language_Model_Text_Detection_Under_Generative_Distribut",
    "title": "2511.22153v2 Simplex-Optimized Hybrid Ensemble for Large Language Model Text Detection Under Generative Distribut",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.22153v2_Simplex-Optimized_Hybrid_Ensemble_for_Large_Language_Model_Text_Detection_Under_Generative_Distribut.pdf",
    "url": "http://arxiv.org/abs/2511.22153v2_Simplex-Optimized_Hybrid_Ensemble_for_Large_Language_Model_Text_Detection_Under_Generative_Distribut",
    "pdf_url": "https://arxiv.org/pdf/2511.22153v2_Simplex-Optimized_Hybrid_Ensemble_for_Large_Language_Model_Text_Detection_Under_Generative_Distribut",
    "file_size_mb": 1.58,
    "abstract": "—The widespread adoption of large language models (LLMs) has made it difficult to distinguish human writing from machine-produced text in many real applications. Detectors that were effective for one generation of models tend to degrade when newer models or modified decoding strategies are in- troduced. In this work, we study this lack of stability and propose a hybrid ensemble that is explicitly designed to cope with changing generator distributions. The ensemble combines three complementary components: a RoBERTa-based classifier fine-tuned for supervised detection, a curvature-inspired score based on perturbing the input and measuring changes in model likelihood, and a compact stylometric model built on hand- crafted linguistic features. The outputs of these components are fused on the probability simplex, and the weights are chosen via validation-based search. We frame this approach in terms of variance reduction and risk under mixtures of generators, and show that the simplex constraint provides a simple way to trade off the strengths and weaknesses of each branch. Experiments on a 30 000-document corpus drawn from several LLM families including models unseen during training and paraphrased attack variants show that the proposed method achieves 94.2% accuracy and an AUC of 0.978. The ensemble also lowers false positives on scientific articles compared to strong baselines, which is critical in educational and research settings where wrongly flagging human work is costly.",
    "keywords": [
      "Generative AI",
      "distribution shift",
      "ensemble learning"
    ]
  },
  {
    "article_id": "2511.22314v1_DeXposure_A_Dataset_and_Benchmarks_for_Inter-protocol_Credit_Exposure_in_Decentralized_Financial_Net",
    "title": "2511.22314v1 DeXposure A Dataset and Benchmarks for Inter-protocol Credit Exposure in Decentralized Financial Net",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.22314v1_DeXposure_A_Dataset_and_Benchmarks_for_Inter-protocol_Credit_Exposure_in_Decentralized_Financial_Net.pdf",
    "url": "http://arxiv.org/abs/2511.22314v1_DeXposure_A_Dataset_and_Benchmarks_for_Inter-protocol_Credit_Exposure_in_Decentralized_Financial_Net",
    "pdf_url": "https://arxiv.org/pdf/2511.22314v1_DeXposure_A_Dataset_and_Benchmarks_for_Inter-protocol_Credit_Exposure_in_Decentralized_Financial_Net",
    "file_size_mb": 8.88,
    "abstract": "We curate the DeXposure dataset, the first large-scale dataset for inter-protocol credit exposure in decentralized financial networks, covering global markets of 43.7 million entries across 4.3 thousand protocols, 602 blockchains, and 24.3 thousand tokens, from 2020 to 2025. A new measure, value-linked credit exposure between protocols, is defined as the inferred financial dependency relationships derived from changes in Total Value Locked (TVL). We develop a token-to-protocol model using DefiLlama metadata to infer inter- protocol credit exposure from the token’s stock dynamics, as reported by the protocols. Based on the curated dataset, we develop three benchmarks for machine learning re- search with financial applications: (1) graph clustering for global network measurement, tracking the structural evolution of credit exposure networks, (2) vector autoregression for sector-level credit exposure dynamics during major shocks (Terra and FTX), and (3) tem- poral graph neural networks for dynamic link prediction on temporal graphs. From the analysis, we observe (1) a rapid growth of network volume, (2) a trend of concentration to key protocols, (3) a decline of network density (the ratio of actual connections to possible connections), and (4) distinct shock propagation across sectors, such as lending platforms, trading exchanges, and asset management protocols. The DeXposure dataset and code have been released publicly. We envision they will help with research and practice in machine learning as well as financial risk monitoring, policy analysis, DeFi market modeling, amongst others. The dataset also contributes to machine learning research by offering benchmarks for graph clustering, vector autoregres- sion, and temporal graph analysis. Data and code: https://github.com/dthinkr/DeXposure Visualisation: https://ccaf.io/defi/ecosystem-map/visualisation/graph",
    "keywords": [
      "Decentralized Finance",
      "Credit Exposure",
      "Network Analysis",
      "Total Value"
    ]
  },
  {
    "article_id": "2511.22521v1_DocVAL_Validated_Chain-of-Thought_Distillation_for_Grounded_Document_VQA",
    "title": "2511.22521v1 DocVAL Validated Chain-of-Thought Distillation for Grounded Document VQA",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.22521v1_DocVAL_Validated_Chain-of-Thought_Distillation_for_Grounded_Document_VQA.pdf",
    "url": "http://arxiv.org/abs/2511.22521v1_DocVAL_Validated_Chain-of-Thought_Distillation_for_Grounded_Document_VQA",
    "pdf_url": "https://arxiv.org/pdf/2511.22521v1_DocVAL_Validated_Chain-of-Thought_Distillation_for_Grounded_Document_VQA",
    "file_size_mb": 2.63,
    "abstract": "Document visual question answering (DocVQA) requires models to jointly reason over textual content and spatial lay- out, yet current systems exhibit a sharp accuracy–efficiency trade-off: large teacher models achieve strong grounding but are too expensive for deployment, while compact students suffer substantial drops in localization performance. We propose DocVAL, a validated chain-of-thought distillation framework that transfers the spatial reasoning ability of a large teacher into a deployable student VLM through three key components: (1) teacher supervision with validation- time text detection to filter and denoise training signals, (2) a multi-module validator (VAL) that enforces answer correctness and geometric consistency while producing fine- grained, pixel-level error feedback, and (3) a two-stage stu- dent training scheme that first learns from validated CoT traces and then undergoes iterative refinement driven by VAL feedback. Our student (Gemma-3 12B) achieves 91.4% ANLS and 82.4% mAP on DocVQA as a pure VLM re- quiring no text detection or OCR at inference. Extensive ablations demonstrate that validated feedback contributes 6.3 mAP gain and iterative refinement accounts for 9.7 mAP improvement. We release 95k high-quality, validator- verified CoT traces to advance spatial reasoning research in document understanding. Dataset and implementation: https://github.com/ahmad-shirazi/DocVAL",
    "keywords": []
  },
  {
    "article_id": "2511.22594v1_HarmoCLIP_Harmonizing_Global_and_Regional_Representations_in_Contrastive_Vision-Language_Models",
    "title": "2511.22594v1 HarmoCLIP Harmonizing Global and Regional Representations in Contrastive Vision-Language Models",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.22594v1_HarmoCLIP_Harmonizing_Global_and_Regional_Representations_in_Contrastive_Vision-Language_Models.pdf",
    "url": "http://arxiv.org/abs/2511.22594v1_HarmoCLIP_Harmonizing_Global_and_Regional_Representations_in_Contrastive_Vision-Language_Models",
    "pdf_url": "https://arxiv.org/pdf/2511.22594v1_HarmoCLIP_Harmonizing_Global_and_Regional_Representations_in_Contrastive_Vision-Language_Models",
    "file_size_mb": 3.28,
    "abstract": "Contrastive Language-Image Pre-training (CLIP) has demonstrated remarkable generalization ability and strong performance across a wide range of vision-language tasks. However, due to the lack of region-level supervision, CLIP exhibits limited fine-grained semantic understanding. Al- though several methods attempt to mitigate this issue, they unintentionally disrupt the global alignment, resulting in a persistent trade-off where improving local perception si- multaneously degrades global coherence. In this paper, we propose HarmoCLIP, a novel framework designed to har- monize global and region representations within CLIP. We first identify that the absence of direct alignment between local textual and visual semantics is the fundamental cause of the trade-off. To address this, HarmoCLIP introduces an explicit fine-grained semantic supervision term that directly aligns textual segments with their corresponding visual re- gions, effectively bridging the image region space and the textual space. To further strengthen the representation ca- pability at the local level, our method introduces a novel Region–Language Alignment supervision strategy that pro- motes fine-grained semantic learning without compromis- ing global semantic consistency. Extensive experiments demonstrate that HarmoCLIP achieves state-of-the-art (im- provement up to 69.78%) performance on the global task of retrieval and yields a substantial 3.2% improvement in Top-1 accuracy on the region task of bounding-box classi- fication, consistently outperforming prior approaches while providing a balanced, efficient, and plug-and-play solution to the global–local trade-off in CLIP. Code is available at https://github.com/Erosist/HarmoCLIP.",
    "keywords": []
  },
  {
    "article_id": "2511.22651v1_Automated_Design_Optimization_via_Strategic_Search_with_Large_Language_Models",
    "title": "2511.22651v1 Automated Design Optimization via Strategic Search with Large Language Models",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.22651v1_Automated_Design_Optimization_via_Strategic_Search_with_Large_Language_Models.pdf",
    "url": "http://arxiv.org/abs/2511.22651v1_Automated_Design_Optimization_via_Strategic_Search_with_Large_Language_Models",
    "pdf_url": "https://arxiv.org/pdf/2511.22651v1_Automated_Design_Optimization_via_Strategic_Search_with_Large_Language_Models",
    "file_size_mb": 0.82,
    "abstract": "Traditional optimization methods excel in well-defined search spaces but struggle with design problems where transformations and design parameters are difficult to define. Large language models (LLMs) offer a promising alternative by dynamically interpreting design spaces and leveraging encoded domain knowledge. To this end, we introduce AUTO, an LLM agent framework that treats design optimization as a gradient-free search problem guided by strategic LLM reasoning. The framework employs two collaborative agents: a Strategist that selects between exploration and exploitation strategies, and an Implementor that executes detailed designs. Applied to GPU code optimization – a domain critical to fields from machine learning to scientific computing – AUTO generates solutions competitive with expert implementations for chemical kinetics integration and dense matrix multiplication. The framework achieves 50-70% search efficiency relative to Bayesian optimization methodologies. It completes optimizations in approximately 8 hours at an estimated cost of up to $159 per run, compared to an estimated cost of up to $480 with median-wage software developers. These findings open the door to automating design optimization in ill-defined search spaces with limited prior information.",
    "keywords": [
      "Large Language Models",
      "GPU Optimization",
      "Agent Systems",
      "Design Optimization",
      "High-Performance"
    ]
  },
  {
    "article_id": "2511.22853v1_TARFVAE_Efficient_One-Step_Generative_Time_Series_Forecasting_via_TARFLOW_based_VAE",
    "title": "2511.22853v1 TARFVAE Efficient One-Step Generative Time Series Forecasting via TARFLOW based VAE",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.22853v1_TARFVAE_Efficient_One-Step_Generative_Time_Series_Forecasting_via_TARFLOW_based_VAE.pdf",
    "url": "http://arxiv.org/abs/2511.22853v1_TARFVAE_Efficient_One-Step_Generative_Time_Series_Forecasting_via_TARFLOW_based_VAE",
    "pdf_url": "https://arxiv.org/pdf/2511.22853v1_TARFVAE_Efficient_One-Step_Generative_Time_Series_Forecasting_via_TARFLOW_based_VAE",
    "file_size_mb": 2.38,
    "abstract": "Time series data is ubiquitous, with forecasting applications spanning from fi- nance to healthcare. Beyond popular deterministic methods, generative models are gaining attention due to advancements in areas like image synthesis and video gener- ation, as well as their inherent ability to provide probabilistic predictions. However, existing generative approaches mostly involve recurrent generative operations or re- peated denoising steps, making the prediction laborious, particularly for long-term forecasting. Most of them only conduct experiments for relatively short-term fore- casting, with limited comparison to deterministic methods in long-term forecasting, leaving their practical advantages unclear. This paper presents TARFVAE, a novel generative framework that combines the Transformer-based autoregressive flow (TARFLOW) and variational autoencoder (VAE) for efficient one-step generative time series forecasting. Inspired by the rethinking that complex architectures for extracting time series representations might not be necessary, we add a flow module, TARFLOW, to VAE to promote spontaneous learning of latent variables that bene- fit predictions. TARFLOW enhances VAE’s posterior estimation by breaking the Gaussian assumption, thereby enabling a more informative latent space. TARFVAE uses only the forward process of TARFLOW, avoiding autoregressive inverse oper- ations and thus ensuring fast generation. During generation, it samples from the prior latent space and directly generates full-horizon forecasts via the VAE decoder. With simple MLP modules, TARFVAE achieves superior performance over state- of-the-art deterministic and generative models across different forecast horizons on benchmark datasets while maintaining efficient prediction speed, demonstrating its effectiveness as an efficient and powerful solution for generative time series forecasting. Our code is available at https://github.com/Gavine77/TARFVAE. ∗Corresponding author. 39th Conference on Neural Information Processing Systems (NeurIPS 2025). arXiv:2511.22853v1 [cs.LG] 28 Nov 2025",
    "keywords": []
  },
  {
    "article_id": "2511.23036v1_Delta-XAI_A_Unified_Framework_for_Explaining_Prediction_Changes_in_Online_Time_Series_Monitoring",
    "title": "2511.23036v1 Delta-XAI A Unified Framework for Explaining Prediction Changes in Online Time Series Monitoring",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.23036v1_Delta-XAI_A_Unified_Framework_for_Explaining_Prediction_Changes_in_Online_Time_Series_Monitoring.pdf",
    "url": "http://arxiv.org/abs/2511.23036v1_Delta-XAI_A_Unified_Framework_for_Explaining_Prediction_Changes_in_Online_Time_Series_Monitoring",
    "pdf_url": "https://arxiv.org/pdf/2511.23036v1_Delta-XAI_A_Unified_Framework_for_Explaining_Prediction_Changes_in_Online_Time_Series_Monitoring",
    "file_size_mb": 31.21,
    "abstract": "Explaining online time series monitoring models is crucial across sensitive do- mains such as healthcare and finance, where temporal and contextual predic- tion dynamics underpin critical decisions. While recent XAI methods have im- proved the explainability of time series models, they mostly analyze each time step independently, overlooking temporal dependencies. This results in further challenges: explaining prediction changes is non-trivial, methods fail to leverage online dynamics, and evaluation remains difficult. To address these challenges, we propose Delta-XAI, which adapts 14 existing XAI methods through a wrap- per function and introduces a principled evaluation suite for the online setting, assessing diverse aspects, such as faithfulness, sufficiency, and coherence. Ex- periments reveal that classical gradient-based methods, such as Integrated Gradi- ents (IG), can outperform recent approaches when adapted for temporal analysis. Building on this, we propose Shifted Window Integrated Gradients (SWING), which incorporates past observations in the integration path to systematically capture temporal dependencies and mitigate out-of-distribution effects. Exten- sive experiments consistently demonstrate the effectiveness of SWING across diverse settings with respect to diverse metrics. Our code is publicly available at https://anonymous.4open.science/r/Delta-XAI.",
    "keywords": []
  },
  {
    "article_id": "2511.23122v1_Evolutionary_Discovery_of_Heuristic_Policies_for_Traffic_Signal_Control",
    "title": "2511.23122v1 Evolutionary Discovery of Heuristic Policies for Traffic Signal Control",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.23122v1_Evolutionary_Discovery_of_Heuristic_Policies_for_Traffic_Signal_Control.pdf",
    "url": "http://arxiv.org/abs/2511.23122v1_Evolutionary_Discovery_of_Heuristic_Policies_for_Traffic_Signal_Control",
    "pdf_url": "https://arxiv.org/pdf/2511.23122v1_Evolutionary_Discovery_of_Heuristic_Policies_for_Traffic_Signal_Control",
    "file_size_mb": 2.65,
    "abstract": ". Traffic Signal Control (TSC) involves a challenging trade- off: classic heuristics are efficient but oversimplified, while Deep Rein- forcement Learning (DRL) achieves high performance yet suffers from poor generalization and opaque policies. Online Large Language Mod- els (LLMs) provide general reasoning but incur high latency and lack environment-specific optimization. To address these issues, we propose Temporal Policy Evolution for Traffic (TPET), which uses LLMs as an evolution engine to derive specialized heuristic policies. The framework introduces two key modules: (1) Structured State Abstraction (SSA), converting high-dimensional traffic data into temporal-logical facts for reasoning; and (2) Credit Assignment Feedback (CAF), tracing flawed micro-decisions to poor macro-outcomes for targeted critique. Operating entirely at the prompt level without training, TPET yields lightweight, robust policies optimized for specific traffic environments, outperforming both heuristics and online LLM actors.",
    "keywords": [
      "Traffic signal control",
      "Sequential decision making",
      "LLM-"
    ]
  },
  {
    "article_id": "2511.23148v1_Peer-to-Peer_Energy_Trading_in_Dairy_Farms_using_Multi-Agent_Reinforcement_Learning",
    "title": "2511.23148v1 Peer-to-Peer Energy Trading in Dairy Farms using Multi-Agent Reinforcement Learning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2511.23148v1_Peer-to-Peer_Energy_Trading_in_Dairy_Farms_using_Multi-Agent_Reinforcement_Learning.pdf",
    "url": "http://arxiv.org/abs/2511.23148v1_Peer-to-Peer_Energy_Trading_in_Dairy_Farms_using_Multi-Agent_Reinforcement_Learning",
    "pdf_url": "https://arxiv.org/pdf/2511.23148v1_Peer-to-Peer_Energy_Trading_in_Dairy_Farms_using_Multi-Agent_Reinforcement_Learning",
    "file_size_mb": 8.62,
    "abstract": "The integration of renewable energy resources in rural areas, such as dairy farming com- munities, enables decentralized energy management through Peer-to-Peer (P2P) energy trad- ing. This research highlights the role of P2P trading in efficient energy distribution and its synergy with advanced optimization techniques. While traditional rule-based methods per- form well under stable conditions, they struggle in dynamic environments. To address this, Multi-Agent Reinforcement Learning (MARL), specifically Proximal Policy Optimization (PPO) and Deep Q-Networks (DQN), is combined with community/distributed P2P trad- ing mechanisms. By incorporating auction-based market clearing, a price advisor agent, and load and battery management, the approach achieves significant improvements. Results show that, compared to baseline models, DQN reduces electricity costs by 14.2% in Ireland and 5.16% in Finland, while increasing electricity revenue by 7.24% and 12.73%, respectively. PPO achieves the lowest peak hour demand, reducing it by 55.5% in Ireland, while DQN reduces peak hour demand by 50.0% in Ireland and 27.02% in Finland. These improve- ments are attributed to both MARL algorithms and P2P energy trading, which together results in electricity cost and peak hour demand reduction, and increase electricity selling revenue. This study highlights the complementary strengths of DQN, PPO, and P2P trading in achieving efficient, adaptable, and sustainable energy management in rural communities.",
    "keywords": [
      "Dairy Farming",
      "Energy Auction",
      "Multi-agent Reinforcement Learning"
    ]
  },
  {
    "article_id": "2512.00275v1_HIMOSA_Efficient_Remote_Sensing_Image_Super-Resolution_with_Hierarchical_Mixture_of_Sparse_Attention",
    "title": "2512.00275v1 HIMOSA Efficient Remote Sensing Image Super-Resolution with Hierarchical Mixture of Sparse Attention",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.00275v1_HIMOSA_Efficient_Remote_Sensing_Image_Super-Resolution_with_Hierarchical_Mixture_of_Sparse_Attention.pdf",
    "url": "http://arxiv.org/abs/2512.00275v1_HIMOSA_Efficient_Remote_Sensing_Image_Super-Resolution_with_Hierarchical_Mixture_of_Sparse_Attention",
    "pdf_url": "https://arxiv.org/pdf/2512.00275v1_HIMOSA_Efficient_Remote_Sensing_Image_Super-Resolution_with_Hierarchical_Mixture_of_Sparse_Attention",
    "file_size_mb": 28.06,
    "abstract": "In remote sensing applications, such as disaster detection and response, real-time efficiency and model lightweight- ing are of critical importance. Consequently, existing re- mote sensing image super-resolution methods often face a trade-off between model performance and computational efficiency. In this paper, we propose a lightweight super- resolution framework for remote sensing imagery, named HIMOSA. Specifically, HIMOSA leverages the inherent re- dundancy in remote sensing imagery and introduces a content-aware sparse attention mechanism, enabling the model to achieve fast inference while maintaining strong reconstruction performance. Furthermore, to effectively leverage the multi-scale repetitive patterns found in remote sensing imagery, we introduce a hierarchical window ex- pansion and reduce the computational complexity by ad- justing the sparsity of the attention. Extensive experiments on multiple remote sensing datasets demonstrate that our method achieves state-of-the-art performance while main- taining computational efficiency.",
    "keywords": []
  },
  {
    "article_id": "2512.00299v1_Stochastic_Dominance_Constrained_Optimization_with_S-shaped_Utilities_Poor-Performance-Region_Algori",
    "title": "2512.00299v1 Stochastic Dominance Constrained Optimization with S-shaped Utilities Poor-Performance-Region Algori",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.00299v1_Stochastic_Dominance_Constrained_Optimization_with_S-shaped_Utilities_Poor-Performance-Region_Algori.pdf",
    "url": "http://arxiv.org/abs/2512.00299v1_Stochastic_Dominance_Constrained_Optimization_with_S-shaped_Utilities_Poor-Performance-Region_Algori",
    "pdf_url": "https://arxiv.org/pdf/2512.00299v1_Stochastic_Dominance_Constrained_Optimization_with_S-shaped_Utilities_Poor-Performance-Region_Algori",
    "file_size_mb": 0.87,
    "abstract": "We investigate the static portfolio selection problem of S-shaped and non-concave utility maximization under ﬁrst-order and second-order stochastic dominance (SD) constraints. In many S-shaped utility optimization problems, one should require a liquidation boundary to guarantee the existence of a ﬁnite concave envelope function. A ﬁrst-order SD (FSD) constraint can replace this requirement and provide an alternative for risk management. We explicitly solve the optimal solution under a general S-shaped utility function with a ﬁrst-order stochastic dominance constraint. However, the second-order SD (SSD) constrained problem under non-concave utilities is diﬃcult to solve analytically due to the invalidity of Sion’s maxmin theorem. For this sake, we propose a numerical algorithm to obtain a plausible and sub-optimal solution for general non-concave utilities. The key idea is to detect the poor performance region with respect to the SSD constraints, characterize its structure and modify the distribution on that region to obtain (sub-)optimality. A key ﬁnancial insight is that the decision maker should follow the SD constraint on the poor performance scenario while conducting the unconstrained optimal strategy otherwise. We provide numerical experiments to show that our algorithm eﬀectively ﬁnds a sub-optimal solution in many cases. Finally, we develop an algorithm-guided piecewise-neural-network framework to learn the solution of the SSD problem, which demonstrates accelerated convergence compared to standard neural network approaches.",
    "keywords": [
      "Non-concave utility",
      "portfolio selection",
      "risk constraints",
      "ﬁrst-order stochastic dominance"
    ]
  },
  {
    "article_id": "2512.00396v2_Time-Series_at_the_Edge_Tiny_Separable_CNNs_for_Wearable_Gait_Detection_and_Optimal_Sensor_Placement",
    "title": "2512.00396v2 Time-Series at the Edge Tiny Separable CNNs for Wearable Gait Detection and Optimal Sensor Placement",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.00396v2_Time-Series_at_the_Edge_Tiny_Separable_CNNs_for_Wearable_Gait_Detection_and_Optimal_Sensor_Placement.pdf",
    "url": "http://arxiv.org/abs/2512.00396v2_Time-Series_at_the_Edge_Tiny_Separable_CNNs_for_Wearable_Gait_Detection_and_Optimal_Sensor_Placement",
    "pdf_url": "https://arxiv.org/pdf/2512.00396v2_Time-Series_at_the_Edge_Tiny_Separable_CNNs_for_Wearable_Gait_Detection_and_Optimal_Sensor_Placement",
    "file_size_mb": 0.24,
    "abstract": "We study on-device time-series analysis for gait detection in Parkinson’s disease (PD) from short windows of triax- ial acceleration, targeting resource-constrained wearables and edge nodes. We compare magnitude thresholding to three 1D CNNs for time-series analysis: a literature baseline (sepa- rable convolutions) and two ultra-light models—one purely separable and one with residual connections. Using the “BioStampRC21” dataset, 2 s windows at 30 Hz, and subject- independent leave-one-subject-out (LOSO) validation on 16 PwPD with chest-worn IMUs, our residual separable model (Model 2, 533 params) attains PR–AUC = 94.5%, F1 = 91.2%, MCC = 89.4%, matching or surpassing the baseline (5,552 params; PR–AUC = 93.7%, F1 = 90.5%, MCC = 88.5%) with ∼10× fewer parameters. The smallest model (Model 1, 305 params) reaches PR–AUC = 94.0%, F1 = 91.0%, MCC = 89.1%. Thresholding obtains high recall (89.0%) but low precision (76.5%), yielding many false posi- tives and high inter-subject variance. Sensor-position analysis (train-on-all) shows chest and thighs are most reliable; fore- arms degrade precision/recall due to non-gait arm motion; naive fusion of all sites does not outperform the best single site. Both compact CNNs execute within tight memory/la- tency budgets on STM32-class MCUs (sub-10 ms on low- power boards), enabling on-sensor gating of transmission/s- torage. Overall, ultra-light separable CNNs provide a superior accuracy–efficiency–generalization trade-off to fixed thresh- olds for wearable PD gait detection and underscore the value of tailored time-series models for edge deployment.",
    "keywords": []
  },
  {
    "article_id": "2512.00410v1_Balancing_Efficiency_and_Fairness_An_Iterative_Exchange_Framework_for_Multi-UAV_Cooperative_Path_Pla",
    "title": "2512.00410v1 Balancing Efficiency and Fairness An Iterative Exchange Framework for Multi-UAV Cooperative Path Pla",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.00410v1_Balancing_Efficiency_and_Fairness_An_Iterative_Exchange_Framework_for_Multi-UAV_Cooperative_Path_Pla.pdf",
    "url": "http://arxiv.org/abs/2512.00410v1_Balancing_Efficiency_and_Fairness_An_Iterative_Exchange_Framework_for_Multi-UAV_Cooperative_Path_Pla",
    "pdf_url": "https://arxiv.org/pdf/2512.00410v1_Balancing_Efficiency_and_Fairness_An_Iterative_Exchange_Framework_for_Multi-UAV_Cooperative_Path_Pla",
    "file_size_mb": 3.11,
    "abstract": "—Multi-UAV cooperative path planning (MUCPP) is a fundamental problem in multi-agent systems, aiming to generate collision-free trajectories for a team of unmanned aerial vehicles (UAVs) to complete distributed tasks effi- ciently. A key challenge lies in achieving both efficiency, by minimizing total mission cost, and fairness, by balancing the workload among UAVs to avoid overburdening individual agents. This paper presents a novel Iterative Exchange Framework for MUCPP, balancing efficiency and fairness through iterative task exchanges and path refinements. The proposed framework formulates a composite objective that combines the total mission distance and the makespan, and iteratively improves the solution via local exchanges under feasibility and safety constraints. For each UAV, collision-free trajectories are generated using A* search over a terrain- aware configuration space. Comprehensive experiments on multiple terrain datasets demonstrate that the proposed method consistently achieves superior trade-offs between total distance and makespan compared to existing baselines.",
    "keywords": [
      "Multi-UAV Systems",
      "Cooperative Path Plan-"
    ]
  },
  {
    "article_id": "2512.00499v1_ESPO_Entropy_Importance_Sampling_Policy_Optimization",
    "title": "2512.00499v1 ESPO Entropy Importance Sampling Policy Optimization",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.00499v1_ESPO_Entropy_Importance_Sampling_Policy_Optimization.pdf",
    "url": "http://arxiv.org/abs/2512.00499v1_ESPO_Entropy_Importance_Sampling_Policy_Optimization",
    "pdf_url": "https://arxiv.org/pdf/2512.00499v1_ESPO_Entropy_Importance_Sampling_Policy_Optimization",
    "file_size_mb": 1.11,
    "abstract": null,
    "keywords": []
  },
  {
    "article_id": "2512.00630v1_Financial_Text_Classification_Based_On_rLoRA_Finetuning_On_Qwen3-8B_model",
    "title": "2512.00630v1 Financial Text Classification Based On rLoRA Finetuning On Qwen3-8B model",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.00630v1_Financial_Text_Classification_Based_On_rLoRA_Finetuning_On_Qwen3-8B_model.pdf",
    "url": "http://arxiv.org/abs/2512.00630v1_Financial_Text_Classification_Based_On_rLoRA_Finetuning_On_Qwen3-8B_model",
    "pdf_url": "https://arxiv.org/pdf/2512.00630v1_Financial_Text_Classification_Based_On_rLoRA_Finetuning_On_Qwen3-8B_model",
    "file_size_mb": 2.38,
    "abstract": "Financial text classification has increasingly become an important aspect in quantitative trading systems and related tasks, such as financial sentiment analysis and the classification of financial news. In this paper, we assess the performance of the large language model Qwen3-8B on both tasks. Qwen3-8B is a state-of-the-art model that exhibits strong instruction-following and multilingual capabilities, and is distinct from standard models, primarily because it is specifically optimized for efficient fine- tuning and high performance on reasoning-based benchmarks, making it suitable for financial applications. To adapt this model, we apply Noisy Embedding Instruction Finetuning and based on our previous work, this method increases robustness by injecting controlled noise into the embedding layers during supervised adaptation. We improve efficiency further with Rank-stabilized Low-Rank Adaptation low-rank optimization approach, and FlashAttention, which allow for faster training with lower GPU memory. For both tasks, we benchmark Qwen3-8B against standard classical transformer models, such as T5, BERT, and RoBERTa, and large models at scale, such as LLaMA1-7B, LLaMA2-7B, and Baichuan2-7B. The findings reveal that Qwen3-8B consistently surpasses these baselines by obtaining better classification accuracy and needing fewer training epochs. The synergy of instruction-based fine-tuning and memory-efficient optimization methods suggests Qwen3-8B can potentially serve as a scalable, economical option for real-time financial NLP applications. Qwen3-8B provides a very promising base for advancing dynamic quantitative trading systems in the future. CCS Concepts Computing methodologies -> Artificial intelligence -> Natural language processing -> Natural language generation Additional Keywords and Phrases Financial Text Classification, rLoRA, Qwen3-8B, LLaMA",
    "keywords": [
      "and Phrases"
    ]
  },
  {
    "article_id": "2512.00916v1_An_Imbalance-Robust_Evaluation_Framework_for_Extreme_Risk_Forecasts",
    "title": "2512.00916v1 An Imbalance-Robust Evaluation Framework for Extreme Risk Forecasts",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.00916v1_An_Imbalance-Robust_Evaluation_Framework_for_Extreme_Risk_Forecasts.pdf",
    "url": "http://arxiv.org/abs/2512.00916v1_An_Imbalance-Robust_Evaluation_Framework_for_Extreme_Risk_Forecasts",
    "pdf_url": "https://arxiv.org/pdf/2512.00916v1_An_Imbalance-Robust_Evaluation_Framework_for_Extreme_Risk_Forecasts",
    "file_size_mb": 2.89,
    "abstract": "Evaluating rare-event forecasts is challenging because standard metrics collapse as event prevalence declines. Measures such as F1-score, AUPRC, MCC, and accuracy induce degenerate thresholds— converging to zero or one—and their values become dominated by class imbalance rather than tail discrimination. We develop a family of rare-event-stable (RES) metrics whose optimal thresholds remain strictly interior as the event probability approaches zero, ensuring coherent decision rules under extreme rarity. Simulations spanning event probabilities from 0.01 down to one in a million show that RES metrics maintain stable thresholds, consistent model rankings, and near-complete prevalence invariance, whereas traditional metrics exhibit statistically significant threshold drift and structural collapse. A credit-default application confirms these results: RES metrics yield interpretable probability-of-default cutoffs (4–9%) and remain robust under subsampling, while classical metrics fail operationally. The RES framework provides a principled, prevalence-invariant basis for evaluating extreme-risk forecasts.",
    "keywords": [
      "Rare events",
      "Classification",
      "Decision analysis",
      "Proper scoring rules",
      "Early warning"
    ]
  },
  {
    "article_id": "2512.01056v1_The_Silence_that_Speaks_Neural_Estimation_via_Communication_Gaps",
    "title": "2512.01056v1 The Silence that Speaks Neural Estimation via Communication Gaps",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.01056v1_The_Silence_that_Speaks_Neural_Estimation_via_Communication_Gaps.pdf",
    "url": "http://arxiv.org/abs/2512.01056v1_The_Silence_that_Speaks_Neural_Estimation_via_Communication_Gaps",
    "pdf_url": "https://arxiv.org/pdf/2512.01056v1_The_Silence_that_Speaks_Neural_Estimation_via_Communication_Gaps",
    "file_size_mb": 1.4,
    "abstract": "Accurate remote state estimation is a fundamental component of many autonomous and networked dynamical systems, where multiple decision-making agents interact and com- municate over shared, bandwidth-constrained channels. These communication constraints introduce an additional layer of complexity, namely, the decision of when to communicate. This results in a fundamental trade-off between estimation accuracy and communication resource usage. Traditional extensions of classical estimation algorithms (e.g., the Kalman filter) treat the absence of communication as ‘missing’ information. However, silence itself can carry implicit information about the system’s state, which, if properly interpreted, can enhance the estimation quality even in the absence of explicit communication. Leveraging this implicit structure, however, poses significant analytical challenges, even in relatively simple systems. In this paper, we propose CALM (Communication-Aware Learning and Monitoring), a novel learning-based framework that jointly addresses the dual challenges of communication scheduling and estimator design. Our approach entails learning not only when to communicate but also how to infer useful information from periods of communica- tion silence. We perform comparative case studies on multiple benchmarks to demonstrate that CALM is able to decode the implicit coordination between the estimator and the scheduler to extract information from the instances of ‘silence’ and enhance the estimation accuracy.",
    "keywords": []
  },
  {
    "article_id": "2512.01256v1_Sentiment_Analysis_and_Emotion_Classification_using_Machine_Learning_Techniques_for_Nagamese_Languag",
    "title": "2512.01256v1 Sentiment Analysis and Emotion Classification using Machine Learning Techniques for Nagamese Languag",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.01256v1_Sentiment_Analysis_and_Emotion_Classification_using_Machine_Learning_Techniques_for_Nagamese_Languag.pdf",
    "url": "http://arxiv.org/abs/2512.01256v1_Sentiment_Analysis_and_Emotion_Classification_using_Machine_Learning_Techniques_for_Nagamese_Languag",
    "pdf_url": "https://arxiv.org/pdf/2512.01256v1_Sentiment_Analysis_and_Emotion_Classification_using_Machine_Learning_Techniques_for_Nagamese_Languag",
    "file_size_mb": 1.19,
    "abstract": "— The Nagamese language, a.k.a Naga Pidgin, is an Assamese-lexified creole language developed primarily as a means of communication in trade between the people from Nagaland and people from Assam in the north-east India. Substantial amount of work in sentiment analysis has been done for resource-rich languages like English, Hindi, etc. However, no work has been done in Nagamese language. To the best of our knowledge, this is the first attempt on sentiment analysis and emotion classification for the Nagamese Language. The aim of this work is to detect sentiments in terms of polarity (positive, negative and neutral) and basic emotions contained in textual content of Nagamese language. We build sentiment polarity lexicon of 1,195 nagamese words and use these to build features along with additional features for supervised machine learning techniques using Naïve Bayes and Support Vector Machines.",
    "keywords": [
      "Nagamese",
      "NLP",
      "sentiment analysis",
      "machine learning"
    ]
  },
  {
    "article_id": "2512.01316v1_Agreement-Constrained_Probabilistic_Minimum_Bayes_Risk_Decoding",
    "title": "2512.01316v1 Agreement-Constrained Probabilistic Minimum Bayes Risk Decoding",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.01316v1_Agreement-Constrained_Probabilistic_Minimum_Bayes_Risk_Decoding.pdf",
    "url": "http://arxiv.org/abs/2512.01316v1_Agreement-Constrained_Probabilistic_Minimum_Bayes_Risk_Decoding",
    "pdf_url": "https://arxiv.org/pdf/2512.01316v1_Agreement-Constrained_Probabilistic_Minimum_Bayes_Risk_Decoding",
    "file_size_mb": 0.57,
    "abstract": "Minimum Bayes risk (MBR) decoding gener- ates high-quality translations by maximizing the expected utility of output candidates, but it evaluates all pairwise scores over the candidate set; hence, it takes quadratic time with respect to the number of candidates. To reduce the num- ber of utility function calls, probabilistic MBR (PMBR) decoding partially evaluates quality scores using sampled pairs of candidates and completes the missing scores with a matrix completion algorithm. Nevertheless, it de- grades the translation quality as the number of utility function calls is reduced. Therefore, to improve the trade-off between quality and cost, we propose agreement-constrained PMBR (AC- PMBR) decoding, which leverages a knowl- edge distilled model to guide the completion of the score matrix. Our AC-PMBR decoding improved approximation errors of matrix com- pletion by up to 3 times and achieved higher translation quality compared with PMBR de- coding at a comparable computational cost on the WMT’23 En↔De translation tasks.",
    "keywords": []
  },
  {
    "article_id": "2512.01392v1_RE-LLM_Integrating_Large_Language_Models_into_Renewable_Energy_Systems",
    "title": "2512.01392v1 RE-LLM Integrating Large Language Models into Renewable Energy Systems",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.01392v1_RE-LLM_Integrating_Large_Language_Models_into_Renewable_Energy_Systems.pdf",
    "url": "http://arxiv.org/abs/2512.01392v1_RE-LLM_Integrating_Large_Language_Models_into_Renewable_Energy_Systems",
    "pdf_url": "https://arxiv.org/pdf/2512.01392v1_RE-LLM_Integrating_Large_Language_Models_into_Renewable_Energy_Systems",
    "file_size_mb": 3.54,
    "abstract": "Energy system models are increasingly employed to guide long-term planning in multi-sectoral environments where decisions span electricity, heat, trans- port, land use, and industry. While these models provide rigorous quantita- tive insights, their outputs are often highly technical, making them difficult to interpret for non-expert stakeholders such as policymakers, planners, and the public. This communication gap limits the accessibility and practical impact of scenario-based modeling, particularly as energy transitions grow more complex with rising shares of renewables, sectoral integration, and deep uncertainties. To address this challenge, we propose the Renewable Energy Large Lan- guage Model (RE-LLM), a hybrid framework that integrates Large Language Models (LLMs) directly into the energy system modeling workflow. RE-LLM com- bines three core elements: (i) optimization-based scenario exploration, (ii) machine learning surrogates that accelerate computationally intensive simu- lations, and (iii) LLM-powered natural language generation that translates complex results into clear, stakeholder-oriented explanations. This inte- grated design not only reduces computational burden but also enhances inter- ∗Ali Forootani Email addresses: ali.forootani@ufz.de/aliforootani@ieee.org (Ali Forootani*), mohammad.sadr@ufz.de (Mohammad Sadr), danial.esmaeili@ufz.de (Danial Esmaeili Aliabadi), daniela.thraen@ufz.de (Daniela Thrän) pretability, enabling real-time reasoning about trade-offs, sensitivities, and policy implications. The framework is adaptable across different optimization platforms and energy system models, ensuring broad applicability beyond the case study presented. By merging speed, rigor, and interpretability, RE-LLM advances a new paradigm of human-centric energy modeling. It enables interactive, multilingual, and accessible engagement with future energy pathways, ulti- mately bridging the final gap between data-driven analysis and actionable decision-making for sustainable transitions.",
    "keywords": [
      "Renewable energy",
      "Scenario modeling",
      "Machine learning",
      "Large"
    ]
  },
  {
    "article_id": "2512.01782v1_Dual_Randomized_Smoothing_Beyond_Global_Noise_Variance",
    "title": "2512.01782v1 Dual Randomized Smoothing Beyond Global Noise Variance",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.01782v1_Dual_Randomized_Smoothing_Beyond_Global_Noise_Variance.pdf",
    "url": "http://arxiv.org/abs/2512.01782v1_Dual_Randomized_Smoothing_Beyond_Global_Noise_Variance",
    "pdf_url": "https://arxiv.org/pdf/2512.01782v1_Dual_Randomized_Smoothing_Beyond_Global_Noise_Variance",
    "file_size_mb": 0.7,
    "abstract": "Randomized Smoothing (RS) is a prominent technique for certifying the robust- ness of neural networks against adversarial perturbations. With RS, achieving high accuracy at small radii requires a small noise variance, while achieving high accu- racy at large radii requires a large noise variance. However, the global noise vari- ance used in the standard RS formulation leads to a fundamental limitation: there exists no global noise variance that simultaneously achieves strong performance at both small and large radii. To break through the global variance limitation, we propose a dual RS framework which enables input-dependent noise variances. To achieve that, we first prove that RS remains valid with input-dependent noise variances, provided the variance is locally constant around each input. Building on this result, we introduce two components which form our dual RS framework: (i) a variance estimator first predicts an optimal noise variance for each input, (ii) this estimated variance is then used by a standard RS classifier. The variance esti- mator is independently smoothed via RS to ensure local constancy, enabling flex- ible design. We also introduce training strategies to iteratively optimize the two components involved in the framework. Extensive experiments on the CIFAR- 10 dataset demonstrate that our dual RS method provides strong performance for both small and large radii—unattainable with global noise variance—while incur- ring only a 60% computational overhead at inference. Moreover, it consistently outperforms prior input-dependent noise approaches across most radii, with par- ticularly large gains at radii 0.5, 0.75, and 1.0, achieving relative improvements of 19.2%, 24.2%, and 20.6%, respectively. On IMAGENET, dual RS remains effec- tive across all radii, with roughly 1.5x performance advantages at radii 0.5, 1.0 and 1.5. Additionally, the proposed dual RS framework naturally provides a routing perspective for certified robustness, improving the accuracy-robustness trade-off with off-the-shelf expert RS models.",
    "keywords": []
  },
  {
    "article_id": "2512.02036v1_Integration_of_LSTM_Networks_in_Random_Forest_Algorithms_for_Stock_Market_Trading_Predictions",
    "title": "2512.02036v1 Integration of LSTM Networks in Random Forest Algorithms for Stock Market Trading Predictions",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.02036v1_Integration_of_LSTM_Networks_in_Random_Forest_Algorithms_for_Stock_Market_Trading_Predictions.pdf",
    "url": "http://arxiv.org/abs/2512.02036v1_Integration_of_LSTM_Networks_in_Random_Forest_Algorithms_for_Stock_Market_Trading_Predictions",
    "pdf_url": "https://arxiv.org/pdf/2512.02036v1_Integration_of_LSTM_Networks_in_Random_Forest_Algorithms_for_Stock_Market_Trading_Predictions",
    "file_size_mb": 1.38,
    "abstract": "The aim of this paper is the analysis and selection of stock trading systems that combine different models with data of different nature, such as financial and microeconomic informa- tion. Specifically, based on previous work by the authors and applying advanced techniques of Machine Learning and Deep Learning, our objective is to formulate trading algorithms for the stock market with empirically tested statistical advantages, thus improving results published in the literature. Our approach integrates Long Short-Term Memory (LSTM) networks with algorithms based on decision trees, such as Random Forest and Gradient Boosting. While the former analyze price patterns of financial assets, the latter are fed with economic data of companies. Numerical simulations of algorithmic trading with data from international companies and 10-weekday predictions confirm that an approach based on both fundamental and technical variables can outperform the usual approaches, which do not combine those two types of variables. In doing so, Random Forest turned out to be the best performer among the decision trees. We also discuss how the prediction performance of such a hybrid approach can be boosted by selecting the technical variables.",
    "keywords": []
  },
  {
    "article_id": "2512.02037v1_Statistical_Arbitrage_in_Polish_Equities_Market_Using_Deep_Learning_Techniques",
    "title": "2512.02037v1 Statistical Arbitrage in Polish Equities Market Using Deep Learning Techniques",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.02037v1_Statistical_Arbitrage_in_Polish_Equities_Market_Using_Deep_Learning_Techniques.pdf",
    "url": "http://arxiv.org/abs/2512.02037v1_Statistical_Arbitrage_in_Polish_Equities_Market_Using_Deep_Learning_Techniques",
    "pdf_url": "https://arxiv.org/pdf/2512.02037v1_Statistical_Arbitrage_in_Polish_Equities_Market_Using_Deep_Learning_Techniques",
    "file_size_mb": 6.64,
    "abstract": "We study a systematic approach to a popular Statistical Arbitrage technique of Pairs Trading. Instead of relying on 2 highly correlated assets, the latter one is substitute with the most accu- rate replication of the first with the use of so called risk-factors. Such factors can be determined by: Principal Components Analysis (PCA), actual market exchange traded funds (ETFs) or, as a authorial technique and thus our contribution to the literature, Long short-term memory networks (LSTMs). Residuals between the main asset and its replication’ returns are analysed on a basis of their potential mean-reversion properties. Trading signals are later generated for sufficiently fast mean-reverting portfolios to profit from any technical mispricings. Besides the introduction of a new deep-learning based method, paper re-defines methods already presented by authors of 2008’s paper Statistical Arbitrage in the U.S. Equities Market to match conditions of the polish stock exchange market. For that reason, instead of SP500 stocks’, com- ponents of WIG20 and mWIG40 combined are in scope of trading activities with an addition of polish sector indices. Overall market factors such as the risk free rate or transaction costs are also adjusted from mentioned paper for better reality matching. After setting up the scope, all details of the strategy are explained: from the theory behind risk- factors representation, through the modelling of residuals with Ornstein-Uhlenbeck process till trading signals generation procedure. They are followed by a separate section concerning specifics of each replicating technique with a general overview of the method and its application for our pur- poses. Throughout the entire thesis various examples are graphically made for better understanding of discussed topics. The final part of the paper concerns testing of the overall Pairs Trading strategy and of its presented variations. To keep the results relevant and tested in different economic conditions, two backtesting periods are distinguished: 2017-2019 and a highly recessive 2020. All strategies manage to profit during the first interval with the PCA approach achieving around 20% of combined return and even up to 2.63 annualized Sharpe ratio (in 2017). Even though a lot of assumptions is changed in comparison to Avellaneda and Lee’ 2008 paper, received results and main conclusions are highly comparable. During the COVID-19 recession, ETFs technique are the only profitable one achieving annual re- turn of 5%- both the PCA and LSTM methods fail to produce any profits. All LSTM results can be seen as promising and should be optimized in future works, especially since it is possibly the first take on such application of recurrent neural networks. Contents",
    "keywords": []
  },
  {
    "article_id": "2512.02061v1_Ada-MoGE_Adaptive_Mixture_of_Gaussian_Expert_Model_for_Time_Series_Forecasting",
    "title": "2512.02061v1 Ada-MoGE Adaptive Mixture of Gaussian Expert Model for Time Series Forecasting",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.02061v1_Ada-MoGE_Adaptive_Mixture_of_Gaussian_Expert_Model_for_Time_Series_Forecasting.pdf",
    "url": "http://arxiv.org/abs/2512.02061v1_Ada-MoGE_Adaptive_Mixture_of_Gaussian_Expert_Model_for_Time_Series_Forecasting",
    "pdf_url": "https://arxiv.org/pdf/2512.02061v1_Ada-MoGE_Adaptive_Mixture_of_Gaussian_Expert_Model_for_Time_Series_Forecasting",
    "file_size_mb": 3.18,
    "abstract": "Multivariate time series forecasts are widely used, such as industrial, transportation and financial forecasts. However, the dominant frequencies in time series may shift with the evolving spectral distribution of the data. Traditional Mixture of Experts (MoE) models, which employ a fixed number of experts, struggle to adapt to these changes, resulting in frequency coverage imbalance issue. Specifically, too few experts can lead to the overlooking of critical information, while too many can introduce noise. To this end, we propose Ada-MoGE, an adaptive Gaussian Mixture of Experts model. Ada-MoGE integrates spectral intensity and frequency response to adaptively determine the number of experts, ensuring alignment with the input data’s frequency distribution. This approach prevents both information loss due to an insufficient number of experts and noise contamination from an excess of experts. Additionally, to prevent noise introduction from direct band truncation, we employ Gaussian band-pass filtering to smoothly decompose the frequency domain features, further optimizing the feature representation. The experimental results show that our model achieves state-of-the-art performance on six public benchmarks with only 0.2 million parameters.",
    "keywords": []
  },
  {
    "article_id": "2512.02092v1_Opening_the_Black_Box_Nowcasting_Singapores_GDP_Growth_and_its_Explainability",
    "title": "2512.02092v1 Opening the Black Box Nowcasting Singapores GDP Growth and its Explainability",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.02092v1_Opening_the_Black_Box_Nowcasting_Singapores_GDP_Growth_and_its_Explainability.pdf",
    "url": "http://arxiv.org/abs/2512.02092v1_Opening_the_Black_Box_Nowcasting_Singapores_GDP_Growth_and_its_Explainability",
    "pdf_url": "https://arxiv.org/pdf/2512.02092v1_Opening_the_Black_Box_Nowcasting_Singapores_GDP_Growth_and_its_Explainability",
    "file_size_mb": 4.47,
    "abstract": null,
    "keywords": []
  },
  {
    "article_id": "2512.02227v1_Orchestration_Framework_for_Financial_Agents_From_Algorithmic_Trading_to_Agentic_Trading",
    "title": "2512.02227v1 Orchestration Framework for Financial Agents From Algorithmic Trading to Agentic Trading",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.02227v1_Orchestration_Framework_for_Financial_Agents_From_Algorithmic_Trading_to_Agentic_Trading.pdf",
    "url": "http://arxiv.org/abs/2512.02227v1_Orchestration_Framework_for_Financial_Agents_From_Algorithmic_Trading_to_Agentic_Trading",
    "pdf_url": "https://arxiv.org/pdf/2512.02227v1_Orchestration_Framework_for_Financial_Agents_From_Algorithmic_Trading_to_Agentic_Trading",
    "file_size_mb": 0.85,
    "abstract": "The ﬁnancial market is a mission-critical playground for AI agents due to its tem- poral dynamics and low signal-to-noise ratio. Building an effective algorithmic trading system may require a professional team to develop and test over the years. In this paper, we propose an orchestration framework for ﬁnancial agents, which aims to democratize ﬁnancial intelligence to the general public. We map each com- ponent of the traditional algorithmic trading system to agents, including planner, orchestrator, alpha agents, risk agents, portfolio agents, backtest agents, execu- tion agents, audit agents, and memory agent. We present two in-house trading examples. For the stock trading task (hourly data from 04/2024 to 12/2024), our approach achieved a return of 20.42%, a Sharpe ratio of 2.63, and a maximum drawdown of −3.59%, while the S&P 500 index yielded a return of 15.97%. For the BTC trading task (minute data from 27/07/2025 to 13/08/2025), our approach achieved a return of 8.39%, a Sharpe ratio of 0.38, and a maximum drawdown of −2.80%, whereas the BTC price increased by 3.80%. Our code is available on GitHub.",
    "keywords": []
  },
  {
    "article_id": "2512.02261v1_TradeTrap_Are_LLM-based_Trading_Agents_Truly_Reliable_and_Faithful",
    "title": "2512.02261v1 TradeTrap Are LLM-based Trading Agents Truly Reliable and Faithful",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.02261v1_TradeTrap_Are_LLM-based_Trading_Agents_Truly_Reliable_and_Faithful.pdf",
    "url": "http://arxiv.org/abs/2512.02261v1_TradeTrap_Are_LLM-based_Trading_Agents_Truly_Reliable_and_Faithful",
    "pdf_url": "https://arxiv.org/pdf/2512.02261v1_TradeTrap_Are_LLM-based_Trading_Agents_Truly_Reliable_and_Faithful",
    "file_size_mb": 1.79,
    "abstract": "LLM-based trading agents are increasingly deployed in real-world financial mar- kets to perform autonomous analysis and execution. However, their reliability and robustness under adversarial or faulty conditions remain largely unexamined, despite operating in high-risk, irreversible financial environments. We propose TradeTrap, a unified evaluation framework for systematically stress-testing both Adaptive and Procedural autonomous trading agents. TradeTrap targets four core components of autonomous trading agents—market intelligence, strategy formulation, portfolio and ledger handling, and trade execution—and eval- uates their robustness under controlled system-level perturbations. All evalua- tions are conducted in a closed-loop historical backtesting setting on real U.S. equity market data with identical initial conditions, enabling fair and reproducible comparisons across agents and attacks. Extensive experiments show that small perturbations at a single component can propagate through the agent’s decision loop and induce extreme concentration, runaway exposure, and large portfolio drawdowns across both agent types, demonstrating that current autonomous trading agents can be systematically misled at the system level. Our code is public at https://github.com/Yanlewen/TradeTrap. Warning: This paper contains examples that may be offensive or upsetting.",
    "keywords": []
  },
  {
    "article_id": "2512.02272v1_Intrusion_Detection_on_Resource-Constrained_IoT_Devices_with_Hardware-Aware_ML_and_DL",
    "title": "2512.02272v1 Intrusion Detection on Resource-Constrained IoT Devices with Hardware-Aware ML and DL",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.02272v1_Intrusion_Detection_on_Resource-Constrained_IoT_Devices_with_Hardware-Aware_ML_and_DL.pdf",
    "url": "http://arxiv.org/abs/2512.02272v1_Intrusion_Detection_on_Resource-Constrained_IoT_Devices_with_Hardware-Aware_ML_and_DL",
    "pdf_url": "https://arxiv.org/pdf/2512.02272v1_Intrusion_Detection_on_Resource-Constrained_IoT_Devices_with_Hardware-Aware_ML_and_DL",
    "file_size_mb": 0.14,
    "abstract": "—This paper proposes a hardware-aware intrusion detection system (IDS) for Internet of Things (IoT) and Industrial IoT (IIoT) networks; it targets scenarios where classification is essential for fast, privacy-preserving, and resource-efficient threat detection. The goal is to optimize both tree-based machine learning (ML) models and compact deep neural networks (DNNs) within strict edge-device constraints. This allows for a fair comparison and reveals trade-offs between model families. We apply constrained grid search for tree-based classifiers and hardware-aware neural architecture search (HW-NAS) for 1D convolutional neural networks (1D-CNNs). Evaluation on the Edge-IIoTset benchmark shows that selected models meet tight flash, RAM, and compute limits: LightGBM achieves 95.3% accuracy using 75 KB flash and 1.2 K operations, while the HW- NAS–optimized CNN reaches 97.2% with 190 KB flash and 840 K floating-point operations (FLOPs). We deploy the full pipeline on a Raspberry Pi 3 B+, confirming that tree-based models operate within 30 ms and that CNNs remain suitable when accuracy outweighs latency. These results highlight the practicality of hardware-constrained model design for real-time IDS at the edge.",
    "keywords": [
      "Intrusion detection",
      "Edge AI",
      "Hardware-aware"
    ]
  },
  {
    "article_id": "2512.02282v1_DialogGuard_Multi-Agent_Psychosocial_Safety_Evaluation_of_Sensitive_LLM_Responses",
    "title": "2512.02282v1 DialogGuard Multi-Agent Psychosocial Safety Evaluation of Sensitive LLM Responses",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.02282v1_DialogGuard_Multi-Agent_Psychosocial_Safety_Evaluation_of_Sensitive_LLM_Responses.pdf",
    "url": "http://arxiv.org/abs/2512.02282v1_DialogGuard_Multi-Agent_Psychosocial_Safety_Evaluation_of_Sensitive_LLM_Responses",
    "pdf_url": "https://arxiv.org/pdf/2512.02282v1_DialogGuard_Multi-Agent_Psychosocial_Safety_Evaluation_of_Sensitive_LLM_Responses",
    "file_size_mb": 2.13,
    "abstract": "Large language models (LLMs) now mediate many web-based mental- health, crisis, and other emotionally sensitive services, yet their psychosocial safety in these settings remains poorly understood and weakly evaluated. We present DialogGuard, a multi-agent frame- work for assessing psychosocial risks in LLM-generated responses along five high-severity dimensions: privacy violations, discrimi- natory behaviour, mental manipulation, psychological harm, and insulting behaviour. DialogGuard can be applied to diverse gen- erative models through four LLM-as-a-judge pipelines, including single-agent scoring, dual-agent correction, multi-agent debate, and stochastic majority voting, grounded in a shared three-level rubric usable by both human annotators and LLM judges. Using PKU-SafeRLHF with human safety annotations, we show that multi- agent mechanisms detect psychosocial risks more accurately than non-LLM baselines and single-agent judging; dual-agent correction and majority voting provide the best trade-off between accuracy, alignment with human ratings, and robustness, while debate attains higher recall but over-flags borderline cases. We release Dialog- Guard as open-source software with a web interface that provides per-dimension risk scores and explainable natural-language ratio- nales. A formative study with 12 practitioners illustrates how it supports prompt design, auditing, and supervision of web-facing applications for vulnerable users. CCS Concepts • Information systems →Web applications; • Human-centered computing →Human computer interaction (HCI); Empiri- cal studies in HCI; • Computing methodologies →Natural language processing; • Applied computing →Psychology; • Security and privacy →Human and societal aspects of secu- rity and privacy.",
    "keywords": [
      "large language models",
      "psychosocial safety",
      "multi-agent evalua-"
    ]
  },
  {
    "article_id": "2512.02386v1_Risk-Sensitive_Q-Learning_in_Continuous_Time_with_Application_to_Dynamic_Portfolio_Selection",
    "title": "2512.02386v1 Risk-Sensitive Q-Learning in Continuous Time with Application to Dynamic Portfolio Selection",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.02386v1_Risk-Sensitive_Q-Learning_in_Continuous_Time_with_Application_to_Dynamic_Portfolio_Selection.pdf",
    "url": "http://arxiv.org/abs/2512.02386v1_Risk-Sensitive_Q-Learning_in_Continuous_Time_with_Application_to_Dynamic_Portfolio_Selection",
    "pdf_url": "https://arxiv.org/pdf/2512.02386v1_Risk-Sensitive_Q-Learning_in_Continuous_Time_with_Application_to_Dynamic_Portfolio_Selection",
    "file_size_mb": 1.01,
    "abstract": "This paper studies the problem of risk-sensitive reinforcement learning (RSRL) in continuous time, where the environment is characterized by a controllable stochastic differential equation (SDE) and the objective is a potentially nonlinear functional of cumulative rewards. We prove that when the functional is an optimized certainty equivalent (OCE), the optimal policy is Markovian with respect to an augmented environment. We also propose CT-RS-q, a risk-sensitive q-learning algorithm based on a novel martingale characterization approach. Finally, we run a simulation study on a dynamic portfolio selection problem and illustrate the effectiveness of our algorithm.",
    "keywords": []
  },
  {
    "article_id": "2512.02436v1_Semantic_Trading_Agentic_AI_for_Clustering_and_Relationship_Discovery_in_Prediction_Markets",
    "title": "2512.02436v1 Semantic Trading Agentic AI for Clustering and Relationship Discovery in Prediction Markets",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.02436v1_Semantic_Trading_Agentic_AI_for_Clustering_and_Relationship_Discovery_in_Prediction_Markets.pdf",
    "url": "http://arxiv.org/abs/2512.02436v1_Semantic_Trading_Agentic_AI_for_Clustering_and_Relationship_Discovery_in_Prediction_Markets",
    "pdf_url": "https://arxiv.org/pdf/2512.02436v1_Semantic_Trading_Agentic_AI_for_Clustering_and_Relationship_Discovery_in_Prediction_Markets",
    "file_size_mb": 0.55,
    "abstract": ". Prediction markets allow users to trade on outcomes of real- world events, but are prone to fragmentation with overlapping ques- tions, implicit equivalences, and hidden contradictions across markets. We present an agentic AI pipeline that autonomously (i) clusters mar- kets into coherent topical groups using natural-language understanding over contract text and metadata, and (ii) identifies within-cluster mar- ket pairs whose resolved outcomes exhibit strong dependence, including “same-outcome” (correlated) and “different-outcome” (anti-correlated) relationships. Using a historical dataset of resolved markets on Poly- market, we evaluate the accuracy of the agent’s relational predictions. We then synthesize discovered relationships into a simple trading strat- egy to quantify how discovered relationships translate into actionable strategies. Results show that agent-identified relationships have around 60-70% accuracy, and their induced trading strategies have an average return of ∼20% over week-long horizons, highlighting the ability of agen- tic AI and large language models to uncover latent semantic structure within prediction markets.",
    "keywords": [
      "Agentic AI",
      "Prediction markets",
      "Topic clustering",
      "Relationship"
    ]
  },
  {
    "article_id": "2512.02720v1_StockMem_An_Event-Reflection_Memory_Framework_for_Stock_Forecasting",
    "title": "2512.02720v1 StockMem An Event-Reflection Memory Framework for Stock Forecasting",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.02720v1_StockMem_An_Event-Reflection_Memory_Framework_for_Stock_Forecasting.pdf",
    "url": "http://arxiv.org/abs/2512.02720v1_StockMem_An_Event-Reflection_Memory_Framework_for_Stock_Forecasting",
    "pdf_url": "https://arxiv.org/pdf/2512.02720v1_StockMem_An_Event-Reflection_Memory_Framework_for_Stock_Forecasting",
    "file_size_mb": 1.2,
    "abstract": "Stock price prediction remains challenging due to market volatility and sensitivity to real-time events. The development of large lan- guage models (LLMs) has opened up new possibilities for text-based stock prediction. While LLMs possess powerful text comprehension capabilities, their effective application in complex real-world tasks often relies on specialized memory modules to enable the consis- tent and stable utilization of relevant historical information. Con- siderable research has been devoted to constructing such memory architectures. However, when confronted with the vast volume of noisy online news data, general-purpose memory architectures face substantial challenges in stock prediction tasks: the text does not contain explicit answers and is filled with noise irrelevant to price movements. The core issue lies in how to autonomously identify and infer the key information and underlying logic that drive stock prices movements from unstructured text. To address this challenge, this paper proposes an event-reflection dual-layer memory frame- work. During the knowledge construction phase, the framework performs in-depth mining of extracted structured events along two dimensions: horizontal event consolidation integrates key daily event content, while longitudinal event tracing tracks the evolution of the same event over time. This process extracts incremental in- formation that reflects market expectation discrepancies, ultimately constructing a temporally-aware structured event knowledge base. Furthermore, by analyzing the dynamic relationship between event sequences and stock price movements, the framework refines stock analysis knowledge to form a reflection knowledge base, thereby achieving systematic and autonomous knowledge construction. In the knowledge application phase, the framework involves two steps: retrieval and reasoning. First, the recent event sequence serves as a semantic query to retrieve semantically similar historical sce- narios from the memory network, providing precise references for current decision-making. Subsequently, during the reasoning phase, the model synthesizes the recent event sequence, incremen- tal information, and retrieved historical experience to generate reliable predictions of stock price movements. Experimental results validate that the proposed framework achieves superior predic- tive performance over existing memory architectures and exhibits stronger explainability. It can clearly trace the information chain affecting stock prices and analyze the underlying mechanisms of ∗Corresponding authors. information transmission, endowing the model with professional reasoning capabilities comparable to those of human analysts. This substantially enhances the transparency and trustworthiness of the decision-making process, showing broad application potential in complex financial semantic reasoning tasks. CCS Concepts • Computing methodologies →Information extraction; Knowl- edge representation and reason",
    "keywords": [
      "Memory Framework for LLM",
      "Financial news mining",
      "Event based"
    ]
  },
  {
    "article_id": "2512.03107v1_Detecting_AI_Hallucinations_in_Finance_An_Information-Theoretic_Method_Cuts_Hallucination_Rate_by_92",
    "title": "2512.03107v1 Detecting AI Hallucinations in Finance An Information-Theoretic Method Cuts Hallucination Rate by 92",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.03107v1_Detecting_AI_Hallucinations_in_Finance_An_Information-Theoretic_Method_Cuts_Hallucination_Rate_by_92.pdf",
    "url": "http://arxiv.org/abs/2512.03107v1_Detecting_AI_Hallucinations_in_Finance_An_Information-Theoretic_Method_Cuts_Hallucination_Rate_by_92",
    "pdf_url": "https://arxiv.org/pdf/2512.03107v1_Detecting_AI_Hallucinations_in_Finance_An_Information-Theoretic_Method_Cuts_Hallucination_Rate_by_92",
    "file_size_mb": 0.48,
    "abstract": "Large language models (LLMs) produce fluent but unsupported answers— hallucinations—limiting safe deployment in high-stakes domains. We propose ECLIPSE, a framework that treats hallucination as a mismatch between a model’s semantic entropy and the capacity of available evidence. We combine entropy estimation via multi-sample clustering with a novel perplexity decomposition that measures how models use retrieved evidence. We prove that under mild conditions, the resulting entropy–capacity objective is strictly convex with a unique stable optimum. We evaluate on a controlled financial question answering dataset with GPT-3.5-turbo (n = 200 balanced samples with synthetic hallucinations), where ECLIPSE achieves ROC AUC of 0.89 and average precision of 0.90, substantially outperforming a semantic entropy-only baseline (AUC 0.50). A controlled abla- tion with Claude-3-Haiku, which lacks token-level log probabilities, shows AUC dropping to 0.59 with coefficient magnitudes decreasing by 95%—demonstrating that ECLIPSE is a logprob-native mechanism whose effectiveness depends on calibrated token-level uncertainties. The perplexity decomposition features exhibit the largest learned coefficients, confirming that evidence utilization is central to hallucination detection. We position this work as a controlled mechanism study; broader validation across domains and naturally occurring hallucinations remains future work.",
    "keywords": []
  },
  {
    "article_id": "2512.03336v1_Single-Round_Scalable_Analytic_Federated_Learning",
    "title": "2512.03336v1 Single-Round Scalable Analytic Federated Learning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.03336v1_Single-Round_Scalable_Analytic_Federated_Learning.pdf",
    "url": "http://arxiv.org/abs/2512.03336v1_Single-Round_Scalable_Analytic_Federated_Learning",
    "pdf_url": "https://arxiv.org/pdf/2512.03336v1_Single-Round_Scalable_Analytic_Federated_Learning",
    "file_size_mb": 2.69,
    "abstract": "Federated Learning (FL) is plagued by two key challenges: high communication overhead and performance collapse on heterogeneous (non-IID) data. Analytic FL (AFL) pro- vides a single-round, data distribution invariant solution, but is limited to linear models. Subsequent non-linear ap- proaches, like DeepAFL, regain accuracy but sacrifice the single-round benefit. In this work, we break this trade- off. We propose SAFLe, a framework that achieves scalable non-linear expressivity by introducing a structured head of bucketed features and sparse, grouped embeddings. We prove this non-linear architecture is mathematically equiva- lent to a high-dimensional linear regression. This key equiv- alence allows SAFLe to be solved with AFL’s single-shot, invariant aggregation law. Empirically, SAFLe establishes a new state-of-the-art for analytic FL, significantly outper- forming both linear AFL and multi-round DeepAFL in ac- curacy across all benchmarks, demonstrating a highly effi- cient and scalable solution for federated vision.",
    "keywords": []
  },
  {
    "article_id": "2512.03477v2_Fairness-Aware_Fine-Tuning_of_Vision-Language_Models_for_Medical_Glaucoma_Diagnosis",
    "title": "2512.03477v2 Fairness-Aware Fine-Tuning of Vision-Language Models for Medical Glaucoma Diagnosis",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.03477v2_Fairness-Aware_Fine-Tuning_of_Vision-Language_Models_for_Medical_Glaucoma_Diagnosis.pdf",
    "url": "http://arxiv.org/abs/2512.03477v2_Fairness-Aware_Fine-Tuning_of_Vision-Language_Models_for_Medical_Glaucoma_Diagnosis",
    "pdf_url": "https://arxiv.org/pdf/2512.03477v2_Fairness-Aware_Fine-Tuning_of_Vision-Language_Models_for_Medical_Glaucoma_Diagnosis",
    "file_size_mb": 0.19,
    "abstract": "Glaucoma, a leading cause of irreversible blindness affecting 70 million people worldwide, disproportionately impacts minority populations who face 2-3× higher disease prevalence. Vision-language models achieve expert-level diagnos- tic performance but exhibit significant accuracy disparities across demographic groups, risking exacerbated health inequities. We introduce fairness-aware Low-Rank Adaptation for medical VLMs, combining parameter efficiency with explicit fairness optimization. Our key algorithmic contribution is a differentiable MaxAccGap loss that enables end-to-end optimization of accuracy parity across demographic groups. We propose three methods: FR-LoRA inte- grates MaxAccGap regularization, GR-LoRA applies inverse frequency weighting, and Hybrid-LoRA combines both mechanisms. Evaluated on 10,000 glaucoma fundus images, GR-LoRA reduces diagnostic accuracy disparities by 69% while maintaining 53.15% overall accuracy. Our approach requires only 0.24% trainable parameters, enabling practical deployment of fair medical AI in resource-constrained healthcare settings.",
    "keywords": []
  },
  {
    "article_id": "2512.03578v2_When_How_Long_and_How_Much_Interpretable_Neural_Networks_for_Time_Series_Regression_by_Learning_to_M",
    "title": "2512.03578v2 When How Long and How Much Interpretable Neural Networks for Time Series Regression by Learning to M",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.03578v2_When_How_Long_and_How_Much_Interpretable_Neural_Networks_for_Time_Series_Regression_by_Learning_to_M.pdf",
    "url": "http://arxiv.org/abs/2512.03578v2_When_How_Long_and_How_Much_Interpretable_Neural_Networks_for_Time_Series_Regression_by_Learning_to_M",
    "pdf_url": "https://arxiv.org/pdf/2512.03578v2_When_How_Long_and_How_Much_Interpretable_Neural_Networks_for_Time_Series_Regression_by_Learning_to_M",
    "file_size_mb": 3.04,
    "abstract": "—Time series extrinsic regression (TSER) refers to the task of predicting a continuous target variable from an input time series. It appears in many domains, including healthcare, finance, environmental monitoring, and engineering. In these settings, accurate predictions and trustworthy reasoning are both essential. Although state-of-the-art TSER models achieve strong predictive performance, they typically operate as black boxes, making it difficult to understand which temporal patterns drive their decisions. Post-hoc interpretability techniques, such as feature attribution, aim to to explain how the model arrives at its predictions, but often produce coarse, noisy, or unstable expla- nations. Recently, inherently interpretable approaches based on concepts, additive decompositions, or symbolic regression, have emerged as promising alternatives. However, these approaches remain limited: they require explicit supervision on the concepts themselves, often cannot capture interactions between time-series features, lack expressiveness for complex temporal patterns, and struggle to scale to high-dimensional multivariate data. To address these limitations, we propose MAGNETS (Mask- and-AGgregate NEtwork for Time Series), an inherently inter- pretable neural architecture for TSER. MAGNETS learns a compact set of human-understandable concepts without requir- ing any annotations. Each concept corresponds to a learned, mask-based aggregation over selected input features, explicitly revealing both which features drive predictions and when they matter in the sequence. Predictions are formed as combinations of these learned concepts through a transparent, additive structure, enabling clear insight into the model’s decision process. Experiments on synthetic and real-world univariate and mul- tivariate TSER datasets show that MAGNETS closely matches the accuracy of black-box models while substantially outperform- ing existing interpretable baselines, particularly on multivariate datasets involving feature interactions. Finally, we also show that MAGNETS provides more faithful and informative explanations than post-hoc methods. The code implementation and datasets are publicly available at https://github.com/FlorentF9/MAGNETS.",
    "keywords": [
      "Time series regression",
      "Machine learning",
      "Ex-"
    ]
  },
  {
    "article_id": "2512.03994v2_Training-Free_Policy_Violation_Detection_via_Activation-Space_Whitening_in_LLMs",
    "title": "2512.03994v2 Training-Free Policy Violation Detection via Activation-Space Whitening in LLMs",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.03994v2_Training-Free_Policy_Violation_Detection_via_Activation-Space_Whitening_in_LLMs.pdf",
    "url": "http://arxiv.org/abs/2512.03994v2_Training-Free_Policy_Violation_Detection_via_Activation-Space_Whitening_in_LLMs",
    "pdf_url": "https://arxiv.org/pdf/2512.03994v2_Training-Free_Policy_Violation_Detection_via_Activation-Space_Whitening_in_LLMs",
    "file_size_mb": 12.23,
    "abstract": "Aligning proprietary large language models (LLMs) with in- ternal organizational policies has become an urgent priority as organizations increasingly deploy LLMs in sensitive domains such as legal support, finance, and medical services. Beyond generic safety filters, enterprises require reliable mechanisms to detect policy violations within their regulatory and opera- tional frameworks, where breaches can trigger legal and repu- tational risks. Existing content moderation frameworks, such as guardrails, remain largely confined to the safety domain and lack the robustness to capture nuanced organizational policies. LLM-as-a-judge and fine-tuning approaches, though flexible, introduce significant latency and lack interpretabil- ity. To address these limitations, we propose a training-free and efficient method that treats policy violation detection as an out-of-distribution (OOD) detection problem. Inspired by whitening techniques, we apply a linear transformation to decorrelate the model’s hidden activations and standardize them to zero mean and unit variance, yielding near-identity covariance matrix. In this transformed space, we use the Eu- clidean norm as a compliance score to detect policy viola- tions. The method requires only the policy text and a small number of illustrative samples, which makes it light-weight and easily deployable. On a challenging policy benchmark, our approach achieves state-of-the-art results, surpassing both existing guardrails and fine-tuned reasoning models. This work provides organizations with a practical and statistically grounded framework for policy-aware oversight of LLMs, ad- vancing the broader goal of deployable AI governance. Code is available at: https://tinyurl.com/policy-violation-detection",
    "keywords": []
  },
  {
    "article_id": "2512.04025v1_PSA_Pyramid_Sparse_Attention_for_Efficient_Video_Understanding_and_Generation",
    "title": "2512.04025v1 PSA Pyramid Sparse Attention for Efficient Video Understanding and Generation",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.04025v1_PSA_Pyramid_Sparse_Attention_for_Efficient_Video_Understanding_and_Generation.pdf",
    "url": "http://arxiv.org/abs/2512.04025v1_PSA_Pyramid_Sparse_Attention_for_Efficient_Video_Understanding_and_Generation",
    "pdf_url": "https://arxiv.org/pdf/2512.04025v1_PSA_Pyramid_Sparse_Attention_for_Efficient_Video_Understanding_and_Generation",
    "file_size_mb": 24.99,
    "abstract": "Attention mechanisms are the core of foundation models, but their quadratic complexity remains a critical bottleneck for scaling. This challenge has driven the development of efficient attention mechanisms, with sparsity emerging as the dom- inant paradigm. Current methods typically re- tain or discard entire key–value blocks with bi- nary masks, resulting in substantial information loss under high sparsity. To mitigate this gap, we present Pyramid Sparse Attention (PSA), a versatile module applicable to both video under- standing and generation tasks. Instead of binary masking, PSA introduces multi-level pooled KV representations, enabling finer mask granularity. Specifically, each query block dynamically allo- cates lower pooling levels to critical KV blocks and higher levels to less important ones, creating an informative interpolation between full reten- tion and complete pruning. This design, anal- ogous to fixed-point quantization and classical feature pyramid networks in computer vision, ef- fectively mitigates information loss while preserv- ing computational efficiency under a low compute budget. It works with a native, hardware-friendly kernel that leverages decoupled block-tile design to ensure efficient execution. Across video un- derstanding and generation benchmarks, PSA pre- serves contextual information and visual fidelity, consistently outperforming or achieving compa- rable performance over existing sparse attention baselines with superior efficiency–quality trade- offs. Our code and model weights are publicly available at: http://ziplab.co/PSA *Equal contribution. 1ZIP Lab, Zhejiang University. Email: Xiaolong Li <xiaolong.ziplab@gmail.com>, Youping Gu <youpgu71@gmail.com>, Xi Lin <erix025@outlook.com>, Weijie Wang <wangweijie@zju.edu.cn>, Bohan Zhuang <bo- han.zhuang@gmail.com>. Figure 1. Comparison of attention mechanisms under identical compute budget. All methods use the same input Q, K, and V tensors extracted from Wan2.1–1.3B (Wan et al., 2025) denoising process. Computation Pattern (top-left two panels): Normalized block-wise FLOPs distribution. The two panels plot query blocks on the horizontal axis and key blocks on the vertical axis. Despite identical FLOPs (20% full), the proposed Pyramid Sparse Atten- tion (PSA) allows each query block to attend to a much larger portion of KV blocks (70% active regions), whereas Block Sparse Attention (BSA) (Dao et al., 2022; Zhang et al., 2025a; Xu et al., 2025) restricts each query to only a narrow subset of KV blocks (20% active regions), concentrating FLOPs in limited areas. At- tention Output (bottom row): Resulting attention visualizations. PSA closely matches the Full Attention baseline with minimal relative error (< 3%), while BSA shows noticeable distortions due to aggressive pruning.",
    "keywords": []
  },
  {
    "article_id": "2512.04044v1_MarkTune_Improving_the_Quality-Detectability_Trade-off_in_Open-Weight_LLM_Watermarking",
    "title": "2512.04044v1 MarkTune Improving the Quality-Detectability Trade-off in Open-Weight LLM Watermarking",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.04044v1_MarkTune_Improving_the_Quality-Detectability_Trade-off_in_Open-Weight_LLM_Watermarking.pdf",
    "url": "http://arxiv.org/abs/2512.04044v1_MarkTune_Improving_the_Quality-Detectability_Trade-off_in_Open-Weight_LLM_Watermarking",
    "pdf_url": "https://arxiv.org/pdf/2512.04044v1_MarkTune_Improving_the_Quality-Detectability_Trade-off_in_Open-Weight_LLM_Watermarking",
    "file_size_mb": 1.07,
    "abstract": "Watermarking aims to embed hidden signals in generated text that can be reliably detected when given access to a secret key. Open-weight language models pose acute challenges for such watermarking schemes because the inference-time interventions that dominate contemporary approaches cannot be enforced once model weights are public. Existing watermaking techniques for open-weight models, such as the recently proposed GaussMark, typically rely on small modifications to model weights, which can yield signals detectable to those equipped with a secret key, but achieving detection power comparable to inference-time watermarks generally requires weight perturbations that noticeably reduce generation quality. We introduce MarkTune, a theoretically principled, on-policy fine-tuning framework that treats the GaussMark signal as a reward while simultaneously regularizing against degradation in text quality. We derive MarkTune as an improvement on GaussMark and demonstrate that MarkTune consistently improves the quality-detectability trade-off over GaussMark by steering finer-grained, watermark-aware weight updates within the model’s representation space while preserving generation quality. Empirically, we show that MarkTune pushes the quality-detectability frontier of GaussMark close to that of inference-time watermarking, remains robust to paraphrasing and fine-tuning attacks, and exhibits strong generalization: a model fine-tuned on one dataset retains substantial watermark detection power on unseen datasets. Together, these results establish MarkTune as a general strategy for embedding robust, high-quality watermarks into open-weight LMs.",
    "keywords": []
  },
  {
    "article_id": "2512.04099v1_Partial_multivariate_transformer_as_a_tool_for_cryptocurrencies_time_series_prediction",
    "title": "2512.04099v1 Partial multivariate transformer as a tool for cryptocurrencies time series prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.04099v1_Partial_multivariate_transformer_as_a_tool_for_cryptocurrencies_time_series_prediction.pdf",
    "url": "http://arxiv.org/abs/2512.04099v1_Partial_multivariate_transformer_as_a_tool_for_cryptocurrencies_time_series_prediction",
    "pdf_url": "https://arxiv.org/pdf/2512.04099v1_Partial_multivariate_transformer_as_a_tool_for_cryptocurrencies_time_series_prediction",
    "file_size_mb": 0.3,
    "abstract": "—Forecasting cryptocurrency prices is hindered by extreme volatility and a methodological dilemma be- tween information-scarce univariate models and noise-prone full-multivariate models. This paper investigates a partial- multivariate approach to balance this trade-off, hypothesizing that a strategic subset of features offers superior predictive power. We apply the Partial-Multivariate Transformer (PMformer) to forecast daily returns for BTCUSDT and ETHUSDT, bench- marking it against eleven classical and deep learning models. Our empirical results yield two primary contributions. First, we demonstrate that the partial-multivariate strategy achieves significant statistical accuracy, effectively balancing informative signals with noise. Second, we experiment and discuss an observ- able disconnect between this statistical performance and practi- cal trading utility; lower prediction error did not consistently translate to higher financial returns in simulations. This finding challenges the reliance on traditional error metrics and highlights the need to develop evaluation criteria more aligned with real- world financial objectives. Index Terms—Time series forecasting, Cryptocurrencies, Transformer, Feature selection, Partial multivariate",
    "keywords": []
  },
  {
    "article_id": "2512.04302v1_Towards_better_dense_rewards_in_Reinforcement_Learning_Applications",
    "title": "2512.04302v1 Towards better dense rewards in Reinforcement Learning Applications",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.04302v1_Towards_better_dense_rewards_in_Reinforcement_Learning_Applications.pdf",
    "url": "http://arxiv.org/abs/2512.04302v1_Towards_better_dense_rewards_in_Reinforcement_Learning_Applications",
    "pdf_url": "https://arxiv.org/pdf/2512.04302v1_Towards_better_dense_rewards_in_Reinforcement_Learning_Applications",
    "file_size_mb": 1.88,
    "abstract": null,
    "keywords": []
  },
  {
    "article_id": "2512.04559v1_Diffusion_Fine-Tuning_via_Reparameterized_Policy_Gradient_of_the_Soft_Q-Function",
    "title": "2512.04559v1 Diffusion Fine-Tuning via Reparameterized Policy Gradient of the Soft Q-Function",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.04559v1_Diffusion_Fine-Tuning_via_Reparameterized_Policy_Gradient_of_the_Soft_Q-Function.pdf",
    "url": "http://arxiv.org/abs/2512.04559v1_Diffusion_Fine-Tuning_via_Reparameterized_Policy_Gradient_of_the_Soft_Q-Function",
    "pdf_url": "https://arxiv.org/pdf/2512.04559v1_Diffusion_Fine-Tuning_via_Reparameterized_Policy_Gradient_of_the_Soft_Q-Function",
    "file_size_mb": 39.95,
    "abstract": "Diffusion models excel at generating high-likelihood samples but often require alignment with downstream objectives. Existing fine-tuning methods for dif- fusion models significantly suffer from reward over-optimization, resulting in high-reward but unnatural samples and degraded diversity. To mitigate over- optimization, we propose Soft Q-based Diffusion Finetuning (SQDF), a novel KL-regularized RL method for diffusion alignment that applies a reparameterized policy gradient of a training-free, differentiable estimation of the soft Q-function. SQDF is further enhanced with three innovations: a discount factor for proper credit assignment in the denoising process, the integration of consistency models to refine Q-function estimates, and the use of an off-policy replay buffer to im- prove mode coverage and manage the reward-diversity trade-off. Our experiments demonstrate that SQDF achieves superior target rewards while preserving diver- sity in text-to-image alignment. Furthermore, in online black-box optimization, SQDF attains high sample efficiency while maintaining naturalness and diversity. Our code is available at https://github.com/Shin-woocheol/SQDF.",
    "keywords": []
  },
  {
    "article_id": "2512.04711v1_Large_Speech_Model_Enabled_Semantic_Communication",
    "title": "2512.04711v1 Large Speech Model Enabled Semantic Communication",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.04711v1_Large_Speech_Model_Enabled_Semantic_Communication.pdf",
    "url": "http://arxiv.org/abs/2512.04711v1_Large_Speech_Model_Enabled_Semantic_Communication",
    "pdf_url": "https://arxiv.org/pdf/2512.04711v1_Large_Speech_Model_Enabled_Semantic_Communication",
    "file_size_mb": 3.39,
    "abstract": "—Existing speech semantic communication systems mainly based on Joint Source-Channel Coding (JSCC) archi- tectures have demonstrated impressive performance, but their effectiveness remains limited by model structures specifically de- signed for particular tasks and datasets. Recent advances indicate that generative large models pre-trained on massive datasets, can achieve outstanding performance arexhibit exceptional per- formance across diverse downstream tasks with minimal fine- tuning. To exploit the rich semantic knowledge embedded in large models and enable adaptive transmission over lossy channels, we propose a Large Speech Model enabled Semantic Commu- nication (LargeSC) system. Simultaneously achieving adaptive compression and robust transmission over lossy channels remains challenging, requiring trade-offs among compression efficiency, speech quality, and latency. In this work, we employ the Mimi as a speech codec, converting speech into discrete tokens compatible with existing network architectures. We propose an adaptive controller module that enables adaptive transmission and in- band Unequal Error Protection (UEP), dynamically adjusting to both speech content and packet loss probability under band- width constraints. Additionally, we employ Low-Rank Adaptation (LoRA) to finetune the Moshi foundation model for generative recovery of lost speech tokens. Simulation results show that the proposed system supports bandwidths ranging from 550 bps to 2.06 kbps, outperforms conventional baselines in speech quality under high packet loss rates and achieves an end-to-end latency of approximately 460 ms, thereby demonstrating its potential for real-time deployment.",
    "keywords": [
      "Semantic Communication",
      "large model",
      "adaptive"
    ]
  },
  {
    "article_id": "2512.05033v2_Arbitrage_Efficient_Reasoning_via_Advantage-Aware_Speculation",
    "title": "2512.05033v2 Arbitrage Efficient Reasoning via Advantage-Aware Speculation",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.05033v2_Arbitrage_Efficient_Reasoning_via_Advantage-Aware_Speculation.pdf",
    "url": "http://arxiv.org/abs/2512.05033v2_Arbitrage_Efficient_Reasoning_via_Advantage-Aware_Speculation",
    "pdf_url": "https://arxiv.org/pdf/2512.05033v2_Arbitrage_Efficient_Reasoning_via_Advantage-Aware_Speculation",
    "file_size_mb": 1.73,
    "abstract": "Modern Large Language Models achieve impressive reasoning capabilities with long Chain of Thoughts, but they incur substantial computational cost during inference, and this motivates techniques to improve the performance-cost ratio. Among these techniques, Speculative Decoding accelerates inference by employing a fast but inaccurate draft model to auto-regressively propose tokens, which are then verified in parallel by a more capable target model. How- ever, due to unnecessary rejections caused by token mismatches in semantically equivalent steps, traditional token- level Speculative Decoding struggles in reasoning tasks. Although recent works have shifted to step-level semantic verification, which improve efficiency by accepting or rejecting entire reasoning steps, existing step-level methods still regenerate many rejected steps with little improvement, wasting valuable target compute. To address this challenge, we propose ARBITRAGE, a novel step-level speculative generation framework that routes generation dynamically based on the relative advantage between draft and target models. Instead of applying a fixed acceptance threshold, ARBITRAGE uses a lightweight router trained to predict when the target model is likely to produce a meaningfully better step. This routing approximates an ideal ARBITRAGE ORACLE that always chooses the higher-quality step, achieving near-optimal efficiency–accuracy trade-offs. Across multiple mathematical reasoning benchmarks, ARBI- TRAGE consistently surpasses prior step-level SD baselines, reducing inference latency by up to ∼2× at matched accuracy. Our code is available at https://github.com/SqueezeAILab/Arbitrage",
    "keywords": []
  },
  {
    "article_id": "2512.05288v1_Beyond_Detection_A_Comprehensive_Benchmark_and_Study_on_Representation_Learning_for_Fine-Grained_Web",
    "title": "2512.05288v1 Beyond Detection A Comprehensive Benchmark and Study on Representation Learning for Fine-Grained Web",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.05288v1_Beyond_Detection_A_Comprehensive_Benchmark_and_Study_on_Representation_Learning_for_Fine-Grained_Web.pdf",
    "url": "http://arxiv.org/abs/2512.05288v1_Beyond_Detection_A_Comprehensive_Benchmark_and_Study_on_Representation_Learning_for_Fine-Grained_Web",
    "pdf_url": "https://arxiv.org/pdf/2512.05288v1_Beyond_Detection_A_Comprehensive_Benchmark_and_Study_on_Representation_Learning_for_Fine-Grained_Web",
    "file_size_mb": 2.54,
    "abstract": "Malicious WebShells pose a significant and evolving threat by compromising critical digital infrastructures and endan- gering public services in sectors such as healthcare and fi- nance. While the research community has made significant progress in WebShell detection (i.e., distinguishing malicious samples from benign ones), we argue that it is time to tran- sition from passive detection to in-depth analysis and proac- tive defense. One promising direction is the automation of WebShell family classification, which involves identifying the specific malware lineage in order to understand an adver- sary’s tactics and enable a precise, rapid response. This cru- cial task, however, remains a largely unexplored area that cur- rently relies on slow, manual expert analysis. To address this gap, we present the first systematic study to automate Web- Shell family classification. Our method begins with extract- ing dynamic function call traces to capture inherent behav- iors that are resistant to common encryption and obfuscation. To enhance the scale and diversity of our dataset for a more stable evaluation, we augment these real-world traces with new variants synthesized by Large Language Models. These augmented traces are then abstracted into sequences, graphs, and trees, providing a foundation to benchmark a comprehen- sive suite of representation methods. Our evaluation spans classic sequence-based embeddings (CBOW, GloVe), trans- formers (BERT, SimCSE), and a range of structure-aware algorithms, including Graph Kernels, Graph Edit Distance, Graph2Vec, and various Graph Neural Networks. Through extensive experiments on four real-world, family-annotated datasets under both supervised and unsupervised settings, we establish a robust baseline and provide practical insights into the most effective combinations of data abstractions, repre- sentation models, and learning paradigms for this challenge. This foundational work is a crucial step toward automating threat intelligence, accelerating incident response, and ulti- mately enhancing the resilience of the digital services that society depends on.",
    "keywords": []
  },
  {
    "article_id": "2512.05343v1_SpaceControl_Introducing_Test-Time_Spatial_Control_to_3D_Generative_Modeling",
    "title": "2512.05343v1 SpaceControl Introducing Test-Time Spatial Control to 3D Generative Modeling",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.05343v1_SpaceControl_Introducing_Test-Time_Spatial_Control_to_3D_Generative_Modeling.pdf",
    "url": "http://arxiv.org/abs/2512.05343v1_SpaceControl_Introducing_Test-Time_Spatial_Control_to_3D_Generative_Modeling",
    "pdf_url": "https://arxiv.org/pdf/2512.05343v1_SpaceControl_Introducing_Test-Time_Spatial_Control_to_3D_Generative_Modeling",
    "file_size_mb": 5.94,
    "abstract": "Generative methods for 3D assets have recently achieved remarkable progress, yet providing intuitive and precise control over the object geometry remains a key challenge. Existing approaches predominantly rely on text or image prompts, which often fall short in geometric specificity: language can be ambiguous, and images are cumbersome to edit. In this work, we introduce SPACECONTROL, a training-free test-time method for explicit spatial control of 3D generation. Our approach accepts a wide range of geometric inputs, from coarse primitives to de- tailed meshes, and integrates seamlessly with modern pre-trained generative mod- els without requiring any additional training. A controllable parameter lets users trade off between geometric fidelity and output realism. Extensive quantitative evaluation and user studies demonstrate that SPACECONTROL outperforms both training-based and optimization-based baselines in geometric faithfulness while preserving high visual quality. Finally, we present an interactive user interface that enables online editing of superquadrics for direct conversion into textured 3D assets, facilitating practical deployment in creative workflows. Find our project page at https://spacecontrol3d.github.io/.",
    "keywords": []
  },
  {
    "article_id": "2512.05402v1_Smart_Timing_for_Mining_A_Deep_Learning_Framework_for_Bitcoin_Hardware_ROI_Prediction",
    "title": "2512.05402v1 Smart Timing for Mining A Deep Learning Framework for Bitcoin Hardware ROI Prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.05402v1_Smart_Timing_for_Mining_A_Deep_Learning_Framework_for_Bitcoin_Hardware_ROI_Prediction.pdf",
    "url": "http://arxiv.org/abs/2512.05402v1_Smart_Timing_for_Mining_A_Deep_Learning_Framework_for_Bitcoin_Hardware_ROI_Prediction",
    "pdf_url": "https://arxiv.org/pdf/2512.05402v1_Smart_Timing_for_Mining_A_Deep_Learning_Framework_for_Bitcoin_Hardware_ROI_Prediction",
    "file_size_mb": 0.89,
    "abstract": ". Bitcoin mining hardware acquisition requires strategic tim- ing due to volatile markets, rapid technological obsolescence, and protocol- driven revenue cycles. Despite mining’s evolution into a capital-intensive industry, there is little guidance on when to purchase new Application- Specific Integrated Circuit (ASIC) hardware, and no prior computa- tional frameworks address this decision problem. We address this gap by formulating hardware acquisition as a time series classification task, predicting whether purchasing ASIC machines yields profitable (Return on Investment (ROI) ≥1), marginal (0 < ROI < 1), or unprofitable (ROI ≤0) returns within one year. We propose MineROI-Net, an open source Transformer-based architecture designed to capture multi- scale temporal patterns in mining profitability. Evaluated on data from 20 ASIC miners released between 2015 and 2024 across diverse market regimes, MineROI-Net outperforms LSTM-based and TSLANet base- lines, achieving 83.7% accuracy and 83.1% macro F1-score. The model demonstrates strong economic relevance, achieving 93.6% precision in detecting unprofitable periods and 98.5% precision for profitable ones, while avoiding misclassification of profitable scenarios as unprofitable and vice versa. These results indicate that MineROI-Net offers a practical, data-driven tool for timing mining hardware acquisitions, potentially re- ducing financial risk in capital-intensive mining operations. The model is available through https://github.com/AMAAI-Lab/MineROI-Net.",
    "keywords": [
      "Bitcoin Mining",
      "Deep Learning",
      "Decision Making",
      "Hard-"
    ]
  },
  {
    "article_id": "2512.05734v1_KANFormer_for_Predicting_Fill_Probabilities_via_Survival_Analysis_in_Limit_Order_Books",
    "title": "2512.05734v1 KANFormer for Predicting Fill Probabilities via Survival Analysis in Limit Order Books",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.05734v1_KANFormer_for_Predicting_Fill_Probabilities_via_Survival_Analysis_in_Limit_Order_Books.pdf",
    "url": "http://arxiv.org/abs/2512.05734v1_KANFormer_for_Predicting_Fill_Probabilities_via_Survival_Analysis_in_Limit_Order_Books",
    "pdf_url": "https://arxiv.org/pdf/2512.05734v1_KANFormer_for_Predicting_Fill_Probabilities_via_Survival_Analysis_in_Limit_Order_Books",
    "file_size_mb": 1.81,
    "abstract": ". This paper introduces KANFormer, a novel deep-learning- based model for predicting the time-to-fill of limit orders by leverag- ing both market- and agent-level information. KANFormer combines a Dilated Causal Convolutional network with a Transformer encoder, en- hanced by Kolmogorov–Arnold Networks (KANs), which improve non- linear approximation. Unlike existing models that rely solely on a series of snapshots of the limit order book, KANFormer integrates the actions of agents related to LOB dynamics and the position of the order in the queue to more effectively capture patterns related to execution likeli- hood. We evaluate the model using CAC 40 index futures data with labeled orders. The results show that KANFormer outperforms existing works in both calibration (Right-Censored Log-Likelihood, Integrated Brier Score) and discrimination (C-index, time-dependent AUC). We further analyze feature importance over time using SHAP (SHapley Ad- ditive exPlanations). Our results highlight the benefits of combining rich market signals with expressive neural architectures to achieve accurate and interpretabl predictions of fill probabilities.",
    "keywords": [
      "Limit order book",
      "Survival analysis",
      "Fill probability predic-"
    ]
  },
  {
    "article_id": "2512.05868v1_Predicting_Price_Movements_in_High-Frequency_Financial_Data_with_Spiking_Neural_Networks",
    "title": "2512.05868v1 Predicting Price Movements in High-Frequency Financial Data with Spiking Neural Networks",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.05868v1_Predicting_Price_Movements_in_High-Frequency_Financial_Data_with_Spiking_Neural_Networks.pdf",
    "url": "http://arxiv.org/abs/2512.05868v1_Predicting_Price_Movements_in_High-Frequency_Financial_Data_with_Spiking_Neural_Networks",
    "pdf_url": "https://arxiv.org/pdf/2512.05868v1_Predicting_Price_Movements_in_High-Frequency_Financial_Data_with_Spiking_Neural_Networks",
    "file_size_mb": 1.38,
    "abstract": "—Modern high-frequency trading (HFT) environ- ments are characterized by sudden price spikes that present both risk and opportunity, but conventional financial models often fail to capture the required fine temporal structure. Spiking Neural Networks (SNNs) offer a biologically inspired framework well- suited to these challenges due to their natural ability to process discrete events and preserve millisecond-scale timing. This work investigates the application of SNNs to high-frequency price-spike forecasting, enhancing performance via robust hyperparameter tuning with Bayesian Optimization (BO). This work converts high-frequency stock data into spike trains and evaluates three architectures: an established unsupervised STDP-trained SNN, a novel SNN with explicit inhibitory competition, and a supervised backpropagation network. BO was driven by a novel objective, Penalized Spike Accuracy (PSA), designed to ensure a network’s predicted price spike rate aligns with the empirical rate of price events. Simulated trading demonstrated that models optimized with PSA consistently outperformed their Spike Accuracy (SA)- tuned counterparts and baselines. Specifically, the extended SNN model with PSA achieved the highest cumulative return (76.8%) in simple backtesting, significantly surpassing the supervised alternative (42.5% return). These results validate the potential of spiking networks, when robustly tuned with task-specific objectives, for effective price spike forecasting in HFT.",
    "keywords": [
      "Spiking Neural Networks",
      "Computational Fi-"
    ]
  },
  {
    "article_id": "2512.05962v1_Whatever_Remains_Must_Be_True_Filtering_Drives_Reasoning_in_LLMs_Shaping_Diversity",
    "title": "2512.05962v1 Whatever Remains Must Be True Filtering Drives Reasoning in LLMs Shaping Diversity",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.05962v1_Whatever_Remains_Must_Be_True_Filtering_Drives_Reasoning_in_LLMs_Shaping_Diversity.pdf",
    "url": "http://arxiv.org/abs/2512.05962v1_Whatever_Remains_Must_Be_True_Filtering_Drives_Reasoning_in_LLMs_Shaping_Diversity",
    "pdf_url": "https://arxiv.org/pdf/2512.05962v1_Whatever_Remains_Must_Be_True_Filtering_Drives_Reasoning_in_LLMs_Shaping_Diversity",
    "file_size_mb": 2.34,
    "abstract": "Reinforcement Learning (RL) has become the de facto standard for tuning LLMs to solve tasks involving reasoning. However, growing evidence shows that models trained in such way often suffer from a significant loss in diversity. We argue that this arises because RL implicitly optimizes the “mode- seeking” or “zero-forcing” Reverse KL to a target distribution causing the model to concentrate mass on certain high-probability regions of the target while neglecting others. In this work, we instead begin from an explicit target distribution, obtained by filtering out incorrect answers while preserving the relative probabilities of correct ones. Starting from a pre-trained LLM, we approximate this target distribution using the 𝛼-divergence family, which unifies prior approaches and enables direct control of the precision–diversity trade-off by interpolating between mode-seeking and mass-covering divergences. On a Lean theorem-proving benchmark, our method achieves state-of-the-art performance along the coverage–precision Pareto frontier, outperforming all prior methods on the coverage axis.",
    "keywords": []
  },
  {
    "article_id": "2512.05976v1_Physics_Enhanced_Deep_Surrogates_for_the_Phonon_Boltzmann_Transport_Equation",
    "title": "2512.05976v1 Physics Enhanced Deep Surrogates for the Phonon Boltzmann Transport Equation",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.05976v1_Physics_Enhanced_Deep_Surrogates_for_the_Phonon_Boltzmann_Transport_Equation.pdf",
    "url": "http://arxiv.org/abs/2512.05976v1_Physics_Enhanced_Deep_Surrogates_for_the_Phonon_Boltzmann_Transport_Equation",
    "pdf_url": "https://arxiv.org/pdf/2512.05976v1_Physics_Enhanced_Deep_Surrogates_for_the_Phonon_Boltzmann_Transport_Equation",
    "file_size_mb": 1.63,
    "abstract": "Designing materials with controlled heat flow at the nano-scale is central to advances in microelec- tronics, thermoelectrics, and energy-conversion technologies. At these scales, phonon transport follows the Boltzmann Transport Equation (BTE), which captures non-diffusive (ballistic) effects but is too costly to solve repeatedly in inverse-design loops. Existing surrogate approaches trade speed for accuracy: fast macroscopic solvers can overestimate conductivities by hundreds of percent, while recent data-driven opera- tor learners often require thousands of high-fidelity simulations. This creates a need for a fast, data-efficient surrogate that remains reliable across ballistic and diffusive regimes. We introduce a Physics-Enhanced Deep Surrogate (PEDS) that combines a differentiable Fourier solver with a neural generator and couples it with uncertainty-driven active learning. The Fourier solver acts as a physical inductive bias, while the network learns geometry-dependent corrections and a mixing coefficient that interpolates between macroscopic and nano-scale behavior. PEDS reduces training-data requirements by up to 70% compared with purely data-driven baselines, achieves roughly 5% fractional error with only 300 high-fidelity BTE simulations, and enables efficient design of porous geometries spanning 12–85 W m−1 K−1 with average design errors of 4%. The learned mixing parameter recovers the ballistic–diffusive transition and improves the out-of-distribution robustness. These results show that embedding simple, differentiable low-fidelity physics dramatically increases the surrogate data-efficiency and interpretability, making repeated PDE-constrained optimization practical for nano-scale thermal-materials design.",
    "keywords": []
  },
  {
    "article_id": "2512.06112v2_WAM-Flow_Parallel_Coarse-to-Fine_Motion_Planning_via_Discrete_Flow_Matching_for_Autonomous_Driving",
    "title": "2512.06112v2 WAM-Flow Parallel Coarse-to-Fine Motion Planning via Discrete Flow Matching for Autonomous Driving",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.06112v2_WAM-Flow_Parallel_Coarse-to-Fine_Motion_Planning_via_Discrete_Flow_Matching_for_Autonomous_Driving.pdf",
    "url": "http://arxiv.org/abs/2512.06112v2_WAM-Flow_Parallel_Coarse-to-Fine_Motion_Planning_via_Discrete_Flow_Matching_for_Autonomous_Driving",
    "pdf_url": "https://arxiv.org/pdf/2512.06112v2_WAM-Flow_Parallel_Coarse-to-Fine_Motion_Planning_via_Discrete_Flow_Matching_for_Autonomous_Driving",
    "file_size_mb": 18.94,
    "abstract": "We introduce WAM-Flow, a vision–language–action (VLA) model that casts ego-trajectory planning as discrete flow matching over a structured token space. In contrast to autoregressive decoders, WAM-Flow performs fully paral- lel, bidirectional denoising, enabling coarse-to-fine refine- ment with a tunable compute–accuracy trade-off. Specif- ically, the approach combines a metric-aligned numeri- cal tokenizer that preserves scalar geometry via triplet- margin learning, a geometry-aware flow objective and a simulator-guided GRPO alignment that integrates safety, ego progress, and comfort rewards while retaining par- ∗: Equal contribution. \u0000: Corresponding authors. {xuyf25, cuijh25}@m.fudan.edu.cn siyuzhu@fudan.edu.cn allel generation. A multi-stage adaptation converts a pre-trained auto-regressive backbone (Janus-1.5B) from causal decoding to non-causal flow model and strength- ens road-scene competence through continued multimodal pretraining. Thanks to the inherent nature of consistency model training and parallel decoding inference, WAM-Flow achieves superior closed-loop performance against autore- gressive and diffusion-based VLA baselines, with 1-step in- ference attaining 89.1 PDMS and 5-step inference reaching 90.3 PDMS on NAVSIM v1 benchmark. These results estab- lish discrete flow matching as a new promising paradigm for end-to-end autonomous driving. The code will be publicly available soon.",
    "keywords": []
  },
  {
    "article_id": "2512.06143v1_gp2Scale_A_Class_of_Compactly-Supported_Non-Stationary_Kernels_and_Distributed_Computing_for_Exact_G",
    "title": "2512.06143v1 gp2Scale A Class of Compactly-Supported Non-Stationary Kernels and Distributed Computing for Exact G",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.06143v1_gp2Scale_A_Class_of_Compactly-Supported_Non-Stationary_Kernels_and_Distributed_Computing_for_Exact_G.pdf",
    "url": "http://arxiv.org/abs/2512.06143v1_gp2Scale_A_Class_of_Compactly-Supported_Non-Stationary_Kernels_and_Distributed_Computing_for_Exact_G",
    "pdf_url": "https://arxiv.org/pdf/2512.06143v1_gp2Scale_A_Class_of_Compactly-Supported_Non-Stationary_Kernels_and_Distributed_Computing_for_Exact_G",
    "file_size_mb": 0.85,
    "abstract": "Despite a large corpus of recent work on scaling up Gaussian processes, a stubborn trade-off between computational speed, prediction and uncertainty quantification accuracy, and customizability persists. This is because the vast majority of existing methodologies exploit various levels of approximations that lower accuracy and limit the flexibility of kernel and noise-model designs — an unacceptable drawback at a time when expressive non-stationary kernels are on the rise in many fields. Here, we propose a methodology we term gp2Scale that scales exact Gaussian processes to more than 10 million data points without relying on inducing points, kernel interpolation, or neighborhood-based approximations, and instead leverag- ing the existing capabilities of a GP: its kernel design. Highly flexible, compactly supported, and non-stationary kernels lead to the identification of naturally oc- curring sparse structure in the covariance matrix, which is then exploited for the calculations of the linear system solution and the log-determinant for training. We demonstrate our method’s functionality on several real-world datasets and compare it with state-of-the-art approximation algorithms. Although we show superior approximation performance in many cases, the method’s real power lies in its agnosticism toward arbitrary GP customizations — core kernel design, noise, and mean functions — and the type of input space, making it optimally suited for modern Gaussian process applications.",
    "keywords": []
  },
  {
    "article_id": "2512.06607v1_A_Fast_and_Effective_Solution_to_the_Problem_of_Look-ahead_Bias_in_LLMs",
    "title": "2512.06607v1 A Fast and Effective Solution to the Problem of Look-ahead Bias in LLMs",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.06607v1_A_Fast_and_Effective_Solution_to_the_Problem_of_Look-ahead_Bias_in_LLMs.pdf",
    "url": "http://arxiv.org/abs/2512.06607v1_A_Fast_and_Effective_Solution_to_the_Problem_of_Look-ahead_Bias_in_LLMs",
    "pdf_url": "https://arxiv.org/pdf/2512.06607v1_A_Fast_and_Effective_Solution_to_the_Problem_of_Look-ahead_Bias_in_LLMs",
    "file_size_mb": 0.49,
    "abstract": "Applying LLMs to predictive tasks in finance is challenging due to look-ahead bias resulting from their training on long time-series data. This precludes the backtests typically employed in finance since retraining frontier models from scratch with a specific knowledge cutoff is prohibitive. In this paper, we introduce a fast, effective, and low-cost alternative. Our method guides generation at inference time by adjusting the logits of a large base model using a pair of smaller, specialized models—one fine-tuned on information to be forgotten and another on information to be retained. We demonstrate that our method effectively removes both verbatim and semantic knowledge, corrects biases, and outperforms prior methods.",
    "keywords": []
  },
  {
    "article_id": "2512.06630v1_Quantum_Temporal_Convolutional_Neural_Networks_for_Cross-Sectional_Equity_Return_Prediction_A_Compar",
    "title": "2512.06630v1 Quantum Temporal Convolutional Neural Networks for Cross-Sectional Equity Return Prediction A Compar",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.06630v1_Quantum_Temporal_Convolutional_Neural_Networks_for_Cross-Sectional_Equity_Return_Prediction_A_Compar.pdf",
    "url": "http://arxiv.org/abs/2512.06630v1_Quantum_Temporal_Convolutional_Neural_Networks_for_Cross-Sectional_Equity_Return_Prediction_A_Compar",
    "pdf_url": "https://arxiv.org/pdf/2512.06630v1_Quantum_Temporal_Convolutional_Neural_Networks_for_Cross-Sectional_Equity_Return_Prediction_A_Compar",
    "file_size_mb": 10.63,
    "abstract": "Quantum machine learning offers a promising pathway for enhancing stock market prediction, particularly under complex, noisy, and highly dynamic financial environments. However, many classical forecasting models struggle with noisy input, regime shifts, and limited generalization capacity. To address these challenges, we propose a Quantum Temporal Convolutional Neural Network (QTCNN) that combines a classical temporal encoder with parameter-efficient quantum convolution circuits for cross-sectional equity return prediction. The temporal encoder extracts multi-scale patterns from sequential technical indicators, while the quantum processing leverages superposition and entanglement to enhance feature representation and suppress overfitting. We conduct a comprehensive benchmarking study on the JPX Tokyo Stock Exchange dataset and evaluate predictions through long-short portfolio construction using out-of-sample Sharpe ratio as the primary performance metric. QTCNN achieves a Sharpe ratio of 0.538, outperforming the best classical baseline by approximately 72%. These results highlight the practical potential of quantum-enhanced forecasting model, QTCNN, for robust decision-making in quantitative finance.",
    "keywords": [
      "Quantum Machine Learning",
      "Financial Time-Series Forecasting",
      "Temporal Convolutional"
    ]
  },
  {
    "article_id": "2512.06639v1_Learning_to_Hedge_Swaptions",
    "title": "2512.06639v1 Learning to Hedge Swaptions",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.06639v1_Learning_to_Hedge_Swaptions.pdf",
    "url": "http://arxiv.org/abs/2512.06639v1_Learning_to_Hedge_Swaptions",
    "pdf_url": "https://arxiv.org/pdf/2512.06639v1_Learning_to_Hedge_Swaptions",
    "file_size_mb": 1.22,
    "abstract": "This paper investigates the deep hedging framework, based on reinforcement learning (RL), for the dynamic hedging of swaptions, contrasting its performance with traditional sensitivity-based rho-hedging. We design agents under three distinct objective functions—mean squared error, downside risk, and Conditional Value-at-Risk—to capture alternative risk preferences and evaluate how these objectives shape hedging styles. Relying on a three-factor arbitrage-free dynamic Nelson-Siegel model for our simulation experiments, our findings show that near-optimal hedging effectiveness is achieved when using two swaps as hedging instruments. Deep hedging strategies dynamically adapt the hedging portfolio’s exposure to risk factors across states of the market. In our experiments, their out-performance over rho- hedging strategies persists even in the presence some of model misspecification. These results highlight RL’s potential to deliver more efficient and resilient swaption hedging strategies. JEL classification: E43, G12.",
    "keywords": [
      "Swaptions",
      "Dynamic Hedging",
      "Deep Reinforcement Learning",
      "Term Structure Models",
      "Risk"
    ]
  },
  {
    "article_id": "2512.06642v1_Masked_Autoencoder_Pretraining_on_Strong-Lensing_Images_for_Joint_Dark-Matter_Model_Classification_a",
    "title": "2512.06642v1 Masked Autoencoder Pretraining on Strong-Lensing Images for Joint Dark-Matter Model Classification a",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.06642v1_Masked_Autoencoder_Pretraining_on_Strong-Lensing_Images_for_Joint_Dark-Matter_Model_Classification_a.pdf",
    "url": "http://arxiv.org/abs/2512.06642v1_Masked_Autoencoder_Pretraining_on_Strong-Lensing_Images_for_Joint_Dark-Matter_Model_Classification_a",
    "pdf_url": "https://arxiv.org/pdf/2512.06642v1_Masked_Autoencoder_Pretraining_on_Strong-Lensing_Images_for_Joint_Dark-Matter_Model_Classification_a",
    "file_size_mb": 0.54,
    "abstract": "Strong gravitational lensing can reveal the influence of dark-matter substructure in galaxies, but analyzing these effects from noisy, low-resolution images poses a significant challenge. In this work, we propose a masked autoencoder (MAE) pretraining strategy on simulated strong-lensing images from the DeepLense ML4SCI benchmark to learn generalizable representations for two downstream tasks: (i) classifying the underlying dark matter model (cold dark matter, axion-like, or no substructure) and (ii) enhancing low- resolution lensed images via super-resolution. We pretrain a Vision Transformer encoder using a masked image modeling objective, then fine-tune the encoder separately for each task. Our results show that MAE pretraining, when combined with appropriate mask ratio tuning, yields a shared encoder that matches or exceeds a ViT trained from scratch. Specifically, at a 90% mask ratio, the fine-tuned classifier achieves macro AUC of 0.968 and accuracy of 88.65%, compared to the scratch baseline (AUC 0.957, accuracy 82.46%). For super-resolution (16 × 16 →64 × 64), the MAE-pretrained model reconstructs images with PSNR ∼33 dB and SSIM 0.961, modestly improving over scratch training. We ablate the MAE mask ratio, revealing a consistent trade-off: higher mask ratios improve classification but slightly degrade reconstruc- tion fidelity. Our findings demonstrate that MAE pretraining on physics-rich simulations provides a flexible, reusable encoder for multiple strong-lensing analysis tasks.",
    "keywords": [
      "masked autoencoder",
      "gravitational lensing",
      "dark matter",
      "super-resolution",
      "Vision Transformer"
    ]
  },
  {
    "article_id": "2512.06648v2_Financial_Fraud_Identification_and_Interpretability_Study_for_Listed_Companies_Based_on_Convolutiona",
    "title": "2512.06648v2 Financial Fraud Identification and Interpretability Study for Listed Companies Based on Convolutiona",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.06648v2_Financial_Fraud_Identification_and_Interpretability_Study_for_Listed_Companies_Based_on_Convolutiona.pdf",
    "url": "http://arxiv.org/abs/2512.06648v2_Financial_Fraud_Identification_and_Interpretability_Study_for_Listed_Companies_Based_on_Convolutiona",
    "pdf_url": "https://arxiv.org/pdf/2512.06648v2_Financial_Fraud_Identification_and_Interpretability_Study_for_Listed_Companies_Based_on_Convolutiona",
    "file_size_mb": 3.66,
    "abstract": null,
    "keywords": []
  },
  {
    "article_id": "2512.06666v1_The_Meta-Learning_Gap_Combining_Hydra_and_Quant_for_Large-Scale_Time_Series_Classification",
    "title": "2512.06666v1 The Meta-Learning Gap Combining Hydra and Quant for Large-Scale Time Series Classification",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.06666v1_The_Meta-Learning_Gap_Combining_Hydra_and_Quant_for_Large-Scale_Time_Series_Classification.pdf",
    "url": "http://arxiv.org/abs/2512.06666v1_The_Meta-Learning_Gap_Combining_Hydra_and_Quant_for_Large-Scale_Time_Series_Classification",
    "pdf_url": "https://arxiv.org/pdf/2512.06666v1_The_Meta-Learning_Gap_Combining_Hydra_and_Quant_for_Large-Scale_Time_Series_Classification",
    "file_size_mb": 0.4,
    "abstract": "Time series classiﬁcation faces a fundamental trade-oﬀbetween accuracy and computational eﬃciency. While comprehensive ensembles like HIVE-COTE 2.0 achieve state-of-the-art accuracy, their 340-hour training time on the UCR bench- mark renders them impractical for large-scale datasets. We investigate whether targeted combinations of two eﬃcient algorithms from complementary paradigms can capture ensemble beneﬁts while maintaining computational feasibility. Com- bining Hydra (competing convolutional kernels) and Quant (hierarchical interval quantiles) across six ensemble conﬁgurations, we evaluate performance on 10 large-scale MONSTER datasets (7,898 to 1,168,774 training instances). Our strongest conﬁguration improves mean accuracy from 0.829 to 0.836, succeeding on 7 of 10 datasets. However, prediction-combination ensembles capture only 11% of theoretical oracle potential, revealing a substantial meta-learning optimiza- tion gap. Feature-concatenation approaches exceeded oracle bounds by learning novel decision boundaries, while prediction-level complementarity shows mod- erate correlation with ensemble gains. The central ﬁnding: the challenge has shifted from ensuring algorithms are diﬀerent to learning how to combine them eﬀectively. Current meta-learning strategies struggle to exploit the complemen- tarity that oracle analysis conﬁrms exists. Improved combination strategies could potentially double or triple ensemble gains across diverse time series classiﬁcation applications.",
    "keywords": [
      "time series classiﬁcation",
      "ensemble methods",
      "stacked generalization"
    ]
  },
  {
    "article_id": "2512.06678v1_GradientSpace_Unsupervised_Data_Clustering_for_Improved_Instruction_Tuning",
    "title": "2512.06678v1 GradientSpace Unsupervised Data Clustering for Improved Instruction Tuning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.06678v1_GradientSpace_Unsupervised_Data_Clustering_for_Improved_Instruction_Tuning.pdf",
    "url": "http://arxiv.org/abs/2512.06678v1_GradientSpace_Unsupervised_Data_Clustering_for_Improved_Instruction_Tuning",
    "pdf_url": "https://arxiv.org/pdf/2512.06678v1_GradientSpace_Unsupervised_Data_Clustering_for_Improved_Instruction_Tuning",
    "file_size_mb": 3.61,
    "abstract": "Instruction tuning is one of the key steps required for adapting large language models (LLMs) to a broad spectrum of downstream applications. However, this procedure is difficult because real-world datasets are rarely homogeneous; they consist of a mixture of diverse information, causing gradient interference, where conflicting gradients pull the model in opposing directions, degrading performance. A common strategy to mitigate this issue is to group data based on semantic or embedding similarity. However, this fails to capture how data influences model parameters during learning. While recent works have attempted to cluster gradients directly, they randomly project gradients into lower dimensions to manage memory, which leads to accuracy loss. Moreover, these methods rely on expert ensembles which necessitates multiple inference passes and expensive on-the-fly gradient computations during inference. To address these limitations, we propose GRADIENTSPACE, a framework that clusters samples directly in full-dimensional gradient space. We introduce an online SVD-based algorithm that operates on LoRA gradients to identify latent skills without the infeasible cost of storing all sample gradients. Each cluster is used to train a specialized LoRA expert along with a lightweight router trained to select the best expert during inference. We show that routing to a single, appropriate expert outperforms expert ensembles used in prior work, while significantly reducing inference latency. Our experiments across mathematical reasoning, code generation, finance, and creative writing tasks demonstrate that GRADIENTSPACE leads to coherent expert specialization and consistent accuracy gains over state-of-the-art clustering methods and finetuning techniques.",
    "keywords": []
  },
  {
    "article_id": "2512.06716v1_Cognitive_Control_Architecture_CCA_A_Lifecycle_Supervision_Framework_for_Robustly_Aligned_AI_Agents",
    "title": "2512.06716v1 Cognitive Control Architecture CCA A Lifecycle Supervision Framework for Robustly Aligned AI Agents",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.06716v1_Cognitive_Control_Architecture_CCA_A_Lifecycle_Supervision_Framework_for_Robustly_Aligned_AI_Agents.pdf",
    "url": "http://arxiv.org/abs/2512.06716v1_Cognitive_Control_Architecture_CCA_A_Lifecycle_Supervision_Framework_for_Robustly_Aligned_AI_Agents",
    "pdf_url": "https://arxiv.org/pdf/2512.06716v1_Cognitive_Control_Architecture_CCA_A_Lifecycle_Supervision_Framework_for_Robustly_Aligned_AI_Agents",
    "file_size_mb": 3.44,
    "abstract": "Autonomous Large Language Model (LLM) agents exhibit significant vulnerabil- ity to Indirect Prompt Injection (IPI) attacks. These attacks hijack agent behavior by polluting external information sources, exploiting fundamental trade-offs be- tween security and functionality in existing defense mechanisms. This leads to malicious and unauthorized tool invocations, diverting agents from their original objectives. The success of complex IPIs reveals a deeper systemic fragility: while current defenses demonstrate some effectiveness, most defense architectures are inherently fragmented. Consequently, they fail to provide full integrity assurance across the entire task execution pipeline, forcing unacceptable multi-dimensional compromises among security, functionality, and efficiency. Our method is pred- icated on a core insight: no matter how subtle an IPI attack, its pursuit of a ma- licious objective will ultimately manifest as a detectable deviation in the action trajectory, distinct from the expected legitimate plan. Based on this, we propose the Cognitive Control Architecture (CCA), a holistic framework achieving full- lifecycle cognitive supervision. CCA constructs an efficient, dual-layered defense system through two synergistic pillars: (i) proactive and preemptive control-flow and data-flow integrity enforcement via a pre-generated ”Intent Graph”; and (ii) an innovative ”Tiered Adjudicator” that, upon deviation detection, initiates deep reasoning based on multi-dimensional scoring, specifically designed to counter complex conditional attacks. Experiments on the AgentDojo benchmark substan- tiate that CCA not only effectively withstands sophisticated attacks that challenge other advanced defense methods but also achieves uncompromised security with notable efficiency and robustness, thereby reconciling the aforementioned multi- dimensional trade-off.",
    "keywords": []
  },
  {
    "article_id": "2512.06944v1_A_Unifying_Human-Centered_AI_Fairness_Framework",
    "title": "2512.06944v1 A Unifying Human-Centered AI Fairness Framework",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.06944v1_A_Unifying_Human-Centered_AI_Fairness_Framework.pdf",
    "url": "http://arxiv.org/abs/2512.06944v1_A_Unifying_Human-Centered_AI_Fairness_Framework",
    "pdf_url": "https://arxiv.org/pdf/2512.06944v1_A_Unifying_Human-Centered_AI_Fairness_Framework",
    "file_size_mb": 2.51,
    "abstract": "The increasing use of Artificial Intelligence (AI) in critical societal domains has amplified concerns about fairness, particularly regarding unequal treatment across sensitive attributes such as race, gender, and socioeconomic status. While there has been substantial work on ensuring AI fairness, navigating trade-offs between competing notions of fairness as well as predictive accuracy remains challenging, which is a barrier to the practical deployment of fair AI systems. To address this, we introduce a unifying human-centered fairness framework that systematically covers eight distinct fairness metrics, formed by combining individual vs. group fairness, infra-marginal vs. intersectional assumptions, and outcome-based vs. equality-of- opportunity (EOO) options, thereby allowing stakeholders to align fairness interventions with their value systems and contextual considerations. The framework uses a consistent and easy to understand formulation for all metrics to reduce the learning curve for non-expert stakeholders. Rather than privileging a single fairness notion, our framework enables stakeholders to assign weights across multiple fairness objectives, reflecting their priorities and values, and enabling multi-stakeholder compromises. We apply this approach to four real-world datasets—the UCI Adult census dataset for income prediction, the COMPAS dataset for criminal recidivism in the justice system, the German Credit dataset for credit risk assessment in financial services, and the MEPS dataset for healthcare utilization—and demonstrate how adjusting weights reveals nuanced trade-offs between different fairness metrics. Finally, through two stakeholder-grounded case studies in judicial decision-making and healthcare, we show how the framework can inform practical and value-sensitive deployment of fair AI systems. ∗Corresponding author. 1 arXiv:2512.06944v1 [cs.LG] 7 Dec 2025",
    "keywords": []
  },
  {
    "article_id": "2512.07142v1_Winning_the_Lottery_by_Preserving_Network_Training_Dynamics_with_Concrete_Ticket_Search",
    "title": "2512.07142v1 Winning the Lottery by Preserving Network Training Dynamics with Concrete Ticket Search",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.07142v1_Winning_the_Lottery_by_Preserving_Network_Training_Dynamics_with_Concrete_Ticket_Search.pdf",
    "url": "http://arxiv.org/abs/2512.07142v1_Winning_the_Lottery_by_Preserving_Network_Training_Dynamics_with_Concrete_Ticket_Search",
    "pdf_url": "https://arxiv.org/pdf/2512.07142v1_Winning_the_Lottery_by_Preserving_Network_Training_Dynamics_with_Concrete_Ticket_Search",
    "file_size_mb": 3.89,
    "abstract": "—The Lottery Ticket Hypothesis asserts the existence of highly sparse, trainable subnetworks (‘winning tickets’) within dense, randomly initialized neural networks. However, state-of- the-art methods of drawing these tickets, like Lottery Ticket Rewinding (LTR), are computationally prohibitive, while more efficient saliency-based Pruning-at-Initialization (PaI) techniques suffer from a significant accuracy-sparsity trade-off and fail basic sanity checks. In this work, we argue that PaI’s reliance on first- order saliency metrics, which ignore inter-weight dependencies, contributes substantially to this performance gap, especially in the sparse regime. To address this, we introduce Concrete Ticket Search (CTS), an algorithm that frames subnetwork discovery as a holistic combinatorial optimization problem. By leveraging a Concrete relaxation of the discrete search space and a novel gradient balancing scheme (GRADBALANCE) to control sparsity, CTS efficiently identifies high-performing subnetworks near initialization without requiring sensitive hyperparameter tuning. Motivated by recent works on lottery ticket training dynamics, we further propose a knowledge distillation-inspired family of pruning objectives, finding that minimizing the reverse Kullback-Leibler divergence between sparse and dense network outputs (CTSKL) is particularly effective. Experiments on varying image classification tasks show that CTS produces subnetworks that robustly pass sanity checks and achieve accuracy comparable to or exceeding LTR, while requiring only a small fraction of the computation. For example, on ResNet-20 on CIFAR10, CTSKL produces subnetworks of 99.3% sparsity with a top-1 accuracy of 74.0% in just 7.9 minutes, while LTR produces subnetworks of the same sparsity with an accuracy of 68.3% in 95.2 minutes. However, while CTS outperforms saliency-based methods in the sparsity-accuracy tradeoff across all sparsities, such advantages over LTR emerge most clearly only in the highly sparse regime.",
    "keywords": [
      "lottery ticket hypothesis (LTH)",
      "neural network"
    ]
  },
  {
    "article_id": "2512.07162v1_DeepSVM_Learning_Stochastic_Volatility_Models_with_Physics-Informed_Deep_Operator_Networks",
    "title": "2512.07162v1 DeepSVM Learning Stochastic Volatility Models with Physics-Informed Deep Operator Networks",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.07162v1_DeepSVM_Learning_Stochastic_Volatility_Models_with_Physics-Informed_Deep_Operator_Networks.pdf",
    "url": "http://arxiv.org/abs/2512.07162v1_DeepSVM_Learning_Stochastic_Volatility_Models_with_Physics-Informed_Deep_Operator_Networks",
    "pdf_url": "https://arxiv.org/pdf/2512.07162v1_DeepSVM_Learning_Stochastic_Volatility_Models_with_Physics-Informed_Deep_Operator_Networks",
    "file_size_mb": 0.75,
    "abstract": "—Real-time calibration of stochastic volatility models (SVMs) is computationally bottlenecked by the need to repeatedly solve coupled partial differential equa- tions (PDEs). In this work, we propose DeepSVM, a physics-informed Deep Operator Network (PI-DeepONet) designed to learn the solution operator of the Heston model across its entire parameter space. Unlike standard data-driven deep learning (DL) approaches, DeepSVM requires no labelled training data. Rather, we employ a hard-constrained ansatz that enforces terminal payoffs and static no-arbitrage conditions by design. Furthermore, we use Residual-based Adaptive Refinement (RAR) to stabilize training in difficult regions subject to high gradients. Overall, DeepSVM achieves a final training loss of 10−5 and predicts highly accurate option prices across a range of typical market dynamics. While pricing accuracy is high, we find that the model’s derivatives (Greeks) exhibit noise in the at-the-money (ATM) regime, highlighting the specific need for higher-order regularization in physics-informed operator learning. Index Terms—Physics-Informed Neural Networks, DeepONet, Heston Model, Option Pricing, Operator Learning",
    "keywords": []
  },
  {
    "article_id": "2512.07390v1_Towards_Reliable_Test-Time_Adaptation_Style_Invariance_as_a_Correctness_Likelihood",
    "title": "2512.07390v1 Towards Reliable Test-Time Adaptation Style Invariance as a Correctness Likelihood",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.07390v1_Towards_Reliable_Test-Time_Adaptation_Style_Invariance_as_a_Correctness_Likelihood.pdf",
    "url": "http://arxiv.org/abs/2512.07390v1_Towards_Reliable_Test-Time_Adaptation_Style_Invariance_as_a_Correctness_Likelihood",
    "pdf_url": "https://arxiv.org/pdf/2512.07390v1_Towards_Reliable_Test-Time_Adaptation_Style_Invariance_as_a_Correctness_Likelihood",
    "file_size_mb": 2.74,
    "abstract": "Test-time adaptation (TTA) enables efficient adaptation of deployed models, yet it often leads to poorly calibrated predictive uncertainty—a critical issue in high-stakes do- mains such as autonomous driving, finance, and healthcare. Existing calibration methods typically assume fixed mod- els or static distributions, which leads to degraded perfor- mance under real-world, dynamic test conditions. To ad- dress these challenges, we introduce Style Invariance as a Correctness Likelihood (SICL), a framework that leverages style-invariance for robust uncertainty estimation. SICL es- timates instance-wise correctness likelihood by measuring prediction consistency across style-altered variants, requir- ing only the model’s forward pass. This makes it a plug-and- play, backpropagation-free calibration module compatible with any TTA method. Comprehensive evaluations across four baselines, five TTA methods, and two realistic scenar- ios with three model architectures demonstrate that SICL reduces calibration error by an average of 13%p compared to conventional calibration approaches.",
    "keywords": []
  },
  {
    "article_id": "2512.07828v2_The_Adoption_and_Usage_of_AI_Agents_Early_Evidence_from_Perplexity",
    "title": "2512.07828v2 The Adoption and Usage of AI Agents Early Evidence from Perplexity",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.07828v2_The_Adoption_and_Usage_of_AI_Agents_Early_Evidence_from_Perplexity.pdf",
    "url": "http://arxiv.org/abs/2512.07828v2_The_Adoption_and_Usage_of_AI_Agents_Early_Evidence_from_Perplexity",
    "pdf_url": "https://arxiv.org/pdf/2512.07828v2_The_Adoption_and_Usage_of_AI_Agents_Early_Evidence_from_Perplexity",
    "file_size_mb": 2.59,
    "abstract": "This paper presents the first large-scale field study of the adoption, usage intensity, and use cases of general-purpose AI agents operating in open-world web environments. Our analysis centers on Comet, an AI-powered browser developed by Perplexity, and its integrated agent, Comet Assistant. Drawing on hundreds of millions of anonymized user interactions, we address three fundamental questions: Who is using AI agents? How intensively are they using them? And what are they using them for? Our findings reveal substantial heterogeneity in adoption and usage across user segments. Earlier adopters, users in countries with higher GDP per capita and educational attainment, and individuals working in digital or knowledge-intensive sectors—such as digital technology, academia, finance, marketing, and entrepreneurship—are more likely to adopt or actively use the agent. To systematically characterize the substance of agent usage, we introduce a hierarchical agentic taxonomy that organizes use cases across three levels: topic, subtopic, and task. The two largest topics—Productivity & Workflow and Learning & Research—account for 57% of all agentic queries, while the two largest subtopics—Courses and Shopping for Goods—make up 22%. The top 10 out of 90 tasks represent 55% of queries. Personal use constitutes 55% of queries, while professional and educational contexts comprise 30% and 16%, respectively. In the short term, use cases exhibit strong stickiness, but over time, users tend to shift toward more cognitively oriented topics. The diffusion of increasingly capable AI agents carries important implications for researchers, businesses, policymakers, and educators, inviting new lines of inquiry into this rapidly emerging class of AI capabilities. ∗J.Y. and N.Y. contributed equally. We thank Gustav Lindqvist, Alexis Weill, and many other Perplexity staff for helpful insights, discussions, and technical assistance. All errors are the authors’ own. Correspondence to jeryang@hbs.edu and jerry@perplexity.ai. 1 arXiv:2512.07828v2 [cs.LG] 10 Dec 2025",
    "keywords": []
  },
  {
    "article_id": "2512.07860v1_Integrating_LSTM_Networks_with_Neural_Levy_Processes_for_Financial_Forecasting",
    "title": "2512.07860v1 Integrating LSTM Networks with Neural Levy Processes for Financial Forecasting",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.07860v1_Integrating_LSTM_Networks_with_Neural_Levy_Processes_for_Financial_Forecasting.pdf",
    "url": "http://arxiv.org/abs/2512.07860v1_Integrating_LSTM_Networks_with_Neural_Levy_Processes_for_Financial_Forecasting",
    "pdf_url": "https://arxiv.org/pdf/2512.07860v1_Integrating_LSTM_Networks_with_Neural_Levy_Processes_for_Financial_Forecasting",
    "file_size_mb": 1.06,
    "abstract": "This paper investigates an optimal integration of deep learning with financial models for robust asset price forecasting. Specifically, we developed a hybrid framework combining a Long Short-Term Memory (LSTM) network with the Merton-L´evy jump-diffusion model. To optimise this framework, we employed the Grey Wolf Optimizer (GWO) for the LSTM hyperparameter tuning, and we explored three calibration methods for the Merton-L´evy model parameters: Artificial Neural Networks (ANNs), the Marine Predators Algorithm (MPA), and the PyTorch-based TorchSDE library. To evaluate the predictive perfor- mance of our hybrid model, we compared it against several benchmark models, including a standard LSTM and an LSTM combined with the Fractional Heston model. This evaluation used three real-world financial datasets: Brent oil prices, the STOXX 600 index, and the IT40 index. Performance was assessed using standard metrics, including Mean Squared Error (MSE), Mean Absolute Error (MAE), Mean Squared Percentage Error (MSPE), and the coefficient of determi- nation (R2). Our experimental results demonstrate that the hybrid model, com- bining a GWO-optimized LSTM network with the L´evy-Merton Jump-Diffusion model calibrated using an ANN, outperformed the base LSTM model and all other models developed in this study. 2",
    "keywords": []
  },
  {
    "article_id": "2512.08124v1_Long-only_cryptocurrency_portfolio_management_by_ranking_the_assets_a_neural_network_approach",
    "title": "2512.08124v1 Long-only cryptocurrency portfolio management by ranking the assets a neural network approach",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.08124v1_Long-only_cryptocurrency_portfolio_management_by_ranking_the_assets_a_neural_network_approach.pdf",
    "url": "http://arxiv.org/abs/2512.08124v1_Long-only_cryptocurrency_portfolio_management_by_ranking_the_assets_a_neural_network_approach",
    "pdf_url": "https://arxiv.org/pdf/2512.08124v1_Long-only_cryptocurrency_portfolio_management_by_ranking_the_assets_a_neural_network_approach",
    "file_size_mb": 0.48,
    "abstract": "—This paper will propose a novel machine learning based portfolio management method in the context of the cryptocurrency market. Previous researchers mainly focus on the prediction of the movement for specific cryptocurrency such as the bitcoin(BTC) and then trade according to the prediction. In contrast to the previous work that treats the cryptocurrencies independently, this paper manages a group of cryptocurrencies by analyzing the relative relationship. Specifically, in each time step, we utilize the neural network to predict the rank of the future return of the managed cryptocurrencies and place weights accordingly. By incorporating such cross-sectional information, the proposed methods is shown to profitable based on the backtesting experiments on the real daily cryptocurrency market data from May, 2020 to Nov, 2023. During this 3.5 years, the market experiences the full cycle of bullish, bearish and stagnant market conditions. Despite under such complex market condi- tions, the proposed method outperforms the existing methods and achieves a Sharpe ratio of 1.01 and annualized return of 64.26%. Additionally, the proposed method is shown to be robust to the increase of transaction fee.",
    "keywords": [
      "cryptocurrency trading",
      "portfolio management"
    ]
  },
  {
    "article_id": "2512.08153v1_TreeGRPO_Tree-Advantage_GRPO_for_Online_RL_Post-Training_of_Diffusion_Models",
    "title": "2512.08153v1 TreeGRPO Tree-Advantage GRPO for Online RL Post-Training of Diffusion Models",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.08153v1_TreeGRPO_Tree-Advantage_GRPO_for_Online_RL_Post-Training_of_Diffusion_Models.pdf",
    "url": "http://arxiv.org/abs/2512.08153v1_TreeGRPO_Tree-Advantage_GRPO_for_Online_RL_Post-Training_of_Diffusion_Models",
    "pdf_url": "https://arxiv.org/pdf/2512.08153v1_TreeGRPO_Tree-Advantage_GRPO_for_Online_RL_Post-Training_of_Diffusion_Models",
    "file_size_mb": 1.32,
    "abstract": "Reinforcement learning (RL) post-training is crucial for aligning generative mod- els with human preferences, but its prohibitive computational cost remains a major barrier to widespread adoption. We introduce TreeGRPO, a novel RL frame- work that dramatically improves training efficiency by recasting the denoising process as a search tree. From shared initial noise samples, TreeGRPO strategi- cally branches to generate multiple candidate trajectories while efficiently reusing their common prefixes. This tree-structured approach delivers three key advan- tages: (1) High sample efficiency, achieving better performance under same train- ing samples (2) Fine-grained credit assignment via reward backpropagation that computes step-specific advantages, overcoming the uniform credit assignment limitation of trajectory-based methods, and (3) Amortized computation where multi-child branching enables multiple policy updates per forward pass. Extensive experiments on both diffusion and flow-based models demonstrate that TreeGRPO achieves 2.4× faster training while establishing a superior Pareto frontier in the efficiency-reward trade-off space. Our method consistently outperforms GRPO baselines across multiple benchmarks and reward models, providing a scalable and effective pathway for RL-based visual generative model alignment. The project website is available at treegrpo.github.io.",
    "keywords": []
  },
  {
    "article_id": "2512.08169v1_Information-Dense_Reasoning_for_Efficient_and_Auditable_Security_Alert_Triage",
    "title": "2512.08169v1 Information-Dense Reasoning for Efficient and Auditable Security Alert Triage",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.08169v1_Information-Dense_Reasoning_for_Efficient_and_Auditable_Security_Alert_Triage.pdf",
    "url": "http://arxiv.org/abs/2512.08169v1_Information-Dense_Reasoning_for_Efficient_and_Auditable_Security_Alert_Triage",
    "pdf_url": "https://arxiv.org/pdf/2512.08169v1_Information-Dense_Reasoning_for_Efficient_and_Auditable_Security_Alert_Triage",
    "file_size_mb": 2.0,
    "abstract": "—Security Operations Centers face massive, heteroge- neous alert streams under minute-level service windows, creating the Alert Triage Latency Paradox: verbose reasoning chains ensure accuracy and compliance but incur prohibitive latency and token costs, while minimal chains sacrifice transparency and auditability. Existing solutions fail: signature systems are brittle, anomaly methods lack actionability, and fully cloud-hosted LLMs raise latency, cost, and privacy concerns. We propose AIDR, a hybrid cloud-edge framework that addresses this trade-off through constrained information-density optimization. The core innovation is gradient-based compression of reasoning chains to retain only decision-critical steps—minimal evidence sufficient to justify predictions while respecting token and latency budgets. We demonstrate that this approach preserves decision-relevant information while minimizing complexity. We construct compact datasets by distilling alerts into 3–5 high-information bullets (68% token reduction), train domain-specialized experts via LoRA, and deploy a cloud-edge architecture: a cloud LLM routes alerts to on-premises experts generating SOAR-ready JSON. Experiments demonstrate AIDR achieves higher accuracy and 40.6% latency reduction versus Chain-of-Thought, with robustness to data corruption and out-of-distribution generaliza- tion, enabling auditable and efficient SOC triage with full data residency compliance.",
    "keywords": [
      "Alert Triage",
      "Chain of Draft",
      "Cloud-Edge Col-"
    ]
  },
  {
    "article_id": "2512.08240v1_HybridToken-VLM_Hybrid_Token_Compression_for_Vision-Language_Models",
    "title": "2512.08240v1 HybridToken-VLM Hybrid Token Compression for Vision-Language Models",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.08240v1_HybridToken-VLM_Hybrid_Token_Compression_for_Vision-Language_Models.pdf",
    "url": "http://arxiv.org/abs/2512.08240v1_HybridToken-VLM_Hybrid_Token_Compression_for_Vision-Language_Models",
    "pdf_url": "https://arxiv.org/pdf/2512.08240v1_HybridToken-VLM_Hybrid_Token_Compression_for_Vision-Language_Models",
    "file_size_mb": 2.38,
    "abstract": "Vision-language models (VLMs) have transformed multi- modal reasoning, but feeding hundreds of visual patch to- kens to LLMs incurs quadratic computational costs, strain- ing memory and context windows. Traditional approaches face a trade-off: continuous compression dilutes high-level semantics like object identities, while discrete quantiza- tion loses granular details such as textures. We chal- lenge this by introducing HTC-VLM, a hybrid framework that disentangles semantics and appearance through dual channels, i.e., a continuous pathway for fine-grained de- tails via ViT patches and a discrete pathway for symbolic anchors using MGVQ quantization projected to four to- kens. These are fused into a 580-token hybrid sequence and compressed to one token via a disentanglement at- tention mask and <voco> bottleneck, ensuring efficient, grounded representations. HTC-VLM achieves an aver- age performance retention of 87.2% across seven bench- marks (GQA, VQAv2, MMBench, MME, POPE, SEED- Bench, ScienceQA-Image), outperforming the leading con- tinuous baseline at 81.0% with a 580-to-1 compression ra- tio. Attention analyses show the compressed token priori- tizes the discrete anchor, validating its semantic guidance. Our work demonstrates that a minimalist hybrid can resolve the efficiency-fidelity dilemma, advancing scalable VLMs.",
    "keywords": []
  },
  {
    "article_id": "2512.08296v2_Towards_a_Science_of_Scaling_Agent_Systems",
    "title": "2512.08296v2 Towards a Science of Scaling Agent Systems",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.08296v2_Towards_a_Science_of_Scaling_Agent_Systems.pdf",
    "url": "http://arxiv.org/abs/2512.08296v2_Towards_a_Science_of_Scaling_Agent_Systems",
    "pdf_url": "https://arxiv.org/pdf/2512.08296v2_Towards_a_Science_of_Scaling_Agent_Systems",
    "file_size_mb": 2.56,
    "abstract": null,
    "keywords": []
  },
  {
    "article_id": "2512.08341v1_Multi-Agent_Deep_Reinforcement_Learning_for_Collaborative_UAV_Relay_Networks_under_Jamming_Atatcks",
    "title": "2512.08341v1 Multi-Agent Deep Reinforcement Learning for Collaborative UAV Relay Networks under Jamming Atatcks",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.08341v1_Multi-Agent_Deep_Reinforcement_Learning_for_Collaborative_UAV_Relay_Networks_under_Jamming_Atatcks.pdf",
    "url": "http://arxiv.org/abs/2512.08341v1_Multi-Agent_Deep_Reinforcement_Learning_for_Collaborative_UAV_Relay_Networks_under_Jamming_Atatcks",
    "pdf_url": "https://arxiv.org/pdf/2512.08341v1_Multi-Agent_Deep_Reinforcement_Learning_for_Collaborative_UAV_Relay_Networks_under_Jamming_Atatcks",
    "file_size_mb": 2.95,
    "abstract": "—The deployment of Unmanned Aerial Vehicle (UAV) swarms as dynamic communication relays is critical for next- generation tactical networks. However, operating in contested en- vironments requires solving a complex trade-off, including max- imizing system throughput while ensuring collision avoidance and resilience against adversarial jamming. Existing heuristic- based approaches often struggle to find effective solutions due to the dynamic and multi-objective nature of this problem. This paper formulates this challenge as a cooperative Multi- Agent Reinforcement Learning (MARL) problem, solved using the Centralized Training with Decentralized Execution (CTDE) framework. Our approach employs a centralized critic that uses global state information to guide decentralized actors which operate using only local observations. Simulation results show that our proposed framework significantly outperforms heuristic baselines, increasing the total system throughput by approxi- mately 50% while simultaneously achieving a near-zero collision rate. A key finding is that the agents develop an emergent anti- jamming strategy without explicit programming. They learn to intelligently position themselves to balance the trade-off between mitigating interference from jammers and maintaining effective communication links with ground users.",
    "keywords": [
      "Multi-Agent Deep Reinforcement Learning"
    ]
  },
  {
    "article_id": "2512.08567v1_A_Hybrid_Model_for_Stock_Market_Forecasting_Integrating_News_Sentiment_and_Time_Series_Data_with_Gra",
    "title": "2512.08567v1 A Hybrid Model for Stock Market Forecasting Integrating News Sentiment and Time Series Data with Gra",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.08567v1_A_Hybrid_Model_for_Stock_Market_Forecasting_Integrating_News_Sentiment_and_Time_Series_Data_with_Gra.pdf",
    "url": "http://arxiv.org/abs/2512.08567v1_A_Hybrid_Model_for_Stock_Market_Forecasting_Integrating_News_Sentiment_and_Time_Series_Data_with_Gra",
    "pdf_url": "https://arxiv.org/pdf/2512.08567v1_A_Hybrid_Model_for_Stock_Market_Forecasting_Integrating_News_Sentiment_and_Time_Series_Data_with_Gra",
    "file_size_mb": 1.49,
    "abstract": "Stock market prediction has long been a challenging problem in the field of finance and investment. Accurately predicting the movements of stock prices is crucial for making informed decisions and maximizing investment returns. Traditional models mainly use historical prices. We found that there is a gap in research in integrating financial news into the model, which has emerged as a promising direction in enhancing predictive accuracy. This research aims to address this problem by exploring a multimodal approach by combining companies’ news articles and their historical stock data to predict future stock movements. The objective was to compare the performance of a Graph Neural Network (GNN) model with an LSTM model. The methodology employed in this research involves an LSTM model that embeds the historical data for each company and a language model to embed news articles. These embeddings will represent nodes that have relationships presented by edges within a graph. Using a GNN message aggregation technique known as GraphSAGE, the model should be able to capture interactions and dependencies between news articles, companies, and industries and use this information to predict future stock movements. Two target variable approaches are explored: one focusing on the binary classification of whether the stock price will increase or decrease, and the other considering the significance of the increase. This methodology was evaluated on two datasets, the US equities dataset and the Bloomberg dataset. The results showed that the GNN model was able to achieve better performance than the baseline LSTM model on both datasets. The GNN model achieved an accuracy of 53% on the first target, a statistically significant 1% improvement over the baseline, and a 4% precision gain on the second target, which confirms the effectiveness of exploiting financial news using graph-based models. Furthermore, we observed that increasing the number of news samples led to improved accuracy. We also find that headlines contain stronger predictive signal than full articles which is consistent with evidence that headlines disproportionately shape readers’ judgments and market reactions.",
    "keywords": [
      "Deep learning",
      "Graph neural networks",
      "Finance",
      "Knowledge graph"
    ]
  },
  {
    "article_id": "2512.08609v2_CogMCTS_A_Novel_Cognitive-Guided_Monte_Carlo_Tree_Search_Framework_for_Iterative_Heuristic_Evolution",
    "title": "2512.08609v2 CogMCTS A Novel Cognitive-Guided Monte Carlo Tree Search Framework for Iterative Heuristic Evolution",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.08609v2_CogMCTS_A_Novel_Cognitive-Guided_Monte_Carlo_Tree_Search_Framework_for_Iterative_Heuristic_Evolution.pdf",
    "url": "http://arxiv.org/abs/2512.08609v2_CogMCTS_A_Novel_Cognitive-Guided_Monte_Carlo_Tree_Search_Framework_for_Iterative_Heuristic_Evolution",
    "pdf_url": "https://arxiv.org/pdf/2512.08609v2_CogMCTS_A_Novel_Cognitive-Guided_Monte_Carlo_Tree_Search_Framework_for_Iterative_Heuristic_Evolution",
    "file_size_mb": 0.67,
    "abstract": "Automatic Heuristic Design (AHD) is an effective framework for solving complex optimization prob- lems. The development of large language mod- els (LLMs) enables the automated generation of heuristics. Existing LLM-based evolutionary meth- ods rely on population strategies and are prone to local optima. Integrating LLMs with Monte Carlo Tree Search (MCTS) improves the trade-off between exploration and exploitation, but multi- round cognitive integration remains limited and search diversity is constrained. To overcome these limitations, this paper proposes a novel cognitive- guided MCTS framework (CogMCTS). CogMCTS tightly integrates the cognitive guidance mecha- nism of LLMs with MCTS to achieve efficient au- tomated heuristic optimization. The framework employs multi-round cognitive feedback to incor- porate historical experience, node information, and negative outcomes, dynamically improving heuris- tic generation. Dual-track node expansion com- bined with elite heuristic management balances the exploration of diverse heuristics and the exploita- tion of high-quality experience. In addition, strate- gic mutation modifies the heuristic forms and pa- rameters to further enhance the diversity of the so- lution and the overall optimization performance. The experimental results indicate that CogMCTS outperforms existing LLM-based AHD methods in stability, efficiency, and solution quality.",
    "keywords": []
  },
  {
    "article_id": "2512.08786v2_A_Systematic_Evaluation_of_Preference_Aggregation_in_Federated_RLHF_for_Pluralistic_Alignment_of_LLM",
    "title": "2512.08786v2 A Systematic Evaluation of Preference Aggregation in Federated RLHF for Pluralistic Alignment of LLM",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.08786v2_A_Systematic_Evaluation_of_Preference_Aggregation_in_Federated_RLHF_for_Pluralistic_Alignment_of_LLM.pdf",
    "url": "http://arxiv.org/abs/2512.08786v2_A_Systematic_Evaluation_of_Preference_Aggregation_in_Federated_RLHF_for_Pluralistic_Alignment_of_LLM",
    "pdf_url": "https://arxiv.org/pdf/2512.08786v2_A_Systematic_Evaluation_of_Preference_Aggregation_in_Federated_RLHF_for_Pluralistic_Alignment_of_LLM",
    "file_size_mb": 0.51,
    "abstract": "This paper addresses the challenge of aligning Large Language Models (LLMs) with diverse human preferences within Federated Learning (FL) environments where standard methods often fail to adequately represent diverse viewpoints. We introduce a comprehensive evaluation framework that systematically assesses the trade-off between alignment quality and fairness when using different aggregation strategies for human preferences. In our federated setting, each group locally evaluates rollouts and produces reward signals, and the server aggregates these group-level rewards without accessing any raw data. Specifically, we evaluate standard reward aggregation techniques (min, max, and average) and introduce a novel adaptive scheme that dynamically adjusts preference weights based on a group’s historical alignment performance. Our experiments on Q/A tasks using a Proximal Policy Optimization (PPO)-based Reinforcement Learning from Human Feedback (RLHF) pipeline demonstrate that our adaptive approach consistently achieves superior fairness while maintaining competitive alignment scores. This work offers a robust methodology for evaluating Large Language Model (LLM) behavior across diverse populations and provides a practical solution for developing truly pluralistic and fairly aligned models.",
    "keywords": []
  },
  {
    "article_id": "2512.08805v1_Identifying_counterfactual_probabilities_using_bivariate_distributions_and_uplift_modeling",
    "title": "2512.08805v1 Identifying counterfactual probabilities using bivariate distributions and uplift modeling",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.08805v1_Identifying_counterfactual_probabilities_using_bivariate_distributions_and_uplift_modeling.pdf",
    "url": "http://arxiv.org/abs/2512.08805v1_Identifying_counterfactual_probabilities_using_bivariate_distributions_and_uplift_modeling",
    "pdf_url": "https://arxiv.org/pdf/2512.08805v1_Identifying_counterfactual_probabilities_using_bivariate_distributions_and_uplift_modeling",
    "file_size_mb": 0.26,
    "abstract": ". Uplift modeling estimates the causal effect of an intervention as the difference between potential outcomes under treatment and control, whereas counterfactual identification aims to recover the joint distribution of these potential outcomes (e.g., “Would this customer still have churned had we given them a marketing offer?”). This joint counterfactual distribution provides richer information than the uplift but is harder to estimate. However, the two approaches are synergistic: uplift models can be leveraged for counterfactual estimation. We propose a counterfactual estimator that fits a bivariate beta distribution to predicted uplift scores, yielding posterior distributions over counterfactual outcomes. Our approach requires no causal assumptions beyond those of uplift modeling. Simulations show the efficacy of the approach, which can be applied, for example, to the problem of customer churn in telecom, where it reveals insights unavailable to standard ML or uplift models alone.",
    "keywords": []
  },
  {
    "article_id": "2512.08828v1_Prediction_Intervals_for_Individual_Treatment_Effects_in_a_Multiple_Decision_Point_Framework_using_C",
    "title": "2512.08828v1 Prediction Intervals for Individual Treatment Effects in a Multiple Decision Point Framework using C",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.08828v1_Prediction_Intervals_for_Individual_Treatment_Effects_in_a_Multiple_Decision_Point_Framework_using_C.pdf",
    "url": "http://arxiv.org/abs/2512.08828v1_Prediction_Intervals_for_Individual_Treatment_Effects_in_a_Multiple_Decision_Point_Framework_using_C",
    "pdf_url": "https://arxiv.org/pdf/2512.08828v1_Prediction_Intervals_for_Individual_Treatment_Effects_in_a_Multiple_Decision_Point_Framework_using_C",
    "file_size_mb": 0.95,
    "abstract": "Accurately quantifying uncertainty of individual treatment effects (ITEs) across multiple decision points is crucial for personalized decision-making in fields such as healthcare, finance, education, and online marketplaces. Previous work has focused on predicting non-causal longitudinal estimands or constructing prediction bands for ITEs using cross-sectional data based on exchangeability assump- tions. We propose a novel method for constructing prediction intervals using conformal inference techniques for time-varying ITEs with weaker assumptions than prior literature. We guarantee a lower bound for coverage, which is dependent on the degree of non-exchangeability in the data. Although our method is broadly applicable across decision-making contexts, we support our theoretical claims with simulations emulating micro-randomized trials (MRTs) – a sequential experimental design for mobile health (mHealth) studies. We demonstrate the practical utility of our method by applying it to a real-world MRT - the Intern Health Study (IHS).",
    "keywords": [
      "Individual Treatment Effects",
      "causal inference",
      "conformal inference",
      "machine learning",
      "mobile health"
    ]
  },
  {
    "article_id": "2512.08851v1_A_New_Application_of_Hoeffdings_Inequality_Can_Give_Traders_Early_Warning_of_Financial_Regime_Change",
    "title": "2512.08851v1 A New Application of Hoeffdings Inequality Can Give Traders Early Warning of Financial Regime Change",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.08851v1_A_New_Application_of_Hoeffdings_Inequality_Can_Give_Traders_Early_Warning_of_Financial_Regime_Change.pdf",
    "url": "http://arxiv.org/abs/2512.08851v1_A_New_Application_of_Hoeffdings_Inequality_Can_Give_Traders_Early_Warning_of_Financial_Regime_Change",
    "pdf_url": "https://arxiv.org/pdf/2512.08851v1_A_New_Application_of_Hoeffdings_Inequality_Can_Give_Traders_Early_Warning_of_Financial_Regime_Change",
    "file_size_mb": 0.43,
    "abstract": null,
    "keywords": []
  },
  {
    "article_id": "2512.08895v2_Unsupervised_Learning_of_Density_Estimates_with_Topological_Optimization",
    "title": "2512.08895v2 Unsupervised Learning of Density Estimates with Topological Optimization",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.08895v2_Unsupervised_Learning_of_Density_Estimates_with_Topological_Optimization.pdf",
    "url": "http://arxiv.org/abs/2512.08895v2_Unsupervised_Learning_of_Density_Estimates_with_Topological_Optimization",
    "pdf_url": "https://arxiv.org/pdf/2512.08895v2_Unsupervised_Learning_of_Density_Estimates_with_Topological_Optimization",
    "file_size_mb": 1.78,
    "abstract": "Kernel density estimation is a key component of a wide variety of algorithms in machine learning, Bayesian inference, stochastic dynamics and signal processing. However, the unsupervised density estimation technique requires tuning a crucial hyperparameter: the kernel bandwidth. The choice of bandwidth is critical as it controls the bias-variance trade-off by over- or under-smoothing the topological features. Topological data analysis provides methods to mathematically quantify topological characteristics, such as connected components, loops, voids et cetera, even in high dimensions where visualization of density estimates is impossible. In this paper, we propose an unsupervised learning approach using a topology-based loss function for the automated and unsupervised selection of the optimal bandwidth and benchmark it against classical techniques—demonstrating its potential across different dimensions.",
    "keywords": []
  },
  {
    "article_id": "2512.08948v1_Online_Inference_of_Constrained_Optimization_Primal-Dual_Optimality_and_Sequential_Quadratic_Program",
    "title": "2512.08948v1 Online Inference of Constrained Optimization Primal-Dual Optimality and Sequential Quadratic Program",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.08948v1_Online_Inference_of_Constrained_Optimization_Primal-Dual_Optimality_and_Sequential_Quadratic_Program.pdf",
    "url": "http://arxiv.org/abs/2512.08948v1_Online_Inference_of_Constrained_Optimization_Primal-Dual_Optimality_and_Sequential_Quadratic_Program",
    "pdf_url": "https://arxiv.org/pdf/2512.08948v1_Online_Inference_of_Constrained_Optimization_Primal-Dual_Optimality_and_Sequential_Quadratic_Program",
    "file_size_mb": 2.1,
    "abstract": "We study online statistical inference for the solutions of stochastic optimization prob- lems with equality and inequality constraints. Such problems are prevalent in statistics andmachinelearning, encompassingconstrained M-estimation, physics-informedmodels, safe reinforcement learning, and algorithmic fairness. We develop a stochastic sequential quadratic programming (SSQP) method to solve these problems, where the step direction is computed by sequentially performing a quadratic approximation of the objective and a linear approximation of the constraints. Despite having access to unbiased estimates of population gradients, a key challenge in constrained stochastic problems lies in dealing with the bias in the step direction. As such, we apply a momentum-style gradient moving- average technique within SSQP to debias the step. We show that our method achieves global almost-sure convergence and exhibits local asymptotic normality with an optimal primal-dual limiting covariance matrix in the sense of Hájek and Le Cam. In addition, we provide a plug-in covariance matrix estimator for practical inference. To our knowledge, the proposed SSQP method is the first fully online method that attains primal-dual asymp- totic minimax optimality without relying on projection operators onto the constraint set, which are generally intractable for nonlinear problems. Through extensive experiments on benchmark nonlinear problems, as well as on constrained generalized linear models and portfolio allocation problems using both synthetic and real data, we demonstrate superior performance of our method, showing that the method and its asymptotic behavior not only solve constrained stochastic problems efficiently but also provide valid and practical on- line inference in real-world applications.",
    "keywords": [
      "constrained model inference",
      "primal-dual minimax optimality",
      "stochastic SQP",
      "gra-"
    ]
  },
  {
    "article_id": "2512.08965v1_Financial_Instruction_Following_Evaluation_FIFE",
    "title": "2512.08965v1 Financial Instruction Following Evaluation FIFE",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.08965v1_Financial_Instruction_Following_Evaluation_FIFE.pdf",
    "url": "http://arxiv.org/abs/2512.08965v1_Financial_Instruction_Following_Evaluation_FIFE",
    "pdf_url": "https://arxiv.org/pdf/2512.08965v1_Financial_Instruction_Following_Evaluation_FIFE",
    "file_size_mb": 0.98,
    "abstract": "Language Models (LMs) struggle with complex, interdependent instructions, particularly in high-stakes domains like finance where precision is critical. We introduce FIFE, a novel, high-difficulty benchmark designed to assess LM instruc­ tion-following capabilities for financial analysis tasks. FIFE comprises 88 human- authored prompts and employs a verification system with chainable, verifiable constraints for fine-grained reward signals. We evaluate 53 models (proprietary, open-weight, open-source) in a zero-shot setting. Our key findings reveal a clear performance hierarchy: the top open-weight model (76.1 strict / 79.5 loose) surpasses the leading proprietary system (65.9 strict / 70.5 loose), while the best open-source models lag significantly (45.5 strict / 48.9 loose). However, even top- performing models struggle with FIFE’s complex requirements, failing to achieve perfect compliance. We release our dataset and code as an open-source resource to promote research in Reinforcement Learning for the financial domain.1. Figure 1: Instruction Following Pipeline.",
    "keywords": []
  },
  {
    "article_id": "2512.08996v1_Demo_Generative_AI_helps_Radiotherapy_Planning_with_User_Preference",
    "title": "2512.08996v1 Demo Generative AI helps Radiotherapy Planning with User Preference",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.08996v1_Demo_Generative_AI_helps_Radiotherapy_Planning_with_User_Preference.pdf",
    "url": "http://arxiv.org/abs/2512.08996v1_Demo_Generative_AI_helps_Radiotherapy_Planning_with_User_Preference",
    "pdf_url": "https://arxiv.org/pdf/2512.08996v1_Demo_Generative_AI_helps_Radiotherapy_Planning_with_User_Preference",
    "file_size_mb": 4.39,
    "abstract": "Radiotherapy planning is a highly complex process that often varies significantly across institutions and individual planners. Most existing deep learning approaches for 3D dose prediction rely on reference plans as ground truth during training, which can inadvertently bias models toward specific planning styles or institutional pref- erences. In this study, we introduce a novel generative model that predicts 3D dose distributions based solely on user-defined preference “flavors”. These customizable preferences enable planners to prioritize specific trade-offs between organs-at-risk (OARs) and planning target volumes (PTVs), offering greater flexibility and per- sonalization. Designed for seamless integration with clinical treatment planning systems, our approach assists users in generating high-quality plans efficiently. Comparative evaluations demonstrate that our method can surpasses the Varian RapidPlanTM model in both adaptability and plan quality in some scenarios. Demo video: https://huggingface.co/Jungle15/DoseProposerDemo.",
    "keywords": []
  },
  {
    "article_id": "2512.09074v1_Modular_Deep-Learning-Based_Early_Warning_System_for_Deadly_Heatwave_Prediction",
    "title": "2512.09074v1 Modular Deep-Learning-Based Early Warning System for Deadly Heatwave Prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.09074v1_Modular_Deep-Learning-Based_Early_Warning_System_for_Deadly_Heatwave_Prediction.pdf",
    "url": "http://arxiv.org/abs/2512.09074v1_Modular_Deep-Learning-Based_Early_Warning_System_for_Deadly_Heatwave_Prediction",
    "pdf_url": "https://arxiv.org/pdf/2512.09074v1_Modular_Deep-Learning-Based_Early_Warning_System_for_Deadly_Heatwave_Prediction",
    "file_size_mb": 1.79,
    "abstract": null,
    "keywords": []
  },
  {
    "article_id": "2512.09224v1_Exploratory_Mean-Variance_with_Jumps_An_Equilibrium_Approach",
    "title": "2512.09224v1 Exploratory Mean-Variance with Jumps An Equilibrium Approach",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.09224v1_Exploratory_Mean-Variance_with_Jumps_An_Equilibrium_Approach.pdf",
    "url": "http://arxiv.org/abs/2512.09224v1_Exploratory_Mean-Variance_with_Jumps_An_Equilibrium_Approach",
    "pdf_url": "https://arxiv.org/pdf/2512.09224v1_Exploratory_Mean-Variance_with_Jumps_An_Equilibrium_Approach",
    "file_size_mb": 0.55,
    "abstract": null,
    "keywords": []
  },
  {
    "article_id": "2512.09463v1_Privacy-Preserving_Computer_Vision_for_Industry_Three_Case_Studies_in_Human-Centric_Manufacturing",
    "title": "2512.09463v1 Privacy-Preserving Computer Vision for Industry Three Case Studies in Human-Centric Manufacturing",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.09463v1_Privacy-Preserving_Computer_Vision_for_Industry_Three_Case_Studies_in_Human-Centric_Manufacturing.pdf",
    "url": "http://arxiv.org/abs/2512.09463v1_Privacy-Preserving_Computer_Vision_for_Industry_Three_Case_Studies_in_Human-Centric_Manufacturing",
    "pdf_url": "https://arxiv.org/pdf/2512.09463v1_Privacy-Preserving_Computer_Vision_for_Industry_Three_Case_Studies_in_Human-Centric_Manufacturing",
    "file_size_mb": 7.29,
    "abstract": "The adoption of AI-powered computer vision in industry is often constrained by the need to balance operational util- ity with worker privacy. Building on our previously pro- posed privacy-preserving framework, this paper presents its first comprehensive validation on real-world data collected directly by industrial partners in active production environ- ments. We evaluate the framework across three representa- tive use cases: woodworking production monitoring, human- aware AGV navigation, and multi-camera ergonomic risk assessment. The approach employs learned visual transfor- mations that obscure sensitive or task-irrelevant informa- tion while retaining features essential for task performance. Through both quantitative evaluation of the privacy–utility trade-off and qualitative feedback from industrial partners, we assess the framework’s effectiveness, deployment feasi- bility, and trust implications. Results demonstrate that task- specific obfuscation enables effective monitoring with re- duced privacy risks, establishing the framework’s readiness for real-world adoption and providing cross-domain recom- mendations for responsible, human-centric AI deployment in industry.",
    "keywords": []
  },
  {
    "article_id": "2512.09736v1_Analyzing_Planner_Design_Trade-offs_for_MAPF_under_Realistic_Simulation",
    "title": "2512.09736v1 Analyzing Planner Design Trade-offs for MAPF under Realistic Simulation",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.09736v1_Analyzing_Planner_Design_Trade-offs_for_MAPF_under_Realistic_Simulation.pdf",
    "url": "http://arxiv.org/abs/2512.09736v1_Analyzing_Planner_Design_Trade-offs_for_MAPF_under_Realistic_Simulation",
    "pdf_url": "https://arxiv.org/pdf/2512.09736v1_Analyzing_Planner_Design_Trade-offs_for_MAPF_under_Realistic_Simulation",
    "file_size_mb": 3.75,
    "abstract": "Multi-Agent Path Finding (MAPF) algorithms are increas- ingly deployed in industrial warehouses and automated man- ufacturing facilities, where robots must operate reliably un- der real-world physical constraints. However, existing MAPF evaluation frameworks typically rely on simplified robot models, leaving a substantial gap between algorithmic bench- marks and practical performance. Recent frameworks such as SMART, incorporate kinodynamic modeling and offer the MAPF community a platform for large-scale, realistic evalu- ation. Building on this capability, this work investigates how key planner design choices influence performance under real- istic execution settings. We systematically study three funda- mental factors: (1) the relationship between solution optimal- ity and execution performance, (2) the sensitivity of system performance to inaccuracies in kinodynamic modeling, and (3) the interaction between model accuracy and plan optimal- ity. Empirically, we examine these factors to understand how these design choices affect performance in realistic scenarios. We highlight open challenges and research directions to steer the community toward practical, real-world deployment.",
    "keywords": []
  },
  {
    "article_id": "2512.10305v1_InfoCom_Kilobyte-Scale_Communication-Efficient_Collaborative_Perception_with_Information_Bottleneck",
    "title": "2512.10305v1 InfoCom Kilobyte-Scale Communication-Efficient Collaborative Perception with Information Bottleneck",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.10305v1_InfoCom_Kilobyte-Scale_Communication-Efficient_Collaborative_Perception_with_Information_Bottleneck.pdf",
    "url": "http://arxiv.org/abs/2512.10305v1_InfoCom_Kilobyte-Scale_Communication-Efficient_Collaborative_Perception_with_Information_Bottleneck",
    "pdf_url": "https://arxiv.org/pdf/2512.10305v1_InfoCom_Kilobyte-Scale_Communication-Efficient_Collaborative_Perception_with_Information_Bottleneck",
    "file_size_mb": 10.51,
    "abstract": "Precise environmental perception is critical for the reli- ability of autonomous driving systems. While collabora- tive perception mitigates the limitations of single-agent perception through information sharing, it encounters a fundamental communication-performance trade-off. Existing communication-efficient approaches typically assume MB- level data transmission per collaboration, which may fail due to practical network constraints. To address these is- sues, we propose InfoCom, an information-aware frame- work establishing the pioneering theoretical foundation for communication-efficient collaborative perception via ex- tended Information Bottleneck principles. Departing from mainstream feature manipulation, InfoCom introduces a novel information purification paradigm that theoretically op- timizes the extraction of minimal sufficient task-critical in- formation under Information Bottleneck constraints. Its core innovations include: i) An Information-Aware Encoding con- densing features into minimal messages while preserving perception-relevant information; ii) A Sparse Mask Genera- tion identifying spatial cues with negligible communication cost; and iii) A Multi-Scale Decoding that progressively re- covers perceptual information through mask-guided mecha- nisms rather than simple feature reconstruction. Comprehen- sive experiments across multiple datasets demonstrate that InfoCom achieves near-lossless perception while reducing communication overhead from megabyte to kilobyte-scale, representing 440-fold and 90-fold reductions per agent com- pared to Where2comm and ERMVP, respectively. Code — https://weiquanmin.github.io/infocom",
    "keywords": []
  },
  {
    "article_id": "2512.10411v2_Sliding_Window_Attention_Adaptation",
    "title": "2512.10411v2 Sliding Window Attention Adaptation",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.10411v2_Sliding_Window_Attention_Adaptation.pdf",
    "url": "http://arxiv.org/abs/2512.10411v2_Sliding_Window_Attention_Adaptation",
    "pdf_url": "https://arxiv.org/pdf/2512.10411v2_Sliding_Window_Attention_Adaptation",
    "file_size_mb": 0.42,
    "abstract": "The self-attention mechanism in Transformer- based Large Language Models (LLMs) scales quadratically with input length, making long- context inference expensive. Sliding win- dow attention (SWA) reduces this cost to lin- ear complexity, but naively enabling complete SWA at inference-time for models pretrained with full attention (FA) causes severe long- context performance degradation due to train- ing–inference mismatch. This makes us won- der: Can FA-pretrained LLMs be well adapted to SWA without pretraining? We investigate this by proposing Sliding Window Attention Adaptation (SWAA), a set of practical recipes that combine five methods for better adapta- tion: (1) applying SWA only during prefilling; (2) preserving “sink” tokens; (3) interleaving FA/SWA layers; (4) chain-of-thought (CoT); and (5) fine-tuning. Our experiments show that SWA adaptation is feasible while non-trivial: no single method suffices, yet specific synergis- tic combinations effectively recover the original long-context performance. We further analyze the performance-efficiency trade-offs of differ- ent SWAA configurations and provide recom- mended recipes for diverse scenarios, which can greatly and fundamentally accelerate LLM long-context inference speed by up to 100%. Our code is available at github.",
    "keywords": []
  },
  {
    "article_id": "2512.10461v1_T-SKM-Net_Trainable_Neural_Network_Framework_for_Linear_Constraint_Satisfaction_via_Sampling_Kaczmar",
    "title": "2512.10461v1 T-SKM-Net Trainable Neural Network Framework for Linear Constraint Satisfaction via Sampling Kaczmar",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.10461v1_T-SKM-Net_Trainable_Neural_Network_Framework_for_Linear_Constraint_Satisfaction_via_Sampling_Kaczmar.pdf",
    "url": "http://arxiv.org/abs/2512.10461v1_T-SKM-Net_Trainable_Neural_Network_Framework_for_Linear_Constraint_Satisfaction_via_Sampling_Kaczmar",
    "pdf_url": "https://arxiv.org/pdf/2512.10461v1_T-SKM-Net_Trainable_Neural_Network_Framework_for_Linear_Constraint_Satisfaction_via_Sampling_Kaczmar",
    "file_size_mb": 4.57,
    "abstract": "Neural network constraint satisfaction is crucial for safety- critical applications such as power system optimization, robotic path planning, and autonomous driving. However, existing constraint satisfaction methods face efficiency- applicability trade-offs, with hard constraint methods suf- fering from either high computational complexity or re- strictive assumptions on constraint structures. The Sampling Kaczmarz-Motzkin (SKM) method is a randomized iterative algorithm for solving large-scale linear inequality systems with favorable convergence properties, but its argmax oper- ations introduce non-differentiability, posing challenges for neural network applications. This work proposes the Train- able Sampling Kaczmarz-Motzkin Network (T-SKM-Net) framework and, for the first time, systematically integrates SKM-type methods into neural network constraint satisfac- tion. The framework transforms mixed constraint problems into pure inequality problems through null space transfor- mation, employs SKM for iterative solving, and maps solu- tions back to the original constraint space, efficiently han- dling both equality and inequality constraints. We provide theoretical proof of post-processing effectiveness in expec- tation and end-to-end trainability guarantees based on un- biased gradient estimators, demonstrating that despite non- differentiable operations, the framework supports standard backpropagation. On the DCOPF case118 benchmark, our method achieves 4.27ms/item GPU serial forward inference with 0.0025% max optimality gap with post-processing mode and 5.25ms/item with 0.0008% max optimality gap with joint training mode, delivering over 25× speedup compared to the pandapower solver while maintaining zero constraint viola- tions under given tolerance. Code — https://github.com/IDO-Lab/T-SKM-Net",
    "keywords": []
  },
  {
    "article_id": "2512.10510v1_Adaptive_Replay_Buffer_for_Offline-to-Online_Reinforcement_Learning",
    "title": "2512.10510v1 Adaptive Replay Buffer for Offline-to-Online Reinforcement Learning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.10510v1_Adaptive_Replay_Buffer_for_Offline-to-Online_Reinforcement_Learning.pdf",
    "url": "http://arxiv.org/abs/2512.10510v1_Adaptive_Replay_Buffer_for_Offline-to-Online_Reinforcement_Learning",
    "pdf_url": "https://arxiv.org/pdf/2512.10510v1_Adaptive_Replay_Buffer_for_Offline-to-Online_Reinforcement_Learning",
    "file_size_mb": 0.46,
    "abstract": "Offline-to-Online Reinforcement Learning (O2O RL) faces a critical dilemma in bal- ancing the use of a fixed offline dataset with newly collected online experiences. Standard methods, often relying on a fixed data-mixing ratio, struggle to manage the trade-off be- tween early learning stability and asymptotic performance. To overcome this, we intro- duce the Adaptive Replay Buffer (ARB), a novel approach that dynamically prioritizes data sampling based on a lightweight metric we call ’on-policyness’. Unlike prior meth- ods that rely on complex learning proce- dures or fixed ratios, ARB is designed to be learning-free and simple to implement, seam- lessly integrating into existing O2O RL algo- rithms. It assesses how closely collected tra- jectories align with the current policy’s be- havior and assigns a proportional sampling weight to each transition within that trajec- tory. This strategy effectively leverages of- fline data for initial stability while progres- sively focusing learning on the most relevant, high-rewarding online experiences. Our ex- tensive experiments on D4RL benchmarks demonstrate that ARB consistently mitigates early performance degradation and signifi- cantly improves the final performance of vari- ous O2O RL algorithms, highlighting the im- portance of an adaptive, behavior-aware re- play buffer design.",
    "keywords": []
  },
  {
    "article_id": "2512.10886v1_Physics-Informed_Learning_of_Flow_Distribution_and_Receiver_Heat_Losses_in_Parabolic_Trough_Solar_Fi",
    "title": "2512.10886v1 Physics-Informed Learning of Flow Distribution and Receiver Heat Losses in Parabolic Trough Solar Fi",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.10886v1_Physics-Informed_Learning_of_Flow_Distribution_and_Receiver_Heat_Losses_in_Parabolic_Trough_Solar_Fi.pdf",
    "url": "http://arxiv.org/abs/2512.10886v1_Physics-Informed_Learning_of_Flow_Distribution_and_Receiver_Heat_Losses_in_Parabolic_Trough_Solar_Fi",
    "pdf_url": "https://arxiv.org/pdf/2512.10886v1_Physics-Informed_Learning_of_Flow_Distribution_and_Receiver_Heat_Losses_in_Parabolic_Trough_Solar_Fi",
    "file_size_mb": 9.53,
    "abstract": "Parabolic trough Concentrating Solar Power (CSP) plants operate large hydraulic networks of collector loops that must deliver a uniform outlet temperature de- spite spatially heterogeneous optical performance, heat losses, and pressure drops. While loop temperatures are measured, loop-level mass flows and receiver heat- loss parameters are unobserved, making it impossible to diagnose hydraulic im- balances or receiver degradation using standard monitoring tools. We present a physics-informed learning framework that infers (i) loop-level mass- flow ratios and (ii) time-varying receiver heat-transfer coefficients directly from routine operational data. The method exploits nocturnal homogenization peri- ods—when hot oil is circulated through a non-irradiated field—to isolate hy- draulic and thermal-loss effects. A differentiable conjugate heat-transfer model is discretized and embedded into an end-to-end learning pipeline optimized using historical plant data from the 50 MW Andasol 3 solar field. The model accurately reconstructs loop temperatures (RMSE < 2◦C) and pro- duces physically meaningful estimates of loop imbalances and receiver heat losses. Comparison against drone-based infrared thermography (QScan) shows strong correspondence, correctly identifying all areas with high-loss receivers. This demonstrates that noisy real-world CSP operational data contain enough in- formation to recover latent physical parameters when combined with appropriate modeling and differentiable optimization.",
    "keywords": []
  },
  {
    "article_id": "2512.10913v1_Reinforcement_Learning_in_Financial_Decision_Making_A_Systematic_Review_of_Performance_Challenges_an",
    "title": "2512.10913v1 Reinforcement Learning in Financial Decision Making A Systematic Review of Performance Challenges an",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.10913v1_Reinforcement_Learning_in_Financial_Decision_Making_A_Systematic_Review_of_Performance_Challenges_an.pdf",
    "url": "http://arxiv.org/abs/2512.10913v1_Reinforcement_Learning_in_Financial_Decision_Making_A_Systematic_Review_of_Performance_Challenges_an",
    "pdf_url": "https://arxiv.org/pdf/2512.10913v1_Reinforcement_Learning_in_Financial_Decision_Making_A_Systematic_Review_of_Performance_Challenges_an",
    "file_size_mb": 6.91,
    "abstract": "Reinforcement learning (RL) is an innovative approach to financial decision making, offer- ing specialized solutions to complex investment problems where traditional methods fail. This review analyzes 167 articles from 2017–2025, focusing on market making, portfolio op- timization, and algorithmic trading. It identifies key performance issues and challenges in RL for finance. Generally, RL offers advantages over traditional methods, particularly in market making. This study proposes a unified framework to address common concerns such as explainability, robustness, and deployment feasibility. Empirical evidence with synthetic data suggests that implementation quality and domain knowledge often outweigh algorithmic complexity. The study highlights the need for interpretable RL architectures for regulatory compliance, enhanced robustness in nonstationary environments, and standardized bench- marking protocols. Organizations should focus less on algorithm sophistication and more on market microstructure, regulatory constraints, and risk management in decision-making.",
    "keywords": [
      "Reinforcement Learning",
      "Financial Decision Making",
      "Market Making"
    ]
  },
  {
    "article_id": "2512.11201v1_Fast_EXP3_Algorithms",
    "title": "2512.11201v1 Fast EXP3 Algorithms",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.11201v1_Fast_EXP3_Algorithms.pdf",
    "url": "http://arxiv.org/abs/2512.11201v1_Fast_EXP3_Algorithms",
    "pdf_url": "https://arxiv.org/pdf/2512.11201v1_Fast_EXP3_Algorithms",
    "file_size_mb": 0.43,
    "abstract": "We point out that EXP3 can be implemented in constant time per round, propose more practical algorithms, and analyze the trade-offs between the regret bounds and time com- plexities of these algorithms.",
    "keywords": []
  },
  {
    "article_id": "2512.11251v1_Insight_Miner_A_Time_Series_Analysis_Dataset_for_Cross-Domain_Alignment_with_Natural_Language",
    "title": "2512.11251v1 Insight Miner A Time Series Analysis Dataset for Cross-Domain Alignment with Natural Language",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.11251v1_Insight_Miner_A_Time_Series_Analysis_Dataset_for_Cross-Domain_Alignment_with_Natural_Language.pdf",
    "url": "http://arxiv.org/abs/2512.11251v1_Insight_Miner_A_Time_Series_Analysis_Dataset_for_Cross-Domain_Alignment_with_Natural_Language",
    "pdf_url": "https://arxiv.org/pdf/2512.11251v1_Insight_Miner_A_Time_Series_Analysis_Dataset_for_Cross-Domain_Alignment_with_Natural_Language",
    "file_size_mb": 1.36,
    "abstract": "Time-series data is critical across many scientific and industrial domains, including environmental analysis, agriculture, transportation, and finance. However, mining insights from this data typically requires deep domain expertise, a process that is both time-consuming and labor-intensive. In this paper, we propose Insight Miner, a large-scale multimodal model (LMM) designed to generate high-quality, comprehensive time-series descriptions enriched with domain-specific knowledge. To facilitate this, we introduce TS-Insights2, the first general-domain dataset for time series and language alignment. TS-Insights contains 100k time-series windows sampled from 20 forecasting datasets. We construct this dataset using a novel agentic workflow, where we use statistical tools to extract features from raw time series before synthesizing them into coherent trend descriptions with GPT-4. Following instruction tuning on TS-Insights, Insight Miner outperforms state-of-the-art multimodal models, such as LLaVA [1] and GPT-4, in generating time-series descriptions and insights. Our findings suggest a promising direction ∗Work done during internship at Google X - Mineral.ai. 2Available at https://huggingface.co/datasets/zhykoties/time-series-language-alignment. NeurIPS 2023 AI for Science Workshop. arXiv:2512.11251v1 [cs.LG] 12 Dec 2025 for leveraging LMMs in time series analysis, and serve as a foundational step toward enabling LLMs to interpret time series as a native input modality.",
    "keywords": []
  },
  {
    "article_id": "2512.11273v2_Integrated_Prediction_and_Multi-period_Portfolio_Optimization",
    "title": "2512.11273v2 Integrated Prediction and Multi-period Portfolio Optimization",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.11273v2_Integrated_Prediction_and_Multi-period_Portfolio_Optimization.pdf",
    "url": "http://arxiv.org/abs/2512.11273v2_Integrated_Prediction_and_Multi-period_Portfolio_Optimization",
    "pdf_url": "https://arxiv.org/pdf/2512.11273v2_Integrated_Prediction_and_Multi-period_Portfolio_Optimization",
    "file_size_mb": 1.29,
    "abstract": "Multi-period portfolio optimization is essential for realistic portfolio management, as it accounts for transaction costs, path-dependent risks, and the intertemporal structure of trading decisions that single-period models cannot capture. However, multi-period portfolio optimization requires multi- stage return forecasts. Classical methods usually follow a two-stage framework: machine learning algorithms are employed to produce forecasts that closely fit the realized returns, and the predicted values are then used in a downstream portfolio optimization problem to determine the asset weights. This separation leads to a fundamental misalignment between predictions and decision outcomes, while also ignoring the impact of transaction costs. To bridge this gap, recent studies have proposed the idea of end-to-end learning, integrating the two stages into a single pipeline. This paper introduces IPMO (Integrated Prediction and Multi-period Portfolio Optimization), a model for multi-period mean-variance portfolio optimization with turnover penalties. The predictor generates multi-period return forecasts that parameterize a differentiable convex optimization layer, which in turn drives learning via portfolio performance. For scalability, we introduce a mirror-descent fixed-point (MDFP) differentiation scheme that avoids factorizing the Karush–Kuhn–Tucker (KKT) systems, which thus yields stable implicit gradients and nearly scale-insensitive runtime as the decision horizon grows. In experiments with real market data and two representative time-series prediction models, the IPMO method consistently outperforms the two-stage benchmarks in risk-adjusted performance net of trans- action costs and achieves more coherent allocation paths. Our results show that integrating machine learning prediction with optimization in the multi-period setting improves financial outcomes and remains computationally tractable.",
    "keywords": [
      "Multi-period portfolio optimization",
      "End-to-end learning",
      "Transaction costs",
      "Implicit"
    ]
  },
  {
    "article_id": "2512.11412v1_Task-Specific_Sparse_Feature_Masks_for_Molecular_Toxicity_Prediction_with_Chemical_Language_Models",
    "title": "2512.11412v1 Task-Specific Sparse Feature Masks for Molecular Toxicity Prediction with Chemical Language Models",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.11412v1_Task-Specific_Sparse_Feature_Masks_for_Molecular_Toxicity_Prediction_with_Chemical_Language_Models.pdf",
    "url": "http://arxiv.org/abs/2512.11412v1_Task-Specific_Sparse_Feature_Masks_for_Molecular_Toxicity_Prediction_with_Chemical_Language_Models",
    "pdf_url": "https://arxiv.org/pdf/2512.11412v1_Task-Specific_Sparse_Feature_Masks_for_Molecular_Toxicity_Prediction_with_Chemical_Language_Models",
    "file_size_mb": 0.44,
    "abstract": "—Reliable in silico molecular toxicity prediction is a cornerstone of modern drug discovery, offering a scalable alternative to experimental screening. However, the black-box nature of state-of-the-art models remains a significant barrier to adoption, as high-stakes safety decisions demand verifiable structural insights alongside predictive performance. To address this, we propose a novel multi-task learning (MTL) framework designed to jointly enhance accuracy and interpretability. Our architecture integrates a shared chemical language model with task-specific attention modules. By imposing an L1 sparsity penalty on these modules, the framework is constrained to focus on a minimal set of salient molecular fragments for each distinct toxicity endpoint. The resulting framework is trained end-to-end and is readily adaptable to various transformer- based backbones. Evaluated on the ClinTox, SIDER, and Tox21 benchmark datasets, our approach consistently outperforms both single-task and standard MTL baselines. Crucially, the sparse attention weights provide chemically intuitive visualizations that reveal the specific fragments influencing predictions, thereby enhancing insight into the model’s decision-making process.",
    "keywords": [
      "Chemical language models",
      "computational toxi-"
    ]
  },
  {
    "article_id": "2512.11525v1_NeuralOGCM_Differentiable_Ocean_Modeling_with_Learnable_Physics",
    "title": "2512.11525v1 NeuralOGCM Differentiable Ocean Modeling with Learnable Physics",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.11525v1_NeuralOGCM_Differentiable_Ocean_Modeling_with_Learnable_Physics.pdf",
    "url": "http://arxiv.org/abs/2512.11525v1_NeuralOGCM_Differentiable_Ocean_Modeling_with_Learnable_Physics",
    "pdf_url": "https://arxiv.org/pdf/2512.11525v1_NeuralOGCM_Differentiable_Ocean_Modeling_with_Learnable_Physics",
    "file_size_mb": 4.61,
    "abstract": "High-precision scientific simulation faces a long- standing trade-off between computational effi- ciency and physical fidelity. To address this challenge, we propose NeuralOGCM, an ocean modeling framework that fuses differentiable pro- gramming with deep learning. At the core of NeuralOGCM is a fully differentiable dynamical solver, which leverages physics knowledge as its core inductive bias. The learnable physics integra- tion captures large-scale, deterministic physical evolution, and transforms key physical parame- ters (e.g., diffusion coefficients) into learnable parameters, enabling the model to autonomously optimize its physical core via end-to-end training. Concurrently, a deep neural network learns to correct for subgrid-scale processes and discretiza- tion errors not captured by the physics model. Both components work in synergy, with their outputs integrated by a unified ODE solver. Ex- periments demonstrate that NeuralOGCM main- tains long-term stability and physical consistency, significantly outperforming traditional numerical models in speed and pure AI baselines in accuracy. Our work paves a new path for building fast, sta- ble, and physically-plausible models for scientific computing. Our codes are available here.",
    "keywords": []
  },
  {
    "article_id": "2512.11901v1_CLARGA_Multimodal_Graph_Representation_Learning_over_Arbitrary_Sets_of_Modalities",
    "title": "2512.11901v1 CLARGA Multimodal Graph Representation Learning over Arbitrary Sets of Modalities",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.11901v1_CLARGA_Multimodal_Graph_Representation_Learning_over_Arbitrary_Sets_of_Modalities.pdf",
    "url": "http://arxiv.org/abs/2512.11901v1_CLARGA_Multimodal_Graph_Representation_Learning_over_Arbitrary_Sets_of_Modalities",
    "pdf_url": "https://arxiv.org/pdf/2512.11901v1_CLARGA_Multimodal_Graph_Representation_Learning_over_Arbitrary_Sets_of_Modalities",
    "file_size_mb": 0.37,
    "abstract": "We introduce CLARGA, a general-purpose multimodal fu- sion architecture for multimodal representation learning that works with any number and type of modalities without chang- ing the underlying framework. Given a supervised dataset, CLARGA can be applied to virtually any machine learning task to fuse different multimodal representations for process- ing by downstream layers. On a sample-by-sample basis, CLARGA learns how modalities should inform one another by building an attention weighted graph over their features and passing messages along this graph with a multi-head Graph Attention Network. Not only does this make CLARGA highly adaptive, as it constructs unique graphs for differ- ent samples, it makes for efficient fusion with sub-quadratic complexity as the number of modalities grows. Through a learnable mask, it can also adapt to missing modality inputs. The model is trained with a hybrid objective that combines a supervised task loss with contrastive InfoNCE loss, improving cross-modal consistency and robustness to noisy inputs. We demonstrate CLARGA’s effectiveness in diverse multimodal representation learning tasks across 7 datasets spanning finance, human-computer interaction, gen- eral multimedia classification, and affective computing. It consistently outperforms baselines, state-of-the-art models, and ablations. Additional experiments also demonstrate its robustness to missing inputs and ability to excel on niche tasks. Overall, CLARGA can be easily plugged into ma- chine learning models for effective and efficient learning of representations across a wide variety of tasks.",
    "keywords": []
  },
  {
    "article_id": "2512.11907v1_Structured_Personalization_Modeling_Constraints_as_Matroids_for_Data-Minimal_LLM_Agents",
    "title": "2512.11907v1 Structured Personalization Modeling Constraints as Matroids for Data-Minimal LLM Agents",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.11907v1_Structured_Personalization_Modeling_Constraints_as_Matroids_for_Data-Minimal_LLM_Agents.pdf",
    "url": "http://arxiv.org/abs/2512.11907v1_Structured_Personalization_Modeling_Constraints_as_Matroids_for_Data-Minimal_LLM_Agents",
    "pdf_url": "https://arxiv.org/pdf/2512.11907v1_Structured_Personalization_Modeling_Constraints_as_Matroids_for_Data-Minimal_LLM_Agents",
    "file_size_mb": 0.39,
    "abstract": "Personalizing Large Language Model (LLM) agents requires conditioning them on user-specific data, creating a critical trade-off between task utility and data disclosure. While the utility of adding user data often exhibits diminishing returns (i.e., submodularity), enabling near-optimal greedy selection, real-world personalization is complicated by structural con- straints. These include logical dependencies (e.g., selecting fact A requires fact B), categorical quotas (e.g., select at most one writing style), and hierarchical rules (e.g., select at most two social media preferences, of which at most one can be for a professional network). These constraints violate the as- sumptions of standard subset selection algorithms. We pro- pose a principled method to formally model such constraints. We introduce a compilation process that transforms a user’s knowledge graph with dependencies into a set of abstract macro-facets. Our central result is a proof that common hier- archical and quota-based constraints over these macro-facets form a valid laminar matroid. This theoretical characteri- zation lets us cast structured personalization as submodular maximization under a matroid constraint, enabling greedy with constant-factor guarantees (and (1−1/e) via continuous greedy) for a much richer and more realistic class of problems.",
    "keywords": []
  },
  {
    "article_id": "2512.11922v1_Vibe_Coding_in_Practice_Flow_Technical_Debt_and_Guidelines_for_Sustainable_Use",
    "title": "2512.11922v1 Vibe Coding in Practice Flow Technical Debt and Guidelines for Sustainable Use",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.11922v1_Vibe_Coding_in_Practice_Flow_Technical_Debt_and_Guidelines_for_Sustainable_Use.pdf",
    "url": "http://arxiv.org/abs/2512.11922v1_Vibe_Coding_in_Practice_Flow_Technical_Debt_and_Guidelines_for_Sustainable_Use",
    "pdf_url": "https://arxiv.org/pdf/2512.11922v1_Vibe_Coding_in_Practice_Flow_Technical_Debt_and_Guidelines_for_Sustainable_Use",
    "file_size_mb": 0.9,
    "abstract": "—Vibe Coding (VC) is a form of software development assisted by generative AI, in which developers describe the intended functionality or logic via natural language prompts, and the AI system generates the corresponding source code. VC can be used for rapid prototyping or developing the Minimum Viable Products (MVPs); however, it may introduce several risks throughout the software development life cycle. Based on our experience from several internally developed MVPs and a review of recent industry reports, this article analyzes the flow–debt tradeoffs associated with VC. The flow–debt trade-off arises when the seamless code generation occurs, leading to the accumulation of technical debt through architectural inconsistencies, security vulnerabilities, and increased maintenance overhead. These issues originate from process-level weaknesses, biases in model training and data, a lack of explicit design rationale, and a tendency to prioritize quick code generation over human-driven iterative development. Based on our experiences, we identify and explain how current model, platform, and hardware limitations contribute to these issues, and propose countermeasures to address them – informing research and practice towards more sustainable VC approaches.",
    "keywords": [
      "AI-assisted programming",
      "technical debt",
      "vibe coding",
      "experience report"
    ]
  },
  {
    "article_id": "2512.11933v1_The_Agentic_Regulator_Risks_for_AI_in_Finance_and_a_Proposed_Agent-based_Framework_for_Governance",
    "title": "2512.11933v1 The Agentic Regulator Risks for AI in Finance and a Proposed Agent-based Framework for Governance",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.11933v1_The_Agentic_Regulator_Risks_for_AI_in_Finance_and_a_Proposed_Agent-based_Framework_for_Governance.pdf",
    "url": "http://arxiv.org/abs/2512.11933v1_The_Agentic_Regulator_Risks_for_AI_in_Finance_and_a_Proposed_Agent-based_Framework_for_Governance",
    "pdf_url": "https://arxiv.org/pdf/2512.11933v1_The_Agentic_Regulator_Risks_for_AI_in_Finance_and_a_Proposed_Agent-based_Framework_for_Governance",
    "file_size_mb": 1.04,
    "abstract": "Generative and agentic artificial intelligence is entering financial markets faster than existing governance can adapt. Current model- risk frameworks assume static, well-specified algorithms and one- time validations; large language models and multi-agent trading systems violate those assumptions by learning continuously, ex- changing latent signals, and exhibiting emergent behavior. Drawing on complex adaptive systems theory, we model these technologies as decentralized ensembles whose risks propagate along multiple time-scales. We then propose a modular governance architecture. The framework decomposes oversight into four layers of “regu- latory blocks”: (i) self-regulation modules embedded beside each model, (ii) firm-level governance blocks that aggregate local teleme- try and enforce policy, (iii) regulator-hosted agents that monitor sector-wide indicators for collusive or destabilizing patterns, and (iv) independent audit blocks that supply third-party assurance. Eight design strategies enable the blocks to evolve as fast as the models they police. A case study on emergent spoofing in multi- agent trading shows how the layered controls quarantine harmful behavior in real time while preserving innovation. The architecture remains compatible with today’s model-risk rules yet closes critical observability and control gaps, providing a practical path toward resilient, adaptive AI governance in financial systems.",
    "keywords": [
      "Artificial Intelligence",
      "AI Regulation",
      "Generative AI",
      "Agentic AI"
    ]
  },
  {
    "article_id": "2512.11944v1_A_Review_of_Learning-Based_Motion_Planning_Toward_a_Data-Driven_Optimal_Control_Approach",
    "title": "2512.11944v1 A Review of Learning-Based Motion Planning Toward a Data-Driven Optimal Control Approach",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.11944v1_A_Review_of_Learning-Based_Motion_Planning_Toward_a_Data-Driven_Optimal_Control_Approach.pdf",
    "url": "http://arxiv.org/abs/2512.11944v1_A_Review_of_Learning-Based_Motion_Planning_Toward_a_Data-Driven_Optimal_Control_Approach",
    "pdf_url": "https://arxiv.org/pdf/2512.11944v1_A_Review_of_Learning-Based_Motion_Planning_Toward_a_Data-Driven_Optimal_Control_Approach",
    "file_size_mb": 3.74,
    "abstract": "Motion planning for high-level autonomous driving is constrained by a fundamental trade-off between the transparent, yet brittle, nature of pipeline methods and the adaptive, yet opaque, \"black-box\" characteristics of modern learning-based systems. This paper critically synthesizes the evolution of the field—from pipeline methods through imitation learning, reinforcement learning, and generative AI—to demonstrate how this persistent dilemma has hindered the development of truly trustworthy systems. To resolve this impasse, we have conducted a review on learning based motion planning method. Based on our review analysis, we outline a data-driven optimal control paradigm as a unifying framework that synergistically integrates the verifiable structure of classical control with the adaptive capacity of machine learning, leveraging real-world data to continuously refine key components like system dynamic, cost function, and safety constraints. We explore this framework's potential to enable three critical next- generation capabilities: \"Human-Centric\" Customization, \"Platform-Adaptive\" Dynamics Adaptation, and \"System Self-Optimization\" Self-Tuning. We concludes by proposing future research directions based on this paradigm, aimed at developing intelligent transportation systems that are simultaneously safe, interpretable, and capable of human-like autonomy.",
    "keywords": [
      "Autonomous Driving",
      "Motion Planning",
      "Learning",
      "Data-Driven Optimal Control"
    ]
  },
  {
    "article_id": "2512.12060v1_CreativeVR_Diffusion-Prior-Guided_Approach_for_Structure_and_Motion_Restoration_in_Generative_and_Re",
    "title": "2512.12060v1 CreativeVR Diffusion-Prior-Guided Approach for Structure and Motion Restoration in Generative and Re",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.12060v1_CreativeVR_Diffusion-Prior-Guided_Approach_for_Structure_and_Motion_Restoration_in_Generative_and_Re.pdf",
    "url": "http://arxiv.org/abs/2512.12060v1_CreativeVR_Diffusion-Prior-Guided_Approach_for_Structure_and_Motion_Restoration_in_Generative_and_Re",
    "pdf_url": "https://arxiv.org/pdf/2512.12060v1_CreativeVR_Diffusion-Prior-Guided_Approach_for_Structure_and_Motion_Restoration_in_Generative_and_Re",
    "file_size_mb": 47.61,
    "abstract": "Modern text-to-video (T2V) diffusion models can syn- thesize visually compelling clips, yet they remain brittle at fine-scale structure: even state-of-the-art generators often produce distorted faces and hands, warped backgrounds, and temporally inconsistent motion. Such severe struc- tural artifacts also appear in very low-quality real-world videos. Classical video restoration and super-resolution (VR/VSR) methods, in contrast, are tuned for synthetic degradations such as blur and downsampling and tend to stabilize these artifacts rather than repair them, while diffusion-prior restorers are usually trained on photomet- ric noise and offer little control over the trade-off between perceptual quality and fidelity. We introduce CreativeVR, a diffusion-prior-guided video restoration framework for AI-generated (AIGC) and real videos with severe structural and temporal artifacts. Our deep-adapter-based method ex- poses a single precision knob that controls how strongly the model follows the input, smoothly trading off between precise restoration on standard degradations and stronger structure- and motion-corrective behavior on challenging content. Our key novelty is a temporally coherent degra- dation module used during training, which applies care- fully designed transformations that produce realistic struc- tural failures. To evaluate AIGC-artifact restoration, we propose the AIGC54 benchmark with FIQA, semantic and perceptual metrics, and multi-aspect scoring. CreativeVR achieves state-of-the-art results on videos with severe arti- facts and performs competitively on standard video restora- tion benchmarks, while running at practical throughput (∼13 FPS @ 720p on a single 80 GB A100).",
    "keywords": []
  },
  {
    "article_id": "2512.12142v1_MeltwaterBench_Deep_learning_for_spatiotemporal_downscaling_of_surface_meltwater",
    "title": "2512.12142v1 MeltwaterBench Deep learning for spatiotemporal downscaling of surface meltwater",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.12142v1_MeltwaterBench_Deep_learning_for_spatiotemporal_downscaling_of_surface_meltwater.pdf",
    "url": "http://arxiv.org/abs/2512.12142v1_MeltwaterBench_Deep_learning_for_spatiotemporal_downscaling_of_surface_meltwater",
    "pdf_url": "https://arxiv.org/pdf/2512.12142v1_MeltwaterBench_Deep_learning_for_spatiotemporal_downscaling_of_surface_meltwater",
    "file_size_mb": 8.45,
    "abstract": "The Greenland ice sheet is melting at an accelerated rate due to processes that are not fully understood and hard to measure. The distribution of surface meltwater can help understand these processes and is observable through remote sensing, but current maps of meltwater face a trade-off: They are either high-resolution in time or space, but not both. We develop a deep learning model that creates gridded surface meltwater maps at daily 100m resolu- tion by fusing data streams from remote sensing observations and physics-based models. In particular, we spatiotemporally downscale regional climate model (RCM) outputs using synthetic aperture radar (SAR), passive microwave (PMW), and a digital elevation model (DEM) over the Helheim Glacier in Eastern Greenland from 2017-2023. Using SAR-derived meltwater as “ground truth”, we show that a deep learning-based method that fuses all data streams is over 10 percentage points more accurate over our study area than existing non deep learning-based approaches that only rely on a regional climate model (83% vs. 95% Acc.) or passive microwave observations (72% vs. 95% Acc.). Alternatively, creating a grid- ded product through a running window calculation with SAR data underestimates extreme melt events, but also achieves notable accuracy (90%) and does not rely on deep learning. We evaluate standard deep learning methods (UNet and DeepLabv3+), and publish our spatiotemporally aligned dataset as a benchmark, MeltwaterBench, for intercomparisons with more complex data-driven downscaling methods. The code and data are available at github.com/blutjens/hrmelt. Plain language summary Understanding why the Greenland ice sheet has been melting faster is challenging due to the difficulty of observing the underlying processes. An important observable indicator is surface meltwater, which is water that forms on top of or within the first meters of the ice sheet. The highest resolution information on surface meltwater can be derived from satellites with a synthetic aperture radar (SAR) instrument, but the resulting data is hard to use due to temporal gaps from the satellites’ flight paths. During such temporal gaps an extreme meltwater event that can produce billions of tons of meltwater within a single day could have occurred. To simplify the use of surface meltwater data, we propose a deep learning method that creates regularly-spaced, daily, high-resolution maps of surface meltwater. The deep learning model does so by fusing the information from SAR with other satellite data and physics-based simulations that are available on a daily basis. We show that surface meltwater maps from our deep learning model are significantly more accurate than currently used maps. And, to encourage the development of more complex models we publish our data as a benchmark dataset.",
    "keywords": []
  },
  {
    "article_id": "2512.12250v1_Stochastic_Volatility_Modelling_with_LSTM_Networks_A_Hybrid_Approach_for_SP_500_Index_Volatility_For",
    "title": "2512.12250v1 Stochastic Volatility Modelling with LSTM Networks A Hybrid Approach for SP 500 Index Volatility For",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.12250v1_Stochastic_Volatility_Modelling_with_LSTM_Networks_A_Hybrid_Approach_for_SP_500_Index_Volatility_For.pdf",
    "url": "http://arxiv.org/abs/2512.12250v1_Stochastic_Volatility_Modelling_with_LSTM_Networks_A_Hybrid_Approach_for_SP_500_Index_Volatility_For",
    "pdf_url": "https://arxiv.org/pdf/2512.12250v1_Stochastic_Volatility_Modelling_with_LSTM_Networks_A_Hybrid_Approach_for_SP_500_Index_Volatility_For",
    "file_size_mb": 1.63,
    "abstract": "Accurate volatility forecasting is essential in various domains, including banking, investment, and risk management, as expectations about future market movements directly influence current decision-making. This study proposes a hybrid modeling framework that integrates a Stochastic Volatility model with a Long Short-Term Memory neural network. The SV model contributes statistical precision and the ability to capture latent volatility dynamics, particularly in response to unforeseen events, while the LSTM network enhances the model’s ability to detect complex, nonlinear patterns in financial time series. The forecasting is conducted using daily data from the S&P 500 index, covering the period from January 1, 1998, to December 31, 2024. A rolling window approach is employed to train the model and generate one-step-ahead volatility forecasts. The performance of the hybrid SV-LSTM model is evaluated through both statistical testing and investment simulations. Results show that the hybrid approach outperforms both the standalone SV and LSTM models. These findings contribute to the ongoing development of volatility model- ing techniques and provide a robust foundation for enhancing risk assessment and strategic investment planning in the context of the S&P 500.",
    "keywords": [
      "Stochastic Volatility",
      "LSTM",
      "Hybrid Models",
      "Financial Forecasting"
    ]
  },
  {
    "article_id": "2512.12334v1_Extending_the_application_of_dynamic_Bayesian_networks_in_calculating_market_risk_Standard_and_stres",
    "title": "2512.12334v1 Extending the application of dynamic Bayesian networks in calculating market risk Standard and stres",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.12334v1_Extending_the_application_of_dynamic_Bayesian_networks_in_calculating_market_risk_Standard_and_stres.pdf",
    "url": "http://arxiv.org/abs/2512.12334v1_Extending_the_application_of_dynamic_Bayesian_networks_in_calculating_market_risk_Standard_and_stres",
    "pdf_url": "https://arxiv.org/pdf/2512.12334v1_Extending_the_application_of_dynamic_Bayesian_networks_in_calculating_market_risk_Standard_and_stres",
    "file_size_mb": 0.54,
    "abstract": "In the last five years, expected shortfall (ES) and stressed ES (SES) have become key required regulatory measures of market risk in the banking sector, especially following events such as the global financial crisis. Thus, finding ways to optimize their estimation is of great importance. We extend the application of dynamic Bayesian networks (DBNs) to the estimation of 10-day 97.5% ES and stressed ES, building on prior work applying DBNs to value at risk. Using the S&P 500 index as a proxy for the equities trading desk of a US bank, we compare the performance of three DBN structure-learning algorithms with several traditional market risk models, using either the normal or the skewed Student’s t return distributions. Backtesting shows that all models fail to produce statistically accurate ES and SES forecasts at the 2.5% level, reflecting the difficulty of modeling extreme tail behavior. For ES, the EGARCH(1,1) model (normal) produces the most accurate forecasts, while, for SES, the GARCH(1,1) model (normal) performs best. All distribution-dependent models deteriorate substantially when using the skewed Student’s t distribution. The DBNs perform comparably to the historical simulation model, but their contribution to tail prediction is limited by the small weight assigned to their one-day-ahead forecasts within the return distribution. Future research should examine weighting schemes that enhance the influence of forward-looking DBN forecasts on tail risk estimation.",
    "keywords": [
      "Market risk forecasting",
      "Basel Accords",
      "Risk management",
      "Equities"
    ]
  },
  {
    "article_id": "2512.12339v1_Unified_Control_for_Inference-Time_Guidance_of_Denoising_Diffusion_Models",
    "title": "2512.12339v1 Unified Control for Inference-Time Guidance of Denoising Diffusion Models",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.12339v1_Unified_Control_for_Inference-Time_Guidance_of_Denoising_Diffusion_Models.pdf",
    "url": "http://arxiv.org/abs/2512.12339v1_Unified_Control_for_Inference-Time_Guidance_of_Denoising_Diffusion_Models",
    "pdf_url": "https://arxiv.org/pdf/2512.12339v1_Unified_Control_for_Inference-Time_Guidance_of_Denoising_Diffusion_Models",
    "file_size_mb": 16.57,
    "abstract": "Aligning diffusion model outputs with downstream objec- tives is essential for improving task-specific performance. Broadly, inference-time training-free approaches for align- ing diffusion models can be categorized into two main strategies: sampling-based methods, which explore multi- ple candidate outputs and select those with higher reward signals, and gradient-guided methods, which use differen- tiable reward approximations to directly steer the genera- tion process. In this work, we propose a universal algo- rithm, UniCoDe, which brings together the strengths of sampling and gradient-based guidance into a unified frame- work. UniCoDe integrates local gradient signals during sampling, thereby addressing the sampling inefficiency in- herent in complex reward-based sampling approaches. By cohesively combining these two paradigms, UniCoDe en- ables more efficient sampling while offering better trade- offs between reward alignment and divergence from the dif- fusion unconditional prior. Empirical results demonstrate that UniCoDe remains competitive with state-of-the-art baselines across a range of tasks. The code is available at https://github.com/maurya-goyal10/UniCoDe",
    "keywords": []
  },
  {
    "article_id": "2512.12420v1_Deep_Hedging_with_Reinforcement_Learning_A_Practical_Framework_for_Option_Risk_Management",
    "title": "2512.12420v1 Deep Hedging with Reinforcement Learning A Practical Framework for Option Risk Management",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.12420v1_Deep_Hedging_with_Reinforcement_Learning_A_Practical_Framework_for_Option_Risk_Management.pdf",
    "url": "http://arxiv.org/abs/2512.12420v1_Deep_Hedging_with_Reinforcement_Learning_A_Practical_Framework_for_Option_Risk_Management",
    "pdf_url": "https://arxiv.org/pdf/2512.12420v1_Deep_Hedging_with_Reinforcement_Learning_A_Practical_Framework_for_Option_Risk_Management",
    "file_size_mb": 0.71,
    "abstract": null,
    "keywords": []
  },
  {
    "article_id": "2512.12526v1_Empirical_Mode_Decomposition_and_Graph_Transformation_of_the_MSCI_World_Index_A_Multiscale_Topologic",
    "title": "2512.12526v1 Empirical Mode Decomposition and Graph Transformation of the MSCI World Index A Multiscale Topologic",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.12526v1_Empirical_Mode_Decomposition_and_Graph_Transformation_of_the_MSCI_World_Index_A_Multiscale_Topologic.pdf",
    "url": "http://arxiv.org/abs/2512.12526v1_Empirical_Mode_Decomposition_and_Graph_Transformation_of_the_MSCI_World_Index_A_Multiscale_Topologic",
    "pdf_url": "https://arxiv.org/pdf/2512.12526v1_Empirical_Mode_Decomposition_and_Graph_Transformation_of_the_MSCI_World_Index_A_Multiscale_Topologic",
    "file_size_mb": 1.33,
    "abstract": "This study applies Empirical Mode Decomposition (EMD) to the MSCI World index and converts the resulting intrinsic mode functions (IMFs) into graph representations to enable modeling with graph neural networks (GNNs). Using CEEMDAN, we extract nine IMFs spanning high-frequency fluctuations to long-term trends. Each IMF is transformed into a graph using four time-series-to-graph methods: natural visibility, horizontal visibility, recurrence, and transition graphs. Topological analysis shows clear scale-dependent structure: high-frequency IMFs yield dense, highly connected small-world graphs, whereas low-frequency IMFs produce sparser networks with longer characteristic path lengths. Visibility-based methods are more sensitive to amplitude variability and typically generate higher clustering, while recurrence graphs better preserve temporal dependencies. These results provide guidance for designing GNN architectures tailored to the structural properties of decomposed components, supporting more effective predictive modeling of financial time series.",
    "keywords": [
      "Time Series-Graph Transformation",
      "Visibility Graphs",
      "Recurrence Graphs",
      "Graph"
    ]
  },
  {
    "article_id": "2512.12708v1_Multi-Trajectory_Physics-Informed_Neural_Networks_for_HJB_Equations_with_Hard-Zero_Terminal_Inventor",
    "title": "2512.12708v1 Multi-Trajectory Physics-Informed Neural Networks for HJB Equations with Hard-Zero Terminal Inventor",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.12708v1_Multi-Trajectory_Physics-Informed_Neural_Networks_for_HJB_Equations_with_Hard-Zero_Terminal_Inventor.pdf",
    "url": "http://arxiv.org/abs/2512.12708v1_Multi-Trajectory_Physics-Informed_Neural_Networks_for_HJB_Equations_with_Hard-Zero_Terminal_Inventor",
    "pdf_url": "https://arxiv.org/pdf/2512.12708v1_Multi-Trajectory_Physics-Informed_Neural_Networks_for_HJB_Equations_with_Hard-Zero_Terminal_Inventor",
    "file_size_mb": 6.41,
    "abstract": "We study optimal trade execution with a hard-zero terminal inventory constraint, modeled via Hamilton-Jacobi-Bellman (HJB) equations. Vanilla PINNs often under-enforce this constraint and produce unstable controls. We propose a Multi- Trajectory PINN (MT-PINN) that adds a rollout-based trajectory loss and prop- agates a terminal penalty on XT via backpropagation-through-time, directly en- forcing XT = 0. A lightweight λ-curriculum is adopted to stabilize training as the state expands from a risk-neutral reduced HJB to a risk-averse HJB. On the Gatheral-Schied single-asset model [1], MT-PINN aligns closely with their derived closed-form solutions and concentrates terminal inventory tightly around zero while reducing errors along optimal paths. We apply MT-PINNs on SPY intraday data, matching TWAP when risk-neutral, and achieving lower exposure and competitive costs, especially in falling windows, for higher risk-aversion.",
    "keywords": []
  },
  {
    "article_id": "2512.12748v1_Complexity_of_Markov_Chain_Monte_Carlo_for_Generalized_Linear_Models",
    "title": "2512.12748v1 Complexity of Markov Chain Monte Carlo for Generalized Linear Models",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.12748v1_Complexity_of_Markov_Chain_Monte_Carlo_for_Generalized_Linear_Models.pdf",
    "url": "http://arxiv.org/abs/2512.12748v1_Complexity_of_Markov_Chain_Monte_Carlo_for_Generalized_Linear_Models",
    "pdf_url": "https://arxiv.org/pdf/2512.12748v1_Complexity_of_Markov_Chain_Monte_Carlo_for_Generalized_Linear_Models",
    "file_size_mb": 1.04,
    "abstract": "Markov Chain Monte Carlo (MCMC), Laplace approximation (LA) and variational inference (VI) methods are popular approaches to Bayesian inference, each with trade-offs between computational cost and accuracy. However, a theoretical understanding of these differences is missing, par- ticularly when both the sample size n and the dimension d are large. LA and Gaussian VI are justified by Bernstein-von Mises (BvM) theorems, and recent work has derived the characteristic condition n ≫d2 for their validity, improving over the condition n ≫d3. In this paper, we show for linear, logistic and Poisson regression that for n ≳d, MCMC attains the same complexity scaling in n, d as first-order optimization algorithms, up to sub-polynomial factors. Thus MCMC is competitive with LA and Gaussian VI in complexity, under a scaling between n and d more gen- eral than BvM regimes. Our complexities apply to appropriately scaled priors that are not necessarily Gaussian-tailed, including Student-t and flat priors, with log-posteriors that are not necessarily globally concave or gradient-Lipschitz.",
    "keywords": []
  },
  {
    "article_id": "2512.12769v2_Adaptive_Edge-Cloud_Inference_for_Speech-to-Action_Systems_Using_ASR_and_Large_Language_Models",
    "title": "2512.12769v2 Adaptive Edge-Cloud Inference for Speech-to-Action Systems Using ASR and Large Language Models",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.12769v2_Adaptive_Edge-Cloud_Inference_for_Speech-to-Action_Systems_Using_ASR_and_Large_Language_Models.pdf",
    "url": "http://arxiv.org/abs/2512.12769v2_Adaptive_Edge-Cloud_Inference_for_Speech-to-Action_Systems_Using_ASR_and_Large_Language_Models",
    "pdf_url": "https://arxiv.org/pdf/2512.12769v2_Adaptive_Edge-Cloud_Inference_for_Speech-to-Action_Systems_Using_ASR_and_Large_Language_Models",
    "file_size_mb": 1.58,
    "abstract": "—Voice-based interaction has emerged as a natural and intuitive modality for controlling IoT devices. However, speech-driven edge devices face a fundamental trade-off between cloud-based solutions, which offer stronger language understand- ing capabilities at the cost of latency, connectivity dependence, and privacy concerns, and edge-based solutions, which provide low latency and improved privacy but are limited by computa- tional constraints. This paper presents ASTA, an adaptive speech- to-action solution that dynamically routes voice commands be- tween edge and cloud inference to balance performance and system resource utilization. ASTA integrates on-device auto- matic speech recognition and lightweight offline language-model inference with cloud-based LLM processing, guided by real- time system metrics such as CPU workload, device temperature, and network latency. A metric-aware routing mechanism selects the inference path at runtime, while a rule-based command validation and repair component ensures successful end-to-end command execution. We implemented our solution on an NVIDIA Jetson-based edge platform and evaluated it using a diverse dataset of 80 spoken commands. Experimental results show that ASTA successfully routes all input commands for execution, achieving a balanced distribution between online and offline inference. The system attains an ASR accuracy of 62.5% and generates executable commands without repair for only 47.5% of inputs, highlighting the importance of the repair mechanism in improving robustness. These results suggest that adaptive edge-cloud orchestration is a viable approach for resilient and resource-aware voice-controlled IoT systems.",
    "keywords": [
      "Edge-cloud computing",
      "Adaptive interface rout-"
    ]
  },
  {
    "article_id": "2512.12858v1_Information-Consistent_Language_Model_Recommendations_through_Group_Relative_Policy_Optimization",
    "title": "2512.12858v1 Information-Consistent Language Model Recommendations through Group Relative Policy Optimization",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.12858v1_Information-Consistent_Language_Model_Recommendations_through_Group_Relative_Policy_Optimization.pdf",
    "url": "http://arxiv.org/abs/2512.12858v1_Information-Consistent_Language_Model_Recommendations_through_Group_Relative_Policy_Optimization",
    "pdf_url": "https://arxiv.org/pdf/2512.12858v1_Information-Consistent_Language_Model_Recommendations_through_Group_Relative_Policy_Optimization",
    "file_size_mb": 0.27,
    "abstract": "Large Language Models (LLMs) are increasingly deployed in business-critical domains such as finance, education, healthcare, and customer support, where users expect consistent and reliable recommendations. Yet LLMs often exhibit variability when prompts are phrased with minor dif- ferences, even when semantically equivalent. Such inconsistency undermines trust, complicates compliance, and disrupts user experience. While personalization is desirable in certain contexts, many enterprise scenarios—such as HR onboarding, customer support, or policy disclosure—require invariant information delivery regardless of phrasing or prior conversational history. Existing ap- proaches, including retrieval-augmented generation (RAG) and temperature tuning, improve factuality or reduce stochasticity but cannot guarantee stability across equivalent prompts. In this paper, we propose a reinforcement learning framework based on Group Relative Policy Optimization (GRPO) to directly optimize for consistency. Unlike prior applications of GRPO, which have been limited to reasoning and code generation, we adapt GRPO to enforce stability of information content across groups of semantically equivalent prompts. We introduce entropy-based helpfulness and stability rewards, treating prompt variants as groups and resetting conversational context to isolate phrasing effects. Experiments on investment and job recommendation tasks show that our GRPO-trained model reduces variability more effectively than fine-tuning or decoding-based baselines. To our knowledge, this is a novel application of GRPO for aligning LLMs toward information consistency, reframing variability not as an acceptable feature of generative diversity but as a correctable flaw in enterprise deployments.",
    "keywords": []
  },
  {
    "article_id": "2512.12922v1_LLM-based_Personalized_Portfolio_Recommender_Integrating_Large_Language_Models_and_Reinforcement_Lea",
    "title": "2512.12922v1 LLM-based Personalized Portfolio Recommender Integrating Large Language Models and Reinforcement Lea",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.12922v1_LLM-based_Personalized_Portfolio_Recommender_Integrating_Large_Language_Models_and_Reinforcement_Lea.pdf",
    "url": "http://arxiv.org/abs/2512.12922v1_LLM-based_Personalized_Portfolio_Recommender_Integrating_Large_Language_Models_and_Reinforcement_Lea",
    "pdf_url": "https://arxiv.org/pdf/2512.12922v1_LLM-based_Personalized_Portfolio_Recommender_Integrating_Large_Language_Models_and_Reinforcement_Lea",
    "file_size_mb": 0.82,
    "abstract": ". In modern financial markets, investors increasingly seek personalized and adaptive portfolio strategies that reflect their individual risk preferences and respond to dynamic market conditions. Traditional rule-based or static optimization approaches often fail to capture the nonlinear interactions among investor behavior, market volatility, and evolving financial objectives. To address these limitations, this paper introduces the LLM-based Personalized Portfolio Recommender (L-PPR), an integrated framework that combines Large Language Models (LLMs), reinforcement learning, and individualized risk preference modeling to support intelligent investment decision-making. The proposed system comprises three core components: (1) a Conversational Financial Agent (FinAgent) that engages with users through natural language, gathers behavioral feedback, and delivers interpretable advisory explanations; (2) a Personalization and Risk Modeling Module that infers investor-specific risk tolerance using Bayesian inference and behavioral imitation learning; and (3) a Strategy Recommendation Engine based on Proximal Policy Optimization (PPO) that generates personalized asset allocation strategies conditioned on user embeddings and real-time market states. Experimental results on a simulated multi-asset portfolio dataset show that L-PPR substantially outperforms established baselines, including Mean – Variance Optimization (MVO), Deep Reinforcement Learning Portfolio (DRL-PPO), and BERT-based Financial Advisor (BERT-FA). Specifically, L-PPR achieves a 73.8% improvement in annualized return and a 33.2% reduction in maximum drawdown relative to MVO. It also records the highest Sharpe Ratio (1.45), Information Ratio (0.78), and User Alignment Score (0.89). These findings demonstrate that L-PPR effectively enhances risk-adjusted performance while delivering superior personalization and user satisfaction.",
    "keywords": [
      "Large Language Models (LLM)",
      "Reinforcement Learning",
      "Personalized"
    ]
  },
  {
    "article_id": "2512.12924v1_Interpretable_Hypothesis-Driven_TradingA_Rigorous_Walk-Forward_Validation_Framework_for_Market_Micro",
    "title": "2512.12924v1 Interpretable Hypothesis-Driven TradingA Rigorous Walk-Forward Validation Framework for Market Micro",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.12924v1_Interpretable_Hypothesis-Driven_TradingA_Rigorous_Walk-Forward_Validation_Framework_for_Market_Micro.pdf",
    "url": "http://arxiv.org/abs/2512.12924v1_Interpretable_Hypothesis-Driven_TradingA_Rigorous_Walk-Forward_Validation_Framework_for_Market_Micro",
    "pdf_url": "https://arxiv.org/pdf/2512.12924v1_Interpretable_Hypothesis-Driven_TradingA_Rigorous_Walk-Forward_Validation_Framework_for_Market_Micro",
    "file_size_mb": 3.08,
    "abstract": "We develop a rigorous walk-forward validation framework for algorithmic trading designed to mitigate overfitting and lookahead bias. Our methodology combines in- terpretable hypothesis-driven signal generation with reinforcement learning and strict out-of-sample testing. The framework enforces strict information set discipline, em- ploys rolling window validation across 34 independent test periods, maintains complete interpretability through natural language hypothesis explanations, and incorporates re- alistic transaction costs and position constraints. Validating five market microstructure patterns across 100 US equities from 2015 to 2024, the system yields modest annualized returns (0.55%, Sharpe ratio 0.33) with exceptional downside protection (maximum drawdown −2.76%) and market-neutral characteristics (β = 0.058). Performance ex- hibits strong regime dependence, generating positive returns during high-volatility pe- riods (0.60% quarterly, 2020–2024) while underperforming in stable markets (−0.16%, 2015–2019). We report statistically insignificant aggregate results (p-value 0.34) to demonstrate a reproducible, honest validation protocol that prioritizes interpretabil- ity and extends naturally to advanced hypothesis generators, including large language models. The key empirical finding reveals that daily OHLCV-based microstructure signals require elevated information arrival and trading activity to function effectively. ∗Department of Mathematics & Statistics, Texas Tech University. Email: gdeep@ttu.edu. Corresponding author. †Department of Mathematics & Statistics, Texas Tech University. Email: akash.deep@ttu.edu. ‡Department of Mathematics & Statistics, Texas Tech University. Email: wilampte@ttu.edu. 1 arXiv:2512.12924v1 [q-fin.TR] 15 Dec 2025 The framework provides complete mathematical specifications and open-source imple- mentation, establishing a template for rigorous trading system evaluation that ad- dresses the reproducibility crisis in quantitative finance research. For researchers, practitioners, and regulators, this work demonstrates that interpretable algorithmic trading strategies can be rigorously validated without sacrificing transparency or reg- ulatory compliance.",
    "keywords": [
      "Algorithmic Trading",
      "Walk-Forward Validation",
      "Market Microstructure"
    ]
  },
  {
    "article_id": "2512.12932v1_Investigating_Data_Pruning_for_Pretraining_Biological_Foundation_Models_at_Scale",
    "title": "2512.12932v1 Investigating Data Pruning for Pretraining Biological Foundation Models at Scale",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.12932v1_Investigating_Data_Pruning_for_Pretraining_Biological_Foundation_Models_at_Scale.pdf",
    "url": "http://arxiv.org/abs/2512.12932v1_Investigating_Data_Pruning_for_Pretraining_Biological_Foundation_Models_at_Scale",
    "pdf_url": "https://arxiv.org/pdf/2512.12932v1_Investigating_Data_Pruning_for_Pretraining_Biological_Foundation_Models_at_Scale",
    "file_size_mb": 0.58,
    "abstract": "Biological foundation models (BioFMs), pretrained on large- scale biological sequences, have recently shown strong po- tential in providing meaningful representations for diverse downstream bioinformatics tasks. However, such models of- ten rely on millions to billions of training sequences and bil- lions of parameters, resulting in prohibitive computational costs and significant barriers to reproducibility and accessi- bility—particularly for academic labs. To address these chal- lenges, we investigate the feasibility of data pruning for BioFM pretraining and propose a post-hoc influence-guided data pruning framework tailored to biological domains. Our approach first introduces a subset-based self-influence for- mulation that enables efficient estimation of sample impor- tance at low computational cost. Built upon this, we propose two simple yet effective selection strategies: Top-k Influence (Top I) and Coverage-Centric Influence (CCI). Then, we em- pirically validate our method on two representative BioFMs: RNA-FM and ESM-C. For RNA, our framework consistently outperforms random selection baselines under an extreme pruning rate of over 99%, which displays our framework’s ef- fectiveness. Furthermore, we demonstrate the generalizabil- ity of our framework on protein-related tasks using ESM-C. In specific, our coreset even outperforms random 10× sub- sets in both RNA and protein settings, revealing substantial redundancy in biological sequence dataset. These findings underscore the potential of influence-guided data pruning to substantially reduce the computational cost of BioFM pre- training, paving the way for more efficient, accessible, and sustainable biological AI research. Code — https://github.com/victor-yifanwu/bio-coreset",
    "keywords": []
  },
  {
    "article_id": "2512.13168v2_Finch_Benchmarking_Finance_Accounting_across_Spreadsheet-Centric_Enterprise_Workflows",
    "title": "2512.13168v2 Finch Benchmarking Finance Accounting across Spreadsheet-Centric Enterprise Workflows",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.13168v2_Finch_Benchmarking_Finance_Accounting_across_Spreadsheet-Centric_Enterprise_Workflows.pdf",
    "url": "http://arxiv.org/abs/2512.13168v2_Finch_Benchmarking_Finance_Accounting_across_Spreadsheet-Centric_Enterprise_Workflows",
    "pdf_url": "https://arxiv.org/pdf/2512.13168v2_Finch_Benchmarking_Finance_Accounting_across_Spreadsheet-Centric_Enterprise_Workflows",
    "file_size_mb": 5.25,
    "abstract": "We introduce a finance & accounting benchmark (FINCH) for evaluating AI agents on real-world, enterprise-grade professional workflows—interleaving data entry, structuring, formatting, web search, cross-file retrieval, calculation, modeling, vali- dation, translation, visualization, and reporting. FINCH is sourced from authentic enterprise workspaces at Enron (15,000 spreadsheets and 500,000 emails from 150 employees) and other financial institutions, preserving in-the-wild messiness across multimodal artifacts (text, tables, formulas, charts, code, and images) and spanning diverse domains such as budgeting, trading, and asset management. We propose a workflow construction process that combines LLM-assisted discovery with expert annotation: (1) LLM-assisted, expert-verified derivation of workflows from real-world email threads and version histories of spreadsheet files, and (2) meticulous expert annotation for workflows, requiring over 700 hours of domain- expert effort. This yields 172 composite workflows with 384 tasks, involving 1,710 spreadsheets with 27 million cells, along with PDFs and other artifacts, capturing the intrinsically messy, long-horizon, knowledge-intensive, and collaborative nature of real-world enterprise work. We conduct both human and automated evaluations of frontier AI systems including GPT 5.1, Claude Sonnet 4.5, Gemini 3 Pro, Grok 4, and Qwen 3 Max, and GPT 5.1 Pro spends 48 hours in total yet passes only 38.4% of workflows, while Claude Sonnet 4.5 passes just 25.0%. Comprehensive case studies further surface the challenges that real-world enterprise workflows pose for AI agents. Dataset: https://huggingface.co/FinWorkBench ∗Full author list: Appendix A. Preprint. arXiv:2512.13168v2 [cs.AI] 19 Dec 2025",
    "keywords": []
  },
  {
    "article_id": "2512.13323v1_Error-Driven_Prompt_Optimization_for_Arithmetic_Reasoning",
    "title": "2512.13323v1 Error-Driven Prompt Optimization for Arithmetic Reasoning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.13323v1_Error-Driven_Prompt_Optimization_for_Arithmetic_Reasoning.pdf",
    "url": "http://arxiv.org/abs/2512.13323v1_Error-Driven_Prompt_Optimization_for_Arithmetic_Reasoning",
    "pdf_url": "https://arxiv.org/pdf/2512.13323v1_Error-Driven_Prompt_Optimization_for_Arithmetic_Reasoning",
    "file_size_mb": 0.93,
    "abstract": "Recent advancements in artificial intelligence have sparked interest in industrial agents capable of supporting analysts in regulated sectors, such as finance and health- care, within tabular data workflows. A key capability for such systems is performing accurate arithmetic opera- tions on structured data while ensuring sensitive informa- tion never leaves secure, on-premises environments. Here, we introduce an error-driven optimization framework for arithmetic reasoning that enhances a Code Generation Agent (CGA), specifically applied to on-premises small language models (SLMs). Through a systematic evalu- ation of a leading SLM (Qwen3 4B), we find that while the base model exhibits fundamental limitations in arith- metic tasks, our proposed error-driven method, which clusters erroneous predictions to refine prompt-rules iter- atively, dramatically improves performance, elevating the model’s accuracy to 70.8%. Our results suggest that de- veloping reliable, interpretable, and industrially deploy- able AI assistants can be achieved not only through costly fine-tuning but also via systematic, error-driven prompt optimization, enabling small models to surpass larger lan- guage models (GPT-3.5 Turbo) in a privacy-compliant manner.",
    "keywords": [
      "Arithmetic calculation"
    ]
  },
  {
    "article_id": "2512.13480v1_Element-wise_Modulation_of_Random_Matrices_for_Efficient_Neural_Layers",
    "title": "2512.13480v1 Element-wise Modulation of Random Matrices for Efficient Neural Layers",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.13480v1_Element-wise_Modulation_of_Random_Matrices_for_Efficient_Neural_Layers.pdf",
    "url": "http://arxiv.org/abs/2512.13480v1_Element-wise_Modulation_of_Random_Matrices_for_Efficient_Neural_Layers",
    "pdf_url": "https://arxiv.org/pdf/2512.13480v1_Element-wise_Modulation_of_Random_Matrices_for_Efficient_Neural_Layers",
    "file_size_mb": 0.41,
    "abstract": "Fully connected layers are a primary source of memory and computational overhead in deep neural networks due to their dense, often redundant param- eterization. While various compression techniques exist, they frequently introduce complex engineer- ing trade-offs or degrade model performance. We propose the Parametrized Random Projection (PRP) layer, a novel approach that decouples feature mixing from adaptation by utilizing a fixed random matrix modulated by lightweight, learnable element-wise parameters. This architecture drastically reduces the trainable parameter count to a linear scale while re- taining reliable accuracy across various benchmarks. The design serves as a stable, computationally effi- cient solution for architectural scaling and deploy- ment in resource-limited settings.",
    "keywords": []
  },
  {
    "article_id": "2512.13727v1_RAST-MoE-RL_A_Regime-Aware_Spatio-Temporal_MoE_Framework_for_Deep_Reinforcement_Learning_in_Ride-Hai",
    "title": "2512.13727v1 RAST-MoE-RL A Regime-Aware Spatio-Temporal MoE Framework for Deep Reinforcement Learning in Ride-Hai",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.13727v1_RAST-MoE-RL_A_Regime-Aware_Spatio-Temporal_MoE_Framework_for_Deep_Reinforcement_Learning_in_Ride-Hai.pdf",
    "url": "http://arxiv.org/abs/2512.13727v1_RAST-MoE-RL_A_Regime-Aware_Spatio-Temporal_MoE_Framework_for_Deep_Reinforcement_Learning_in_Ride-Hai",
    "pdf_url": "https://arxiv.org/pdf/2512.13727v1_RAST-MoE-RL_A_Regime-Aware_Spatio-Temporal_MoE_Framework_for_Deep_Reinforcement_Learning_in_Ride-Hai",
    "file_size_mb": 4.76,
    "abstract": "Ride-hailing platforms face the challenge of balancing passenger waiting times with overall system efficiency under highly uncertain supply–demand conditions. Adaptive delayed matching, which decides whether to assign drivers immediately or hold requests for batching, creates a fundamental trade-off between matching delay and pickup delay. Because these outcomes accumulate over long horizons and depend on stochastic, evolving supply–demand states, reinforcement learn- ing (RL) is a natural framework for this problem. Yet existing approaches often oversimplify traffic dynamics, misrepresenting congestion effects, or employ RL models with shallow encoders that fail to capture complex spatiotemporal patterns. We introduce the Regime-Aware Spatio-Temporal Mixture-of-Experts framework (RAST-MoE), which formalizes adaptive delayed matching as a regime-aware MDP and equips RL agents with a self-attention MoE encoder. Instead of relying on a single monolithic network, our design allows different experts to specialize automatically, improving representation capacity while keeping per-sample com- putation efficient. A physics-informed congestion surrogate preserves realistic density–speed feedback while enabling millions of efficient rollouts. An adap- tive reward scheme further guards against pathological strategies by dynamically penalizing service-quality violations. Despite its modest size of only 12M param- eters, our framework consistently outperforms strong baselines. On real-world Uber trajectory data from San Francisco, it improves total reward by over 13%, reduces average matching delay by 10%, and reduces pickup delay by 15%. In addition, it demonstrates strong robustness across unseen demand regimes, sta- ble training without reward hacking, and validated expert specialization. These findings demonstrate the broader potential of MoE-enhanced RL for large-scale decision-making tasks with complex spatiotemporal dynamics and large action spaces.",
    "keywords": []
  },
  {
    "article_id": "2512.13729v1_Composite_Classifier-Free_Guidance_for_Multi-Modal_Conditioning_in_Wind_Dynamics_Super-Resolution",
    "title": "2512.13729v1 Composite Classifier-Free Guidance for Multi-Modal Conditioning in Wind Dynamics Super-Resolution",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.13729v1_Composite_Classifier-Free_Guidance_for_Multi-Modal_Conditioning_in_Wind_Dynamics_Super-Resolution.pdf",
    "url": "http://arxiv.org/abs/2512.13729v1_Composite_Classifier-Free_Guidance_for_Multi-Modal_Conditioning_in_Wind_Dynamics_Super-Resolution",
    "pdf_url": "https://arxiv.org/pdf/2512.13729v1_Composite_Classifier-Free_Guidance_for_Multi-Modal_Conditioning_in_Wind_Dynamics_Super-Resolution",
    "file_size_mb": 4.06,
    "abstract": "Various weather modelling problems (e.g., weather fore- casting, optimizing turbine placements, etc.) require ample access to high-resolution, highly accurate wind data. Ac- quiring such high-resolution wind data, however, remains a challenging and expensive endeavour. Traditional recon- struction approaches are typically either cost-effective or accurate, but not both. Deep learning methods, includ- ing diffusion models, have been proposed to resolve this trade-off by leveraging advances in natural image super- resolution. Wind data, however, is distinct from natu- ral images, and wind super-resolvers often use upwards of 10 input channels, significantly more than the usual 3- channel RGB inputs in natural images. To better leverage a large number of conditioning variables in diffusion mod- els, we present a generalization of classifier-free guidance (CFG) to multiple conditioning inputs. Our novel compos- ite classifier-free guidance (CCFG) can be dropped into any pre-trained diffusion model trained with standard CFG dropout. We demonstrate that CCFG outputs are higher- fidelity than those from CFG on wind super-resolution tasks. We present WindDM, a diffusion model trained for industrial-scale wind dynamics reconstruction and leverag- ing CCFG. WindDM achieves state-of-the-art reconstruc- tion quality among deep learning models and costs up to 1000× less than classical methods.",
    "keywords": []
  },
  {
    "article_id": "2512.13733v1_Low-Rank_Compression_of_Language_Models_via_Differentiable_Rank_Selection",
    "title": "2512.13733v1 Low-Rank Compression of Language Models via Differentiable Rank Selection",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.13733v1_Low-Rank_Compression_of_Language_Models_via_Differentiable_Rank_Selection.pdf",
    "url": "http://arxiv.org/abs/2512.13733v1_Low-Rank_Compression_of_Language_Models_via_Differentiable_Rank_Selection",
    "pdf_url": "https://arxiv.org/pdf/2512.13733v1_Low-Rank_Compression_of_Language_Models_via_Differentiable_Rank_Selection",
    "file_size_mb": 0.71,
    "abstract": "Approaches for compressing large-language models using low-rank decomposition have made strides, particularly with the introduction of activation and loss-aware SVD, which improves the trade-off between decomposition rank and downstream task performance. Despite these advancements, a persistent challenge remains–selecting the optimal ranks for each layer to jointly optimise compression rate and downstream task accuracy. Current methods either rely on heuristics that can yield sub-optimal results due to their limited discrete search space or are gradient-based but are not as performant as heuristic approaches without post-compression fine-tuning. To address these issues, we propose Learning to Low-Rank Compress (LLRC), a gradient-based approach which directly learns the weights of masks that select singular values in a fine-tuning-free setting. Using a calibration dataset, we train only the mask weights to select fewer and fewer singular values while minimising the divergence of intermediate activations from the original model. Our approach outperforms competing ranking selection methods that similarly require no post-compression fine-tuning across various compression rates on common-sense reasoning and open-domain question-answering tasks. For instance, with a compression rate of 20% on Llama-2-13B, LLRC outperforms the competitive Sensitivity-based Truncation Rank Searching (STRS) on MMLU, BoolQ, and OpenbookQA by 12%, 3.5%, and 4.4%, respectively. Compared to other compression techniques, our approach consistently outperforms fine-tuning-free variants of SVD-LLM and LLM-Pruner across datasets and compression rates. Our fine-tuning-free approach also performs competitively with the fine-tuning variant of LLM-Pruner.",
    "keywords": [
      "LLM Compression",
      "Low-Rank Decomposition",
      "Rank Selection"
    ]
  },
  {
    "article_id": "2512.13752v1_STAR_STacked_AutoRegressive_Scheme_for_Unified_Multimodal_Learning",
    "title": "2512.13752v1 STAR STacked AutoRegressive Scheme for Unified Multimodal Learning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.13752v1_STAR_STacked_AutoRegressive_Scheme_for_Unified_Multimodal_Learning.pdf",
    "url": "http://arxiv.org/abs/2512.13752v1_STAR_STacked_AutoRegressive_Scheme_for_Unified_Multimodal_Learning",
    "pdf_url": "https://arxiv.org/pdf/2512.13752v1_STAR_STacked_AutoRegressive_Scheme_for_Unified_Multimodal_Learning",
    "file_size_mb": 19.97,
    "abstract": "Multimodal large language models (MLLMs) play a pivotal role in advancing the quest for general artificial intelligence. However, achieving unified target for mul- timodal understanding and generation remains challenging due to optimization conflicts and performance trade-offs. To effectively enhance generative perfor- mance while preserving existing comprehension capabilities, we introduce STAR: a STacked AutoRegressive scheme for task-progressive unified multimodal learn- ing. This approach decomposes multimodal learning into multiple stages: under- standing, generation, and editing. By freezing the parameters of the fundamental autoregressive (AR) model and progressively stacking isomorphic AR modules, it avoids cross-task interference while expanding the model’s capabilities. Concur- rently, we introduce a high-capacity VQ to enhance the granularity of image rep- resentations and employ an implicit reasoning mechanism to improve generation quality under complex conditions. Experiments demonstrate that STAR achieves state-of-the-art performance on GenEval (0.91), DPG-Bench (87.44), and ImgEdit (4.34), validating its efficacy for unified multimodal learning.",
    "keywords": []
  },
  {
    "article_id": "2512.13886v1_OPTIMA_Optimal_One-shot_Pruning_for_LLMs_via_Quadratic_Programming_Reconstruction",
    "title": "2512.13886v1 OPTIMA Optimal One-shot Pruning for LLMs via Quadratic Programming Reconstruction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.13886v1_OPTIMA_Optimal_One-shot_Pruning_for_LLMs_via_Quadratic_Programming_Reconstruction.pdf",
    "url": "http://arxiv.org/abs/2512.13886v1_OPTIMA_Optimal_One-shot_Pruning_for_LLMs_via_Quadratic_Programming_Reconstruction",
    "pdf_url": "https://arxiv.org/pdf/2512.13886v1_OPTIMA_Optimal_One-shot_Pruning_for_LLMs_via_Quadratic_Programming_Reconstruction",
    "file_size_mb": 1.84,
    "abstract": "Post-training model pruning is a promising solution, yet it faces a trade-off: simple heuristics that zero weights are fast but degrade accuracy, while principled joint optimization methods recover accuracy but are computationally infeasible at modern scale. One-shot methods such as SparseGPT offer a practical trade-off in optimality by applying efficient, approximate heuristic weight updates. To close this gap, we introduce OPTIMA, a practical one-shot post-training pruning method that balances accuracy and scalability. OPTIMA casts layer-wise weight reconstruction after mask selection as independent, row-wise Quadratic Programs (QPs) that share a common layer Hessian. Solving these QPs yields the per-row globally optimal update with respect to the reconstruction objective given the estimated Hessian. The shared-Hessian structure makes the problem highly amenable to batching on accelerators. We implement an accelerator-friendly QP solver that accumulates one Hessian per layer and solves many small QPs in parallel, enabling one-shot post-training pruning at scale on a single accelerator without fine-tuning. OPTIMA integrates with existing mask selectors and consistently improves zero-shot performance across multiple LLM families and sparsity regimes, yielding up to 3.97% absolute accuracy improvement. On an NVIDIA H100, OPTIMA prunes a 8B-parameter transformer end-to-end in 40 hours with 60 GB peak memory. Together, these results set a new state-of-the-art accuracy-efficiency trade-offs for one-shot post-training pruning.1",
    "keywords": []
  },
  {
    "article_id": "2512.14078v1_FusAD_Time-Frequency_Fusion_with_Adaptive_Denoising_for_General_Time_Series_Analysis",
    "title": "2512.14078v1 FusAD Time-Frequency Fusion with Adaptive Denoising for General Time Series Analysis",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.14078v1_FusAD_Time-Frequency_Fusion_with_Adaptive_Denoising_for_General_Time_Series_Analysis.pdf",
    "url": "http://arxiv.org/abs/2512.14078v1_FusAD_Time-Frequency_Fusion_with_Adaptive_Denoising_for_General_Time_Series_Analysis",
    "pdf_url": "https://arxiv.org/pdf/2512.14078v1_FusAD_Time-Frequency_Fusion_with_Adaptive_Denoising_for_General_Time_Series_Analysis",
    "file_size_mb": 2.89,
    "abstract": "—Time series analysis plays a vital role in fields such as finance, healthcare, industry, and meteorology, underpinning key tasks including classification, forecasting, and anomaly detec- tion. Although deep learning models have achieved remarkable progress in these areas in recent years, constructing an efficient, multi-task compatible, and generalizable unified framework for time series analysis remains a significant challenge. Existing approaches are often tailored to single tasks or specific data types, making it difficult to simultaneously handle multi-task modeling and effectively integrate information across diverse time series types. Moreover, real-world data are often affected by noise, complex frequency components, and multi-scale dynamic patterns, which further complicate robust feature extraction and analysis. To ameliorate these challenges, we propose FusAD, a unified analysis framework designed for diverse time series tasks. FusAD features an adaptive time-frequency fusion mechanism, integrating both Fourier and Wavelet transforms to efficiently capture global-local and multi-scale dynamic features. With an adaptive denoising mechanism, FusAD automatically senses and filters various types of noise, highlighting crucial sequence variations and enabling robust feature extraction in complex environments. In addition, the framework integrates a general in- formation fusion and decoding structure, combined with masked pre-training, to promote efficient learning and transfer of multi- granularity representations. Extensive experiments demonstrate that FusAD consistently outperforms state-of-the-art models on mainstream time series benchmarks for classification, forecasting, and anomaly detection tasks, while maintaining high efficiency and scalability. Code is available at FusAD.",
    "keywords": [
      "Time Series Analysis",
      "Time-Frequency Fusion"
    ]
  },
  {
    "article_id": "2512.14185v1_End-to-End_Learning-based_Video_Streaming_Enhancement_Pipeline_A_Generative_AI_Approach",
    "title": "2512.14185v1 End-to-End Learning-based Video Streaming Enhancement Pipeline A Generative AI Approach",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.14185v1_End-to-End_Learning-based_Video_Streaming_Enhancement_Pipeline_A_Generative_AI_Approach.pdf",
    "url": "http://arxiv.org/abs/2512.14185v1_End-to-End_Learning-based_Video_Streaming_Enhancement_Pipeline_A_Generative_AI_Approach",
    "pdf_url": "https://arxiv.org/pdf/2512.14185v1_End-to-End_Learning-based_Video_Streaming_Enhancement_Pipeline_A_Generative_AI_Approach",
    "file_size_mb": 1.31,
    "abstract": "The primary challenge of video streaming is to balance high video quality with smooth playback. Traditional codecs are well tuned for this trade-off, yet their inability to use context means they must encode the entire video data and transmit it to the client. This paper introduces ELVIS (End-to-end Learning-based VIdeo Streaming Enhancement Pipeline), an end-to-end architecture that combines server-side encoding optimizations with client-side gen- erative in-painting to remove and reconstruct redundant video data. Its modular design allows ELVIS to integrate different codecs, in- painting models, and quality metrics, making it adaptable to future innovations. Our results show that current technologies achieve improvements of up to 11 VMAF points over baseline benchmarks, though challenges remain for real-time applications due to com- putational demands. ELVIS represents a foundational step toward incorporating generative AI into video streaming pipelines, en- abling higher quality experiences without increased bandwidth requirements. CCS Concepts • Computing methodologies →Object identification; Artifi- cial intelligence; Concurrent algorithms; Image compression; • Information systems →Online analytical processing; Multime- dia streaming.",
    "keywords": [
      "HTTP adaptive streaming",
      "Generative AI",
      "End-to-end architecture"
    ]
  },
  {
    "article_id": "2512.14410v1_Pattern_Recognition_of_Aluminium_Arbitrage_in_Global_Trade_Data",
    "title": "2512.14410v1 Pattern Recognition of Aluminium Arbitrage in Global Trade Data",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.14410v1_Pattern_Recognition_of_Aluminium_Arbitrage_in_Global_Trade_Data.pdf",
    "url": "http://arxiv.org/abs/2512.14410v1_Pattern_Recognition_of_Aluminium_Arbitrage_in_Global_Trade_Data",
    "pdf_url": "https://arxiv.org/pdf/2512.14410v1_Pattern_Recognition_of_Aluminium_Arbitrage_in_Global_Trade_Data",
    "file_size_mb": 2.87,
    "abstract": "As the global economy transitions toward decarbonization, the aluminium sector has become a focal point for strategic resource management. While policies such as the Carbon Border Adjustment Mechanism (CBAM) aim to reduce emissions, they have inadvertently widened the price arbitrage between primary metal, scrap, and semi-finished goods, creating new incentives for market optimization. This study presents a unified, unsupervised machine learning framework to detect and classify emerging trade anomalies within UN Comtrade data (2020–2024). Moving beyond traditional rule-based monitoring, we apply a four-layer analytical pipeline utilizing Forensic Statistics, Isolation Forests, Network Science, and Deep Autoencoders. Contrary to the hypothesis that Sustainability Arbitrage would be the primary driver, empirical results reveal a contradictory and more severe phenomenon of Hardware Masking. Illicit actors exploit bi-directional tariff incentives by misclassifying scrap as high-count heterogeneous goods to justify extreme unit-price outliers of >$160/kg, a 1,900% markup indicative of Trade-Based Money Laundering (TBML) rather than commercial arbitrage. Topologically, risk is not concentrated in major exporters but in high-centrality Shadow Hubs that function as pivotal nodes for illicit rerouting. These actors execute a strategy of Void-Shoring, systematically suppressing destination data to Unspecified Code to fracture mirror statistics and sever forensic trails. Validated by SHAP (Shapley Additive Explanations), the results confirm that price deviation is the dominant predictor of anomalies, necessitating a paradigm shift in customs enforcement from physical volume checks to dynamic, algorithmic valuation auditing.",
    "keywords": []
  },
  {
    "article_id": "2512.14481v1_SASQ_Static_Activation_Scaling_for_Quantization-Aware_Training_in_Large_Language_Models",
    "title": "2512.14481v1 SASQ Static Activation Scaling for Quantization-Aware Training in Large Language Models",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.14481v1_SASQ_Static_Activation_Scaling_for_Quantization-Aware_Training_in_Large_Language_Models.pdf",
    "url": "http://arxiv.org/abs/2512.14481v1_SASQ_Static_Activation_Scaling_for_Quantization-Aware_Training_in_Large_Language_Models",
    "pdf_url": "https://arxiv.org/pdf/2512.14481v1_SASQ_Static_Activation_Scaling_for_Quantization-Aware_Training_in_Large_Language_Models",
    "file_size_mb": 1.05,
    "abstract": "Large language models (LLMs) excel at natural language tasks but face deploy- ment challenges due to their growing size outpacing GPU memory advancements. Model quantization mitigates this issue by lowering weight and activation pre- cision, but existing solutions face fundamental trade-offs: dynamic quantization incurs high computational overhead and poses deployment challenges on edge devices, while static quantization sacrifices accuracy. Existing approaches of quantization-aware training (QAT) further suffer from weight training costs. We propose SASQ: a lightweight QAT framework specifically tailored for activation quantization factors. SASQ exclusively optimizes only the quantization factors (without changing pre-trained weights), enabling static inference with high accu- racy while maintaining deployment efficiency. SASQ adaptively truncates some outliers, thereby reducing the difficulty of quantization while preserving the dis- tributional characteristics of the activations. SASQ not only surpasses existing SOTA quantization schemes but also outperforms the corresponding FP16 mod- els. On LLaMA2-7B, it achieves 5.2% lower perplexity than QuaRot and 4.7% lower perplexity than the FP16 model on WikiText2.",
    "keywords": []
  },
  {
    "article_id": "2512.14686v1_Bias-Variance_Trade-off_for_Clipped_Stochastic_First-Order_Methods_From_Bounded_Variance_to_Infinite",
    "title": "2512.14686v1 Bias-Variance Trade-off for Clipped Stochastic First-Order Methods From Bounded Variance to Infinite",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.14686v1_Bias-Variance_Trade-off_for_Clipped_Stochastic_First-Order_Methods_From_Bounded_Variance_to_Infinite.pdf",
    "url": "http://arxiv.org/abs/2512.14686v1_Bias-Variance_Trade-off_for_Clipped_Stochastic_First-Order_Methods_From_Bounded_Variance_to_Infinite",
    "pdf_url": "https://arxiv.org/pdf/2512.14686v1_Bias-Variance_Trade-off_for_Clipped_Stochastic_First-Order_Methods_From_Bounded_Variance_to_Infinite",
    "file_size_mb": 1.93,
    "abstract": "Stochastic optimization is fundamental to modern machine learning. Recent research has extended the study of stochastic first-order methods (SFOMs) from light-tailed to heavy-tailed noise, which frequently arises in practice, with clipping emerging as a key technique for controlling heavy-tailed gradients. Extensive theoretical advances have further shown that the oracle complexity of SFOMs depends on the tail index α of the noise. Nonetheless, existing complexity results often cover only the case α ∈(1, 2], that is, the regime where the noise has a finite mean, while the complexity bounds tend to infinity as α approaches 1. This paper tackles the general case of noise with tail index α ∈(0, 2], covering regimes ranging from noise with bounded variance to noise with an infinite mean, where the latter case has been scarcely studied. Through a novel analysis of the bias-variance trade-off in gradient clipping, we show that when a symmetry measure of the noise tail is controlled, clipped SFOMs achieve improved complexity guarantees in the presence of heavy-tailed noise for any tail index α ∈(0, 2]. Our analysis of the bias-variance trade-off not only yields new unified complexity guarantees for clipped SFOMs across this full range of tail indices, but is also straightforward to apply and can be combined with classical analyses under light-tailed noise to establish oracle complexity guarantees under heavy-tailed noise. Finally, numerical experiments validate our theoretical findings.",
    "keywords": [
      "Stochastic composite optimization",
      "Heavy-tailed noise",
      "Gradient clipping",
      "First-order oracle complexity"
    ]
  },
  {
    "article_id": "2512.14967v1_Deep_Learning_and_Elicitability_for_McKean-Vlasov_FBSDEs_With_Common_Noise",
    "title": "2512.14967v1 Deep Learning and Elicitability for McKean-Vlasov FBSDEs With Common Noise",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.14967v1_Deep_Learning_and_Elicitability_for_McKean-Vlasov_FBSDEs_With_Common_Noise.pdf",
    "url": "http://arxiv.org/abs/2512.14967v1_Deep_Learning_and_Elicitability_for_McKean-Vlasov_FBSDEs_With_Common_Noise",
    "pdf_url": "https://arxiv.org/pdf/2512.14967v1_Deep_Learning_and_Elicitability_for_McKean-Vlasov_FBSDEs_With_Common_Noise",
    "file_size_mb": 0.85,
    "abstract": ". We present a novel numerical method for solving McKean-Vlasov forward- backward stochastic differential equations (MV-FBSDEs) with common noise, combining Picard iterations, elicitability and deep learning. The key innovation involves elicitability to derive a path-wise loss function, enabling efficient training of neural networks to approx- imate both the backward process and the conditional expectations arising from common noise — without requiring computationally expensive nested Monte Carlo simulations. The mean-field interaction term is parameterized via a recurrent neural network trained to min- imize an elicitable score, while the backward process is approximated through a feedforward network representing the decoupling field. We validate the algorithm on a systemic risk inter- bank borrowing and lending model, where analytical solutions exist, demonstrating accurate recovery of the true solution. We further extend the model to quantile–mediated interac- tions, showcasing the flexibility of the elicitability framework beyond conditional means or moments. Finally, we apply the method to a non-stationary Aiyagari–Bewley–Huggett eco- nomic growth model with endogenous interest rates, illustrating its applicability to complex mean-field games without closed-form solutions.",
    "keywords": []
  },
  {
    "article_id": "2512.14990v1_Imitation_Game_Reproducing_Deep_Learning_Bugs_Leveraging_an_Intelligent_Agent",
    "title": "2512.14990v1 Imitation Game Reproducing Deep Learning Bugs Leveraging an Intelligent Agent",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.14990v1_Imitation_Game_Reproducing_Deep_Learning_Bugs_Leveraging_an_Intelligent_Agent.pdf",
    "url": "http://arxiv.org/abs/2512.14990v1_Imitation_Game_Reproducing_Deep_Learning_Bugs_Leveraging_an_Intelligent_Agent",
    "pdf_url": "https://arxiv.org/pdf/2512.14990v1_Imitation_Game_Reproducing_Deep_Learning_Bugs_Leveraging_an_Intelligent_Agent",
    "file_size_mb": 1.75,
    "abstract": "Despite their wide adoption in various domains (e.g., healthcare, finance, software engineering), Deep Learning (DL)-based applica- tions suffer from many bugs, failures, and vulnerabilities. Reproduc- ing these bugs is essential for their resolution, but it is extremely challenging due to the inherent nondeterminism of DL models and their tight coupling with hardware and software environments. Ac- cording to recent studies, only about 3% of DL bugs can be reliably reproduced using manual approaches. To address these challenges, we present RepGen, a novel, automated, and intelligent approach for reproducing deep learning bugs. RepGen constructs a learning- enhanced context from a project, develops a comprehensive plan for bug reproduction, employs an iterative generate-validate-refine mechanism, and thus generates such code using an LLM that re- produces the bug at hand. We evaluate RepGen on 106 real-world deep learning bugs and achieve a reproduction rate of 80.19%, a 19.81% improvement over the state-of-the-art measure. A developer study involving 27 participants shows that RepGen improves the success rate of DL bug reproduction by 23.35%, reduces the time to reproduce by 56.8%, and lowers participants’ cognitive load. CCS Concepts • Software and its engineering →Software testing and debug- ging.",
    "keywords": [
      "Deep learning bugs",
      "debugging",
      "bug reproduction",
      "Agentic AI"
    ]
  },
  {
    "article_id": "2512.14991v1_Adaptive_Partitioning_and_Learning_for_Stochastic_Control_of_Diffusion_Processes",
    "title": "2512.14991v1 Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.14991v1_Adaptive_Partitioning_and_Learning_for_Stochastic_Control_of_Diffusion_Processes.pdf",
    "url": "http://arxiv.org/abs/2512.14991v1_Adaptive_Partitioning_and_Learning_for_Stochastic_Control_of_Diffusion_Processes",
    "pdf_url": "https://arxiv.org/pdf/2512.14991v1_Adaptive_Partitioning_and_Learning_for_Stochastic_Control_of_Diffusion_Processes",
    "file_size_mb": 1.32,
    "abstract": "We study reinforcement learning for controlled diffusion processes with unbounded continu- ous state spaces, bounded continuous actions, and polynomially growing rewards—settings that arise naturally in finance, economics, and operations research. To overcome the challenges of con- tinuous and high-dimensional domains, we introduce a model-based algorithm that adaptively partitions the joint state–action space. The algorithm maintains estimators of drift, volatility, and rewards within each partition, refining the discretization whenever estimation bias exceeds statistical confidence. This adaptive scheme balances exploration and approximation, enabling efficient learning in unbounded domains. Our analysis establishes regret bounds that depend on the problem horizon, state dimension, reward growth order, and a newly defined notion of zooming dimension tailored to unbounded diffusion processes. The bounds recover existing re- sults for bounded settings as a special case, while extending theoretical guarantees to a broader class of diffusion-type problems. Finally, we validate the effectiveness of our approach through numerical experiments, including applications to high-dimensional problems such as multi-asset mean-variance portfolio selection.",
    "keywords": []
  },
  {
    "article_id": "2512.15033v1_Beyond_Accuracy_A_Geometric_Stability_Analysis_of_Large_Language_Models_in_Chess_Evaluation",
    "title": "2512.15033v1 Beyond Accuracy A Geometric Stability Analysis of Large Language Models in Chess Evaluation",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.15033v1_Beyond_Accuracy_A_Geometric_Stability_Analysis_of_Large_Language_Models_in_Chess_Evaluation.pdf",
    "url": "http://arxiv.org/abs/2512.15033v1_Beyond_Accuracy_A_Geometric_Stability_Analysis_of_Large_Language_Models_in_Chess_Evaluation",
    "pdf_url": "https://arxiv.org/pdf/2512.15033v1_Beyond_Accuracy_A_Geometric_Stability_Analysis_of_Large_Language_Models_in_Chess_Evaluation",
    "file_size_mb": 1.04,
    "abstract": "The evaluation of Large Language Models (LLMs) in complex reasoning domains typically relies on performance alignment with ground-truth oracles. In the domain of chess, this standard manifests as accuracy benchmarks against strong engines like Stockfish. However, high scalar accuracy does not necessarily imply robust conceptual understanding. This paper argues that standard accuracy metrics fail to distinguish between genuine geometric reasoning and the superfi- cial memorization of canonical board states. To address this gap, we propose a Geometric Stability Framework, a novel evaluation methodology that rigor- ously tests model consistency under invariant transformations—including board rotation, mirror symmetry, color inversion, and format conversion. We applied this framework to a comparative analysis of six state-of-the-art LLMs (including GPT-5.1, Claude Sonnet 4.5, and Kimi K2 Turbo), utilizing a dataset of approximately 3,000 positions. Our results reveal a significant Accuracy- Stability Paradox. While models such as GPT-5.1 achieve near-optimal accuracy on standard positions (Mean Absolute Error ≈362 centipawns), they exhibit catastrophic degradation under geometric perturbation, specifically in rotation tasks where error rates surge by over 600% (> 2500 cp). This disparity suggests a reliance on pattern matching over abstract spatial logic. Conversely, Claude Sonnet 4.5 and Kimi K2 Turbo demonstrate superior dual robust- ness, maintaining high consistency across all transformation axes. Furthermore, 1 arXiv:2512.15033v1 [cs.AI] 17 Dec 2025 we analyze the trade-off between “helpfulness” and “safety,” identifying Gem- ini 2.5 Flash as the leader in illegal state rejection (96.0%). We conclude that geometric stability provides an orthogonal and essential metric for AI evalua- tion, offering a necessary proxy for disentangling reasoning capabilities from data contamination and overfitting in large-scale models.",
    "keywords": [
      "Large Language Models Geometric Stability Chess Evaluation Robustness"
    ]
  },
  {
    "article_id": "2512.15088v1_SigMA_Path_Signatures_and_Multi-head_Attention_for_Learning_Parameters_in_fBm-driven_SDEs",
    "title": "2512.15088v1 SigMA Path Signatures and Multi-head Attention for Learning Parameters in fBm-driven SDEs",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.15088v1_SigMA_Path_Signatures_and_Multi-head_Attention_for_Learning_Parameters_in_fBm-driven_SDEs.pdf",
    "url": "http://arxiv.org/abs/2512.15088v1_SigMA_Path_Signatures_and_Multi-head_Attention_for_Learning_Parameters_in_fBm-driven_SDEs",
    "pdf_url": "https://arxiv.org/pdf/2512.15088v1_SigMA_Path_Signatures_and_Multi-head_Attention_for_Learning_Parameters_in_fBm-driven_SDEs",
    "file_size_mb": 0.69,
    "abstract": "Stochastic differential equations (SDEs) driven by fractional Brownian motion (fBm) are increasingly used to model systems with rough dynamics and long-range dependence, such as those arising in quantitative finance and reliability engineering. However, these processes are non-Markovian and lack a semimartingale structure, rendering many classical parameter estimation techniques inapplicable or computationally intractable beyond very specific cases. This work investigates two central questions: (i) whether integrating path signatures into deep learning architectures can improve the trade-off between estimation accuracy and model complexity, and (ii) what constitutes an effective architecture for leveraging signatures as feature maps. We introduce SigMA (Signature Multi-head Attention), a neural architecture that integrates path signatures with multi-head self-attention, supported by a convolutional preprocessing layer and a multilayer perceptron for effective feature encoding. SigMA learns model parameters from synthetically generated paths of fBm-driven SDEs, including fractional Brownian motion, fractional Ornstein–Uhlenbeck, and rough Heston models, with a particular focus on estimating the Hurst parameter and on joint multi-parameter inference, and it generalizes robustly to unseen trajectories. Extensive experiments on synthetic data and two real-world datasets (i.e., equity-index re- alized volatility and Li-ion battery degradation) show that SigMA consistently outperforms CNN, LSTM, vanilla Transformer, and Deep Signature baselines in accuracy, robustness, and model compactness. These results demon- strate that combining signature transforms with attention-based architectures provides an effective and scalable framework for parameter inference in stochastic systems with rough or persistent temporal structure.",
    "keywords": [
      "fractional Brownian motion",
      "Stochastic differential equations",
      "non-Markovian processes",
      "parameter"
    ]
  },
  {
    "article_id": "2512.15113v1_Adaptive_Weighted_Genetic_Algorithm-Optimized_SVR_for_Robust_Long-Term_Forecasting_of_Global_Stock_I",
    "title": "2512.15113v1 Adaptive Weighted Genetic Algorithm-Optimized SVR for Robust Long-Term Forecasting of Global Stock I",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.15113v1_Adaptive_Weighted_Genetic_Algorithm-Optimized_SVR_for_Robust_Long-Term_Forecasting_of_Global_Stock_I.pdf",
    "url": "http://arxiv.org/abs/2512.15113v1_Adaptive_Weighted_Genetic_Algorithm-Optimized_SVR_for_Robust_Long-Term_Forecasting_of_Global_Stock_I",
    "pdf_url": "https://arxiv.org/pdf/2512.15113v1_Adaptive_Weighted_Genetic_Algorithm-Optimized_SVR_for_Robust_Long-Term_Forecasting_of_Global_Stock_I",
    "file_size_mb": 1.74,
    "abstract": null,
    "keywords": [
      "Long-Term Forecasting"
    ]
  },
  {
    "article_id": "2512.15115v1_How_Many_Heads_Make_an_SSM_A_Unified_Framework_for_Attention_and_State_Space_Models",
    "title": "2512.15115v1 How Many Heads Make an SSM A Unified Framework for Attention and State Space Models",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.15115v1_How_Many_Heads_Make_an_SSM_A_Unified_Framework_for_Attention_and_State_Space_Models.pdf",
    "url": "http://arxiv.org/abs/2512.15115v1_How_Many_Heads_Make_an_SSM_A_Unified_Framework_for_Attention_and_State_Space_Models",
    "pdf_url": "https://arxiv.org/pdf/2512.15115v1_How_Many_Heads_Make_an_SSM_A_Unified_Framework_for_Attention_and_State_Space_Models",
    "file_size_mb": 0.81,
    "abstract": "Sequence modeling has produced diverse architectures—from classical recurrent neural networks to modern Transformers and state space models (SSMs)—yet a unified the- oretical understanding of expressivity and trainability trade-offs remains limited. We introduce a unified framework that represents a broad class of sequence maps via an input-dependent effective interaction operator Wij(X), making explicit two recurring con- struction patterns: (i) the Unified Factorized Framework (Explicit) (attention-style mixing), in which Wij(X) varies through scalar coefficients applied to shared value maps, and (ii) Structured Dynamics (Implicit) (state-space recurrences), in which Wij is induced by a latent dynamical system. Using this framework, we derive three theoretical results. First, we establish the Interaction Rank Gap: models in the Unified Factorized Framework, such as single- head attention, are constrained to a low-dimensional operator span and cannot represent certain structured dynamical maps. Second, we prove an Equivalence (Head-Count) Theorem showing that, within our multi-head factorized class, representing a linear SSM whose lag operators span a k-dimensional subspace on length-n sequences requires and is achievable with H = k heads. Third, we prove a Gradient Highway Result, showing that attention layers admit inputs with distance-independent gradient paths, whereas stable linear dynamics exhibit distance-dependent gradient attenuation. Together, these results formalize a fundamental trade-off between algebraic expressivity (interaction/operator span) and long-range gradient propagation, providing theoretical grounding for modern sequence architecture design.",
    "keywords": []
  },
  {
    "article_id": "2512.15600v1_How_Smoothing_is_N-simplicial_Attention",
    "title": "2512.15600v1 How Smoothing is N-simplicial Attention",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.15600v1_How_Smoothing_is_N-simplicial_Attention.pdf",
    "url": "http://arxiv.org/abs/2512.15600v1_How_Smoothing_is_N-simplicial_Attention",
    "pdf_url": "https://arxiv.org/pdf/2512.15600v1_How_Smoothing_is_N-simplicial_Attention",
    "file_size_mb": 0.95,
    "abstract": "Going from pure Multilayer Perceptron (MLP) to a learnable graph message-passing mechanism at each layer has been foundational to state-of-the-art results, despite the computational trade-off (e.g. GATs or Transformers). To go a step further, in this work, we introduce N-simplicial attention, going from pairwise token similarity to higher-order interactions, and adapt it for Rotary Position Embeddings (RoPE). To help manage the increased complexity, we propose a cost-effective simplex selection enabling the model to focus its computation load onto the more task-sensitive interactions. Beyond these core mechanisms, we study how smoothing N-simplicial attention is by deriving a Lipschitz upper-bound and by demonstrating that by itself it also suffers from over-smoothing, despite opening the attention message-passing to higher-order interactions.",
    "keywords": []
  },
  {
    "article_id": "2512.15634v1_How_Much_is_Too_Much_Exploring_LoRA_Rank_Trade-offs_for_Retaining_Knowledge_and_Domain_Robustness",
    "title": "2512.15634v1 How Much is Too Much Exploring LoRA Rank Trade-offs for Retaining Knowledge and Domain Robustness",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.15634v1_How_Much_is_Too_Much_Exploring_LoRA_Rank_Trade-offs_for_Retaining_Knowledge_and_Domain_Robustness.pdf",
    "url": "http://arxiv.org/abs/2512.15634v1_How_Much_is_Too_Much_Exploring_LoRA_Rank_Trade-offs_for_Retaining_Knowledge_and_Domain_Robustness",
    "pdf_url": "https://arxiv.org/pdf/2512.15634v1_How_Much_is_Too_Much_Exploring_LoRA_Rank_Trade-offs_for_Retaining_Knowledge_and_Domain_Robustness",
    "file_size_mb": 2.67,
    "abstract": "Large language models are increasingly adapted to downstream tasks through fine- tuning. Full supervised fine-tuning (SFT) and parameter-efficient fine-tuning (PEFT) meth- ods, such as Low-Rank Adaptation (LoRA), are two dominant approaches. While PEFT meth- ods are widely used for their computational effi- ciency, the implications of their configurations (e.g., rank) remain under-explored in down- stream Q&A tasks and generalization. In this work, we perform a comprehensive evaluation across multiple reasoning and recall datasets, conducting a rank sweep to quantify the trade- off between SFT and PEFT. We also compare the accuracy of PEFT and SFT models across in-domain and out-of-domain adaptation, high- lighting distinct generalization behavior and task-specific forgetting. We demonstrate that LoRA achieves competitive and in some cases superior performance compared to SFT, par- ticularly on reasoning tasks at specific rank values. Additionally, we analyze the internal representations via spectral features and layer- wise attention structures, offering insights into representational drift and structural changes in attention patterns.",
    "keywords": []
  },
  {
    "article_id": "2512.15732v1_The_Red_Queens_Trap_Limits_of_Deep_Evolution_in_High-Frequency_Trading",
    "title": "2512.15732v1 The Red Queens Trap Limits of Deep Evolution in High-Frequency Trading",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.15732v1_The_Red_Queens_Trap_Limits_of_Deep_Evolution_in_High-Frequency_Trading.pdf",
    "url": "http://arxiv.org/abs/2512.15732v1_The_Red_Queens_Trap_Limits_of_Deep_Evolution_in_High-Frequency_Trading",
    "pdf_url": "https://arxiv.org/pdf/2512.15732v1_The_Red_Queens_Trap_Limits_of_Deep_Evolution_in_High-Frequency_Trading",
    "file_size_mb": 0.72,
    "abstract": "The integration of Deep Reinforcement Learning (DRL) and Evolutionary Computation (EC) is frequently hypothesized to be the \"Holy Grail\" of algorithmic trading, promising systems that adapt autonomously to non-stationary market regimes. This paper presents a rigorous post-mortem analysis of \"Galaxy Empire,\" a hybrid framework coupling LSTM/Transformer-based perception with a genetic \"Time-is-Life\" survival mechanism. Deploying a population of 500 autonomous agents in a high-frequency cryptocurrency environment, we observed a catastrophic divergence between training metrics (Validation APY > 300%) and live performance (Capital Decay > 70%). We deconstruct this failure through a multi-disciplinary lens, identifying three critical failure modes: the overfitting of Aleatoric Uncertainty in low-entropy time-series, the Survivor Bias inherent in evolutionary selection under high variance, and the mathematical impossibility of overcoming microstructure friction without order-flow data. Our findings provide empirical evidence that increasing model complexity in the absence of information asymmetry exacerbates systemic fragility.",
    "keywords": [
      "Deep Learning",
      "Evolutionary Algorithms",
      "High-Frequency Trading",
      "Complex Adaptive Systems"
    ]
  },
  {
    "article_id": "2512.15738v1_Hybrid_Quantum-Classical_Ensemble_Learning_for_SP_500_Directional_Prediction",
    "title": "2512.15738v1 Hybrid Quantum-Classical Ensemble Learning for SP 500 Directional Prediction",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.15738v1_Hybrid_Quantum-Classical_Ensemble_Learning_for_SP_500_Directional_Prediction.pdf",
    "url": "http://arxiv.org/abs/2512.15738v1_Hybrid_Quantum-Classical_Ensemble_Learning_for_SP_500_Directional_Prediction",
    "pdf_url": "https://arxiv.org/pdf/2512.15738v1_Hybrid_Quantum-Classical_Ensemble_Learning_for_SP_500_Directional_Prediction",
    "file_size_mb": 1.13,
    "abstract": "Financial market prediction remains one of the most challenging applications of machine learning, where even modest improvements in directional accuracy can yield substantial economic value. Despite extensive research, most prediction systems struggle to exceed 55-57% accuracy due to high noise, non-stationarity, and market efficiency constraints. This paper introduces a novel hybrid ensemble framework that combines quantum sentiment analysis, Decision Transformer architecture, and strategic model selection to achieve 60.14% directional accuracy in S&P 500 prediction—a statistically significant 3.10% improvement over individual models. Our framework addresses three fundamental limitations of existing approaches. First, we demonstrate that architecture diversity dominates dataset diversity in ensemble construction: combining different learning algorithms (LSTM, Decision Transformer, XGBoost, Random Forest, Logistic Regression) on the same data yields superior performance (60.14%) compared to training identical architectures on multiple datasets (52.80%). This finding, confirmed through correlation analysis showing r > 0.6 among same-architecture models, contradicts conventional wisdom that more data sources necessarily improve ensembles. Second, we integrate a 4-qubit variational quantum circuit for sentiment analysis, leveraging quantum superposition to represent market uncertainty. While quantum features provide modest individual gains (+0.8% to +1.5% per model), these improvements compound across ensemble aggregation and prove statistically reliable in ablation studies. Our hybrid quantum- classical approach offers a pragmatic pathway for near-term quantum advantage without requiring fault-tolerant quantum computers. Third, we introduce smart filtering that automatically excludes weak predictors (accuracy < 52%) before ensemble aggregation. This quality-over-quantity principle proves critical: naive combination of all 35 trained models achieves only 51.2% accuracy, while our Top-7 selection strategy reaches 60.14%—demonstrating that careful model curation matters more than simply scaling ensemble size. We evaluate our framework on 3 years of market data (2020-2023) spanning diverse regimes: the COVID-19 crash, subsequent bull market, and inflation-driven correction. Training 35 model combinations across 7 financial instruments (S&P 500, VIX, Gold, sector ETFs, small caps), we obtain 286 out-of-sample test predictions. McNemar’s test confirms our ensemble improvement is statistically significant (p < 0.05) with 95% confidence interval [56.84%, 63.44%]. Beyond directional accuracy, we analyze practical trading implications. Preliminary backtesting suggests our ensemble, when combined with confidence-based filtering (trading only on 6+ model consensus), achieves Sharpe ratio of 1.2 compared to buy-and-hold’s 0.8 over the test period.",
    "keywords": [
      "Ensemble learning",
      "quantum machine learning",
      "financial prediction",
      "decision transformer",
      "attention mechanism",
      "S&P 500"
    ]
  },
  {
    "article_id": "2512.15739v1_Bayesian_Modeling_for_Uncertainty_Management_in_Financial_Risk_Forecasting_and_Compliance",
    "title": "2512.15739v1 Bayesian Modeling for Uncertainty Management in Financial Risk Forecasting and Compliance",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.15739v1_Bayesian_Modeling_for_Uncertainty_Management_in_Financial_Risk_Forecasting_and_Compliance.pdf",
    "url": "http://arxiv.org/abs/2512.15739v1_Bayesian_Modeling_for_Uncertainty_Management_in_Financial_Risk_Forecasting_and_Compliance",
    "pdf_url": "https://arxiv.org/pdf/2512.15739v1_Bayesian_Modeling_for_Uncertainty_Management_in_Financial_Risk_Forecasting_and_Compliance",
    "file_size_mb": 8.61,
    "abstract": "—A Bayesian analytics framework that precisely quantifies uncertainty offers a significant advance for financial risk management. We develop an integrated approach that consistently enhances the handling of risk in market volatility forecasting, fraud detection, and compliance monitoring. Our probabilistic, interpretable models deliver reliable results: We evaluate the performance of one-day-ahead 95% Value-at-Risk (VaR) forecasts on daily S&P 500 returns, with a training period from 2000 to 2019 and an out-of-sample test period spanning 2020 to 2024. Formal tests of unconditional (Kupiec) and conditional (Christoffersen) coverage reveal that an LSTM baseline achieves near-nominal calibration. In contrast, a GARCH(1,1) model with Student-t innovations underestimates tail risk. Our proposed discount-factor DLM model produces a slightly liberal VaR estimate, with evidence of clustered violations. Bayesian logistic regression improves recall and AUC-ROC for fraud detection, and a hierarchical Beta state-space model provides transparent and adaptive compliance risk assessment. The pipeline is dis- tinguished by precise uncertainty quantification, interpretability, and GPU-accelerated analysis, delivering up to 50x speedup. Remaining challenges include sparse fraud data and proxy compliance labels, but the framework enables actionable risk insights. Future expansion will extend feature sets, explore regime-switching priors, and enhance scalable inference.",
    "keywords": [
      "bayesian modeling",
      "volatility forecasting",
      "fraud"
    ]
  },
  {
    "article_id": "2512.15784v1_Beyond_Training_Enabling_Self-Evolution_of_Agents_with_MOBIMEM",
    "title": "2512.15784v1 Beyond Training Enabling Self-Evolution of Agents with MOBIMEM",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.15784v1_Beyond_Training_Enabling_Self-Evolution_of_Agents_with_MOBIMEM.pdf",
    "url": "http://arxiv.org/abs/2512.15784v1_Beyond_Training_Enabling_Self-Evolution_of_Agents_with_MOBIMEM",
    "pdf_url": "https://arxiv.org/pdf/2512.15784v1_Beyond_Training_Enabling_Self-Evolution_of_Agents_with_MOBIMEM",
    "file_size_mb": 2.32,
    "abstract": "Large Language Model (LLM) agents are increasingly de- ployed to automate complex workflows in mobile and desktop environments. However, current model-centric agent archi- tectures struggle to self-evolve post-deployment: improving personalization, capability, and efficiency typically requires continuous model retraining/fine-tuning, which incurs pro- hibitive computational overheads and suffers from an inherent trade-off between model accuracy and inference efficiency. To enable iterative self-evolution without model retrain- ing, we propose MOBIMEM, a memory-centric agent sys- tem. MOBIMEM first introduces three specialized memory primitives to decouple agent evolution from model weights: (1) Profile Memory uses a lightweight distance-graph (Dis- Graph) structure to align with user preferences, resolving the accuracy-latency trade-off in user profile retrieval; (2) Expe- rience Memory employs multi-level templates to instantiate execution logic for new tasks, ensuring capability generaliza- tion; and (3) Action Memory records fine-grained interaction sequences, reducing the reliance on expensive model infer- ence. Building upon this memory architecture, MOBIMEM further integrates a suite of OS-inspired services to orches- trate execution: a scheduler that coordinates parallel sub-task execution and memory operations; an agent record-and-replay (AgentRR) mechanism that enables safe and efficient action reuse; and a context-aware exception handling that ensures graceful recovery from user interruptions and runtime errors. Evaluation on AndroidWorld and top-50 apps shows that MOBIMEM achieves 83.1% profile alignment with 23.83 ms retrieval time (280× faster than GraphRAG baselines), im- proves task success rates by up to 50.3%, and reduces end- to-end latency by up to 9× on mobile devices, demonstrating the efficiency and practicality of memory-centric evolution in real-world deployments. 1The three authors contributed equally to this work and should be consid- ered co-first authors. ✉Erhu Feng is the corresponding author: fengerhu1@sjtu.edu.cn Accuracy End-to-End Latency Qwen3 VL 30B A3B GUI-Owl 7B UI-TARS -1.5 7B GUI-Owl 32B Seed-1.5- VL 20B Ours Gemini 2.5 Flash Small Scale Medium Scale Large Scale Extra-Large Scale MobileUse- V2 30B UI-Venus- Navi 72B UI-TARS-2 72B Gemini 2.5 Computer Use DroidRun (Gemini 2.5 Pro) GBOX (Claude Sonnet 4.5) Figure 1: MOBIMEM tames the trade-off between AI agents’ latency and accuracy by a memory-centric design.",
    "keywords": []
  },
  {
    "article_id": "2512.15892v1_VET_Your_Agent_Towards_Host-Independent_Autonomy_via_Verifiable_Execution_Traces",
    "title": "2512.15892v1 VET Your Agent Towards Host-Independent Autonomy via Verifiable Execution Traces",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.15892v1_VET_Your_Agent_Towards_Host-Independent_Autonomy_via_Verifiable_Execution_Traces.pdf",
    "url": "http://arxiv.org/abs/2512.15892v1_VET_Your_Agent_Towards_Host-Independent_Autonomy_via_Verifiable_Execution_Traces",
    "pdf_url": "https://arxiv.org/pdf/2512.15892v1_VET_Your_Agent_Towards_Host-Independent_Autonomy_via_Verifiable_Execution_Traces",
    "file_size_mb": 5.67,
    "abstract": "Recent advances in large language models (LLMs) have enabled a new generation of autonomous agents that operate over sustained periods and manage sensitive resources on behalf of users. Trusted for their ability to act without direct oversight, such agents are increasingly considered in high-stakes domains including financial management, dispute resolution, and governance. Yet in practice, agents execute on infrastructure controlled by a host, who can tam- per with models, inputs, or outputs, undermining any meaningful notion of autonomy. We address this gap by introducing VET (Verifiable Execution Traces), a formal framework that achieves host-independent authen- tication of agent outputs and takes a step toward host-independent autonomy. Central to VET is the Agent Identity Document (AID), which specifies an agent’s configuration together with the proof systems required for verification. VET is compositional: it supports multiple proof mechanisms, including trusted hardware, succinct cryptographic proofs, and notarized TLS transcripts (Web Proofs). We implement VET for an API-based LLM agent and evaluate our instantiation on realistic workloads. We find that for today’s black-box, secret-bearing API calls, Web Proofs appear to be the most practical choice, with overhead typically under 3× compared to direct API calls, while for public API calls, a lower-overhead TEE Proxy is often sufficient. As a case study, we deploy a verifiable trading agent that produces proofs for each decision and composes Web Proofs with a TEE Proxy. Our results demonstrate that practi- cal, host-agnostic authentication is already possible with current technology, laying the foundation for future systems that achieve full host-independent autonomy. CCS Concepts • Security and privacy →Authentication; Privacy-preserving protocols; Systems security; • Computing methodologies →In- telligent agents.",
    "keywords": [
      "autonomous agents",
      "host-independent authentication",
      "agent iden-"
    ]
  },
  {
    "article_id": "2512.15923v1_A_Unification_of_Discrete_Gaussian_and_Simplicial_Diffusion",
    "title": "2512.15923v1 A Unification of Discrete Gaussian and Simplicial Diffusion",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.15923v1_A_Unification_of_Discrete_Gaussian_and_Simplicial_Diffusion.pdf",
    "url": "http://arxiv.org/abs/2512.15923v1_A_Unification_of_Discrete_Gaussian_and_Simplicial_Diffusion",
    "pdf_url": "https://arxiv.org/pdf/2512.15923v1_A_Unification_of_Discrete_Gaussian_and_Simplicial_Diffusion",
    "file_size_mb": 1.21,
    "abstract": "To model discrete sequences such as DNA, proteins, and language using diffusion, practitioners must choose between three major methods: diffusion in discrete space, Gaussian diffusion in Euclidean space, or diffusion on the simplex. Despite their shared goal, these models have disparate algorithms, theoretical structures, and tradeoffs: discrete diffusion has the most natural domain, Gaussian diffusion has more mature algorithms, and diffusion on the simplex in principle combines the strengths of the other two but in practice suffers from a numerically unstable stochastic processes. Ideally we could see each of these models as instances of the same underlying framework, and enable practitioners to switch between models for downstream applications. However previous theories have only considered connections in special cases. Here we build a theory unifying all three methods of discrete diffusion as different parameterizations of the same underlying process: the Wright-Fisher population genetics model. In particular, we find simplicial and Gaussian diffusion as two large-population limits. Our theory formally connects the likelihoods and hyperparameters of these models and leverages decades of mathematical genetics literature to unlock stable simplicial diffusion. Finally, we relieve the practitioner of balancing model trade-offs by demonstrating it is possible to train a single model that can perform diffusion in any of these three domains at test time. Our experiments show that Wright-Fisher simplicial diffusion is more stable and outperforms previous simplicial diffusion models on conditional DNA generation. We also show that we can train models on multiple domains at once that are competitive with models trained on any individual domain.",
    "keywords": []
  },
  {
    "article_id": "2512.16032v1_Techno-economic_optimization_of_a_heat-pipe_microreactor_part_I_theory_and_cost_optimization",
    "title": "2512.16032v1 Techno-economic optimization of a heat-pipe microreactor part I theory and cost optimization",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.16032v1_Techno-economic_optimization_of_a_heat-pipe_microreactor_part_I_theory_and_cost_optimization.pdf",
    "url": "http://arxiv.org/abs/2512.16032v1_Techno-economic_optimization_of_a_heat-pipe_microreactor_part_I_theory_and_cost_optimization",
    "pdf_url": "https://arxiv.org/pdf/2512.16032v1_Techno-economic_optimization_of_a_heat-pipe_microreactor_part_I_theory_and_cost_optimization",
    "file_size_mb": 4.53,
    "abstract": "Microreactors (µR)s, particularly heat-pipe microreactors (HPMRs), are compact, transportable, self-regulated power systems well-suited for access-challenged remote areas where costly fossil fuels dominate. However, they suffer from diseconomies of scale, and their financial viability remains unconvincing. One step in addressing this shortcoming is to design these reactors with comprehensive economic and physics analyses informing early-stage design iteration. In this work, we present a novel unifying geometric design optimization approach that accounts for techno-economic considerations. We start by generating random samples to train surrogate models, including Gaussian processes (GPs) and multi-layer perceptrons (MLPs). We then deploy these surrogates within a reinforcement learning (RL)-based optimization framework to optimize the levelized cost of electricity (LCOE), all the while imposing constraints on the fuel lifetime, shutdown margin (SDM), peak heat flux, and rod-integrated peaking factor F∆h. We study two cases: one in which the axial reflector cost is very high, and one in which it is inexpensive. We found that the operation and maintenance (O&M) and capital costs are the primary contributors to the overall LCOE—particularly the cost of the axial reflectors (for the first case) and the control drum materials. The optimizer cleverly changes the design parameters so as to minimize one of them while still satisfying the constraints, ultimately reducing the LCOE by more than 57% in both instances. A comprehensive integration of fuel and HP performance with multi-objective optimization is currently being pursued to fully understand the interaction between constraints and cost performance.",
    "keywords": [
      "Heat-Pipe Microreactor",
      "Techno-Economic Analysis",
      "Reinforcement Learning",
      "Levelized Cost of Electricity"
    ]
  },
  {
    "article_id": "2512.16037v1_Explainable_AI_in_Big_Data_Fraud_Detection",
    "title": "2512.16037v1 Explainable AI in Big Data Fraud Detection",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.16037v1_Explainable_AI_in_Big_Data_Fraud_Detection.pdf",
    "url": "http://arxiv.org/abs/2512.16037v1_Explainable_AI_in_Big_Data_Fraud_Detection",
    "pdf_url": "https://arxiv.org/pdf/2512.16037v1_Explainable_AI_in_Big_Data_Fraud_Detection",
    "file_size_mb": 0.31,
    "abstract": "—Big Data has become central to modern applications in finance, insurance, and cybersecurity, enabling machine learn- ing systems to perform large-scale risk assessments and fraud detection. However, the increasing dependence on automated analytics introduces important concerns about transparency, regulatory compliance, and trust. This paper examines how explainable artificial intelligence (XAI) can be integrated into Big Data analytics pipelines for fraud detection and risk man- agement. We review key Big Data characteristics and survey major analytical tools, including distributed storage systems, streaming platforms, and advanced fraud detection models such as anomaly detectors, graph-based approaches, and ensemble classifiers. We also present a structured review of widely used XAI methods, including LIME, SHAP, counterfactual explana- tions, and attention mechanisms, and analyze their strengths and limitations when deployed at scale. Based on these findings, we identify key research gaps related to scalability, real-time processing, and explainability for graph and temporal models. To address these challenges, we outline a conceptual framework that integrates scalable Big Data infrastructure with context- aware explanation mechanisms and human feedback. The paper concludes with open research directions in scalable XAI, privacy- aware explanations, and standardized evaluation methods for explainable fraud detection systems.",
    "keywords": [
      "Big Data analytics",
      "fraud detection",
      "risk man-"
    ]
  },
  {
    "article_id": "2512.16046v1_CauSTream_Causal_Spatio-Temporal_Representation_Learning_for_Streamflow_Forecasting",
    "title": "2512.16046v1 CauSTream Causal Spatio-Temporal Representation Learning for Streamflow Forecasting",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.16046v1_CauSTream_Causal_Spatio-Temporal_Representation_Learning_for_Streamflow_Forecasting.pdf",
    "url": "http://arxiv.org/abs/2512.16046v1_CauSTream_Causal_Spatio-Temporal_Representation_Learning_for_Streamflow_Forecasting",
    "pdf_url": "https://arxiv.org/pdf/2512.16046v1_CauSTream_Causal_Spatio-Temporal_Representation_Learning_for_Streamflow_Forecasting",
    "file_size_mb": 3.54,
    "abstract": "—Streamflow forecasting is crucial for water resource management and risk mitigation. While deep learning mod- els have achieved strong predictive performance, they often overlook underlying physical processes, limiting interpretability and generalization. Recent causal learning approaches address these issues by integrating domain knowledge, yet they typically rely on fixed causal graphs that fail to adapt to data. We propose CauSTream, a unified framework for causal spatiotem- poral streamflow forecasting. CauSTream jointly learns (i) a runoff causal graph among meteorological forcings and (ii) a routing graph capturing dynamic dependencies across stations. We further establish identifiability conditions for these causal structures under a nonparametric setting. We evaluate CauS- Tream on three major U.S. river basins across three forecasting horizons. The model consistently outperforms prior state-of- the-art methods, with performance gaps widening at longer forecast windows, indicating stronger generalization to unseen conditions. Beyond forecasting, CauSTream also learns causal graphs that capture relationships among hydrological factors and stations. The inferred structures align closely with established domain knowledge, offering interpretable insights into watershed dynamics. CauSTream offers a principled foundation for causal spatiotemporal modeling, with the potential to extend to a wide range of scientific and environmental applications.",
    "keywords": [
      "Causal representation learning",
      "Causal discov-"
    ]
  },
  {
    "article_id": "2512.16103v1_AIMM_An_AI-Driven_Multimodal_Framework_for_Detecting_Social-Media-Influenced_Stock_Market_Manipulati",
    "title": "2512.16103v1 AIMM An AI-Driven Multimodal Framework for Detecting Social-Media-Influenced Stock Market Manipulati",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.16103v1_AIMM_An_AI-Driven_Multimodal_Framework_for_Detecting_Social-Media-Influenced_Stock_Market_Manipulati.pdf",
    "url": "http://arxiv.org/abs/2512.16103v1_AIMM_An_AI-Driven_Multimodal_Framework_for_Detecting_Social-Media-Influenced_Stock_Market_Manipulati",
    "pdf_url": "https://arxiv.org/pdf/2512.16103v1_AIMM_An_AI-Driven_Multimodal_Framework_for_Detecting_Social-Media-Influenced_Stock_Market_Manipulati",
    "file_size_mb": 3.2,
    "abstract": "Market manipulation now routinely originates from coordinated social media campaigns, not isolated trades. Retail investors, regulators, and brokerages need tools that connect online narratives and coordination patterns to market behavior. We present AIMM, an AI-driven framework that fuses Reddit activity, bot and coordination indicators, and OHLCV market features into a daily AIMM Manipulation Risk Score for each ticker. The system uses a parquet-native pipeline with a Streamlit dashboard that allows analysts to explore suspicious windows, inspect underlying posts and price action, and log model outputs over time. Due to Reddit API restrictions, we employ calibrated synthetic social features matching documented event characteristics; market data (OHLCV) uses real historical data from Yahoo Finance. This release makes three contributions. First, we build the AIMM Ground Truth dataset (AIMM-GT): 33 labeled ticker-days spanning eight equities, drawing from SEC enforcement actions, community-verified manipulation cases, and matched normal controls. Second, we implement forward-walk evaluation and prospective prediction logging for both retrospective and deployment-style assessment. Third, we analyze lead times and show that AIMM flagged GME 22 days before the January 2021 squeeze peak. The current labeled set is small (33 ticker-days, 3 positive events), but results show preliminary discriminative capability and early warnings for the GME incident. We release the code, dataset schema, and dashboard design to support research on social media-driven market surveillance. 1 Funding Disclosure This research did not receive external funding. 2",
    "keywords": []
  },
  {
    "article_id": "2512.16115v2_An_Efficient_Machine_Learning_Framework_for_Option_Pricing_via_Fourier_Transform",
    "title": "2512.16115v2 An Efficient Machine Learning Framework for Option Pricing via Fourier Transform",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.16115v2_An_Efficient_Machine_Learning_Framework_for_Option_Pricing_via_Fourier_Transform.pdf",
    "url": "http://arxiv.org/abs/2512.16115v2_An_Efficient_Machine_Learning_Framework_for_Option_Pricing_via_Fourier_Transform",
    "pdf_url": "https://arxiv.org/pdf/2512.16115v2_An_Efficient_Machine_Learning_Framework_for_Option_Pricing_via_Fourier_Transform",
    "file_size_mb": 3.8,
    "abstract": "The increasing need for rapid recalibration of option pricing models in dynamic markets places stringent computational demands on data generation and valuation algorithms. In this work, we propose a hybrid algorithmic framework that integrates the smooth offset al- gorithm (SOA) with supervised machine learning models for the fast pricing of multiple path- independent options under exponential L´evy dynamics. Building upon the SOA-generated dataset, we train neural networks, random forests, and gradient boosted decision trees to con- struct surrogate pricing operators. Extensive numerical experiments demonstrate that, once trained, these surrogates achieve order-of-magnitude acceleration over direct SOA evaluation. Importantly, the proposed framework overcomes key numerical limitations inherent to fast Fourier transform–based methods, including input data consistency and instability in deep out-of-the-money option pricing.",
    "keywords": [
      "Option Pricing",
      "Machine Learning",
      "Fast Fourier Transform"
    ]
  },
  {
    "article_id": "2512.16221v1_Neural_emulation_of_gravity-driven_geohazard_runout",
    "title": "2512.16221v1 Neural emulation of gravity-driven geohazard runout",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.16221v1_Neural_emulation_of_gravity-driven_geohazard_runout.pdf",
    "url": "http://arxiv.org/abs/2512.16221v1_Neural_emulation_of_gravity-driven_geohazard_runout",
    "pdf_url": "https://arxiv.org/pdf/2512.16221v1_Neural_emulation_of_gravity-driven_geohazard_runout",
    "file_size_mb": 17.34,
    "abstract": null,
    "keywords": []
  },
  {
    "article_id": "2512.16251v2_Interpretable_Deep_Learning_for_Stock_Returns_A_Consensus-Bottleneck_Asset_Pricing_Model",
    "title": "2512.16251v2 Interpretable Deep Learning for Stock Returns A Consensus-Bottleneck Asset Pricing Model",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.16251v2_Interpretable_Deep_Learning_for_Stock_Returns_A_Consensus-Bottleneck_Asset_Pricing_Model.pdf",
    "url": "http://arxiv.org/abs/2512.16251v2_Interpretable_Deep_Learning_for_Stock_Returns_A_Consensus-Bottleneck_Asset_Pricing_Model",
    "pdf_url": "https://arxiv.org/pdf/2512.16251v2_Interpretable_Deep_Learning_for_Stock_Returns_A_Consensus-Bottleneck_Asset_Pricing_Model",
    "file_size_mb": 1.64,
    "abstract": "We introduce the Consensus-Bottleneck Asset Pricing Model (CB-APM), a partially inter- pretable neural network that replicates the reasoning processes of sell-side analysts by capturing how dispersed investor beliefs are compressed into asset prices through a consensus formation process. By modeling this “bottleneck” to summarize firm- and macro-level information, CB- APM not only predicts future risk premiums of U.S. equities but also links belief aggregation to expected returns in a structurally interpretable manner. The model improves long-horizon return forecasts and outperforms standard deep learning approaches in both predictive accuracy and explanatory power. Comprehensive portfolio analyses show that CB-APM’s out-of-sample predictions translate into economically meaningful payoffs, with monotonic return differentials and stable long-short performance across regularization settings. Empirically, CB-APM lever- ages consensus as a regularizer to amplify long-horizon predictability and yields interpretable consensus-based components that clarify how information is priced in returns. Moreover, re- gression and Gibbons–Ross–Shanken (GRS)-based pricing diagnostics reveal that the learned consensus representations capture priced variation only partially spanned by traditional factor models, demonstrating that CB-APM uncovers belief-driven structure in expected returns be- yond the canonical factor space. Overall, CB-APM provides an interpretable and empirically grounded framework for understanding belief-driven return dynamics.",
    "keywords": [
      "Asset Pricing Model",
      "Analysts’ Consensus",
      "Neural Network",
      "Interpretable Deep"
    ]
  },
  {
    "article_id": "2512.16266v1_Pixel_Super-Resolved_Fluorescence_Lifetime_Imaging_Using_Deep_Learning",
    "title": "2512.16266v1 Pixel Super-Resolved Fluorescence Lifetime Imaging Using Deep Learning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.16266v1_Pixel_Super-Resolved_Fluorescence_Lifetime_Imaging_Using_Deep_Learning.pdf",
    "url": "http://arxiv.org/abs/2512.16266v1_Pixel_Super-Resolved_Fluorescence_Lifetime_Imaging_Using_Deep_Learning",
    "pdf_url": "https://arxiv.org/pdf/2512.16266v1_Pixel_Super-Resolved_Fluorescence_Lifetime_Imaging_Using_Deep_Learning",
    "file_size_mb": 3.04,
    "abstract": "Fluorescence lifetime imaging microscopy (FLIM) is a powerful quantitative technique that provides metabolic and molecular contrast, offering strong translational potential for label-free, real-time diagnostics. However, its clinical adoption remains limited by long pixel dwell times and low signal-to-noise ratio (SNR), which impose a stricter resolution-speed trade-off than conventional optical imaging approaches. Here, we introduce FLIMPSR_k, a deep learning-based multi-channel pixel super-resolution (PSR) framework that reconstructs high-resolution FLIM images from data acquired with up to a 5-fold increased pixel size. The model is trained using the conditional generative adversarial network (cGAN) framework, which, compared to diffusion model-based alternatives, delivers a more robust PSR reconstruction with substantially shorter inference times, a crucial advantage for practical deployment. FLIMPSR_k not only enables faster image acquisition but can also alleviate SNR limitations in autofluorescence-based FLIM. Blind testing on held-out patient-derived tumor tissue samples demonstrates that FLIMPSR_k reliably achieves a super-resolution factor of k = 5, resulting in a 25-fold increase in the space-bandwidth product of the output images and revealing fine architectural features lost in lower-resolution inputs, with statistically significant improvements across various image quality metrics. By increasing FLIM’s effective spatial resolution, FLIMPSR_k advances lifetime imaging toward faster, higher-resolution, and hardware-flexible implementations compatible with low-numerical- aperture and miniaturized platforms, better positioning FLIM for translational applications. 2",
    "keywords": [
      "Fluorescence lifetime imaging microscopy (FLIM)",
      "Pixel super-resolution",
      "Deep learning"
    ]
  },
  {
    "article_id": "2512.16310v1_Agent_Tools_Orchestration_Leaks_More_Dataset_Benchmark_and_Mitigation",
    "title": "2512.16310v1 Agent Tools Orchestration Leaks More Dataset Benchmark and Mitigation",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.16310v1_Agent_Tools_Orchestration_Leaks_More_Dataset_Benchmark_and_Mitigation.pdf",
    "url": "http://arxiv.org/abs/2512.16310v1_Agent_Tools_Orchestration_Leaks_More_Dataset_Benchmark_and_Mitigation",
    "pdf_url": "https://arxiv.org/pdf/2512.16310v1_Agent_Tools_Orchestration_Leaks_More_Dataset_Benchmark_and_Mitigation",
    "file_size_mb": 3.69,
    "abstract": "Driven by Large Language Models, the single-agent, multi-tool architecture has become a popular paradigm for autonomous agents due to its simplicity and effectiveness. However, this architecture also introduces a new and severe privacy risk, which we term Tools Orchestration Privacy Risk (TOP-R), where an agent, to achieve a benign user goal, autonomously aggregates information fragments across multiple tools and leverages its reasoning capabilities to synthesize unexpected sensitive information. We provide the first systematic study of this risk. First, we establish a formal framework, attributing the risk’s root cause to the agent’s misaligned objective function: an over- optimization for helpfulness while neglecting privacy awareness. Second, we construct TOP-Bench, comprising paired leakage and benign scenarios, to comprehensively evaluate this risk. To quantify the trade-off between safety and robustness, we introduce the H-Score as a holistic metric. The evaluation results reveal that TOP-R is a severe risk: the average Risk Leakage Rate (RLR) of eight representative models reaches 90.24%, while the average H-Score is merely 0.167, with no model exceeding 0.3. Finally, we propose the Privacy Enhancement Principle (PEP) method, which effectively mitigates TOP-R, reducing the Risk Leakage Rate to 46.58% and significantly improving the H-Score to 0.624. Our work reveals both a new class of risk and inherent structural limitations in current agent architectures, while also offering feasible mitigation strategies.1",
    "keywords": [
      "Tools Orchestration Privacy Risk",
      "Tool Use Risk",
      "LLM Agents",
      "Privacy Benchmark",
      "Agent Privacy"
    ]
  },
  {
    "article_id": "2512.16433v1_Emergent_Bias_and_Fairness_in_Multi-Agent_Decision_Systems",
    "title": "2512.16433v1 Emergent Bias and Fairness in Multi-Agent Decision Systems",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.16433v1_Emergent_Bias_and_Fairness_in_Multi-Agent_Decision_Systems.pdf",
    "url": "http://arxiv.org/abs/2512.16433v1_Emergent_Bias_and_Fairness_in_Multi-Agent_Decision_Systems",
    "pdf_url": "https://arxiv.org/pdf/2512.16433v1_Emergent_Bias_and_Fairness_in_Multi-Agent_Decision_Systems",
    "file_size_mb": 1.13,
    "abstract": "Multi-agent systems have demonstrated the ability to improve performance on a variety of predictive tasks by leveraging collaborative decision making. However, the lack of effective evaluation methodologies has made it difficult to estimate the risk of bias, making deployment of such systems unsafe in high stakes domains such as consumer finance, where biased decisions can translate directly into regulatory breaches and financial loss. To address this challenge, we need to develop fairness evaluation methodologies for multi-agent predictive systems and measure the fairness characteristics of these sys- tems in the financial tabular domain. Examining fairness met- rics using large-scale simulations across diverse multi-agent configurations, with varying communication and collaboration mechanisms, we reveal patterns of emergent bias in finan- cial decision-making that cannot be traced to individual agent components, indicating that multi-agent systems may exhibit genuinely collective behaviors. Our findings highlight that fairness risks in financial multi-agent systems represent a sig- nificant component of model risk, with tangible impacts on tasks such as credit scoring and income estimation. We advo- cate that multi-agent decision systems must be evaluated as holistic entities rather than through reductionist analyses of their constituent components.",
    "keywords": []
  },
  {
    "article_id": "2512.16650v1_Prefix_Probing_Lightweight_Harmful_Content_Detection_for_Large_Language_Models",
    "title": "2512.16650v1 Prefix Probing Lightweight Harmful Content Detection for Large Language Models",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.16650v1_Prefix_Probing_Lightweight_Harmful_Content_Detection_for_Large_Language_Models.pdf",
    "url": "http://arxiv.org/abs/2512.16650v1_Prefix_Probing_Lightweight_Harmful_Content_Detection_for_Large_Language_Models",
    "pdf_url": "https://arxiv.org/pdf/2512.16650v1_Prefix_Probing_Lightweight_Harmful_Content_Detection_for_Large_Language_Models",
    "file_size_mb": 2.89,
    "abstract": "Large language models often face a three- way trade-off among detection accuracy, in- ference latency, and deployment cost when used in real-world safety-sensitive applications. This paper introduces Prefix Probing, a black- box harmful content detection method that compares the conditional log-probabilities of \"agreement/execution\" versus \"refusal/safety\" opening prefixes and leverages prefix caching to reduce detection overhead to near first-token latency. During inference, the method requires only a single log-probability computation over the probe prefixes to produce a harmfulness score and apply a threshold, without invoking any additional models or multi-stage inference. To further enhance the discriminative power of the prefixes, we design an efficient prefix con- struction algorithm that automatically discov- ers highly informative prefixes, substantially improving detection performance. Extensive experiments demonstrate that Prefix Probing achieves detection effectiveness comparable to mainstream external safety models while in- curring only minimal computational cost and requiring no extra model deployment, highlight- ing its strong practicality and efficiency.",
    "keywords": []
  },
  {
    "article_id": "2512.16707v2_Dual_Computational_Horizons_Incompleteness_and_Unpredictability_in_Intelligent_Systems",
    "title": "2512.16707v2 Dual Computational Horizons Incompleteness and Unpredictability in Intelligent Systems",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.16707v2_Dual_Computational_Horizons_Incompleteness_and_Unpredictability_in_Intelligent_Systems.pdf",
    "url": "http://arxiv.org/abs/2512.16707v2_Dual_Computational_Horizons_Incompleteness_and_Unpredictability_in_Intelligent_Systems",
    "pdf_url": "https://arxiv.org/pdf/2512.16707v2_Dual_Computational_Horizons_Incompleteness_and_Unpredictability_in_Intelligent_Systems",
    "file_size_mb": 0.3,
    "abstract": "We formalize two independent computational limitations that constrain algo- rithmic intelligence: formal incompleteness and dynamical unpredictability. The former limits the deductive power of consistent reasoning systems while the latter bounds long-term prediction under finite precision. We show that these two extrema together impose structural bounds on an agent’s ability to reason about its own predictive capabilities. In particular, an algorithmic agent cannot verify its own maximal prediction horizon universally. This perspective clarifies inherent trade-offs between reasoning, prediction, and self-analysis in intelligent systems. The construction presented here consti- tutes one representative instance of a broader logical class of such limitations.",
    "keywords": [
      "Algorithmic intelligence",
      "Computability",
      "Gödel incompleteness"
    ]
  },
  {
    "article_id": "2512.16912v2_Exploration_vs_Exploitation_Rethinking_RLVR_through_Clipping_Entropy_and_Spurious_Reward",
    "title": "2512.16912v2 Exploration vs Exploitation Rethinking RLVR through Clipping Entropy and Spurious Reward",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.16912v2_Exploration_vs_Exploitation_Rethinking_RLVR_through_Clipping_Entropy_and_Spurious_Reward.pdf",
    "url": "http://arxiv.org/abs/2512.16912v2_Exploration_vs_Exploitation_Rethinking_RLVR_through_Clipping_Entropy_and_Spurious_Reward",
    "pdf_url": "https://arxiv.org/pdf/2512.16912v2_Exploration_vs_Exploitation_Rethinking_RLVR_through_Clipping_Entropy_and_Spurious_Reward",
    "file_size_mb": 1.04,
    "abstract": "This paper examines the exploration-exploitation trade-off in reinforcement learn- ing with verifiable rewards (RLVR), a framework for improving the reasoning of Large Language Models (LLMs). Recent studies suggest that RLVR can elicit strong mathematical reasoning in LLMs through two seemingly paradoxical mech- anisms: spurious rewards, which suppress exploitation by rewarding outcomes unrelated to the ground truth, and entropy minimization, which suppresses ex- ploration by pushing the model toward more confident and deterministic outputs, highlighting a puzzling dynamic: both discouraging exploitation and discouraging exploration improve reasoning performance, yet the underlying principles that reconcile these effects remain poorly understood. We focus on two fundamental questions: (i) how policy entropy relates to performance, and (ii) whether spu- rious rewards yield gains, potentially through the interplay of clipping bias and model contamination. Our results show that clipping bias under spurious rewards reduces policy entropy, leading to more confident and deterministic outputs, while entropy minimization alone is insufficient for improvement. We further propose a reward-misalignment model explaining why spurious rewards can enhance perfor- mance beyond contaminated settings. Our findings clarify the mechanisms behind spurious-reward benefits and provide principles for more effective RLVR training.",
    "keywords": []
  },
  {
    "article_id": "2512.17185v1_Systemic_Risk_Radar_A_Multi-Layer_Graph_Framework_for_Early_Market_Crash_Warning",
    "title": "2512.17185v1 Systemic Risk Radar A Multi-Layer Graph Framework for Early Market Crash Warning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.17185v1_Systemic_Risk_Radar_A_Multi-Layer_Graph_Framework_for_Early_Market_Crash_Warning.pdf",
    "url": "http://arxiv.org/abs/2512.17185v1_Systemic_Risk_Radar_A_Multi-Layer_Graph_Framework_for_Early_Market_Crash_Warning",
    "pdf_url": "https://arxiv.org/pdf/2512.17185v1_Systemic_Risk_Radar_A_Multi-Layer_Graph_Framework_for_Early_Market_Crash_Warning",
    "file_size_mb": 3.06,
    "abstract": "Financial crises emerge when structural vulnerabilities accumulate across sectors, markets, and investor behavior. Predicting these systemic transitions is challenging because they arise from evolving interactions between market participants, not isolated price movements. We present Systemic Risk Radar (SRR), a framework that models financial markets as multi-layer graphs to detect early signs of systemic fragility and crash-regime transitions. We evaluate SRR across three major crises: the Dot-com crash, the Global Financial Crisis, and the COVID-19 shock. Our experiments compare snapshot GNNs, a simplified temporal GNN prototype, and standard baselines (logistic regression and Random Forest). Results show that structural network information provides useful early-warning signals compared to feature-based models alone. This correlation-based instantiation of SRR demonstrates that graph-derived features cap- ture meaningful changes in market structure during stress events. The findings motivate ex- tending SRR with additional graph layers (sector/factor exposure, sentiment) and advanced temporal architectures (LSTM/GRU or Transformer encoders) to better handle diverse crisis types.",
    "keywords": []
  },
  {
    "article_id": "2512.17225v1_Modelling_financial_time_series_with_φ4_quantum_field_theory",
    "title": "2512.17225v1 Modelling financial time series with φ4 quantum field theory",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.17225v1_Modelling_financial_time_series_with_φ4_quantum_field_theory.pdf",
    "url": "http://arxiv.org/abs/2512.17225v1_Modelling_financial_time_series_with_φ4_quantum_field_theory",
    "pdf_url": "https://arxiv.org/pdf/2512.17225v1_Modelling_financial_time_series_with_φ4_quantum_field_theory",
    "file_size_mb": 1.0,
    "abstract": null,
    "keywords": []
  },
  {
    "article_id": "2512.17251v1_AlignDP_Hybrid_Differential_Privacy_with_Rarity-Aware_Protection_for_LLMs",
    "title": "2512.17251v1 AlignDP Hybrid Differential Privacy with Rarity-Aware Protection for LLMs",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.17251v1_AlignDP_Hybrid_Differential_Privacy_with_Rarity-Aware_Protection_for_LLMs.pdf",
    "url": "http://arxiv.org/abs/2512.17251v1_AlignDP_Hybrid_Differential_Privacy_with_Rarity-Aware_Protection_for_LLMs",
    "pdf_url": "https://arxiv.org/pdf/2512.17251v1_AlignDP_Hybrid_Differential_Privacy_with_Rarity-Aware_Protection_for_LLMs",
    "file_size_mb": 0.29,
    "abstract": "Large language models are exposed to risks of extraction, distillation, and unau- thorized fine-tuning. Existing defenses use watermarking or monitoring, but these act after leakage. We design AlignDP, a hybrid privacy lock that blocks knowl- edge transfer at the data interface. The key idea is to separate rare and non-rare fields. Rare fields are shielded by PAC indistinguishability, giving effective zero-ϵ local DP. Non-rare fields are privatized with RAPPOR, giving unbiased frequency estimates under local DP. A global aggregator enforces composition and budget. This two-tier design hides rare events and adds controlled noise to frequent events. We prove limits of PAC extension to global aggregation, give bounds for RAP- POR estimates, and analyze utility trade-off. A toy simulation confirms feasibil- ity: rare categories remain hidden, frequent categories are recovered with small error. AlignDP aligns with Lock-LLM goals, making models un-distillable, un- finetunable, and un-editable by mechanism.",
    "keywords": []
  },
  {
    "article_id": "2512.17308v1_Large_Language_Models_as_Pokémon_Battle_Agents_Strategic_Play_and_Content_Generation",
    "title": "2512.17308v1 Large Language Models as Pokémon Battle Agents Strategic Play and Content Generation",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.17308v1_Large_Language_Models_as_Pokémon_Battle_Agents_Strategic_Play_and_Content_Generation.pdf",
    "url": "http://arxiv.org/abs/2512.17308v1_Large_Language_Models_as_Pokémon_Battle_Agents_Strategic_Play_and_Content_Generation",
    "pdf_url": "https://arxiv.org/pdf/2512.17308v1_Large_Language_Models_as_Pokémon_Battle_Agents_Strategic_Play_and_Content_Generation",
    "file_size_mb": 0.18,
    "abstract": "Strategic decision-making in Pokémon bat- tles presents a unique testbed for evaluating large language models. Pokémon battles de- mand reasoning about type matchups, statisti- cal trade-offs, and risk assessment, skills that mirror human strategic thinking. This work examines whether Large Language Models (LLMs) can serve as competent battle agents, capable of both making tactically sound de- cisions and generating novel, balanced game content. We developed a turn-based Pokémon battle system where LLMs select moves based on battle state rather than pre-programmed logic. The framework captures essential Poké- mon mechanics: type effectiveness multipli- ers, stat-based damage calculations, and multi- Pokémon team management. Through sys- tematic evaluation across multiple model ar- chitectures we measured win rates, decision latency, type-alignment accuracy, and token efficiency. These results suggest LLMs can function as dynamic game opponents without domain-specific training, offering a practical alternative to reinforcement learning for turn- based strategic games. The dual capability of tactical reasoning and content creation, po- sitions LLMs as both players and designers, with implications for procedural generation and adaptive difficulty systems in interactive enter- tainment.",
    "keywords": []
  },
  {
    "article_id": "2512.17373v2_Dialectics_for_Artificial_Intelligence",
    "title": "2512.17373v2 Dialectics for Artificial Intelligence",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.17373v2_Dialectics_for_Artificial_Intelligence.pdf",
    "url": "http://arxiv.org/abs/2512.17373v2_Dialectics_for_Artificial_Intelligence",
    "pdf_url": "https://arxiv.org/pdf/2512.17373v2_Dialectics_for_Artificial_Intelligence",
    "file_size_mb": 0.71,
    "abstract": "Can artificial intelligence discover, from raw experience and without human supervision, concepts that humans have discovered? One chal- lenge is that human concepts themselves are fluid: conceptual boundaries can shift, split, and merge as inquiry progresses (e.g., Pluto is no longer considered a planet). To make progress, we need a definition of “concept” that is not merely a dictionary label, but a structure that can be revised, compared, and aligned across agents. We propose an algorithmic-information viewpoint that treats a con- cept as an information object defined only through its structural relation to an agent’s total experience. The core constraint is determination: a set of parts forms a reversible consistency relation if any missing part is recoverable from the others (up to the standard logarithmic slack in Kolmogorov-style identities). This reversibility prevents “concepts” from floating free of experience and turns concept existence into a checkable structural claim. To judge whether a decomposition is natural, we de- fine excess information, measuring the redundancy overhead introduced by splitting experience into multiple separately described parts. On top of these definitions, we formulate dialectics as an optimization dynamics: as new patches of information appear (or become contested), competing concepts bid to explain them via shorter conditional descrip- tions, driving systematic expansion, contraction, splitting, and merging. Finally, we formalize low-cost concept transmission and multi-agent align- ment using small grounds/seeds that allow another agent to reconstruct the same concept under a shared protocol, making communication a con- crete compute-bits trade-off.",
    "keywords": []
  },
  {
    "article_id": "2512.17381v1_Timely_Information_Updating_for_Mobile_Devices_Without_and_With_ML_Advice",
    "title": "2512.17381v1 Timely Information Updating for Mobile Devices Without and With ML Advice",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.17381v1_Timely_Information_Updating_for_Mobile_Devices_Without_and_With_ML_Advice.pdf",
    "url": "http://arxiv.org/abs/2512.17381v1_Timely_Information_Updating_for_Mobile_Devices_Without_and_With_ML_Advice",
    "pdf_url": "https://arxiv.org/pdf/2512.17381v1_Timely_Information_Updating_for_Mobile_Devices_Without_and_With_ML_Advice",
    "file_size_mb": 1.87,
    "abstract": "—This paper investigates an information update sys- tem in which a mobile device monitors a physical process and sends status updates to an access point (AP). A fundamen- tal trade-off arises between the timeliness of the information maintained at the AP and the update cost incurred at the device. To address this trade-off, we propose an online algorithm that determines when to transmit updates using only available observations. The proposed algorithm asymptotically achieves the optimal competitive ratio against an adversary that can simultane- ously manipulate multiple sources of uncertainty, including the operation duration, the information staleness, the update cost, and the availability of update opportunities. Furthermore, by in- corporating machine learning (ML) advice of unknown reliability into the design, we develop an ML-augmented algorithm that asymptotically attains the optimal consistency-robustness trade- off, even when the adversary can additionally corrupt the ML advice. The optimal competitive ratio scales linearly with the range of update costs, but is unaffected by other uncertainties. Moreover, an optimal competitive online algorithm exhibits a threshold-like response to the ML advice: it either fully trusts or completely ignores the ML advice, as partially trusting the advice cannot improve the consistency without severely degrading the robustness. Extensive simulations in stochastic settings further validate the theoretical findings in the adversarial environment.",
    "keywords": [
      "Age of information",
      "scheduling",
      "competitive"
    ]
  },
  {
    "article_id": "2512.17607v1_More_Consistent_Accuracy_PINN_via_Alternating_Easy-Hard_Training",
    "title": "2512.17607v1 More Consistent Accuracy PINN via Alternating Easy-Hard Training",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.17607v1_More_Consistent_Accuracy_PINN_via_Alternating_Easy-Hard_Training.pdf",
    "url": "http://arxiv.org/abs/2512.17607v1_More_Consistent_Accuracy_PINN_via_Alternating_Easy-Hard_Training",
    "pdf_url": "https://arxiv.org/pdf/2512.17607v1_More_Consistent_Accuracy_PINN_via_Alternating_Easy-Hard_Training",
    "file_size_mb": 9.54,
    "abstract": "Physics-informed neural networks (PINNs) have recently emerged as a prominent paradigm for solving partial diﬀerential equations (PDEs), yet their training strategies remain un- derexplored. While hard prioritization methods inspired by ﬁnite element methods are widely adopted, recent research suggests that easy prioritization can also be eﬀective. Nevertheless, we ﬁnd that both approaches exhibit notable trade-oﬀs and inconsistent performance across PDE types. To address this issue, we develop a hybrid strategy that combines the strengths of hard and easy prioritization through an alternating training algorithm. On PDEs with steep gradients, nonlinearity, and high dimensionality, the proposed method achieves consistently high accuracy, with relative L2 errors mostly in the range of O(10−5) to O(10−6), signiﬁcantly surpassing baseline methods. Moreover, it oﬀers greater reliability across diverse problems, whereas compared approaches often suﬀer from variable accuracy depending on the PDE. This work provides new insights into designing hybrid training strategies to enhance the performance and robustness of PINNs.",
    "keywords": [
      "Physics-informed neural networks",
      "Easy-hard prioritization",
      "Hybrid training"
    ]
  },
  {
    "article_id": "2512.17923v1_Inferring_Latent_Market_Forces_Evaluating_LLM_Detection_of_Gamma_Exposure_Patterns_via_Obfuscation_T",
    "title": "2512.17923v1 Inferring Latent Market Forces Evaluating LLM Detection of Gamma Exposure Patterns via Obfuscation T",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.17923v1_Inferring_Latent_Market_Forces_Evaluating_LLM_Detection_of_Gamma_Exposure_Patterns_via_Obfuscation_T.pdf",
    "url": "http://arxiv.org/abs/2512.17923v1_Inferring_Latent_Market_Forces_Evaluating_LLM_Detection_of_Gamma_Exposure_Patterns_via_Obfuscation_T",
    "pdf_url": "https://arxiv.org/pdf/2512.17923v1_Inferring_Latent_Market_Forces_Evaluating_LLM_Detection_of_Gamma_Exposure_Patterns_via_Obfuscation_T",
    "file_size_mb": 1.61,
    "abstract": "—We introduce obfuscation testing, a novel methodology for validating whether large language models detect structural market patterns through causal reasoning rather than temporal association. Testing three dealer hedging constraint patterns (gamma posi- tioning, stock pinning, 0DTE hedging) on 242 trading days (95.6% coverage) of S&P 500 options data, we find LLMs achieve 71.5% detection rate using unbiased prompts that provide only raw gamma exposure val- ues without regime labels or temporal context. The WHO→WHOM→WHAT causal framework forces mod- els to identify the economic actors (dealers), affected parties (directional traders), and structural mechanisms (forced hedging) underlying observed market dynamics. Critically, detection accuracy (91.2%) remains stable even as economic profitability varies quarterly, demon- strating that models identify structural constraints rather than profitable patterns. When prompted with regime labels, detection increases to 100%, but the 71.5% unbiased rate validates genuine pattern recog- nition. Our findings suggest LLMs possess emergent capabilities for detecting complex financial mechanisms through pure structural reasoning, with implications for systematic strategy development, risk management, and our understanding of how transformer architectures process financial market dynamics. This is the conference version accepted at IEEE Big Data 2025. An extended journal version with additional validation experiments is in preparation.",
    "keywords": [
      "large language models",
      "market mi-"
    ]
  },
  {
    "article_id": "2512.17929v1_Reinforcement_Learning_for_Monetary_Policy_Under_Macroeconomic_Uncertainty_Analyzing_Tabular_and_Fun",
    "title": "2512.17929v1 Reinforcement Learning for Monetary Policy Under Macroeconomic Uncertainty Analyzing Tabular and Fun",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.17929v1_Reinforcement_Learning_for_Monetary_Policy_Under_Macroeconomic_Uncertainty_Analyzing_Tabular_and_Fun.pdf",
    "url": "http://arxiv.org/abs/2512.17929v1_Reinforcement_Learning_for_Monetary_Policy_Under_Macroeconomic_Uncertainty_Analyzing_Tabular_and_Fun",
    "pdf_url": "https://arxiv.org/pdf/2512.17929v1_Reinforcement_Learning_for_Monetary_Policy_Under_Macroeconomic_Uncertainty_Analyzing_Tabular_and_Fun",
    "file_size_mb": 3.25,
    "abstract": "We study how a central bank should dynamically set short-term nominal interest rates to stabilize inflation and unemployment when macroeconomic relationships are uncertain and time-varying. We model monetary policy as a sequential decision- making problem where the central bank observes macroeconomic conditions quar- terly and chooses interest rate adjustments. Using publically accessible historical Federal Reserve Economic Data (FRED), we construct a linear-Gaussian transition model and implement a discrete-action Markov Decision Process with a quadratic loss reward function. We chose to compare nine different reinforcement learn- ing style approaches against Taylor Rule and naive baselines, including tabular Q-learning variants, SARSA, Actor-Critic, Deep Q-Networks, Bayesian Q-learning with uncertainty quantification, and POMDP formulations with partial observ- ability. Surprisingly, standard tabular Q-learning achieved the best performance (-615.13 ± 309.58 mean return), outperforming both enhanced RL methods and traditional policy rules. Our results suggest that while sophisticated RL techniques show promise for monetary policy applications, simpler approaches may be more robust in this domain, highlighting important challenges in applying modern RL to macroeconomic policy. Code: https://github.com/tonywangs/cs238-final-project",
    "keywords": []
  },
  {
    "article_id": "2512.17936v1_Risk-Aware_Financial_Forecasting_Enhanced_by_Machine_Learning_and_Intuitionistic_Fuzzy_Multi-Criteri",
    "title": "2512.17936v1 Risk-Aware Financial Forecasting Enhanced by Machine Learning and Intuitionistic Fuzzy Multi-Criteri",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.17936v1_Risk-Aware_Financial_Forecasting_Enhanced_by_Machine_Learning_and_Intuitionistic_Fuzzy_Multi-Criteri.pdf",
    "url": "http://arxiv.org/abs/2512.17936v1_Risk-Aware_Financial_Forecasting_Enhanced_by_Machine_Learning_and_Intuitionistic_Fuzzy_Multi-Criteri",
    "pdf_url": "https://arxiv.org/pdf/2512.17936v1_Risk-Aware_Financial_Forecasting_Enhanced_by_Machine_Learning_and_Intuitionistic_Fuzzy_Multi-Criteri",
    "file_size_mb": 0.65,
    "abstract": "In the face of increasing financial uncertainty and market complexity, this study presents a novel risk-aware financial forecasting framework that integrates advanced machine learning techniques with intuitionistic fuzzy multi-criteria decision-making (MCDM). Tailored to the BIST 100 index and validated through a case study of a major defense company in Türkiye, the framework fuses structured financial data, unstructured text data, and macroeconomic indicators to enhance predictive accuracy and robustness. It incorporates a hybrid suite of models, including extreme gradient boosting (XGBoost), long short-term memory (LSTM) network, graph neural network (GNN), to deliver probabilistic forecasts with quantified uncertainty. The empirical results demonstrate high forecasting accuracy, with a net profit mean absolute percentage error (MAPE) of 3.03% and narrow 95% confidence intervals for key financial indicators. The risk-aware analysis indicates a favorable risk-return profile, with a Sharpe ratio of 1.25 and a higher Sortino ratio of 1.80, suggesting relatively low downside volatility and robust performance under market fluctuations. Sensitivity analysis shows that the key financial indicator predictions are highly sensitive to variations of inflation, interest rates, sentiment, and exchange rates. Additionally, using an intuitionistic fuzzy MCDM approach, combining entropy weighting, evaluation based on distance from the average solution (EDAS), and the measurement of alternatives and ranking according to compromise solution (MARCOS) methods, the tabular data learning network (TabNet) outperforms the other models and is identified as the most suitable candidate for deployment. Overall, the findings of this work highlight the importance of integrating advanced machine learning, risk quantification, and fuzzy MCDM methodologies in financial forecasting, particularly in emerging markets. Preliminary Draft Manuscript 2",
    "keywords": [
      "Financial Forecasting",
      "Machine Learning",
      "Group Decision Making",
      "Intuitionistic"
    ]
  },
  {
    "article_id": "2512.17945v1_Whats_the_Price_of_Monotonicity_A_Multi-Dataset_Benchmark_of_Monotone-Constrained_Gradient_Boosting_",
    "title": "2512.17945v1 Whats the Price of Monotonicity A Multi-Dataset Benchmark of Monotone-Constrained Gradient Boosting ",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.17945v1_Whats_the_Price_of_Monotonicity_A_Multi-Dataset_Benchmark_of_Monotone-Constrained_Gradient_Boosting_.pdf",
    "url": "http://arxiv.org/abs/2512.17945v1_Whats_the_Price_of_Monotonicity_A_Multi-Dataset_Benchmark_of_Monotone-Constrained_Gradient_Boosting_",
    "pdf_url": "https://arxiv.org/pdf/2512.17945v1_Whats_the_Price_of_Monotonicity_A_Multi-Dataset_Benchmark_of_Monotone-Constrained_Gradient_Boosting_",
    "file_size_mb": 1.04,
    "abstract": null,
    "keywords": []
  },
  {
    "article_id": "2512.17952v1_Will_AI_Trade_A_Computational_Inversion_of_the_No-Trade_Theorem",
    "title": "2512.17952v1 Will AI Trade A Computational Inversion of the No-Trade Theorem",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.17952v1_Will_AI_Trade_A_Computational_Inversion_of_the_No-Trade_Theorem.pdf",
    "url": "http://arxiv.org/abs/2512.17952v1_Will_AI_Trade_A_Computational_Inversion_of_the_No-Trade_Theorem",
    "pdf_url": "https://arxiv.org/pdf/2512.17952v1_Will_AI_Trade_A_Computational_Inversion_of_the_No-Trade_Theorem",
    "file_size_mb": 0.23,
    "abstract": "Classic no-trade theorems attribute trade to heterogeneous beliefs. We re-examine this conclusion for AI agents, asking if trade can arise from computational limitations, under common beliefs. We model agents’ bounded computational rationality within an unfolding game framework, where computational power determines the complexity of its strategy. Our central ﬁnding inverts the classic paradigm: a stable no-trade outcome (Nash equilibrium) is reached only when “almost rational” agents have slightly different computational power. Paradoxically, when agents possess identical power, they may fail to converge to equilibrium, resulting in persistent strategic adjustments that constitute a form of trade. This instability is exacerbated if agents can strategically under-utilize their computational resources, which eliminates any chance of equilibrium in Matching Pennies scenarios. Our results suggest that the inherent computational limitations of AI agents can lead to situations where equilibrium is not reached, creating a more lively and unpredictable trade environment than traditional models would predict.",
    "keywords": []
  },
  {
    "article_id": "2512.17968v1_A_Critical_Review_of_Monte_Carlo_Algorithms_Balancing_Performance_and_Probabilistic_Accuracy_with_AI",
    "title": "2512.17968v1 A Critical Review of Monte Carlo Algorithms Balancing Performance and Probabilistic Accuracy with AI",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.17968v1_A_Critical_Review_of_Monte_Carlo_Algorithms_Balancing_Performance_and_Probabilistic_Accuracy_with_AI.pdf",
    "url": "http://arxiv.org/abs/2512.17968v1_A_Critical_Review_of_Monte_Carlo_Algorithms_Balancing_Performance_and_Probabilistic_Accuracy_with_AI",
    "pdf_url": "https://arxiv.org/pdf/2512.17968v1_A_Critical_Review_of_Monte_Carlo_Algorithms_Balancing_Performance_and_Probabilistic_Accuracy_with_AI",
    "file_size_mb": 1.68,
    "abstract": "—Monte Carlo algorithms are a foundational pillar of modern computational science, yet their effective application hinges on a deep understanding of their performance trade-offs. This paper presents a critical analysis of the evolution of Monte Carlo algorithms, focusing on the persistent tension between statistical efficiency and computational cost. We describe the his- torical development from the foundational Metropolis–Hastings algorithm to contemporary methods like Hamiltonian Monte Carlo (HMC). A central emphasis of this survey is the rigorous discussion of time and space complexity, including upper, lower, and asymptotic tight bounds for each major algorithm class. We examine the specific motivations for developing these methods and the key theoretical and practical observations such as the introduction of gradient information and adaptive tuning in HMC—that led to successively better solutions. Furthermore, we provide a justification framework that discusses explicit situations in which using one algorithm is demonstrably superior to another for the same problem. The paper concludes by assessing the profound significance and impact of these algorithms and detailing major current research challenges.",
    "keywords": [
      "Monte Carlo methods",
      "Markov Chain Monte"
    ]
  },
  {
    "article_id": "2512.17979v1_Adaptive_Agents_in_Spatial_Double-Auction_Markets_Modeling_the_Emergence_of_Industrial_Symbiosis",
    "title": "2512.17979v1 Adaptive Agents in Spatial Double-Auction Markets Modeling the Emergence of Industrial Symbiosis",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.17979v1_Adaptive_Agents_in_Spatial_Double-Auction_Markets_Modeling_the_Emergence_of_Industrial_Symbiosis.pdf",
    "url": "http://arxiv.org/abs/2512.17979v1_Adaptive_Agents_in_Spatial_Double-Auction_Markets_Modeling_the_Emergence_of_Industrial_Symbiosis",
    "pdf_url": "https://arxiv.org/pdf/2512.17979v1_Adaptive_Agents_in_Spatial_Double-Auction_Markets_Modeling_the_Emergence_of_Industrial_Symbiosis",
    "file_size_mb": 3.95,
    "abstract": "Industrial symbiosis fosters circularity by enabling firms to re- purpose residual resources, yet its emergence is constrained by socio-spatial frictions that shape costs, matching opportunities, and market efficiency. Existing models often overlook the interaction between spatial structure, market design, and adaptive firm behav- ior, limiting our understanding of where and how symbiosis arises. We develop an agent-based model where heterogeneous firms trade byproducts through a spatially embedded double-auction market, with prices and quantities emerging endogenously from local in- teractions. Leveraging reinforcement learning, firms adapt their bidding strategies to maximize profit while accounting for transport costs, disposal penalties, and resource scarcity. Simulation exper- iments reveal the economic and spatial conditions under which decentralized exchanges converge toward stable and efficient out- comes. Counterfactual regret analysis shows that sellers’ strategies approach a near Nash equilibrium, while sensitivity analysis high- lights how spatial structures and market parameters jointly govern circularity. Our model provides a basis for exploring policy inter- ventions that seek to align firm incentives with sustainability goals, and more broadly demonstrates how decentralized coordination can emerge from adaptive agents in spatially constrained markets.",
    "keywords": [
      "Agent Based Simulation",
      "Industrial Symbiosis",
      "Circular Economy"
    ]
  },
  {
    "article_id": "2512.18640v1_Geometric-Photometric_Event-based_3D_Gaussian_Ray_Tracing",
    "title": "2512.18640v1 Geometric-Photometric Event-based 3D Gaussian Ray Tracing",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.18640v1_Geometric-Photometric_Event-based_3D_Gaussian_Ray_Tracing.pdf",
    "url": "http://arxiv.org/abs/2512.18640v1_Geometric-Photometric_Event-based_3D_Gaussian_Ray_Tracing",
    "pdf_url": "https://arxiv.org/pdf/2512.18640v1_Geometric-Photometric_Event-based_3D_Gaussian_Ray_Tracing",
    "file_size_mb": 18.42,
    "abstract": "Event cameras offer a high temporal resolution over tra- ditional frame-based cameras, which makes them suitable for motion and structure estimation. However, it has been unclear how event-based 3D Gaussian Splatting (3DGS) approaches could leverage fine-grained temporal informa- tion of sparse events. This work proposes a framework to address the trade-off between accuracy and temporal res- olution in event-based 3DGS. Our key idea is to decou- ple the rendering into two branches: event-by-event ge- ometry (depth) rendering and snapshot-based radiance (in- tensity) rendering, by using ray-tracing and the image of warped events. The extensive evaluation shows that our method achieves state-of-the-art performance on the real- world datasets and competitive performance on the syn- thetic dataset. Also, the proposed method works with- out prior information (e.g., pretrained image reconstruction models) or COLMAP-based initialization, is more flexible in the event selection number, and achieves sharp recon- struction on scene edges with fast training time. We hope that this work deepens our understanding of the sparse na- ture of events for 3D reconstruction. The code will be re- leased.",
    "keywords": []
  },
  {
    "article_id": "2512.18661v1_ASTIF_Adaptive_Semantic-Temporal_Integration_for_Cryptocurrency_Price_Forecasting",
    "title": "2512.18661v1 ASTIF Adaptive Semantic-Temporal Integration for Cryptocurrency Price Forecasting",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.18661v1_ASTIF_Adaptive_Semantic-Temporal_Integration_for_Cryptocurrency_Price_Forecasting.pdf",
    "url": "http://arxiv.org/abs/2512.18661v1_ASTIF_Adaptive_Semantic-Temporal_Integration_for_Cryptocurrency_Price_Forecasting",
    "pdf_url": "https://arxiv.org/pdf/2512.18661v1_ASTIF_Adaptive_Semantic-Temporal_Integration_for_Cryptocurrency_Price_Forecasting",
    "file_size_mb": 11.36,
    "abstract": "Financial time series forecasting is fundamentally an information fusion chal- lenge, yet most existing models rely on static architectures that struggle to integrate heterogeneous knowledge sources or adjust to rapid regime shifts. Conventional approaches, relying exclusively on historical price sequences, often neglect the semantic drivers of volatility such as policy uncertainty and market narratives. To address these limitations, we propose the ASTIF (Adaptive Semantic-Temporal Integration for Cryptocurrency Price Fore- casting), a hybrid intelligent system that adapts its forecasting strategy in real time through confidence-based meta-learning. The framework in- tegrates three complementary components. A dual-channel Small Language Model using MirrorPrompt extracts semantic market cues alongside numeri- cal trends. A hybrid LSTM–Random Forest model captures sequential tem- poral dependencies. A confidence-aware meta-learner functions as an adap- tive inference layer, modulating each predictor’s contribution based on its real-time uncertainty. Experimental evaluation on a diverse dataset of AI- focused cryptocurrencies and major technology stocks from 2020 to 2024 shows that ASTIF outperforms leading deep learning and Transformer base- lines (e.g., Informer, TFT). The ablation studies further confirm the critical role of the adaptive meta-learning mechanism, which successfully mitigates risk by shifting reliance between semantic and temporal channels during mar- ∗Corresponding author Email addresses: saif_@msn.com (Hafiz Saif Ur Rehman), lingliu@swufe.edu.cn (Ling Liu), kaleemullah@swjtu.edu.cn (Kaleem Ullah Qasim) arXiv:2512.18661v1 [cs.AI] 21 Dec 2025 ket turbulence. The research contributes a scalable, knowledge-based solu- tion for fusing quantitative and qualitative data in non-stationary environ- ments.",
    "keywords": [
      "Cryptocurrency Forecasting",
      "Adaptive Semantic-Temporal"
    ]
  },
  {
    "article_id": "2512.19142v1_A_Convex_Loss_Function_for_Set_Prediction_with_Optimal_Trade-offs_Between_Size_and_Conditional_Cover",
    "title": "2512.19142v1 A Convex Loss Function for Set Prediction with Optimal Trade-offs Between Size and Conditional Cover",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.19142v1_A_Convex_Loss_Function_for_Set_Prediction_with_Optimal_Trade-offs_Between_Size_and_Conditional_Cover.pdf",
    "url": "http://arxiv.org/abs/2512.19142v1_A_Convex_Loss_Function_for_Set_Prediction_with_Optimal_Trade-offs_Between_Size_and_Conditional_Cover",
    "pdf_url": "https://arxiv.org/pdf/2512.19142v1_A_Convex_Loss_Function_for_Set_Prediction_with_Optimal_Trade-offs_Between_Size_and_Conditional_Cover",
    "file_size_mb": 1.53,
    "abstract": "We consider supervised learning problems in which set predictions provide explicit uncertainty esti- mates. Using Choquet integrals (a.k.a. Lov´asz extensions), we propose a convex loss function for non- decreasing subset-valued functions obtained as level sets of a real-valued function. This loss function allows optimal trade-oﬀs between conditional probabilistic coverage and the “size” of the set, measured by a non-decreasing submodular function. We also propose several extensions that mimic loss functions and criteria for binary classiﬁcation with asymmetric losses, and show how to naturally obtain sets with optimized conditional coverage. We derive eﬃcient optimization algorithms, either based on stochastic gradient descent or reweighted least-squares formulations, and illustrate our ﬁndings with a series of experiments on synthetic datasets for classiﬁcation and regression tasks, showing improvements over approaches that aim for marginal coverage.",
    "keywords": []
  },
  {
    "article_id": "2512.19484v1_Structured_Event_Representation_and_Stock_Return_Predictability",
    "title": "2512.19484v1 Structured Event Representation and Stock Return Predictability",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.19484v1_Structured_Event_Representation_and_Stock_Return_Predictability.pdf",
    "url": "http://arxiv.org/abs/2512.19484v1_Structured_Event_Representation_and_Stock_Return_Predictability",
    "pdf_url": "https://arxiv.org/pdf/2512.19484v1_Structured_Event_Representation_and_Stock_Return_Predictability",
    "file_size_mb": 13.8,
    "abstract": "We find that event features extracted by large language models (LLMs) are effective for text-based stock return prediction. Using a pre-trained LLM to extract event features from news articles, we propose a novel deep learning model based on structured event representation (SER) and attention mechanisms to predict stock returns in the cross- section. Our SER-based model provides superior performance compared with other existing text-driven models to forecast stock returns out of sample and offers highly interpretable feature structures to examine the mechanisms underlying the stock return predictability. We further provide various implications based on SER and highlight the crucial benefit of structured model inputs in stock return predictability. JEL Classification: G11, G12, G13, G14",
    "keywords": [
      "large language models",
      "structured event representation",
      "textual analysis"
    ]
  },
  {
    "article_id": "2512.19729v1_High-Performance_Self-Supervised_Learning_by_Joint_Training_of_Flow_Matching",
    "title": "2512.19729v1 High-Performance Self-Supervised Learning by Joint Training of Flow Matching",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.19729v1_High-Performance_Self-Supervised_Learning_by_Joint_Training_of_Flow_Matching.pdf",
    "url": "http://arxiv.org/abs/2512.19729v1_High-Performance_Self-Supervised_Learning_by_Joint_Training_of_Flow_Matching",
    "pdf_url": "https://arxiv.org/pdf/2512.19729v1_High-Performance_Self-Supervised_Learning_by_Joint_Training_of_Flow_Matching",
    "file_size_mb": 2.15,
    "abstract": "Diffusion models can learn rich rep- resentations during data generation, showing potential for Self-Supervised Learning (SSL), but they face a trade- off between generative quality and discriminative performance. Their iter- ative sampling also incurs substantial computational and energy costs, hinder- ing industrial and edge AI applications. To address these issues, we propose the Flow Matching-based Founda- tion Model (FlowFM), which jointly trains a representation encoder and a conditional flow matching generator. This decoupled design achieves both high-fidelity generation and effective recognition. By using flow match- ing to learn a simpler velocity field, FlowFM accelerates and stabilizes training, improving its efficiency for representation learning. Experiments on wearable sensor data show FlowFM reduces training time by 50.4% com- pared to a diffusion-based approach. On downstream tasks, FlowFM sur- passed the state-of-the-art SSL method (SSL-Wearables) on all five datasets while achieving up to a 51.0x infer- ence speedup and maintaining high generative quality. The implementa- tion code is available at https:// github.com/Okita-Laboratory/ jointOptimizationFlowMatching.",
    "keywords": []
  },
  {
    "article_id": "2512.19743v1_From_Theory_to_Throughput_CUDA-Optimized_APML_for_Large-Batch_3D_Learning",
    "title": "2512.19743v1 From Theory to Throughput CUDA-Optimized APML for Large-Batch 3D Learning",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.19743v1_From_Theory_to_Throughput_CUDA-Optimized_APML_for_Large-Batch_3D_Learning.pdf",
    "url": "http://arxiv.org/abs/2512.19743v1_From_Theory_to_Throughput_CUDA-Optimized_APML_for_Large-Batch_3D_Learning",
    "pdf_url": "https://arxiv.org/pdf/2512.19743v1_From_Theory_to_Throughput_CUDA-Optimized_APML_for_Large-Batch_3D_Learning",
    "file_size_mb": 0.61,
    "abstract": "—Loss functions are fundamental to learning accurate 3D point cloud models, yet common choices trade geometric fidelity for computational cost. Chamfer Distance is efficient but permits many-to-one correspondences, while Earth Mover Distance better reflects one-to-one transport at high computa- tional cost. APML approximates transport with differentiable Sinkhorn iterations and an analytically derived temperature, but its dense formulation scales quadratically in memory. We present CUDA-APML, a sparse GPU implementation that thresholds negligible assignments and runs adaptive softmax, bidirectional symmetrization, and Sinkhorn normalization directly in COO form. This yields near-linear memory scaling and preserves gra- dients on the stored support, while pairwise distance evaluation remains quadratic in the current implementation. On ShapeNet and MM-Fi, CUDA-APML matches dense APML within a small tolerance while reducing peak GPU memory by 99.9%. Code available at: https://github.com/Multimodal-Sensing-Lab/apml",
    "keywords": [
      "Point cloud learning",
      "optimal transport",
      "adap-"
    ]
  },
  {
    "article_id": "2512.19986v1_Covariance-Aware_Simplex_Projection_for_Cardinality-Constrained_Portfolio_Optimization",
    "title": "2512.19986v1 Covariance-Aware Simplex Projection for Cardinality-Constrained Portfolio Optimization",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.19986v1_Covariance-Aware_Simplex_Projection_for_Cardinality-Constrained_Portfolio_Optimization.pdf",
    "url": "http://arxiv.org/abs/2512.19986v1_Covariance-Aware_Simplex_Projection_for_Cardinality-Constrained_Portfolio_Optimization",
    "pdf_url": "https://arxiv.org/pdf/2512.19986v1_Covariance-Aware_Simplex_Projection_for_Cardinality-Constrained_Portfolio_Optimization",
    "file_size_mb": 0.34,
    "abstract": "Metaheuristic algorithms for cardinality-constrained portfo- lio optimization require repair operators to map infeasible candidates onto the feasible region. Standard Euclidean projection treats assets as independent and can ignore the covariance structure that governs portfolio risk, potentially producing less diversified portfolios. This paper introduces Covariance-Aware Simplex Projection (CASP), a two-stage repair operator that (i) selects a target number of assets using volatility-normalized scores and (ii) projects the candidate weights using a covariance-aware geometry aligned with tracking-error risk. This provides a portfolio-theoretic foun- dation for using a covariance-induced distance in repair oper- ators. On S&P 500 data (2020–2024), CASP-Basic delivers materially lower portfolio variance than standard Euclidean repair without relying on return estimates, with improve- ments that are robust across assets and statistically significant. Ablation results indicate that volatility-normalized selection drives most of the variance reduction, while the covariance- aware projection provides an additional, consistent improve- ment. We further show that optional return-aware extensions can improve Sharpe ratios, and out-of-sample tests confirm that gains transfer to realized performance. CASP integrates as a drop-in replacement for Euclidean projection in meta- heuristic portfolio optimizers.",
    "keywords": [
      "Cardinality-constrained portfolio optimization"
    ]
  },
  {
    "article_id": "2512.19992v1_S3IT_A_Benchmark_for_Spatially_Situated_Social_Intelligence_Test",
    "title": "2512.19992v1 S3IT A Benchmark for Spatially Situated Social Intelligence Test",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.19992v1_S3IT_A_Benchmark_for_Spatially_Situated_Social_Intelligence_Test.pdf",
    "url": "http://arxiv.org/abs/2512.19992v1_S3IT_A_Benchmark_for_Spatially_Situated_Social_Intelligence_Test",
    "pdf_url": "https://arxiv.org/pdf/2512.19992v1_S3IT_A_Benchmark_for_Spatially_Situated_Social_Intelligence_Test",
    "file_size_mb": 8.77,
    "abstract": null,
    "keywords": [
      "Situated Social Intelligence",
      "Embodied social intelligence",
      "Embodied Agent",
      "AI benchmark"
    ]
  },
  {
    "article_id": "2512.20002v1_LoFT-LLM_Low-Frequency_Time-Series_Forecasting_with_Large_Language_Models",
    "title": "2512.20002v1 LoFT-LLM Low-Frequency Time-Series Forecasting with Large Language Models",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.20002v1_LoFT-LLM_Low-Frequency_Time-Series_Forecasting_with_Large_Language_Models.pdf",
    "url": "http://arxiv.org/abs/2512.20002v1_LoFT-LLM_Low-Frequency_Time-Series_Forecasting_with_Large_Language_Models",
    "pdf_url": "https://arxiv.org/pdf/2512.20002v1_LoFT-LLM_Low-Frequency_Time-Series_Forecasting_with_Large_Language_Models",
    "file_size_mb": 2.32,
    "abstract": "Time-series forecasting in real-world applications such as finance and energy often faces challenges due to limited training data and complex, noisy temporal dynamics. Existing deep forecast- ing models typically supervise predictions using full-length tem- poral windows, which include substantial high-frequency noise and obscure long-term trends. Moreover, auxiliary variables con- taining rich domain-specific information are often underutilized, especially in few-shot settings. To address these challenges, we propose LoFT-LLM, a frequency-aware forecasting pipeline that integrates low-frequency learning with semantic calibration via a large language model (LLM). Firstly, a Patch Low-Frequency fore- casting Module (PLFM) extracts stable low-frequency trends from localized spectral patches. Secondly, a residual learner then models high-frequency variations. Finally, a fine-tuned LLM refines the pre- dictions by incorporating auxiliary context and domain knowledge through structured natural language prompts. Extensive experi- ments on financial and energy datasets demonstrate that LoFT-LLM significantly outperforms strong baselines under both full-data and few-shot regimes, delivering superior accuracy, robustness, and interpretability. ∗Corresponding author. CCS Concepts • Computing methodologies →Neural networks; Natural lan- guage processing; • Information systems →Data mining.",
    "keywords": [
      "Time Series Forecasting",
      "Low-Frequency Learning",
      "Few Shot",
      "Large"
    ]
  },
  {
    "article_id": "2512.20216v1_Quantitative_Financial_Modeling_for_Sri_Lankan_Markets_Approach_Combining_NLP_Clustering_and_Time-Se",
    "title": "2512.20216v1 Quantitative Financial Modeling for Sri Lankan Markets Approach Combining NLP Clustering and Time-Se",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.20216v1_Quantitative_Financial_Modeling_for_Sri_Lankan_Markets_Approach_Combining_NLP_Clustering_and_Time-Se.pdf",
    "url": "http://arxiv.org/abs/2512.20216v1_Quantitative_Financial_Modeling_for_Sri_Lankan_Markets_Approach_Combining_NLP_Clustering_and_Time-Se",
    "pdf_url": "https://arxiv.org/pdf/2512.20216v1_Quantitative_Financial_Modeling_for_Sri_Lankan_Markets_Approach_Combining_NLP_Clustering_and_Time-Se",
    "file_size_mb": 0.91,
    "abstract": null,
    "keywords": [
      "Quantitative Finance",
      "Time-Series Forecasting"
    ]
  },
  {
    "article_id": "2512.20272v1_HGAN-SDEs_Learning_Neural_Stochastic_Differential_Equations_with_Hermite-Guided_Adversarial_Training",
    "title": "2512.20272v1 HGAN-SDEs Learning Neural Stochastic Differential Equations with Hermite-Guided Adversarial Training",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.20272v1_HGAN-SDEs_Learning_Neural_Stochastic_Differential_Equations_with_Hermite-Guided_Adversarial_Training.pdf",
    "url": "http://arxiv.org/abs/2512.20272v1_HGAN-SDEs_Learning_Neural_Stochastic_Differential_Equations_with_Hermite-Guided_Adversarial_Training",
    "pdf_url": "https://arxiv.org/pdf/2512.20272v1_HGAN-SDEs_Learning_Neural_Stochastic_Differential_Equations_with_Hermite-Guided_Adversarial_Training",
    "file_size_mb": 1.84,
    "abstract": "Neural Stochastic Differential Equations (Neural SDEs) provide a principled framework for modeling continuous-time stochastic pro- cesses and have been widely adopted in fields ranging from physics to finance. Recent advances suggest that Generative Adversarial Networks (GANs) offer a promising solution to learning the complex path distributions induced by SDEs. However, a critical bottleneck lies in designing a discriminator that faithfully captures temporal de- pendencies while remaining computationally efficient. Prior works have explored Neural Controlled Differential Equations (CDEs) as discriminators due to their ability to model continuous-time dynam- ics, but such architectures suffer from high computational costs and exacerbate the instability of adversarial training. To address these limitations, we introduce HGAN-SDEs, a novel GAN-based frame- work that leverages Neural Hermite functions to construct a struc- tured and efficient discriminator. Hermite functions provide an ex- pressive yet lightweight basis for approximating path-level dynam- ics, enabling both reduced runtime complexity and improved train- ing stability. We establish the universal approximation property of our framework for a broad class of SDE-driven distributions and theoretically characterize its convergence behavior. Extensive em- pirical evaluations on synthetic and real-world systems demonstrate that HGAN-SDEs achieve superior sample quality and learning effi- ciency compared to existing generative models for SDEs.",
    "keywords": [
      "Neural Stochastic Differential Equations",
      "Gen-"
    ]
  },
  {
    "article_id": "2512.20460v1_The_Aligned_Economic_Index_The_State_Switching_Model",
    "title": "2512.20460v1 The Aligned Economic Index The State Switching Model",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.20460v1_The_Aligned_Economic_Index_The_State_Switching_Model.pdf",
    "url": "http://arxiv.org/abs/2512.20460v1_The_Aligned_Economic_Index_The_State_Switching_Model",
    "pdf_url": "https://arxiv.org/pdf/2512.20460v1_The_Aligned_Economic_Index_The_State_Switching_Model",
    "file_size_mb": 0.62,
    "abstract": "A growing empirical literature suggests that equity-premium predictability is state dependent, with much of the forecasting power concentrated around recessionary periods [10, 11, 18]. I study U.S. stock return predictability across economic regimes and document strong evidence of time-varying expected returns across both expansionary and contractionary states. I contribute in two ways. First, I introduce a state- switching predictive regression in which the market state is defined in real time using the slope of the yield curve. Relative to the standard one-state predictive regression, the state-switching specification increases both in-sample and out-of-sample performance for the set of popular predictors considered by Welch and Goyal [32], improving the out-of-sample performance of most predictors in economically mean- ingful ways. Second, I propose a new aggregate predictor, the Aligned Economic Index, constructed via partial least squares (PLS). Under the state-switching model, the Aligned Economic Index exhibits statistically and economically significant predictive power in sample and out of sample, and it outperforms widely used benchmark predictors and alternative predictor-combination methods.",
    "keywords": [
      "return predictability",
      "regime switching",
      "partial least squares",
      "equity premium"
    ]
  },
  {
    "article_id": "2512.20586v1_Automated_stereotactic_radiosurgery_planning_using_a_human-in-the-loop_reasoning_large_language_mode",
    "title": "2512.20586v1 Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language mode",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.20586v1_Automated_stereotactic_radiosurgery_planning_using_a_human-in-the-loop_reasoning_large_language_mode.pdf",
    "url": "http://arxiv.org/abs/2512.20586v1_Automated_stereotactic_radiosurgery_planning_using_a_human-in-the-loop_reasoning_large_language_mode",
    "pdf_url": "https://arxiv.org/pdf/2512.20586v1_Automated_stereotactic_radiosurgery_planning_using_a_human-in-the-loop_reasoning_large_language_mode",
    "file_size_mb": 4.91,
    "abstract": "Stereotactic radiosurgery (SRS) demands precise dose shaping around critical structures, yet black-box AI systems have limited clinical adoption due to opacity concerns. We tested whether chain-of-thought reasoning improves agentic plan- ning in a retrospective cohort of 41 patients with brain metastases treated with 18 Gy single-fraction SRS. We developed SAGE (Secure Agent for Generative Dose Expertise), an LLM-based planning agent for automated SRS treatment planning. Two variants generated plans for each case: one using a non-reasoning model, one using a reasoning model. The reasoning variant showed comparable plan dosimetry relative to human planners on primary endpoints (PTV coverage, maximum dose, conformity index, gradient index; all p > 0.21) while reducing cochlear dose below human baselines (p = 0.022). When prompted to improve conformity, the rea- soning model demonstrated systematic planning behaviors including prospective constraint verification (457 instances) and trade-off deliberation (609 instances), while the standard model exhibited none of these deliberative processes (0 and 7 instances, respectively). Content analysis revealed that constraint verification and causal explanation concentrated in the reasoning agent. The optimization traces serve as auditable logs, offering a path toward transparent automated planning.",
    "keywords": [
      "Reasoning model",
      "Radiotherapy planning",
      "Agentic AI"
    ]
  },
  {
    "article_id": "2512.20650v1_Mixture_of_Attention_Schemes_MoAS_Learning_to_Route_Between_MHA_GQA_and_MQA",
    "title": "2512.20650v1 Mixture of Attention Schemes MoAS Learning to Route Between MHA GQA and MQA",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.20650v1_Mixture_of_Attention_Schemes_MoAS_Learning_to_Route_Between_MHA_GQA_and_MQA.pdf",
    "url": "http://arxiv.org/abs/2512.20650v1_Mixture_of_Attention_Schemes_MoAS_Learning_to_Route_Between_MHA_GQA_and_MQA",
    "pdf_url": "https://arxiv.org/pdf/2512.20650v1_Mixture_of_Attention_Schemes_MoAS_Learning_to_Route_Between_MHA_GQA_and_MQA",
    "file_size_mb": 0.26,
    "abstract": "The choice of attention mechanism in Transformer models involves a critical trade-off be- tween modeling quality and inference efficiency. Multi-Head Attention (MHA) offers the best quality but suffers from large Key-Value (KV) cache memory requirements during inference. Multi-Query Attention (MQA) and Grouped-Query Attention (GQA) reduce memory usage but often at the cost of model performance. In this work, we propose Mixture of Attention Schemes (MoAS), a novel architecture that dynamically selects the optimal attention scheme (MHA, GQA, or MQA) for each token via a learned router. We demonstrate that dynamic routing performs better than static averaging of schemes and achieves performance competitive with the MHA baseline while offering potential for conditional compute efficiency. Experimental results on WikiText-2 show that dynamic routing (val loss 2.3074) outperforms a static mix- ture (2.3093), validating the effectiveness of the proposed method. Our code is available at https://github.com/Esmail-ibraheem/Mixture-of-Attention-Schemes-MoAS.",
    "keywords": []
  },
  {
    "article_id": "2512.20687v1_PHOTON_Hierarchical_Autoregressive_Modeling_for_Lightspeed_and_Memory-Efficient_Language_Generation",
    "title": "2512.20687v1 PHOTON Hierarchical Autoregressive Modeling for Lightspeed and Memory-Efficient Language Generation",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.20687v1_PHOTON_Hierarchical_Autoregressive_Modeling_for_Lightspeed_and_Memory-Efficient_Language_Generation.pdf",
    "url": "http://arxiv.org/abs/2512.20687v1_PHOTON_Hierarchical_Autoregressive_Modeling_for_Lightspeed_and_Memory-Efficient_Language_Generation",
    "pdf_url": "https://arxiv.org/pdf/2512.20687v1_PHOTON_Hierarchical_Autoregressive_Modeling_for_Lightspeed_and_Memory-Efficient_Language_Generation",
    "file_size_mb": 1.49,
    "abstract": "Transformers operate as horizontal token-by- token scanners; at each generation step, the model attends to an ever-growing sequence of token-level states. This access pattern increases prefill latency and makes long-context decod- ing increasingly memory-bound, as KV-cache reads and writes dominate inference through- put rather than arithmetic computation. We propose Parallel Hierarchical Operation for TOp-down Networks (PHOTON), a hierarchi- cal autoregressive model that replaces flat scan- ning with vertical, multi-resolution context ac- cess. PHOTON maintains a hierarchy of latent streams: a bottom-up encoder progressively compresses tokens into low-rate contextual states, while lightweight top-down decoders reconstruct fine-grained token representations. Experimental results show that PHOTON is superior to competitive Transformer-based lan- guage models regarding the throughput-quality trade-off, offering significant advantages in long-context and multi-query tasks. This re- duces decode-time KV-cache traffic, yielding up to 103× higher throughput per unit memory.",
    "keywords": []
  },
  {
    "article_id": "2512.20755v1_Bridging_Efficiency_and_Safety_Formal_Verification_of_Neural_Networks_with_Early_Exits",
    "title": "2512.20755v1 Bridging Efficiency and Safety Formal Verification of Neural Networks with Early Exits",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.20755v1_Bridging_Efficiency_and_Safety_Formal_Verification_of_Neural_Networks_with_Early_Exits.pdf",
    "url": "http://arxiv.org/abs/2512.20755v1_Bridging_Efficiency_and_Safety_Formal_Verification_of_Neural_Networks_with_Early_Exits",
    "pdf_url": "https://arxiv.org/pdf/2512.20755v1_Bridging_Efficiency_and_Safety_Formal_Verification_of_Neural_Networks_with_Early_Exits",
    "file_size_mb": 0.76,
    "abstract": ". Ensuring the safety and efficiency of AI systems is a central goal of modern research. Formal verification provides guarantees of neural network robustness, while early exits improve inference efficiency by enabling intermediate predictions. Yet verifying networks with early exits introduces new challenges due to their conditional execution paths. In this work, we define a robustness property tailored to early exit architectures and show how off-the-shelf solvers can be used to assess it. We present a baseline algorithm, enhanced with an early stopping strategy and heuristic optimizations that maintain soundness and completeness. Experiments on multiple benchmarks validate our framework’s effectiveness and demonstrate the performance gains of the improved algorithm. Alongside the natural inference acceleration provided by early exits, we show that they also enhance verifiability, enabling more queries to be solved in less time compared to standard networks. Together with a robustness analysis, we show how these metrics can help users navigate the inherent trade-off between accuracy and efficiency.",
    "keywords": []
  },
  {
    "article_id": "2512.20814v1_FedMPDD_Communication-Efficient_Federated_Learning_with_Privacy_Preservation_Attributes_via_Projecte",
    "title": "2512.20814v1 FedMPDD Communication-Efficient Federated Learning with Privacy Preservation Attributes via Projecte",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.20814v1_FedMPDD_Communication-Efficient_Federated_Learning_with_Privacy_Preservation_Attributes_via_Projecte.pdf",
    "url": "http://arxiv.org/abs/2512.20814v1_FedMPDD_Communication-Efficient_Federated_Learning_with_Privacy_Preservation_Attributes_via_Projecte",
    "pdf_url": "https://arxiv.org/pdf/2512.20814v1_FedMPDD_Communication-Efficient_Federated_Learning_with_Privacy_Preservation_Attributes_via_Projecte",
    "file_size_mb": 3.1,
    "abstract": "— This paper introduces FedMPDD (Federated Learning via Multi-Projected Directional Derivatives), a novel algorithm that simultaneously optimizes bandwidth utilization and enhances privacy in Federated Learning. The core idea of FedMPDD is to encode each client’s high- dimensional gradient by computing its directional deriva- tives along multiple random vectors. This compresses the gradient into a much smaller message, significantly reduc- ing uplink communication costs from O(d) to O(m), where m ≪d. The server then decodes the aggregated informa- tion by projecting it back onto the same random vectors. Our key insight is that averaging multiple projections over- comes the dimension-dependent convergence limitations of a single projection. We provide a rigorous theoretical analysis, establishing that FedMPDD converges at a rate of O(1/ √ K), matching the performance of FedSGD. Fur- thermore, we demonstrate that our method provides some inherent privacy against gradient inversion attacks due to the geometric properties of low-rank projections, offering a tunable privacy-utility trade-off controlled by the number of projections. Extensive experiments on benchmark datasets validate our theory and demonstrates our results.",
    "keywords": []
  },
  {
    "article_id": "2512.21348v1_Fairness_Is_Not_Just_Ethical_Performance_Trade-Off_via_Data_Correlation_Tuning_to_Mitigate_Bias_in_M",
    "title": "2512.21348v1 Fairness Is Not Just Ethical Performance Trade-Off via Data Correlation Tuning to Mitigate Bias in M",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.21348v1_Fairness_Is_Not_Just_Ethical_Performance_Trade-Off_via_Data_Correlation_Tuning_to_Mitigate_Bias_in_M.pdf",
    "url": "http://arxiv.org/abs/2512.21348v1_Fairness_Is_Not_Just_Ethical_Performance_Trade-Off_via_Data_Correlation_Tuning_to_Mitigate_Bias_in_M",
    "pdf_url": "https://arxiv.org/pdf/2512.21348v1_Fairness_Is_Not_Just_Ethical_Performance_Trade-Off_via_Data_Correlation_Tuning_to_Mitigate_Bias_in_M",
    "file_size_mb": 0.78,
    "abstract": "Traditional software fairness research typically emphasizes ethi- cal and social imperatives, neglecting that fairness fundamentally represents a core software quality issue arising directly from perfor- mance disparities across sensitive user groups. Recognizing fairness explicitly as a software quality dimension yields practical benefits beyond ethical considerations, notably improved predictive per- formance for unprivileged groups, enhanced out-of-distribution generalization, and increased geographic transferability in real- world deployments. Nevertheless, existing bias mitigation methods face a critical dilemma: while pre-processing methods offer broad applicability across model types, they generally fall short in ef- fectiveness compared to post-processing techniques. To overcome this challenge, we propose Correlation Tuning (CoT), a novel pre- processing approach designed to mitigate bias by adjusting data correlations. Specifically, CoT introduces the Phi-coefficient, an in- tuitive correlation measure, to systematically quantify correlation between sensitive attributes and labels, and employs multi-objective optimization to address the proxy biases. Extensive evaluations demonstrate that CoT increases the true positive rate of unprivi- leged groups by an average of 17.5% and reduces three key bias metrics, including statistical parity difference (SPD), average odds difference (AOD), and equal opportunity difference (EOD), by more than 50% on average. CoT outperforms state-of-the-art methods by three and ten percentage points in single attribute and multi- ple attributes scenarios, respectively. We will publicly release our experimental results and source code to facilitate future research. ∗Corresponding author. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. ICSE ’26, Rio de Janeiro, Brazil © 2026 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-XXXX-X/2018/06 https://doi.org/XXXXXXX.XXXXXXX CCS Concepts • Software and its engineering →Software creation and man- agement; • Computing methodologies →Machine learning.",
    "keywords": [
      "Software Fairness",
      "ML Bias",
      "Correlation Tuning",
      "Data Debugging"
    ]
  },
  {
    "article_id": "2512.21540v1_Leash_Adaptive_Length_Penalty_and_Reward_Shaping_for_Efficient_Large_Reasoning_Model",
    "title": "2512.21540v1 Leash Adaptive Length Penalty and Reward Shaping for Efficient Large Reasoning Model",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.21540v1_Leash_Adaptive_Length_Penalty_and_Reward_Shaping_for_Efficient_Large_Reasoning_Model.pdf",
    "url": "http://arxiv.org/abs/2512.21540v1_Leash_Adaptive_Length_Penalty_and_Reward_Shaping_for_Efficient_Large_Reasoning_Model",
    "pdf_url": "https://arxiv.org/pdf/2512.21540v1_Leash_Adaptive_Length_Penalty_and_Reward_Shaping_for_Efficient_Large_Reasoning_Model",
    "file_size_mb": 0.42,
    "abstract": "Large Language Models (LLMs) often produce unnecessarily lengthy reasoning traces, which significantly increase computational cost and latency. Existing approaches typically rely on fixed length penalties, but such penalties are hard to tune and fail to adapt to the evolving reasoning abilities of LLMs, leading to subop- timal trade-offs between accuracy and concise- ness. To address this challenge, we propose LEASH (adaptive LEngth penAlty and reward SHaping), a reinforcement learning framework for efficient reasoning in LLMs. We formulate length control as a constrained optimization problem and employ a Lagrangian primal–dual method to dynamically adjust the penalty co- efficient. When generations exceed the target length, the penalty is intensified; when they are shorter, it is relaxed. This adaptive mechanism guides models toward producing concise rea- soning without sacrificing task performance. Experiments on Deepseek-R1-Distill-Qwen- 1.5B and Qwen3-4B-Thinking-2507 show that LEASH reduces the average reasoning length by 60% across diverse tasks—including in- distribution mathematical reasoning and out- of-distribution domains such as coding and in- struction following—while maintaining com- petitive performance. Our work thus presents a practical and effective paradigm for developing controllable and efficient LLMs that balance reasoning capabilities with computational bud- gets.",
    "keywords": []
  },
  {
    "article_id": "2512.21782v1_Accelerating_Scientific_Discovery_with_Autonomous_Goal-evolving_Agents",
    "title": "2512.21782v1 Accelerating Scientific Discovery with Autonomous Goal-evolving Agents",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.21782v1_Accelerating_Scientific_Discovery_with_Autonomous_Goal-evolving_Agents.pdf",
    "url": "http://arxiv.org/abs/2512.21782v1_Accelerating_Scientific_Discovery_with_Autonomous_Goal-evolving_Agents",
    "pdf_url": "https://arxiv.org/pdf/2512.21782v1_Accelerating_Scientific_Discovery_with_Autonomous_Goal-evolving_Agents",
    "file_size_mb": 16.45,
    "abstract": "There has been unprecedented interest in developing agents that expand the boundary of scientiﬁc discovery, primarily by optimizing quantitative objective functions speciﬁed by scientists. However, for grand challenges in science , these objectives are only imperfect proxies. We argue that automating objective function design is a central, yet unmet requirement for scientiﬁc discovery agents. In this work, we introduce the Scientiﬁc Autonomous Goal-evolving Agent (SAGA) to amend this challenge. SAGA employs a bi-level architecture in which an outer loop of LLM agents analyzes optimization outcomes, proposes new objectives, and converts them into computable scoring functions, while an inner loop performs solution optimization under the current objectives. This bi-level design enables systematic exploration of the space of objectives and their trade-oﬀs, rather than treating them as ﬁxed inputs. We demonstrate the framework through a broad spectrum of applications, including antibiotic design, inorganic materials design, functional DNA sequence design, and chemical process design, showing that automating objective formulation can substantially improve the eﬀectiveness of scientiﬁc discovery agents.",
    "keywords": []
  },
  {
    "article_id": "2512.21791v1_Synthetic_Financial_Data_Generation_for_Enhanced_Financial_Modelling",
    "title": "2512.21791v1 Synthetic Financial Data Generation for Enhanced Financial Modelling",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.21791v1_Synthetic_Financial_Data_Generation_for_Enhanced_Financial_Modelling.pdf",
    "url": "http://arxiv.org/abs/2512.21791v1_Synthetic_Financial_Data_Generation_for_Enhanced_Financial_Modelling",
    "pdf_url": "https://arxiv.org/pdf/2512.21791v1_Synthetic_Financial_Data_Generation_for_Enhanced_Financial_Modelling",
    "file_size_mb": 1.18,
    "abstract": "Data scarcity and confidentiality in finance often impede model development and robust testing. This paper presents a unified multi-criteria evaluation framework for synthetic financial data and applies it to three representative generative paradigms: the statistical ARIMA–GARCH baseline, Variational Autoencoders (VAEs), and Time-series Generative Adversarial Networks (TimeGAN). Using historical S&P 500 daily data, we evaluate fidelity (Maximum Mean Discrepancy, MMD), temporal structure (autocorrelation and volatility clustering), and practical utility in down- stream tasks, specifically mean–variance portfolio optimization and volatility forecasting. Empirical results indicate that ARIMA–GARCH captures linear trends and conditional volatility but fails to reproduce nonlinear dynamics; VAEs produce smooth trajectories that underestimate extreme events; and TimeGAN achieves the best trade-off be- tween realism and temporal coherence (e.g., TimeGAN attained the lowest MMD: 1.84 × 10−3, average over 5 seeds). Finally, we articulate practical guidelines for selecting generative models according to application needs and compu- tational constraints. Our unified evaluation protocol and reproducible codebase aim to standardize benchmarking in synthetic financial data research.",
    "keywords": []
  },
  {
    "article_id": "2512.21798v1_Applications_of_synthetic_financial_data_in_portfolio_and_risk_modeling",
    "title": "2512.21798v1 Applications of synthetic financial data in portfolio and risk modeling",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.21798v1_Applications_of_synthetic_financial_data_in_portfolio_and_risk_modeling.pdf",
    "url": "http://arxiv.org/abs/2512.21798v1_Applications_of_synthetic_financial_data_in_portfolio_and_risk_modeling",
    "pdf_url": "https://arxiv.org/pdf/2512.21798v1_Applications_of_synthetic_financial_data_in_portfolio_and_risk_modeling",
    "file_size_mb": 0.8,
    "abstract": "Synthetic financial data offers a practical way to address the privacy and accessibility challenges that limit research in quantitative finance. This paper examines the use of generative models, in particular TimeGAN and Variational Autoencoders (VAEs), for creating synthetic return series that support portfolio construction, trading analysis, and risk modeling. Using historical daily returns from the S&P 500 as a benchmark, we generate synthetic datasets under comparable market conditions and evaluate them using statistical similarity metrics, temporal structure tests, and downstream financial tasks. The study shows that TimeGAN produces synthetic data with distributional shapes, volatility patterns, and autocorrelation behaviour that are close to those observed in real returns. When applied to mean–variance portfolio optimization, the resulting synthetic datasets lead to portfolio weights, Sharpe ratios, and risk levels that remain close to those obtained from real data. The VAE provides more stable training but tends to smooth extreme market movements, which affects risk estimation. Finally, the analysis supports the use of synthetic datasets as substitutes for real financial data in portfolio analysis and risk simulation, particularly when models are able to capture temporal dynamics. Synthetic data therefore provides a privacy-preserving, cost-effective, and reproducible tool for financial experimentation and model development.",
    "keywords": []
  },
  {
    "article_id": "2512.21804v1_SP_500_Stocks_Movement_Prediction_using_CNN",
    "title": "2512.21804v1 SP 500 Stocks Movement Prediction using CNN",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.21804v1_SP_500_Stocks_Movement_Prediction_using_CNN.pdf",
    "url": "http://arxiv.org/abs/2512.21804v1_SP_500_Stocks_Movement_Prediction_using_CNN",
    "pdf_url": "https://arxiv.org/pdf/2512.21804v1_SP_500_Stocks_Movement_Prediction_using_CNN",
    "file_size_mb": 0.74,
    "abstract": "This paper is about predicting the movement of stock consist of S&P 500 index. Historically there are many approaches have been tried using various methods to predict the stock movement and being used in the market currently for algorithm trading and alpha generating systems using traditional mathematical approaches [1, 2]. The success of artificial neural network recently created a lot of interest and paved the way to enable prediction using cutting-edge research in the machine learning and deep learning. Some of these papers have done a great job in implementing and explaining benefits of these new technologies. Although most these papers do not go into the complexity of the financial data and mostly utilize single dimension data, still most of these papers were successful in creating the ground for future research in this comparatively new phenomenon. In this paper, I am trying to use multivariate raw data including stock split/dividend events (as-is) present in real-world market data instead of engineered financial data. Convolution Neural Network (CNN), the best-known tool so far for image classification, is used on the multi- dimensional stock numbers taken from the market mimicking them as a vector of historical data matrices (read images) and the model achieves promising results. The predictions can be made stock by stock, i.e., a single stock, sector-wise or for the portfolio of stocks.",
    "keywords": []
  },
  {
    "article_id": "2512.21849v1_HeartBench_Probing_Core_Dimensions_of_Anthropomorphic_Intelligence_in_LLMs",
    "title": "2512.21849v1 HeartBench Probing Core Dimensions of Anthropomorphic Intelligence in LLMs",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.21849v1_HeartBench_Probing_Core_Dimensions_of_Anthropomorphic_Intelligence_in_LLMs.pdf",
    "url": "http://arxiv.org/abs/2512.21849v1_HeartBench_Probing_Core_Dimensions_of_Anthropomorphic_Intelligence_in_LLMs",
    "pdf_url": "https://arxiv.org/pdf/2512.21849v1_HeartBench_Probing_Core_Dimensions_of_Anthropomorphic_Intelligence_in_LLMs",
    "file_size_mb": 0.8,
    "abstract": "While Large Language Models (LLMs) have achieved remarkable success in cognitive and reasoning benchmarks, they exhibit a persistent deficit in anthropomorphic intelligence—the capacity to navigate complex social, emotional, and ethical nuances. This gap is particularly acute in the Chinese linguistic and cultural context, where a lack of specialized evaluation frameworks and high-quality socio-emotional data impedes progress. To address these limitations, we present HeartBench, a framework designed to evaluate the integrated emotional, cultural, and ethical dimensions of Chinese LLMs. Grounded in authentic psychological counseling scenarios and developed in collaboration with clinical experts, the benchmark is structured around a theory-driven taxonomy comprising five primary dimensions and 15 secondary capabilities. We implement a case-specific, rubric-based methodology that translates abstract human-like traits into granular, measurable criteria through a “reasoning-before-scoring” evaluation protocol. Our assessment of 13 state-of- the-art LLMs indicates a substantial performance ceiling: even leading models achieve only 60% of the expert-defined ideal score. Furthermore, analysis using a difficulty-stratified “Hard Set” reveals a significant performance decay in scenarios involving subtle emotional subtexts and complex ethical trade-offs. HeartBench establishes a standardized metric for anthropomorphic AI evaluation and provides a methodological blueprint for constructing high-quality, human-aligned training data. Github: https://github.com/inclusionAI/HeartBench",
    "keywords": []
  },
  {
    "article_id": "2512.21861v1_Balancing_Accuracy_and_Efficiency_CNN_Fusion_Models_for_Diabetic_Retinopathy_Screening",
    "title": "2512.21861v1 Balancing Accuracy and Efficiency CNN Fusion Models for Diabetic Retinopathy Screening",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.21861v1_Balancing_Accuracy_and_Efficiency_CNN_Fusion_Models_for_Diabetic_Retinopathy_Screening.pdf",
    "url": "http://arxiv.org/abs/2512.21861v1_Balancing_Accuracy_and_Efficiency_CNN_Fusion_Models_for_Diabetic_Retinopathy_Screening",
    "pdf_url": "https://arxiv.org/pdf/2512.21861v1_Balancing_Accuracy_and_Efficiency_CNN_Fusion_Models_for_Diabetic_Retinopathy_Screening",
    "file_size_mb": 2.43,
    "abstract": "—Diabetic retinopathy (DR) remains a leading cause of preventable blindness, yet large-scale screening is constrained by limited specialist availability and variable image quality across devices and populations. This work investigates whether feature- level fusion of complementary convolutional neural network (CNN) backbones can deliver accurate and efficient binary DR screening on globally sourced fundus images. Using 11,156 images pooled from five public datasets (APTOS, EyePACS, IDRiD, Messidor, and ODIR), we frame DR detection as a binary classification task and compare three pretrained models (ResNet50, EfficientNet-B0, and DenseNet121) against pairwise and tri-fusion variants. Across five independent runs, fusion consistently outperforms single backbones. The EfficientNet-B0 + DenseNet121 (Eff+Den) fusion model achieves the best overall mean performance (accuracy: 82.89%) with balanced class-wise F1-scores for normal (83.60%) and diabetic (82.60%) cases. While the tri-fusion is competitive, it incurs a substantially higher computational cost. Inference profiling highlights a practical trade-off: EfficientNet-B0 is the fastest (approximately 1.16 ms/image at batch size 1000), whereas the Eff+Den fusion offers a favorable accuracy–latency balance. These findings indicate that lightweight feature fusion can enhance generalization across heterogeneous datasets, supporting scalable binary DR screening workflows where both accuracy and throughput are critical.",
    "keywords": [
      "Diabetic retinopathy",
      "medical image classifica-"
    ]
  },
  {
    "article_id": "2512.21866v1_Secure_and_Explainable_Fraud_Detection_in_Finance_via_Hierarchical_Multi-source_Dataset_Distillation",
    "title": "2512.21866v1 Secure and Explainable Fraud Detection in Finance via Hierarchical Multi-source Dataset Distillation",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.21866v1_Secure_and_Explainable_Fraud_Detection_in_Finance_via_Hierarchical_Multi-source_Dataset_Distillation.pdf",
    "url": "http://arxiv.org/abs/2512.21866v1_Secure_and_Explainable_Fraud_Detection_in_Finance_via_Hierarchical_Multi-source_Dataset_Distillation",
    "pdf_url": "https://arxiv.org/pdf/2512.21866v1_Secure_and_Explainable_Fraud_Detection_in_Finance_via_Hierarchical_Multi-source_Dataset_Distillation",
    "file_size_mb": 1.8,
    "abstract": "We present an explainable, privacy-preserving dataset–distillation framework for collaborative fraud detection in finance. Our method converts a trained random forest into a set of transparent, axis- aligned rule regions (leaf hyperrectangles) and synthesizes trans- actions by uniformly sampling within each region. The resulting dataset is a compact, auditable surrogate of the original that pre- serves local feature interactions while avoiding direct exposure of sensitive records. Beyond privacy and utility, the rule regions provide explainable AI artifacts at both global and local levels: aggregated rule summaries (support, lift) reveal global structure, while per-case assignment to generating regions yields concise, human-readable rationales and calibrated uncertainty from tree- vote disagreement. Using the IEEE-CIS fraud dataset (590k transactions; three institution- style clusters), our distilled sets reduce volume by 85–93% (typically < 15% of the original size) while maintaining competitive perfor- mance: models trained on distilled data achieve comparable preci- sion and micro-F1 with only a modest AUC reduction. Importantly, augmenting models with synthesized data across institutions sub- stantially improves cross-cluster precision, recall, and AUC. Struc- tural similarity between real and synthesized data exceeds 93% via nearest-neighbor cosine analysis, while membership-inference ∗Corresponding author. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Conference’17, Washington, DC, USA © 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-x-xxxx-xxxx-x/YYYY/MM https://doi.org/10.1145/nnnnnnn.nnnnnnn attacks perform at chance when distinguishing real hold-out vs. training samples (AUC≈0.50), indicating low memorization risk. Filtering high-uncertainty synthetic points by disagreement scores further improves downstream AUC (up to 0.687) and enhances calibration. Sensitivity analysis shows weak dependence on the distillation ratio (AUC 0.641→0.645 from 6% to 60%). Overall, tree-region distillation offers a practical path to trustwor- thy fraud analytics: interpretable global rules, per-case rationales with quantified uncertainty, and strong privacy guarantees—supporting real-time deployment and regulatory audit in multi-institution fi- nancial settings. CCS Concepts • Information systems →Data exchange; • Security and pri- vacy →Privacy-preserving protocols; • Applied compu",
    "keywords": [
      "Dataset distillation",
      "fraud detection",
      "random forest classifier",
      "syn-"
    ]
  },
  {
    "article_id": "2512.22022v1_Meta-Learning-Based_Handover_Management_in_NextG_O-RAN",
    "title": "2512.22022v1 Meta-Learning-Based Handover Management in NextG O-RAN",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.22022v1_Meta-Learning-Based_Handover_Management_in_NextG_O-RAN.pdf",
    "url": "http://arxiv.org/abs/2512.22022v1_Meta-Learning-Based_Handover_Management_in_NextG_O-RAN",
    "pdf_url": "https://arxiv.org/pdf/2512.22022v1_Meta-Learning-Based_Handover_Management_in_NextG_O-RAN",
    "file_size_mb": 5.02,
    "abstract": "—While traditional handovers (THOs) have served as a backbone for mobile connectivity, they increasingly suffer from failures and delays, especially in dense deployments and high- frequency bands. To address these limitations, 3GPP introduced Conditional Handovers (CHOs) that enable proactive cell reser- vations and user-driven execution. However, both handover (HO) types present intricate trade-offs in signaling, resource usage, and reliability. This paper presents unique, countrywide mobility management datasets from a top-tier mobile network operator (MNO) that offer fresh insights into these issues and call for adaptive and robust HO control in next-generation networks. Motivated by these findings, we propose CONTRA, a framework that, for the first time, jointly optimizes THOs and CHOs within the O-RAN architecture. We study two variants of CONTRA: one where users are a priori assigned to one of the HO types, reflecting distinct service or user-specific requirements, as well as a more dynamic formulation where the controller decides on-the- fly the HO type, based on system conditions and needs. To this end, it relies on a practical meta-learning algorithm that adapts to runtime observations and guarantees performance comparable to an oracle with perfect future information (universal no-regret). CONTRA is specifically designed for near-real-time deployment as an O-RAN xApp and aligns with the 6G goals of flexible and intelligent control. Extensive evaluations leveraging crowdsourced datasets show that CONTRA improves user throughput and reduces both THO and CHO switching costs, outperforming 3GPP-compliant and Reinforcement Learning (RL) baselines in dynamic and real-world scenarios.",
    "keywords": [
      "Mobility Management",
      "O-RAN",
      "Conditional"
    ]
  },
  {
    "article_id": "2512.22106v1_Pruning_as_a_Game_Equilibrium-Driven_Sparsification_of_Neural_Networks",
    "title": "2512.22106v1 Pruning as a Game Equilibrium-Driven Sparsification of Neural Networks",
    "source": "arXiv",
    "pdf_path": "pdfs_articles\\arxiv\\2512.22106v1_Pruning_as_a_Game_Equilibrium-Driven_Sparsification_of_Neural_Networks.pdf",
    "url": "http://arxiv.org/abs/2512.22106v1_Pruning_as_a_Game_Equilibrium-Driven_Sparsification_of_Neural_Networks",
    "pdf_url": "https://arxiv.org/pdf/2512.22106v1_Pruning_as_a_Game_Equilibrium-Driven_Sparsification_of_Neural_Networks",
    "file_size_mb": 0.35,
    "abstract": "Neural network pruning is widely used to reduce model size and computational cost. Yet, most existing methods treat sparsity as an externally imposed constraint, enforced through heuristic importance scores or training-time regularization. In this work, we propose a fundamentally different perspective: pruning as an equilibrium outcome of strategic interaction among model components. We model parameter groups such as weights, neurons, or filters as players in a continuous non-cooperative game, where each player selects its level of participation in the network to balance contribution against redundancy and competition. Within this formulation, sparsity emerges naturally when continued participation becomes a dominated strategy at equilibrium. We analyze the resulting game and show that dominated players collapse to zero participation under mild conditions, providing a principled explanation for pruning behavior. Building on this insight, we derive a simple equilibrium-driven pruning algorithm that jointly updates network parameters and participation variables without relying on explicit importance scores. This work focuses on establishing a principled formulation and empirical validation of pruning as an equilibrium phenomenon, rather than exhaustive architectural or large-scale benchmarking. Experiments on standard benchmarks demonstrate that the proposed approach achieves competitive sparsity– accuracy trade-offs while offering an interpretable, theory-grounded alternative to existing pruning methods.",
    "keywords": []
  }
]